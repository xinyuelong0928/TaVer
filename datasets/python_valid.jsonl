{"idx": 862, "func": "# -*- coding: utf-8 -*-\n#\n# fastecdsa documentation build configuration file, created by\n# sphinx-quickstart on Thu Dec 15 20:02:52 2016.\n#\n# This file is execfile()d with the current directory set to its\n# containing dir.\n#\n# Note that not all possible configuration values are present in this\n# autogenerated file.\n#\n# All configuration values have a default; values that are commented out\n# serve to show the default.\n\n# If extensions (or modules to document with autodoc) are in another directory,\n# add these directories to sys.path here. If the directory is relative to the\n# documentation root, use os.path.abspath to make it absolute, like shown here.\n#\nfrom datetime import datetime\nimport os\nimport sys\nfrom unittest import mock\n\nsys.path.insert(0, os.path.abspath('.'))\nsys.path.insert(0, os.path.abspath('../'))\n\nMOCK_MODULES = ['fastecdsa._ecdsa', 'fastecdsa.curvemath']\nfor mod_name in MOCK_MODULES:\n    sys.modules[mod_name] = mock.Mock()\n\n\n# -- General configuration ------------------------------------------------\n\n# If your documentation needs a minimal Sphinx version, state it here.\n#\n# needs_sphinx = '1.0'\n\n# Add any Sphinx extension module names here, as strings. They can be\n# extensions coming with Sphinx (named 'sphinx.ext.*') or your custom\n# ones.\nextensions = ['sphinx.ext.mathjax', 'sphinx.ext.autodoc']\n\n# Add any paths that contain templates here, relative to this directory.\ntemplates_path = ['_templates']\n\n# The suffix(es) of source filenames.\n# You can specify multiple suffix as a list of string:\n#\n# source_suffix = ['.rst', '.md']\nsource_suffix = ['.rst', '.md']\n\n# The master toctree document.\nmaster_doc = 'index'\n\n# General information about the project.\nproject = 'fastecdsa'\ncopyright = '{}, Anton Kueltz'.format(datetime.now().year)\nauthor = 'Anton Kueltz'\n\n# The version info for the project you're documenting, acts as replacement for\n# |version| and |release|, also used in various other places throughout the\n# built documents.\n#\n# The short X.Y version.\nversion = '2.1'\n# The full version, including alpha/beta/rc tags.\nrelease = '2.1.2'\n\n# The language for content autogenerated by Sphinx. Refer to documentation\n# for a list of supported languages.\n#\n# This is also used if you do content translation via gettext catalogs.\n# Usually you set \"language\" from the command line for these cases.\nlanguage = None\n\n# List of patterns, relative to source directory, that match files and\n# directories to ignore when looking for source files.\n# This patterns also effect to html_static_path and html_extra_path\nexclude_patterns = ['_build', 'Thumbs.db', '.DS_Store']\n\n# The name of the Pygments (syntax highlighting) style to use.\npygments_style = 'sphinx'\n\n# If true, `todo` and `todoList` produce output, else they produce nothing.\ntodo_include_todos = False\n\n\n# -- Options for HTML output ----------------------------------------------\n\n# The theme to use for HTML and HTML Help pages.  See the documentation for\n# a list of builtin themes.\n#\n# html_theme = 'alabaster'\nhtml_theme = 'default'\n\n# Theme options are theme-specific and customize the look and feel of a theme\n# further.  For a list of options available for each theme, see the\n# documentation.\n#\n# html_theme_options = {}\n\n# Add any paths that contain custom static files (such as style sheets) here,\n# relative to this directory. They are copied after the builtin static files,\n# so a file named \"default.css\" will overwrite the builtin \"default.css\".\nhtml_static_path = ['_static']\n\n\n# -- Options for HTMLHelp output ------------------------------------------\n\n# Output file base name for HTML help builder.\nhtmlhelp_basename = 'fastecdsadoc'\n\n\n# -- Options for LaTeX output ---------------------------------------------\n\nlatex_elements = {\n    # The paper size ('letterpaper' or 'a4paper').\n    #\n    # 'papersize': 'letterpaper',\n\n    # The font size ('10pt', '11pt' or '12pt').\n    #\n    # 'pointsize': '10pt',\n\n    # Additional stuff for the LaTeX preamble.\n    #\n    # 'preamble': '',\n\n    # Latex figure (float) alignment\n    #\n    # 'figure_align': 'htbp',\n}\n\n# Grouping the document tree into LaTeX files. List of tuples\n# (source start file, target name, title,\n#  author, documentclass [howto, manual, or own class]).\nlatex_documents = [\n    (master_doc, 'fastecdsa.tex', 'fastecdsa Documentation',\n     'Anton Kueltz', 'manual'),\n]\n\n\n# -- Options for manual page output ---------------------------------------\n\n# One entry per manual page. List of tuples\n# (source start file, name, description, authors, manual section).\nman_pages = [\n    (master_doc, 'fastecdsa', 'fastecdsa Documentation',\n     [author], 1)\n]\n\n\n# -- Options for Texinfo output -------------------------------------------\n\n# Grouping the document tree into Texinfo files. List of tuples\n# (source start file, target name, title, author,\n#  dir menu entry, description, category)\ntexinfo_documents = [\n    (master_doc, 'fastecdsa', 'fastecdsa Documentation',\n     author, 'fastecdsa', 'One line description of project.',\n     'Miscellaneous'),\n]\n", "target": 0}
{"idx": 863, "func": "# vim: ft=python fileencoding=utf-8 sts=4 sw=4 et:\n\n# Copyright 2016-2018 Florian Bruhin (The Compiler) <mail@qutebrowser.org>\n#\n# This file is part of qutebrowser.\n#\n# qutebrowser is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# qutebrowser is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with qutebrowser.  If not, see <http://www.gnu.org/licenses/>.\n\n\"\"\"Backend-independent qute://* code.\n\nModule attributes:\n    pyeval_output: The output of the last :pyeval command.\n    _HANDLERS: The handlers registered via decorators.\n\"\"\"\n\nimport json\nimport os\nimport time\nimport textwrap\nimport mimetypes\nimport urllib\nimport collections\n\nimport pkg_resources\nimport sip\nfrom PyQt5.QtCore import QUrlQuery, QUrl\n\nimport qutebrowser\nfrom qutebrowser.config import config, configdata, configexc, configdiff\nfrom qutebrowser.utils import (version, utils, jinja, log, message, docutils,\n                               objreg, urlutils)\nfrom qutebrowser.misc import objects\n\n\npyeval_output = \":pyeval was never called\"\nspawn_output = \":spawn was never called\"\n\n\n_HANDLERS = {}\n\n\nclass NoHandlerFound(Exception):\n\n    \"\"\"Raised when no handler was found for the given URL.\"\"\"\n\n    pass\n\n\nclass QuteSchemeOSError(Exception):\n\n    \"\"\"Called when there was an OSError inside a handler.\"\"\"\n\n    pass\n\n\nclass QuteSchemeError(Exception):\n\n    \"\"\"Exception to signal that a handler should return an ErrorReply.\n\n    Attributes correspond to the arguments in\n    networkreply.ErrorNetworkReply.\n\n    Attributes:\n        errorstring: Error string to print.\n        error: Numerical error value.\n    \"\"\"\n\n    def __init__(self, errorstring, error):\n        self.errorstring = errorstring\n        self.error = error\n        super().__init__(errorstring)\n\n\nclass Redirect(Exception):\n\n    \"\"\"Exception to signal a redirect should happen.\n\n    Attributes:\n        url: The URL to redirect to, as a QUrl.\n    \"\"\"\n\n    def __init__(self, url):\n        super().__init__(url.toDisplayString())\n        self.url = url\n\n\nclass add_handler:  # noqa: N801,N806 pylint: disable=invalid-name\n\n    \"\"\"Decorator to register a qute://* URL handler.\n\n    Attributes:\n        _name: The 'foo' part of qute://foo\n        backend: Limit which backends the handler can run with.\n    \"\"\"\n\n    def __init__(self, name, backend=None):\n        self._name = name\n        self._backend = backend\n        self._function = None\n\n    def __call__(self, function):\n        self._function = function\n        _HANDLERS[self._name] = self.wrapper\n        return function\n\n    def wrapper(self, *args, **kwargs):\n        \"\"\"Call the underlying function.\"\"\"\n        if self._backend is not None and objects.backend != self._backend:\n            return self.wrong_backend_handler(*args, **kwargs)\n        else:\n            return self._function(*args, **kwargs)\n\n    def wrong_backend_handler(self, url):\n        \"\"\"Show an error page about using the invalid backend.\"\"\"\n        html = jinja.render('error.html',\n                            title=\"Error while opening qute://url\",\n                            url=url.toDisplayString(),\n                            error='{} is not available with this '\n                                  'backend'.format(url.toDisplayString()))\n        return 'text/html', html\n\n\ndef data_for_url(url):\n    \"\"\"Get the data to show for the given URL.\n\n    Args:\n        url: The QUrl to show.\n\n    Return:\n        A (mimetype, data) tuple.\n    \"\"\"\n    norm_url = url.adjusted(QUrl.NormalizePathSegments |\n                            QUrl.StripTrailingSlash)\n    if norm_url != url:\n        raise Redirect(norm_url)\n\n    path = url.path()\n    host = url.host()\n    query = urlutils.query_string(url)\n    # A url like \"qute:foo\" is split as \"scheme:path\", not \"scheme:host\".\n    log.misc.debug(\"url: {}, path: {}, host {}\".format(\n        url.toDisplayString(), path, host))\n    if not path or not host:\n        new_url = QUrl()\n        new_url.setScheme('qute')\n        # When path is absent, e.g. qute://help (with no trailing slash)\n        if host:\n            new_url.setHost(host)\n        # When host is absent, e.g. qute:help\n        else:\n            new_url.setHost(path)\n\n        new_url.setPath('/')\n        if query:\n            new_url.setQuery(query)\n        if new_url.host():  # path was a valid host\n            raise Redirect(new_url)\n\n    try:\n        handler = _HANDLERS[host]\n    except KeyError:\n        raise NoHandlerFound(url)\n\n    try:\n        mimetype, data = handler(url)\n    except OSError as e:\n        # FIXME:qtwebengine how to handle this?\n        raise QuteSchemeOSError(e)\n    except QuteSchemeError:\n        raise\n\n    assert mimetype is not None, url\n    if mimetype == 'text/html' and isinstance(data, str):\n        # We let handlers return HTML as text\n        data = data.encode('utf-8', errors='xmlcharrefreplace')\n\n    return mimetype, data\n\n\n@add_handler('bookmarks')\ndef qute_bookmarks(_url):\n    \"\"\"Handler for qute://bookmarks. Display all quickmarks / bookmarks.\"\"\"\n    bookmarks = sorted(objreg.get('bookmark-manager').marks.items(),\n                       key=lambda x: x[1])  # Sort by title\n    quickmarks = sorted(objreg.get('quickmark-manager').marks.items(),\n                        key=lambda x: x[0])  # Sort by name\n\n    html = jinja.render('bookmarks.html',\n                        title='Bookmarks',\n                        bookmarks=bookmarks,\n                        quickmarks=quickmarks)\n    return 'text/html', html\n\n\n@add_handler('tabs')\ndef qute_tabs(_url):\n    \"\"\"Handler for qute://tabs. Display information about all open tabs.\"\"\"\n    tabs = collections.defaultdict(list)\n    for win_id, window in objreg.window_registry.items():\n        if sip.isdeleted(window):\n            continue\n        tabbed_browser = objreg.get('tabbed-browser',\n                                    scope='window',\n                                    window=win_id)\n        for tab in tabbed_browser.widgets():\n            if tab.url() not in [QUrl(\"qute://tabs/\"), QUrl(\"qute://tabs\")]:\n                urlstr = tab.url().toDisplayString()\n                tabs[str(win_id)].append((tab.title(), urlstr))\n\n    html = jinja.render('tabs.html',\n                        title='Tabs',\n                        tab_list_by_window=tabs)\n    return 'text/html', html\n\n\ndef history_data(start_time, offset=None):\n    \"\"\"Return history data.\n\n    Arguments:\n        start_time: select history starting from this timestamp.\n        offset: number of items to skip\n    \"\"\"\n    # history atimes are stored as ints, ensure start_time is not a float\n    start_time = int(start_time)\n    hist = objreg.get('web-history')\n    if offset is not None:\n        entries = hist.entries_before(start_time, limit=1000, offset=offset)\n    else:\n        # end is 24hrs earlier than start\n        end_time = start_time - 24*60*60\n        entries = hist.entries_between(end_time, start_time)\n\n    return [{\"url\": e.url, \"title\": e.title or e.url, \"time\": e.atime}\n            for e in entries]\n\n\n@add_handler('history')\ndef qute_history(url):\n    \"\"\"Handler for qute://history. Display and serve history.\"\"\"\n    if url.path() == '/data':\n        try:\n            offset = QUrlQuery(url).queryItemValue(\"offset\")\n            offset = int(offset) if offset else None\n        except ValueError as e:\n            raise QuteSchemeError(\"Query parameter offset is invalid\", e)\n        # Use start_time in query or current time.\n        try:\n            start_time = QUrlQuery(url).queryItemValue(\"start_time\")\n            start_time = float(start_time) if start_time else time.time()\n        except ValueError as e:\n            raise QuteSchemeError(\"Query parameter start_time is invalid\", e)\n\n        return 'text/html', json.dumps(history_data(start_time, offset))\n    else:\n        return 'text/html', jinja.render(\n            'history.html',\n            title='History',\n            gap_interval=config.val.history_gap_interval\n        )\n\n\n@add_handler('javascript')\ndef qute_javascript(url):\n    \"\"\"Handler for qute://javascript.\n\n    Return content of file given as query parameter.\n    \"\"\"\n    path = url.path()\n    if path:\n        path = \"javascript\" + os.sep.join(path.split('/'))\n        return 'text/html', utils.read_file(path, binary=False)\n    else:\n        raise QuteSchemeError(\"No file specified\", ValueError())\n\n\n@add_handler('pyeval')\ndef qute_pyeval(_url):\n    \"\"\"Handler for qute://pyeval.\"\"\"\n    html = jinja.render('pre.html', title='pyeval', content=pyeval_output)\n    return 'text/html', html\n\n\n@add_handler('spawn-output')\ndef qute_spawn_output(_url):\n    \"\"\"Handler for qute://spawn-output.\"\"\"\n    html = jinja.render('pre.html', title='spawn output', content=spawn_output)\n    return 'text/html', html\n\n\n@add_handler('version')\n@add_handler('verizon')\ndef qute_version(_url):\n    \"\"\"Handler for qute://version.\"\"\"\n    html = jinja.render('version.html', title='Version info',\n                        version=version.version(),\n                        copyright=qutebrowser.__copyright__)\n    return 'text/html', html\n\n\n@add_handler('plainlog')\ndef qute_plainlog(url):\n    \"\"\"Handler for qute://plainlog.\n\n    An optional query parameter specifies the minimum log level to print.\n    For example, qute://log?level=warning prints warnings and errors.\n    Level can be one of: vdebug, debug, info, warning, error, critical.\n    \"\"\"\n    if log.ram_handler is None:\n        text = \"Log output was disabled.\"\n    else:\n        level = QUrlQuery(url).queryItemValue('level')\n        if not level:\n            level = 'vdebug'\n        text = log.ram_handler.dump_log(html=False, level=level)\n    html = jinja.render('pre.html', title='log', content=text)\n    return 'text/html', html\n\n\n@add_handler('log')\ndef qute_log(url):\n    \"\"\"Handler for qute://log.\n\n    An optional query parameter specifies the minimum log level to print.\n    For example, qute://log?level=warning prints warnings and errors.\n    Level can be one of: vdebug, debug, info, warning, error, critical.\n    \"\"\"\n    if log.ram_handler is None:\n        html_log = None\n    else:\n        level = QUrlQuery(url).queryItemValue('level')\n        if not level:\n            level = 'vdebug'\n        html_log = log.ram_handler.dump_log(html=True, level=level)\n\n    html = jinja.render('log.html', title='log', content=html_log)\n    return 'text/html', html\n\n\n@add_handler('gpl')\ndef qute_gpl(_url):\n    \"\"\"Handler for qute://gpl. Return HTML content as string.\"\"\"\n    return 'text/html', utils.read_file('html/license.html')\n\n\n@add_handler('help')\ndef qute_help(url):\n    \"\"\"Handler for qute://help.\"\"\"\n    urlpath = url.path()\n    if not urlpath or urlpath == '/':\n        urlpath = 'index.html'\n    else:\n        urlpath = urlpath.lstrip('/')\n    if not docutils.docs_up_to_date(urlpath):\n        message.error(\"Your documentation is outdated! Please re-run \"\n                      \"scripts/asciidoc2html.py.\")\n\n    path = 'html/doc/{}'.format(urlpath)\n    if not urlpath.endswith('.html'):\n        try:\n            bdata = utils.read_file(path, binary=True)\n        except OSError as e:\n            raise QuteSchemeOSError(e)\n        mimetype, _encoding = mimetypes.guess_type(urlpath)\n        assert mimetype is not None, url\n        return mimetype, bdata\n\n    try:\n        data = utils.read_file(path)\n    except OSError:\n        # No .html around, let's see if we find the asciidoc\n        asciidoc_path = path.replace('.html', '.asciidoc')\n        if asciidoc_path.startswith('html/doc/'):\n            asciidoc_path = asciidoc_path.replace('html/doc/', '../doc/help/')\n\n        try:\n            asciidoc = utils.read_file(asciidoc_path)\n        except OSError:\n            asciidoc = None\n\n        if asciidoc is None:\n            raise\n\n        preamble = textwrap.dedent(\"\"\"\n            There was an error loading the documentation!\n\n            This most likely means the documentation was not generated\n            properly. If you are running qutebrowser from the git repository,\n            please (re)run scripts/asciidoc2html.py and reload this page.\n\n            If you're running a released version this is a bug, please use\n            :report to report it.\n\n            Falling back to the plaintext version.\n\n            ---------------------------------------------------------------\n\n\n        \"\"\")\n        return 'text/plain', (preamble + asciidoc).encode('utf-8')\n    else:\n        return 'text/html', data\n\n\n@add_handler('backend-warning')\ndef qute_backend_warning(_url):\n    \"\"\"Handler for qute://backend-warning.\"\"\"\n    html = jinja.render('backend-warning.html',\n                        distribution=version.distribution(),\n                        Distribution=version.Distribution,\n                        version=pkg_resources.parse_version,\n                        title=\"Legacy backend warning\")\n    return 'text/html', html\n\n\ndef _qute_settings_set(url):\n    \"\"\"Handler for qute://settings/set.\"\"\"\n    query = QUrlQuery(url)\n    option = query.queryItemValue('option', QUrl.FullyDecoded)\n    value = query.queryItemValue('value', QUrl.FullyDecoded)\n\n    # https://github.com/qutebrowser/qutebrowser/issues/727\n    if option == 'content.javascript.enabled' and value == 'false':\n        msg = (\"Refusing to disable javascript via qute://settings \"\n               \"as it needs javascript support.\")\n        message.error(msg)\n        return 'text/html', b'error: ' + msg.encode('utf-8')\n\n    try:\n        config.instance.set_str(option, value, save_yaml=True)\n        return 'text/html', b'ok'\n    except configexc.Error as e:\n        message.error(str(e))\n        return 'text/html', b'error: ' + str(e).encode('utf-8')\n\n\n@add_handler('settings')\ndef qute_settings(url):\n    \"\"\"Handler for qute://settings. View/change qute configuration.\"\"\"\n    if url.path() == '/set':\n        return _qute_settings_set(url)\n\n    html = jinja.render('settings.html', title='settings',\n                        configdata=configdata,\n                        confget=config.instance.get_str)\n    return 'text/html', html\n\n\n@add_handler('bindings')\ndef qute_bindings(_url):\n    \"\"\"Handler for qute://bindings. View keybindings.\"\"\"\n    bindings = {}\n    defaults = config.val.bindings.default\n    modes = set(defaults.keys()).union(config.val.bindings.commands)\n    modes.remove('normal')\n    modes = ['normal'] + sorted(list(modes))\n    for mode in modes:\n        bindings[mode] = config.key_instance.get_bindings_for(mode)\n\n    html = jinja.render('bindings.html', title='Bindings',\n                        bindings=bindings)\n    return 'text/html', html\n\n\n@add_handler('back')\ndef qute_back(url):\n    \"\"\"Handler for qute://back.\n\n    Simple page to free ram / lazy load a site, goes back on focusing the tab.\n    \"\"\"\n    html = jinja.render(\n        'back.html',\n        title='Suspended: ' + urllib.parse.unquote(url.fragment()))\n    return 'text/html', html\n\n\n@add_handler('configdiff')\ndef qute_configdiff(url):\n    \"\"\"Handler for qute://configdiff.\"\"\"\n    if url.path() == '/old':\n        try:\n            return 'text/html', configdiff.get_diff()\n        except OSError as e:\n            error = (b'Failed to read old config: ' +\n                     str(e.strerror).encode('utf-8'))\n            return 'text/plain', error\n    else:\n        data = config.instance.dump_userconfig().encode('utf-8')\n        return 'text/plain', data\n\n\n@add_handler('pastebin-version')\ndef qute_pastebin_version(_url):\n    \"\"\"Handler that pastebins the version string.\"\"\"\n    version.pastebin_version()\n    return 'text/plain', b'Paste called.'\n", "target": 1}
{"idx": 864, "func": "# coding: utf-8\n\"\"\"A tornado based Jupyter notebook server.\"\"\"\n\n# Copyright (c) Jupyter Development Team.\n# Distributed under the terms of the Modified BSD License.\n\nfrom __future__ import absolute_import, print_function\n\nimport base64\nimport datetime\nimport errno\nimport importlib\nimport io\nimport json\nimport logging\nimport os\nimport random\nimport re\nimport select\nimport signal\nimport socket\nimport ssl\nimport sys\nimport threading\nimport webbrowser\n\n\nfrom jinja2 import Environment, FileSystemLoader\n\n# Install the pyzmq ioloop. This has to be done before anything else from\n# tornado is imported.\nfrom zmq.eventloop import ioloop\nioloop.install()\n\n# check for tornado 3.1.0\nmsg = \"The Jupyter Notebook requires tornado >= 4.0\"\ntry:\n    import tornado\nexcept ImportError:\n    raise ImportError(msg)\ntry:\n    version_info = tornado.version_info\nexcept AttributeError:\n    raise ImportError(msg + \", but you have < 1.1.0\")\nif version_info < (4,0):\n    raise ImportError(msg + \", but you have %s\" % tornado.version)\n\nfrom tornado import httpserver\nfrom tornado import web\nfrom tornado.log import LogFormatter, app_log, access_log, gen_log\n\nfrom notebook import (\n    DEFAULT_STATIC_FILES_PATH,\n    DEFAULT_TEMPLATE_PATH_LIST,\n    __version__,\n)\nfrom .base.handlers import Template404\nfrom .log import log_request\nfrom .services.kernels.kernelmanager import MappingKernelManager\nfrom .services.config import ConfigManager\nfrom .services.contents.manager import ContentsManager\nfrom .services.contents.filemanager import FileContentsManager\nfrom .services.sessions.sessionmanager import SessionManager\n\nfrom .auth.login import LoginHandler\nfrom .auth.logout import LogoutHandler\nfrom .base.handlers import FileFindHandler, IPythonHandler\n\nfrom traitlets.config import Config\nfrom traitlets.config.application import catch_config_error, boolean_flag\nfrom jupyter_core.application import (\n    JupyterApp, base_flags, base_aliases,\n)\nfrom jupyter_client import KernelManager\nfrom jupyter_client.kernelspec import KernelSpecManager, NoSuchKernel, NATIVE_KERNEL_NAME\nfrom jupyter_client.session import Session\nfrom nbformat.sign import NotebookNotary\nfrom traitlets import (\n    Dict, Unicode, Integer, List, Bool, Bytes, Instance,\n    TraitError, Type,\n)\nfrom ipython_genutils import py3compat\nfrom IPython.paths import get_ipython_dir\nfrom jupyter_core.paths import jupyter_runtime_dir, jupyter_path\nfrom notebook._sysinfo import get_sys_info\n\nfrom .utils import url_path_join, check_pid\n\n#-----------------------------------------------------------------------------\n# Module globals\n#-----------------------------------------------------------------------------\n\n_examples = \"\"\"\njupyter notebook                       # start the notebook\njupyter notebook --certfile=mycert.pem # use SSL/TLS certificate\n\"\"\"\n\n#-----------------------------------------------------------------------------\n# Helper functions\n#-----------------------------------------------------------------------------\n\ndef random_ports(port, n):\n    \"\"\"Generate a list of n random ports near the given port.\n\n    The first 5 ports will be sequential, and the remaining n-5 will be\n    randomly selected in the range [port-2*n, port+2*n].\n    \"\"\"\n    for i in range(min(5, n)):\n        yield port + i\n    for i in range(n-5):\n        yield max(1, port + random.randint(-2*n, 2*n))\n\ndef load_handlers(name):\n    \"\"\"Load the (URL pattern, handler) tuples for each component.\"\"\"\n    name = 'notebook.' + name\n    mod = __import__(name, fromlist=['default_handlers'])\n    return mod.default_handlers\n\n\nclass DeprecationHandler(IPythonHandler):\n    def get(self, url_path):\n        self.set_header(\"Content-Type\", 'text/javascript')\n        self.finish(\"\"\"\n            console.warn('`/static/widgets/js` is deprecated.  Use `/nbextensions/widgets/widgets/js` instead.');\n            define(['%s'], function(x) { return x; });\n        \"\"\" % url_path_join('nbextensions', 'widgets', 'widgets', url_path.rstrip('.js')))\n        self.log.warn('Deprecated widget Javascript path /static/widgets/js/*.js was used')\n\n#-----------------------------------------------------------------------------\n# The Tornado web application\n#-----------------------------------------------------------------------------\n\nclass NotebookWebApplication(web.Application):\n\n    def __init__(self, ipython_app, kernel_manager, contents_manager,\n                 session_manager, kernel_spec_manager,\n                 config_manager, log,\n                 base_url, default_url, settings_overrides, jinja_env_options):\n\n        settings = self.init_settings(\n            ipython_app, kernel_manager, contents_manager,\n            session_manager, kernel_spec_manager, config_manager, log, base_url,\n            default_url, settings_overrides, jinja_env_options)\n        handlers = self.init_handlers(settings)\n\n        super(NotebookWebApplication, self).__init__(handlers, **settings)\n\n    def init_settings(self, ipython_app, kernel_manager, contents_manager,\n                      session_manager, kernel_spec_manager,\n                      config_manager,\n                      log, base_url, default_url, settings_overrides,\n                      jinja_env_options=None):\n\n        _template_path = settings_overrides.get(\n            \"template_path\",\n            ipython_app.template_file_path,\n        )\n        if isinstance(_template_path, py3compat.string_types):\n            _template_path = (_template_path,)\n        template_path = [os.path.expanduser(path) for path in _template_path]\n\n        jenv_opt = jinja_env_options if jinja_env_options else {}\n        env = Environment(loader=FileSystemLoader(template_path), **jenv_opt)\n        \n        sys_info = get_sys_info()\n        if sys_info['commit_source'] == 'repository':\n            # don't cache (rely on 304) when working from master\n            version_hash = ''\n        else:\n            # reset the cache on server restart\n            version_hash = datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")\n\n        settings = dict(\n            # basics\n            log_function=log_request,\n            base_url=base_url,\n            default_url=default_url,\n            template_path=template_path,\n            static_path=ipython_app.static_file_path,\n            static_custom_path=ipython_app.static_custom_path,\n            static_handler_class = FileFindHandler,\n            static_url_prefix = url_path_join(base_url,'/static/'),\n            static_handler_args = {\n                # don't cache custom.js\n                'no_cache_paths': [url_path_join(base_url, 'static', 'custom')],\n            },\n            version_hash=version_hash,\n            ignore_minified_js=ipython_app.ignore_minified_js,\n            \n            # authentication\n            cookie_secret=ipython_app.cookie_secret,\n            login_url=url_path_join(base_url,'/login'),\n            login_handler_class=ipython_app.login_handler_class,\n            logout_handler_class=ipython_app.logout_handler_class,\n            password=ipython_app.password,\n\n            # managers\n            kernel_manager=kernel_manager,\n            contents_manager=contents_manager,\n            session_manager=session_manager,\n            kernel_spec_manager=kernel_spec_manager,\n            config_manager=config_manager,\n\n            # IPython stuff\n            jinja_template_vars=ipython_app.jinja_template_vars,\n            nbextensions_path=ipython_app.nbextensions_path,\n            websocket_url=ipython_app.websocket_url,\n            mathjax_url=ipython_app.mathjax_url,\n            config=ipython_app.config,\n            config_dir=ipython_app.config_dir,\n            jinja2_env=env,\n            terminals_available=False,  # Set later if terminals are available\n        )\n\n        # allow custom overrides for the tornado web app.\n        settings.update(settings_overrides)\n        return settings\n\n    def init_handlers(self, settings):\n        \"\"\"Load the (URL pattern, handler) tuples for each component.\"\"\"\n        \n        # Order matters. The first handler to match the URL will handle the request.\n        handlers = []\n        handlers.append((r'/deprecatedwidgets/(.*)', DeprecationHandler))\n        handlers.extend(load_handlers('tree.handlers'))\n        handlers.extend([(r\"/login\", settings['login_handler_class'])])\n        handlers.extend([(r\"/logout\", settings['logout_handler_class'])])\n        handlers.extend(load_handlers('files.handlers'))\n        handlers.extend(load_handlers('notebook.handlers'))\n        handlers.extend(load_handlers('nbconvert.handlers'))\n        handlers.extend(load_handlers('kernelspecs.handlers'))\n        handlers.extend(load_handlers('edit.handlers'))\n        handlers.extend(load_handlers('services.api.handlers'))\n        handlers.extend(load_handlers('services.config.handlers'))\n        handlers.extend(load_handlers('services.kernels.handlers'))\n        handlers.extend(load_handlers('services.contents.handlers'))\n        handlers.extend(load_handlers('services.sessions.handlers'))\n        handlers.extend(load_handlers('services.nbconvert.handlers'))\n        handlers.extend(load_handlers('services.kernelspecs.handlers'))\n        handlers.extend(load_handlers('services.security.handlers'))\n        \n        # BEGIN HARDCODED WIDGETS HACK\n        try:\n            import ipywidgets\n            handlers.append(\n                (r\"/nbextensions/widgets/(.*)\", FileFindHandler, {\n                    'path': ipywidgets.find_static_assets(),\n                    'no_cache_paths': ['/'], # don't cache anything in nbextensions\n                }),\n            )\n        except:\n            app_log.warn('ipywidgets package not installed.  Widgets are unavailable.')\n        # END HARDCODED WIDGETS HACK\n        \n        handlers.append(\n            (r\"/nbextensions/(.*)\", FileFindHandler, {\n                'path': settings['nbextensions_path'],\n                'no_cache_paths': ['/'], # don't cache anything in nbextensions\n            }),\n        )\n        handlers.append(\n            (r\"/custom/(.*)\", FileFindHandler, {\n                'path': settings['static_custom_path'],\n                'no_cache_paths': ['/'], # don't cache anything in custom\n            })\n        )\n        # register base handlers last\n        handlers.extend(load_handlers('base.handlers'))\n        # set the URL that will be redirected from `/`\n        handlers.append(\n            (r'/?', web.RedirectHandler, {\n                'url' : settings['default_url'],\n                'permanent': False, # want 302, not 301\n            })\n        )\n\n        # prepend base_url onto the patterns that we match\n        new_handlers = []\n        for handler in handlers:\n            pattern = url_path_join(settings['base_url'], handler[0])\n            new_handler = tuple([pattern] + list(handler[1:]))\n            new_handlers.append(new_handler)\n        # add 404 on the end, which will catch everything that falls through\n        new_handlers.append((r'(.*)', Template404))\n        return new_handlers\n\n\nclass NbserverListApp(JupyterApp):\n    version = __version__\n    description=\"List currently running notebook servers in this profile.\"\n    \n    flags = dict(\n        json=({'NbserverListApp': {'json': True}},\n              \"Produce machine-readable JSON output.\"),\n    )\n    \n    json = Bool(False, config=True,\n          help=\"If True, each line of output will be a JSON object with the \"\n                  \"details from the server info file.\")\n\n    def start(self):\n        if not self.json:\n            print(\"Currently running servers:\")\n        for serverinfo in list_running_servers(self.runtime_dir):\n            if self.json:\n                print(json.dumps(serverinfo))\n            else:\n                print(serverinfo['url'], \"::\", serverinfo['notebook_dir'])\n\n#-----------------------------------------------------------------------------\n# Aliases and Flags\n#-----------------------------------------------------------------------------\n\nflags = dict(base_flags)\nflags['no-browser']=(\n    {'NotebookApp' : {'open_browser' : False}},\n    \"Don't open the notebook in a browser after startup.\"\n)\nflags['pylab']=(\n    {'NotebookApp' : {'pylab' : 'warn'}},\n    \"DISABLED: use %pylab or %matplotlib in the notebook to enable matplotlib.\"\n)\nflags['no-mathjax']=(\n    {'NotebookApp' : {'enable_mathjax' : False}},\n    \"\"\"Disable MathJax\n    \n    MathJax is the javascript library Jupyter uses to render math/LaTeX. It is\n    very large, so you may want to disable it if you have a slow internet\n    connection, or for offline use of the notebook.\n    \n    When disabled, equations etc. will appear as their untransformed TeX source.\n    \"\"\"\n)\n\n# Add notebook manager flags\nflags.update(boolean_flag('script', 'FileContentsManager.save_script',\n               'DEPRECATED, IGNORED',\n               'DEPRECATED, IGNORED'))\n\naliases = dict(base_aliases)\n\naliases.update({\n    'ip': 'NotebookApp.ip',\n    'port': 'NotebookApp.port',\n    'port-retries': 'NotebookApp.port_retries',\n    'transport': 'KernelManager.transport',\n    'keyfile': 'NotebookApp.keyfile',\n    'certfile': 'NotebookApp.certfile',\n    'notebook-dir': 'NotebookApp.notebook_dir',\n    'browser': 'NotebookApp.browser',\n    'pylab': 'NotebookApp.pylab',\n})\n\n#-----------------------------------------------------------------------------\n# NotebookApp\n#-----------------------------------------------------------------------------\n\nclass NotebookApp(JupyterApp):\n\n    name = 'jupyter-notebook'\n    version = __version__\n    description = \"\"\"\n        The Jupyter HTML Notebook.\n        \n        This launches a Tornado based HTML Notebook Server that serves up an\n        HTML5/Javascript Notebook client.\n    \"\"\"\n    examples = _examples\n    aliases = aliases\n    flags = flags\n    \n    classes = [\n        KernelManager, Session, MappingKernelManager,\n        ContentsManager, FileContentsManager, NotebookNotary,\n        KernelSpecManager,\n    ]\n    flags = Dict(flags)\n    aliases = Dict(aliases)\n    \n    subcommands = dict(\n        list=(NbserverListApp, NbserverListApp.description.splitlines()[0]),\n    )\n\n    _log_formatter_cls = LogFormatter\n\n    def _log_level_default(self):\n        return logging.INFO\n\n    def _log_datefmt_default(self):\n        \"\"\"Exclude date from default date format\"\"\"\n        return \"%H:%M:%S\"\n    \n    def _log_format_default(self):\n        \"\"\"override default log format to include time\"\"\"\n        return u\"%(color)s[%(levelname)1.1s %(asctime)s.%(msecs).03d %(name)s]%(end_color)s %(message)s\"\n\n    # create requested profiles by default, if they don't exist:\n    auto_create = Bool(True)\n\n    ignore_minified_js = Bool(False,\n            config=True,\n            help='Use minified JS file or not, mainly use during dev to avoid JS recompilation', \n            )\n\n    # file to be opened in the notebook server\n    file_to_run = Unicode('', config=True)\n\n    # Network related information\n    \n    allow_origin = Unicode('', config=True,\n        help=\"\"\"Set the Access-Control-Allow-Origin header\n        \n        Use '*' to allow any origin to access your server.\n        \n        Takes precedence over allow_origin_pat.\n        \"\"\"\n    )\n    \n    allow_origin_pat = Unicode('', config=True,\n        help=\"\"\"Use a regular expression for the Access-Control-Allow-Origin header\n        \n        Requests from an origin matching the expression will get replies with:\n        \n            Access-Control-Allow-Origin: origin\n        \n        where `origin` is the origin of the request.\n        \n        Ignored if allow_origin is set.\n        \"\"\"\n    )\n    \n    allow_credentials = Bool(False, config=True,\n        help=\"Set the Access-Control-Allow-Credentials: true header\"\n    )\n    \n    default_url = Unicode('/tree', config=True,\n        help=\"The default URL to redirect to from `/`\"\n    )\n    \n    ip = Unicode('localhost', config=True,\n        help=\"The IP address the notebook server will listen on.\"\n    )\n    def _ip_default(self):\n        \"\"\"Return localhost if available, 127.0.0.1 otherwise.\n        \n        On some (horribly broken) systems, localhost cannot be bound.\n        \"\"\"\n        s = socket.socket()\n        try:\n            s.bind(('localhost', 0))\n        except socket.error as e:\n            self.log.warn(\"Cannot bind to localhost, using 127.0.0.1 as default ip\\n%s\", e)\n            return '127.0.0.1'\n        else:\n            s.close()\n            return 'localhost'\n\n    def _ip_changed(self, name, old, new):\n        if new == u'*': self.ip = u''\n\n    port = Integer(8888, config=True,\n        help=\"The port the notebook server will listen on.\"\n    )\n    port_retries = Integer(50, config=True,\n        help=\"The number of additional ports to try if the specified port is not available.\"\n    )\n\n    certfile = Unicode(u'', config=True, \n        help=\"\"\"The full path to an SSL/TLS certificate file.\"\"\"\n    )\n    \n    keyfile = Unicode(u'', config=True, \n        help=\"\"\"The full path to a private key file for usage with SSL/TLS.\"\"\"\n    )\n    \n    cookie_secret_file = Unicode(config=True,\n        help=\"\"\"The file where the cookie secret is stored.\"\"\"\n    )\n    def _cookie_secret_file_default(self):\n        return os.path.join(self.runtime_dir, 'notebook_cookie_secret')\n    \n    cookie_secret = Bytes(b'', config=True,\n        help=\"\"\"The random bytes used to secure cookies.\n        By default this is a new random number every time you start the Notebook.\n        Set it to a value in a config file to enable logins to persist across server sessions.\n        \n        Note: Cookie secrets should be kept private, do not share config files with\n        cookie_secret stored in plaintext (you can read the value from a file).\n        \"\"\"\n    )\n    def _cookie_secret_default(self):\n        if os.path.exists(self.cookie_secret_file):\n            with io.open(self.cookie_secret_file, 'rb') as f:\n                return f.read()\n        else:\n            secret = base64.encodestring(os.urandom(1024))\n            self._write_cookie_secret_file(secret)\n            return secret\n    \n    def _write_cookie_secret_file(self, secret):\n        \"\"\"write my secret to my secret_file\"\"\"\n        self.log.info(\"Writing notebook server cookie secret to %s\", self.cookie_secret_file)\n        with io.open(self.cookie_secret_file, 'wb') as f:\n            f.write(secret)\n        try:\n            os.chmod(self.cookie_secret_file, 0o600)\n        except OSError:\n            self.log.warn(\n                \"Could not set permissions on %s\",\n                self.cookie_secret_file\n            )\n\n    password = Unicode(u'', config=True,\n                      help=\"\"\"Hashed password to use for web authentication.\n\n                      To generate, type in a python/IPython shell:\n\n                        from notebook.auth import passwd; passwd()\n\n                      The string should be of the form type:salt:hashed-password.\n                      \"\"\"\n    )\n\n    open_browser = Bool(True, config=True,\n                        help=\"\"\"Whether to open in a browser after starting.\n                        The specific browser used is platform dependent and\n                        determined by the python standard library `webbrowser`\n                        module, unless it is overridden using the --browser\n                        (NotebookApp.browser) configuration option.\n                        \"\"\")\n\n    browser = Unicode(u'', config=True,\n                      help=\"\"\"Specify what command to use to invoke a web\n                      browser when opening the notebook. If not specified, the\n                      default browser will be determined by the `webbrowser`\n                      standard library module, which allows setting of the\n                      BROWSER environment variable to override it.\n                      \"\"\")\n    \n    webapp_settings = Dict(config=True,\n        help=\"DEPRECATED, use tornado_settings\"\n    )\n    def _webapp_settings_changed(self, name, old, new):\n        self.log.warn(\"\\n    webapp_settings is deprecated, use tornado_settings.\\n\")\n        self.tornado_settings = new\n    \n    tornado_settings = Dict(config=True,\n            help=\"Supply overrides for the tornado.web.Application that the \"\n                 \"Jupyter notebook uses.\")\n    \n    ssl_options = Dict(config=True,\n            help=\"\"\"Supply SSL options for the tornado HTTPServer.\n            See the tornado docs for details.\"\"\")\n    \n    jinja_environment_options = Dict(config=True, \n            help=\"Supply extra arguments that will be passed to Jinja environment.\")\n\n    jinja_template_vars = Dict(\n        config=True,\n        help=\"Extra variables to supply to jinja templates when rendering.\",\n    )\n    \n    enable_mathjax = Bool(True, config=True,\n        help=\"\"\"Whether to enable MathJax for typesetting math/TeX\n\n        MathJax is the javascript library Jupyter uses to render math/LaTeX. It is\n        very large, so you may want to disable it if you have a slow internet\n        connection, or for offline use of the notebook.\n\n        When disabled, equations etc. will appear as their untransformed TeX source.\n        \"\"\"\n    )\n    def _enable_mathjax_changed(self, name, old, new):\n        \"\"\"set mathjax url to empty if mathjax is disabled\"\"\"\n        if not new:\n            self.mathjax_url = u''\n\n    base_url = Unicode('/', config=True,\n                               help='''The base URL for the notebook server.\n\n                               Leading and trailing slashes can be omitted,\n                               and will automatically be added.\n                               ''')\n    def _base_url_changed(self, name, old, new):\n        if not new.startswith('/'):\n            self.base_url = '/'+new\n        elif not new.endswith('/'):\n            self.base_url = new+'/'\n    \n    base_project_url = Unicode('/', config=True, help=\"\"\"DEPRECATED use base_url\"\"\")\n    def _base_project_url_changed(self, name, old, new):\n        self.log.warn(\"base_project_url is deprecated, use base_url\")\n        self.base_url = new\n\n    extra_static_paths = List(Unicode(), config=True,\n        help=\"\"\"Extra paths to search for serving static files.\n        \n        This allows adding javascript/css to be available from the notebook server machine,\n        or overriding individual files in the IPython\"\"\"\n    )\n    \n    @property\n    def static_file_path(self):\n        \"\"\"return extra paths + the default location\"\"\"\n        return self.extra_static_paths + [DEFAULT_STATIC_FILES_PATH]\n    \n    static_custom_path = List(Unicode(),\n        help=\"\"\"Path to search for custom.js, css\"\"\"\n    )\n    def _static_custom_path_default(self):\n        return [\n            os.path.join(d, 'custom') for d in (\n                self.config_dir,\n                # FIXME: serve IPython profile while we don't have `jupyter migrate`\n                os.path.join(get_ipython_dir(), 'profile_default', 'static'),\n                DEFAULT_STATIC_FILES_PATH)\n        ]\n\n    extra_template_paths = List(Unicode(), config=True,\n        help=\"\"\"Extra paths to search for serving jinja templates.\n\n        Can be used to override templates from notebook.templates.\"\"\"\n    )\n\n    @property\n    def template_file_path(self):\n        \"\"\"return extra paths + the default locations\"\"\"\n        return self.extra_template_paths + DEFAULT_TEMPLATE_PATH_LIST\n\n    extra_nbextensions_path = List(Unicode(), config=True,\n        help=\"\"\"extra paths to look for Javascript notebook extensions\"\"\"\n    )\n    \n    @property\n    def nbextensions_path(self):\n        \"\"\"The path to look for Javascript notebook extensions\"\"\"\n        path = self.extra_nbextensions_path + jupyter_path('nbextensions')\n        # FIXME: remove IPython nbextensions path once migration is setup\n        path.append(os.path.join(get_ipython_dir(), 'nbextensions'))\n        return path\n\n    websocket_url = Unicode(\"\", config=True,\n        help=\"\"\"The base URL for websockets,\n        if it differs from the HTTP server (hint: it almost certainly doesn't).\n        \n        Should be in the form of an HTTP origin: ws[s]://hostname[:port]\n        \"\"\"\n    )\n    mathjax_url = Unicode(\"\", config=True,\n        help=\"\"\"The url for MathJax.js.\"\"\"\n    )\n    def _mathjax_url_default(self):\n        if not self.enable_mathjax:\n            return u''\n        static_url_prefix = self.tornado_settings.get(\"static_url_prefix\",\n                         url_path_join(self.base_url, \"static\")\n        )\n        return url_path_join(static_url_prefix, 'components', 'MathJax', 'MathJax.js')\n    \n    def _mathjax_url_changed(self, name, old, new):\n        if new and not self.enable_mathjax:\n            # enable_mathjax=False overrides mathjax_url\n            self.mathjax_url = u''\n        else:\n            self.log.info(\"Using MathJax: %s\", new)\n\n    contents_manager_class = Type(\n        default_value=FileContentsManager,\n        klass=ContentsManager,\n        config=True,\n        help='The notebook manager class to use.'\n    )\n    kernel_manager_class = Type(\n        default_value=MappingKernelManager,\n        config=True,\n        help='The kernel manager class to use.'\n    )\n    session_manager_class = Type(\n        default_value=SessionManager,\n        config=True,\n        help='The session manager class to use.'\n    )\n\n    config_manager_class = Type(\n        default_value=ConfigManager,\n        config = True,\n        help='The config manager class to use'\n    )\n\n    kernel_spec_manager = Instance(KernelSpecManager, allow_none=True)\n\n    kernel_spec_manager_class = Type(\n        default_value=KernelSpecManager,\n        config=True,\n        help=\"\"\"\n        The kernel spec manager class to use. Should be a subclass\n        of `jupyter_client.kernelspec.KernelSpecManager`.\n\n        The Api of KernelSpecManager is provisional and might change\n        without warning between this version of Jupyter and the next stable one.\n        \"\"\"\n    )\n\n    login_handler_class = Type(\n        default_value=LoginHandler,\n        klass=web.RequestHandler,\n        config=True,\n        help='The login handler class to use.',\n    )\n\n    logout_handler_class = Type(\n        default_value=LogoutHandler,\n        klass=web.RequestHandler,\n        config=True,\n        help='The logout handler class to use.',\n    )\n\n    trust_xheaders = Bool(False, config=True,\n        help=(\"Whether to trust or not X-Scheme/X-Forwarded-Proto and X-Real-Ip/X-Forwarded-For headers\"\n              \"sent by the upstream reverse proxy. Necessary if the proxy handles SSL\")\n    )\n\n    info_file = Unicode()\n\n    def _info_file_default(self):\n        info_file = \"nbserver-%s.json\" % os.getpid()\n        return os.path.join(self.runtime_dir, info_file)\n    \n    pylab = Unicode('disabled', config=True,\n        help=\"\"\"\n        DISABLED: use %pylab or %matplotlib in the notebook to enable matplotlib.\n        \"\"\"\n    )\n    def _pylab_changed(self, name, old, new):\n        \"\"\"when --pylab is specified, display a warning and exit\"\"\"\n        if new != 'warn':\n            backend = ' %s' % new\n        else:\n            backend = ''\n        self.log.error(\"Support for specifying --pylab on the command line has been removed.\")\n        self.log.error(\n            \"Please use `%pylab{0}` or `%matplotlib{0}` in the notebook itself.\".format(backend)\n        )\n        self.exit(1)\n\n    notebook_dir = Unicode(config=True,\n        help=\"The directory to use for notebooks and kernels.\"\n    )\n\n    def _notebook_dir_default(self):\n        if self.file_to_run:\n            return os.path.dirname(os.path.abspath(self.file_to_run))\n        else:\n            return py3compat.getcwd()\n\n    def _notebook_dir_changed(self, name, old, new):\n        \"\"\"Do a bit of validation of the notebook dir.\"\"\"\n        if not os.path.isabs(new):\n            # If we receive a non-absolute path, make it absolute.\n            self.notebook_dir = os.path.abspath(new)\n            return\n        if not os.path.isdir(new):\n            raise TraitError(\"No such notebook dir: %r\" % new)\n        \n        # setting App.notebook_dir implies setting notebook and kernel dirs as well\n        self.config.FileContentsManager.root_dir = new\n        self.config.MappingKernelManager.root_dir = new\n\n    server_extensions = List(Unicode(), config=True,\n        help=(\"Python modules to load as notebook server extensions. \"\n              \"This is an experimental API, and may change in future releases.\")\n    )\n\n    reraise_server_extension_failures = Bool(\n        False,\n        config=True,\n        help=\"Reraise exceptions encountered loading server extensions?\",\n    )\n\n    def parse_command_line(self, argv=None):\n        super(NotebookApp, self).parse_command_line(argv)\n        \n        if self.extra_args:\n            arg0 = self.extra_args[0]\n            f = os.path.abspath(arg0)\n            self.argv.remove(arg0)\n            if not os.path.exists(f):\n                self.log.critical(\"No such file or directory: %s\", f)\n                self.exit(1)\n            \n            # Use config here, to ensure that it takes higher priority than\n            # anything that comes from the profile.\n            c = Config()\n            if os.path.isdir(f):\n                c.NotebookApp.notebook_dir = f\n            elif os.path.isfile(f):\n                c.NotebookApp.file_to_run = f\n            self.update_config(c)\n\n    def init_configurables(self):\n        self.kernel_spec_manager = self.kernel_spec_manager_class(\n            parent=self,\n        )\n        self.kernel_manager = self.kernel_manager_class(\n            parent=self,\n            log=self.log,\n            connection_dir=self.runtime_dir,\n            kernel_spec_manager=self.kernel_spec_manager,\n        )\n        self.contents_manager = self.contents_manager_class(\n            parent=self,\n            log=self.log,\n        )\n        self.session_manager = self.session_manager_class(\n            parent=self,\n            log=self.log,\n            kernel_manager=self.kernel_manager,\n            contents_manager=self.contents_manager,\n        )\n        self.config_manager = self.config_manager_class(\n            parent=self,\n            log=self.log,\n            config_dir=os.path.join(self.config_dir, 'nbconfig'),\n        )\n\n    def init_logging(self):\n        # This prevents double log messages because tornado use a root logger that\n        # self.log is a child of. The logging module dipatches log messages to a log\n        # and all of its ancenstors until propagate is set to False.\n        self.log.propagate = False\n        \n        for log in app_log, access_log, gen_log:\n            # consistent log output name (NotebookApp instead of tornado.access, etc.)\n            log.name = self.log.name\n        # hook up tornado 3's loggers to our app handlers\n        logger = logging.getLogger('tornado')\n        logger.propagate = True\n        logger.parent = self.log\n        logger.setLevel(self.log.level)\n    \n    def init_webapp(self):\n        \"\"\"initialize tornado webapp and httpserver\"\"\"\n        self.tornado_settings['allow_origin'] = self.allow_origin\n        if self.allow_origin_pat:\n            self.tornado_settings['allow_origin_pat'] = re.compile(self.allow_origin_pat)\n        self.tornado_settings['allow_credentials'] = self.allow_credentials\n        # ensure default_url starts with base_url\n        if not self.default_url.startswith(self.base_url):\n            self.default_url = url_path_join(self.base_url, self.default_url)\n        \n        self.web_app = NotebookWebApplication(\n            self, self.kernel_manager, self.contents_manager,\n            self.session_manager, self.kernel_spec_manager,\n            self.config_manager,\n            self.log, self.base_url, self.default_url, self.tornado_settings,\n            self.jinja_environment_options\n        )\n        ssl_options = self.ssl_options\n        if self.certfile:\n            ssl_options['certfile'] = self.certfile\n        if self.keyfile:\n            ssl_options['keyfile'] = self.keyfile\n        if not ssl_options:\n            # None indicates no SSL config\n            ssl_options = None\n        else:\n            # Disable SSLv3, since its use is discouraged.\n            ssl_options['ssl_version']=ssl.PROTOCOL_TLSv1\n        self.login_handler_class.validate_security(self, ssl_options=ssl_options)\n        self.http_server = httpserver.HTTPServer(self.web_app, ssl_options=ssl_options,\n                                                 xheaders=self.trust_xheaders)\n\n        success = None\n        for port in random_ports(self.port, self.port_retries+1):\n            try:\n                self.http_server.listen(port, self.ip)\n            except socket.error as e:\n                if e.errno == errno.EADDRINUSE:\n                    self.log.info('The port %i is already in use, trying another random port.' % port)\n                    continue\n                elif e.errno in (errno.EACCES, getattr(errno, 'WSAEACCES', errno.EACCES)):\n                    self.log.warn(\"Permission to listen on port %i denied\" % port)\n                    continue\n                else:\n                    raise\n            else:\n                self.port = port\n                success = True\n                break\n        if not success:\n            self.log.critical('ERROR: the notebook server could not be started because '\n                              'no available port could be found.')\n            self.exit(1)\n    \n    @property\n    def display_url(self):\n        ip = self.ip if self.ip else '[all ip addresses on your system]'\n        return self._url(ip)\n\n    @property\n    def connection_url(self):\n        ip = self.ip if self.ip else 'localhost'\n        return self._url(ip)\n\n    def _url(self, ip):\n        proto = 'https' if self.certfile else 'http'\n        return \"%s://%s:%i%s\" % (proto, ip, self.port, self.base_url)\n\n    def init_terminals(self):\n        try:\n            from .terminal import initialize\n            initialize(self.web_app, self.notebook_dir, self.connection_url)\n            self.web_app.settings['terminals_available'] = True\n        except ImportError as e:\n            log = self.log.debug if sys.platform == 'win32' else self.log.warn\n            log(\"Terminals not available (error was %s)\", e)\n\n    def init_signal(self):\n        if not sys.platform.startswith('win') and sys.stdin.isatty():\n            signal.signal(signal.SIGINT, self._handle_sigint)\n        signal.signal(signal.SIGTERM, self._signal_stop)\n        if hasattr(signal, 'SIGUSR1'):\n            # Windows doesn't support SIGUSR1\n            signal.signal(signal.SIGUSR1, self._signal_info)\n        if hasattr(signal, 'SIGINFO'):\n            # only on BSD-based systems\n            signal.signal(signal.SIGINFO, self._signal_info)\n    \n    def _handle_sigint(self, sig, frame):\n        \"\"\"SIGINT handler spawns confirmation dialog\"\"\"\n        # register more forceful signal handler for ^C^C case\n        signal.signal(signal.SIGINT, self._signal_stop)\n        # request confirmation dialog in bg thread, to avoid\n        # blocking the App\n        thread = threading.Thread(target=self._confirm_exit)\n        thread.daemon = True\n        thread.start()\n    \n    def _restore_sigint_handler(self):\n        \"\"\"callback for restoring original SIGINT handler\"\"\"\n        signal.signal(signal.SIGINT, self._handle_sigint)\n    \n    def _confirm_exit(self):\n        \"\"\"confirm shutdown on ^C\n        \n        A second ^C, or answering 'y' within 5s will cause shutdown,\n        otherwise original SIGINT handler will be restored.\n        \n        This doesn't work on Windows.\n        \"\"\"\n        info = self.log.info\n        info('interrupted')\n        print(self.notebook_info())\n        sys.stdout.write(\"Shutdown this notebook server (y/[n])? \")\n        sys.stdout.flush()\n        r,w,x = select.select([sys.stdin], [], [], 5)\n        if r:\n            line = sys.stdin.readline()\n            if line.lower().startswith('y') and 'n' not in line.lower():\n                self.log.critical(\"Shutdown confirmed\")\n                ioloop.IOLoop.current().stop()\n                return\n        else:\n            print(\"No answer for 5s:\", end=' ')\n        print(\"resuming operation...\")\n        # no answer, or answer is no:\n        # set it back to original SIGINT handler\n        # use IOLoop.add_callback because signal.signal must be called\n        # from main thread\n        ioloop.IOLoop.current().add_callback(self._restore_sigint_handler)\n    \n    def _signal_stop(self, sig, frame):\n        self.log.critical(\"received signal %s, stopping\", sig)\n        ioloop.IOLoop.current().stop()\n\n    def _signal_info(self, sig, frame):\n        print(self.notebook_info())\n    \n    def init_components(self):\n        \"\"\"Check the components submodule, and warn if it's unclean\"\"\"\n        # TODO: this should still check, but now we use bower, not git submodule\n        pass\n\n    def init_server_extensions(self):\n        \"\"\"Load any extensions specified by config.\n\n        Import the module, then call the load_jupyter_server_extension function,\n        if one exists.\n        \n        The extension API is experimental, and may change in future releases.\n        \"\"\"\n        for modulename in self.server_extensions:\n            try:\n                mod = importlib.import_module(modulename)\n                func = getattr(mod, 'load_jupyter_server_extension', None)\n                if func is not None:\n                    func(self)\n            except Exception:\n                if self.reraise_server_extension_failures:\n                    raise\n                self.log.warn(\"Error loading server extension %s\", modulename,\n                              exc_info=True)\n    \n    @catch_config_error\n    def initialize(self, argv=None):\n        super(NotebookApp, self).initialize(argv)\n        self.init_logging()\n        if self._dispatching:\n            return\n        self.init_configurables()\n        self.init_components()\n        self.init_webapp()\n        self.init_terminals()\n        self.init_signal()\n        self.init_server_extensions()\n\n    def cleanup_kernels(self):\n        \"\"\"Shutdown all kernels.\n        \n        The kernels will shutdown themselves when this process no longer exists,\n        but explicit shutdown allows the KernelManagers to cleanup the connection files.\n        \"\"\"\n        self.log.info('Shutting down kernels')\n        self.kernel_manager.shutdown_all()\n\n    def notebook_info(self):\n        \"Return the current working directory and the server url information\"\n        info = self.contents_manager.info_string() + \"\\n\"\n        info += \"%d active kernels \\n\" % len(self.kernel_manager._kernels)\n        return info + \"The Jupyter Notebook is running at: %s\" % self.display_url\n\n    def server_info(self):\n        \"\"\"Return a JSONable dict of information about this server.\"\"\"\n        return {'url': self.connection_url,\n                'hostname': self.ip if self.ip else 'localhost',\n                'port': self.port,\n                'secure': bool(self.certfile),\n                'base_url': self.base_url,\n                'notebook_dir': os.path.abspath(self.notebook_dir),\n                'pid': os.getpid()\n               }\n\n    def write_server_info_file(self):\n        \"\"\"Write the result of server_info() to the JSON file info_file.\"\"\"\n        with open(self.info_file, 'w') as f:\n            json.dump(self.server_info(), f, indent=2)\n\n    def remove_server_info_file(self):\n        \"\"\"Remove the nbserver-<pid>.json file created for this server.\n        \n        Ignores the error raised when the file has already been removed.\n        \"\"\"\n        try:\n            os.unlink(self.info_file)\n        except OSError as e:\n            if e.errno != errno.ENOENT:\n                raise\n\n    def start(self):\n        \"\"\" Start the Notebook server app, after initialization\n        \n        This method takes no arguments so all configuration and initialization\n        must be done prior to calling this method.\"\"\"\n        super(NotebookApp, self).start()\n\n        info = self.log.info\n        for line in self.notebook_info().split(\"\\n\"):\n            info(line)\n        info(\"Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).\")\n\n        self.write_server_info_file()\n\n        if self.open_browser or self.file_to_run:\n            try:\n                browser = webbrowser.get(self.browser or None)\n            except webbrowser.Error as e:\n                self.log.warn('No web browser found: %s.' % e)\n                browser = None\n            \n            if self.file_to_run:\n                if not os.path.exists(self.file_to_run):\n                    self.log.critical(\"%s does not exist\" % self.file_to_run)\n                    self.exit(1)\n\n                relpath = os.path.relpath(self.file_to_run, self.notebook_dir)\n                uri = url_path_join('notebooks', *relpath.split(os.sep))\n            else:\n                uri = 'tree'\n            if browser:\n                b = lambda : browser.open(url_path_join(self.connection_url, uri),\n                                          new=2)\n                threading.Thread(target=b).start()\n        \n        self.io_loop = ioloop.IOLoop.current()\n        if sys.platform.startswith('win'):\n            # add no-op to wake every 5s\n            # to handle signals that may be ignored by the inner loop\n            pc = ioloop.PeriodicCallback(lambda : None, 5000)\n            pc.start()\n        try:\n            self.io_loop.start()\n        except KeyboardInterrupt:\n            info(\"Interrupted...\")\n        finally:\n            self.cleanup_kernels()\n            self.remove_server_info_file()\n    \n    def stop(self):\n        def _stop():\n            self.http_server.stop()\n            self.io_loop.stop()\n        self.io_loop.add_callback(_stop)\n\n\ndef list_running_servers(runtime_dir=None):\n    \"\"\"Iterate over the server info files of running notebook servers.\n    \n    Given a profile name, find nbserver-* files in the security directory of\n    that profile, and yield dicts of their information, each one pertaining to\n    a currently running notebook server instance.\n    \"\"\"\n    if runtime_dir is None:\n        runtime_dir = jupyter_runtime_dir()\n\n    # The runtime dir might not exist\n    if not os.path.isdir(runtime_dir):\n        return\n\n    for file in os.listdir(runtime_dir):\n        if file.startswith('nbserver-'):\n            with io.open(os.path.join(runtime_dir, file), encoding='utf-8') as f:\n                info = json.load(f)\n\n            # Simple check whether that process is really still running\n            # Also remove leftover files from IPython 2.x without a pid field\n            if ('pid' in info) and check_pid(info['pid']):\n                yield info\n            else:\n                # If the process has died, try to delete its info file\n                try:\n                    os.unlink(file)\n                except OSError:\n                    pass  # TODO: This should warn or log or something\n#-----------------------------------------------------------------------------\n# Main entry point\n#-----------------------------------------------------------------------------\n\nmain = launch_new_instance = NotebookApp.launch_instance\n\n", "target": 1}
{"idx": 865, "func": "# -*- coding: utf-8 -*-\n'''\nSupport for the Git SCM\n'''\nfrom __future__ import absolute_import\n\n# Import python libs\nimport os\nimport re\nimport subprocess\n\n# Import salt libs\nfrom salt import utils\nfrom salt.exceptions import SaltInvocationError, CommandExecutionError\nfrom salt.ext.six.moves.urllib.parse import urlparse as _urlparse  # pylint: disable=no-name-in-module,import-error\nfrom salt.ext.six.moves.urllib.parse import urlunparse as _urlunparse  # pylint: disable=no-name-in-module,import-error\n\n\ndef __virtual__():\n    '''\n    Only load if git exists on the system\n    '''\n    return True if utils.which('git') else False\n\n\ndef _git_run(cmd, cwd=None, runas=None, identity=None, **kwargs):\n    '''\n    simple, throw an exception with the error message on an error return code.\n\n    this function may be moved to the command module, spliced with\n    'cmd.run_all', and used as an alternative to 'cmd.run_all'. Some\n    commands don't return proper retcodes, so this can't replace 'cmd.run_all'.\n    '''\n    env = {}\n\n    if identity:\n        stderrs = []\n\n        # if the statefile provides multiple identities, they need to be tried\n        # (but also allow a string instead of a list)\n        if not isinstance(identity, list):\n            # force it into a list\n            identity = [identity]\n\n        # try each of the identities, independently\n        for id_file in identity:\n            env = {\n                'GIT_IDENTITY': id_file\n            }\n\n            # copy wrapper to area accessible by ``runas`` user\n            # currently no suppport in windows for wrapping git ssh\n            if not utils.is_windows():\n                ssh_id_wrapper = os.path.join(utils.templates.TEMPLATE_DIRNAME,\n                                              'git/ssh-id-wrapper')\n                tmp_file = utils.mkstemp()\n                utils.files.copyfile(ssh_id_wrapper, tmp_file)\n                os.chmod(tmp_file, 0o500)\n                os.chown(tmp_file, __salt__['file.user_to_uid'](runas), -1)\n                env['GIT_SSH'] = tmp_file\n\n            try:\n                result = __salt__['cmd.run_all'](cmd,\n                                                 cwd=cwd,\n                                                 runas=runas,\n                                                 output_loglevel='quiet',\n                                                 env=env,\n                                                 python_shell=False,\n                                                 **kwargs)\n            finally:\n                if 'GIT_SSH' in env:\n                    os.remove(env['GIT_SSH'])\n\n            # if the command was successful, no need to try additional IDs\n            if result['retcode'] == 0:\n                return result['stdout']\n            else:\n                stderr = _remove_sensitive_data(result['stderr'])\n                stderrs.append(stderr)\n\n        # we've tried all IDs and still haven't passed, so error out\n        raise CommandExecutionError(\"\\n\\n\".join(stderrs))\n\n    else:\n        result = __salt__['cmd.run_all'](cmd,\n                                         cwd=cwd,\n                                         runas=runas,\n                                         output_loglevel='quiet',\n                                         env=env,\n                                         python_shell=False,\n                                         **kwargs)\n        retcode = result['retcode']\n\n        if retcode == 0:\n            return result['stdout']\n        else:\n            stderr = _remove_sensitive_data(result['stderr'])\n            raise CommandExecutionError(\n                'Command {0!r} failed. Stderr: {1!r}'.format(cmd, stderr))\n\n\ndef _remove_sensitive_data(sensitive_output):\n    '''\n        Remove HTTP user and password.\n    '''\n    return re.sub('(https?)://.*@', r'\\1://<redacted>@', sensitive_output)\n\n\ndef _git_getdir(cwd, user=None):\n    '''\n    Returns the absolute path to the top-level of a given repo because some Git\n    commands are sensitive to where they're run from (archive for one)\n    '''\n    cmd_bare = 'git rev-parse --is-bare-repository'\n    is_bare = __salt__['cmd.run_stdout'](cmd_bare, cwd, runas=user) == 'true'\n\n    if is_bare:\n        return cwd\n\n    cmd_toplvl = 'git rev-parse --show-toplevel'\n    return __salt__['cmd.run'](cmd_toplvl, cwd)\n\n\ndef _check_git():\n    '''\n    Check if git is available\n    '''\n    utils.check_or_die('git')\n\n\ndef _add_http_basic_auth(repository, https_user=None, https_pass=None):\n    if https_user is None and https_pass is None:\n        return repository\n    else:\n        urltuple = _urlparse(repository)\n        if urltuple.scheme == 'https':\n            if https_pass:\n                auth_string = \"{0}:{1}\".format(https_user, https_pass)\n            else:\n                auth_string = https_user\n            netloc = \"{0}@{1}\".format(auth_string, urltuple.netloc)\n            urltuple = urltuple._replace(netloc=netloc)\n            return _urlunparse(urltuple)\n        else:\n            raise ValueError('Basic Auth only supported for HTTPS scheme')\n\n\ndef current_branch(cwd, user=None):\n    '''\n    Returns the current branch name, if on a branch.\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' git.current_branch /path/to/repo\n    '''\n    cmd = r'git rev-parse --abbrev-ref HEAD'\n\n    return __salt__['cmd.run_stdout'](cmd, cwd=cwd, runas=user)\n\n\ndef revision(cwd, rev='HEAD', short=False, user=None):\n    '''\n    Returns the long hash of a given identifier (hash, branch, tag, HEAD, etc)\n\n    cwd\n        The path to the Git repository\n\n    rev: HEAD\n        The revision\n\n    short: False\n        Return an abbreviated SHA1 git hash\n\n    user : None\n        Run git as a user other than what the minion runs as\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' git.revision /path/to/repo mybranch\n    '''\n    _check_git()\n\n    cmd = 'git rev-parse {0}{1}'.format('--short ' if short else '', rev)\n    return _git_run(cmd, cwd, runas=user)\n\n\ndef clone(cwd, repository, opts=None, user=None, identity=None,\n          https_user=None, https_pass=None):\n    '''\n    Clone a new repository\n\n    cwd\n        The path to the Git repository\n\n    repository\n        The git URI of the repository\n\n    opts : None\n        Any additional options to add to the command line\n\n    user : None\n        Run git as a user other than what the minion runs as\n\n    identity : None\n        A path to a private key to use over SSH\n\n    https_user : None\n        HTTP Basic Auth username for HTTPS (only) clones\n\n        .. versionadded:: 20515.5.0\n\n    https_pass : None\n        HTTP Basic Auth password for HTTPS (only) clones\n\n        .. versionadded:: 2015.5.0\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' git.clone /path/to/repo git://github.com/saltstack/salt.git\n\n        salt '*' git.clone /path/to/repo.git\\\\\n                git://github.com/saltstack/salt.git '--bare --origin github'\n\n    '''\n    _check_git()\n\n    repository = _add_http_basic_auth(repository, https_user, https_pass)\n\n    if not opts:\n        opts = ''\n    if utils.is_windows():\n        cmd = 'git clone {0} {1} {2}'.format(repository, cwd, opts)\n    else:\n        cmd = 'git clone {0} {1!r} {2}'.format(repository, cwd, opts)\n\n    return _git_run(cmd, runas=user, identity=identity)\n\n\ndef describe(cwd, rev='HEAD', user=None):\n    '''\n    Returns the git describe string (or the SHA hash if there are no tags) for\n    the given revision\n\n    cwd\n        The path to the Git repository\n\n    rev: HEAD\n        The revision to describe\n\n    user : None\n        Run git as a user other than what the minion runs as\n\n    CLI Examples:\n\n    .. code-block:: bash\n\n        salt '*' git.describe /path/to/repo\n\n        salt '*' git.describe /path/to/repo develop\n    '''\n    cmd = 'git describe {0}'.format(rev)\n    return __salt__['cmd.run_stdout'](cmd,\n                                      cwd=cwd,\n                                      runas=user,\n                                      python_shell=False)\n\n\ndef archive(cwd, output, rev='HEAD', fmt=None, prefix=None, user=None):\n    '''\n    Export a tarball from the repository\n\n    cwd\n        The path to the Git repository\n\n    output\n        The path to the archive tarball\n\n    rev: HEAD\n        The revision to create an archive from\n\n    fmt: None\n        Format of the resulting archive, zip and tar are commonly used\n\n    prefix : None\n        Prepend <prefix>/ to every filename in the archive\n\n    user : None\n        Run git as a user other than what the minion runs as\n\n    If ``prefix`` is not specified it defaults to the basename of the repo\n    directory.\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' git.archive /path/to/repo /path/to/archive.tar.gz\n    '''\n    _check_git()\n\n    basename = '{0}/'.format(os.path.basename(_git_getdir(cwd, user=user)))\n\n    cmd = 'git archive{prefix}{fmt} -o {output} {rev}'.format(\n            rev=rev,\n            output=output,\n            fmt=' --format={0}'.format(fmt) if fmt else '',\n            prefix=' --prefix=\"{0}\"'.format(prefix if prefix else basename)\n    )\n\n    return _git_run(cmd, cwd=cwd, runas=user)\n\n\ndef fetch(cwd, opts=None, user=None, identity=None):\n    '''\n    Perform a fetch on the given repository\n\n    cwd\n        The path to the Git repository\n\n    opts : None\n        Any additional options to add to the command line\n\n    user : None\n        Run git as a user other than what the minion runs as\n\n    identity : None\n        A path to a private key to use over SSH\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' git.fetch /path/to/repo '--all'\n\n        salt '*' git.fetch cwd=/path/to/repo opts='--all' user=johnny\n    '''\n    _check_git()\n\n    if not opts:\n        opts = ''\n    cmd = 'git fetch {0}'.format(opts)\n\n    return _git_run(cmd, cwd=cwd, runas=user, identity=identity)\n\n\ndef pull(cwd, opts=None, user=None, identity=None):\n    '''\n    Perform a pull on the given repository\n\n    cwd\n        The path to the Git repository\n\n    opts : None\n        Any additional options to add to the command line\n\n    user : None\n        Run git as a user other than what the minion runs as\n\n    identity : None\n        A path to a private key to use over SSH\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' git.pull /path/to/repo opts='--rebase origin master'\n    '''\n    _check_git()\n\n    if not opts:\n        opts = ''\n    return _git_run('git pull {0}'.format(opts),\n                    cwd=cwd,\n                    runas=user,\n                    identity=identity)\n\n\ndef rebase(cwd, rev='master', opts=None, user=None):\n    '''\n    Rebase the current branch\n\n    cwd\n        The path to the Git repository\n\n    rev : master\n        The revision to rebase onto the current branch\n\n    opts : None\n        Any additional options to add to the command line\n\n    user : None\n        Run git as a user other than what the minion runs as\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' git.rebase /path/to/repo master\n        salt '*' git.rebase /path/to/repo 'origin master'\n\n    That is the same as:\n\n    .. code-block:: bash\n\n        git rebase master\n        git rebase origin master\n    '''\n    _check_git()\n\n    if not opts:\n        opts = ''\n    return _git_run('git rebase {0} {1}'.format(opts, rev),\n                    cwd=cwd,\n                    runas=user)\n\n\ndef checkout(cwd, rev, force=False, opts=None, user=None):\n    '''\n    Checkout a given revision\n\n    cwd\n        The path to the Git repository\n\n    rev\n        The remote branch or revision to checkout\n\n    force : False\n        Force a checkout even if there might be overwritten changes\n\n    opts : None\n        Any additional options to add to the command line\n\n    user : None\n        Run git as a user other than what the minion runs as\n\n    CLI Examples:\n\n    .. code-block:: bash\n\n        salt '*' git.checkout /path/to/repo somebranch user=jeff\n\n        salt '*' git.checkout /path/to/repo opts='testbranch -- conf/file1 file2'\n\n        salt '*' git.checkout /path/to/repo rev=origin/mybranch opts=--track\n    '''\n    _check_git()\n\n    if not opts:\n        opts = ''\n    cmd = 'git checkout {0} {1} {2}'.format(' -f' if force else '', rev, opts)\n    return _git_run(cmd, cwd=cwd, runas=user)\n\n\ndef merge(cwd, branch='@{upstream}', opts=None, user=None):\n    '''\n    Merge a given branch\n\n    cwd\n        The path to the Git repository\n\n    branch : @{upstream}\n        The remote branch or revision to merge into the current branch\n\n    opts : None\n        Any additional options to add to the command line\n\n    user : None\n        Run git as a user other than what the minion runs as\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' git.fetch /path/to/repo\n        salt '*' git.merge /path/to/repo @{upstream}\n    '''\n    _check_git()\n\n    if not opts:\n        opts = ''\n    cmd = 'git merge {0} {1}'.format(branch,\n                                     opts)\n\n    return _git_run(cmd, cwd, runas=user)\n\n\ndef init(cwd, opts=None, user=None):\n    '''\n    Initialize a new git repository\n\n    cwd\n        The path to the Git repository\n\n    opts : None\n        Any additional options to add to the command line\n\n    user : None\n        Run git as a user other than what the minion runs as\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' git.init /path/to/repo.git opts='--bare'\n    '''\n    _check_git()\n    if not opts:\n        opts = ''\n    cmd = 'git init {0} {1}'.format(cwd, opts)\n    return _git_run(cmd, runas=user)\n\n\ndef submodule(cwd, init=True, opts=None, user=None, identity=None):\n    '''\n    Initialize git submodules\n\n    cwd\n        The path to the Git repository\n\n    init : True\n        Ensure that new submodules are initialized\n\n    opts : None\n        Any additional options to add to the command line\n\n    user : None\n        Run git as a user other than what the minion runs as\n\n    identity : None\n        A path to a private key to use over SSH\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' git.submodule /path/to/repo.git/sub/repo\n    '''\n    _check_git()\n\n    if not opts:\n        opts = ''\n    cmd = 'git submodule update {0} {1}'.format('--init' if init else '', opts)\n    return _git_run(cmd, cwd=cwd, runas=user, identity=identity)\n\n\ndef status(cwd, user=None):\n    '''\n    Return the status of the repository. The returned format uses the status\n    codes of git's 'porcelain' output mode\n\n    cwd\n        The path to the Git repository\n\n    user : None\n        Run git as a user other than what the minion runs as\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' git.status /path/to/git/repo\n    '''\n    cmd = 'git status -z --porcelain'\n    stdout = _git_run(cmd, cwd=cwd, runas=user)\n    state_by_file = []\n    for line in stdout.split(\"\\0\"):\n        state = line[:2]\n        filename = line[3:]\n        if filename != '' and state != '':\n            state_by_file.append((state, filename))\n    return state_by_file\n\n\ndef add(cwd, file_name, user=None, opts=None):\n    '''\n    add a file to git\n\n    cwd\n        The path to the Git repository\n\n    file_name\n        Path to the file in the cwd\n\n    opts : None\n        Any additional options to add to the command line\n\n    user : None\n        Run git as a user other than what the minion runs as\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' git.add /path/to/git/repo /path/to/file\n\n    '''\n\n    if not opts:\n        opts = ''\n    cmd = 'git add {0} {1}'.format(file_name, opts)\n    return _git_run(cmd, cwd=cwd, runas=user)\n\n\ndef rm(cwd, file_name, user=None, opts=None):\n    '''\n    Remove a file from git\n\n    cwd\n        The path to the Git repository\n\n    file_name\n        Path to the file in the cwd\n\n    opts : None\n        Any additional options to add to the command line\n\n    user : None\n        Run git as a user other than what the minion runs as\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' git.rm /path/to/git/repo /path/to/file\n    '''\n\n    if not opts:\n        opts = ''\n    cmd = 'git rm {0} {1}'.format(file_name, opts)\n    return _git_run(cmd, cwd=cwd, runas=user)\n\n\ndef commit(cwd, message, user=None, opts=None):\n    '''\n    create a commit\n\n    cwd\n        The path to the Git repository\n\n    message\n        The commit message\n\n    opts : None\n        Any additional options to add to the command line\n\n    user : None\n        Run git as a user other than what the minion runs as\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' git.commit /path/to/git/repo 'The commit message'\n    '''\n\n    cmd = subprocess.list2cmdline(['git', 'commit', '-m', message])\n    # add opts separately; they don't need to be quoted\n    if opts:\n        cmd = cmd + ' ' + opts\n    return _git_run(cmd, cwd=cwd, runas=user)\n\n\ndef push(cwd, remote_name, branch='master', user=None, opts=None,\n         identity=None):\n    '''\n    Push to remote\n\n    cwd\n        The path to the Git repository\n\n    remote_name\n        Name of the remote to push to\n\n    branch : master\n        Name of the branch to push\n\n    opts : None\n        Any additional options to add to the command line\n\n    user : None\n        Run git as a user other than what the minion runs as\n\n    identity : None\n        A path to a private key to use over SSH\n\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' git.push /path/to/git/repo remote-name\n    '''\n\n    if not opts:\n        opts = ''\n    cmd = 'git push {0} {1} {2}'.format(remote_name, branch, opts)\n    return _git_run(cmd, cwd=cwd, runas=user, identity=identity)\n\n\ndef remotes(cwd, user=None):\n    '''\n    Get remotes like git remote -v\n\n    cwd\n        The path to the Git repository\n\n    user : None\n        Run git as a user other than what the minion runs as\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' git.remotes /path/to/repo\n    '''\n    cmd = 'git remote'\n    ret = _git_run(cmd, cwd=cwd, runas=user)\n    res = dict()\n    for remote_name in ret.splitlines():\n        remote = remote_name.strip()\n        res[remote] = remote_get(cwd, remote, user=user)\n    return res\n\n\ndef remote_get(cwd, remote='origin', user=None):\n    '''\n    get the fetch and push URL for a specified remote name\n\n    remote : origin\n        the remote name used to define the fetch and push URL\n\n    user : None\n        Run git as a user other than what the minion runs as\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' git.remote_get /path/to/repo\n        salt '*' git.remote_get /path/to/repo upstream\n    '''\n    try:\n        cmd = 'git remote show -n {0}'.format(remote)\n        ret = _git_run(cmd, cwd=cwd, runas=user)\n        lines = ret.splitlines()\n        remote_fetch_url = lines[1].replace('Fetch URL: ', '').strip()\n        remote_push_url = lines[2].replace('Push  URL: ', '').strip()\n        if remote_fetch_url != remote and remote_push_url != remote:\n            res = (remote_fetch_url, remote_push_url)\n            return res\n        else:\n            return None\n    except CommandExecutionError:\n        return None\n\n\ndef remote_set(cwd, name='origin', url=None, user=None, https_user=None,\n               https_pass=None):\n    '''\n    sets a remote with name and URL like git remote add <remote_name> <remote_url>\n\n    remote_name : origin\n        defines the remote name\n\n    remote_url : None\n        defines the remote URL; should not be None!\n\n    user : None\n        Run git as a user other than what the minion runs as\n\n    https_user : None\n        HTTP Basic Auth username for HTTPS (only) clones\n\n        .. versionadded:: 2015.5.0\n\n    https_pass : None\n        HTTP Basic Auth password for HTTPS (only) clones\n\n        .. versionadded:: 2015.5.0\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' git.remote_set /path/to/repo remote_url=git@github.com:saltstack/salt.git\n        salt '*' git.remote_set /path/to/repo origin git@github.com:saltstack/salt.git\n    '''\n    if remote_get(cwd, name):\n        cmd = 'git remote rm {0}'.format(name)\n        _git_run(cmd, cwd=cwd, runas=user)\n    url = _add_http_basic_auth(url, https_user, https_pass)\n    cmd = 'git remote add {0} {1}'.format(name, url)\n    _git_run(cmd, cwd=cwd, runas=user)\n    return remote_get(cwd=cwd, remote=name, user=None)\n\n\ndef branch(cwd, rev, opts=None, user=None):\n    '''\n    Interacts with branches.\n\n    cwd\n        The path to the Git repository\n\n    rev\n        The branch/revision to be used in the command.\n\n    opts : None\n        Any additional options to add to the command line\n\n    user : None\n        Run git as a user other than what the minion runs as\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' git.branch mybranch --set-upstream-to=origin/mybranch\n    '''\n    cmd = 'git branch {0} {1}'.format(rev, opts)\n    _git_run(cmd, cwd=cwd, user=user)\n    return current_branch(cwd, user=user)\n\n\ndef reset(cwd, opts=None, user=None):\n    '''\n    Reset the repository checkout\n\n    cwd\n        The path to the Git repository\n\n    opts : None\n        Any additional options to add to the command line\n\n    user : None\n        Run git as a user other than what the minion runs as\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' git.reset /path/to/repo master\n    '''\n    _check_git()\n\n    if not opts:\n        opts = ''\n    return _git_run('git reset {0}'.format(opts), cwd=cwd, runas=user)\n\n\ndef stash(cwd, opts=None, user=None):\n    '''\n    Stash changes in the repository checkout\n\n    cwd\n        The path to the Git repository\n\n    opts : None\n        Any additional options to add to the command line\n\n    user : None\n        Run git as a user other than what the minion runs as\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' git.stash /path/to/repo master\n    '''\n    _check_git()\n\n    if not opts:\n        opts = ''\n    return _git_run('git stash {0}'.format(opts), cwd=cwd, runas=user)\n\n\ndef config_set(cwd=None, setting_name=None, setting_value=None, user=None, is_global=False):\n    '''\n    Set a key in the git configuration file (.git/config) of the repository or\n    globally.\n\n    cwd : None\n        Options path to the Git repository\n\n        .. versionchanged:: 2014.7.0\n            Made ``cwd`` optional\n\n    setting_name : None\n        The name of the configuration key to set. Required.\n\n    setting_value : None\n        The (new) value to set. Required.\n\n    user : None\n        Run git as a user other than what the minion runs as\n\n    is_global : False\n        Set to True to use the '--global' flag with 'git config'\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' git.config_set /path/to/repo user.email me@example.com\n    '''\n    if setting_name is None or setting_value is None:\n        raise TypeError('Missing required parameter setting_name for git.config_set')\n    if cwd is None and not is_global:\n        raise SaltInvocationError('Either `is_global` must be set to True or '\n                                  'you must provide `cwd`')\n\n    if is_global:\n        cmd = 'git config --global {0} \"{1}\"'.format(setting_name, setting_value)\n    else:\n        cmd = 'git config {0} \"{1}\"'.format(setting_name, setting_value)\n\n    _check_git()\n\n    return _git_run(cmd, cwd=cwd, runas=user)\n\n\ndef config_get(cwd=None, setting_name=None, user=None):\n    '''\n    Get a key or keys from the git configuration file (.git/config).\n\n    cwd : None\n        Optional path to a Git repository\n\n        .. versionchanged:: 2014.7.0\n            Made ``cwd`` optional\n\n    setting_name : None\n        The name of the configuration key to get. Required.\n\n    user : None\n        Run git as a user other than what the minion runs as\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' git.config_get setting_name=user.email\n        salt '*' git.config_get /path/to/repo user.name arthur\n    '''\n    if setting_name is None:\n        raise TypeError('Missing required parameter setting_name for git.config_get')\n    _check_git()\n\n    return _git_run('git config {0}'.format(setting_name), cwd=cwd, runas=user)\n\n\ndef ls_remote(cwd, repository=\"origin\", branch=\"master\", user=None,\n              identity=None, https_user=None, https_pass=None):\n    '''\n    Returns the upstream hash for any given URL and branch.\n\n    cwd\n        The path to the Git repository\n\n    repository: origin\n        The name of the repository to get the revision from. Can be the name of\n        a remote, an URL, etc.\n\n    branch: master\n        The name of the branch to get the revision from.\n\n    user : none\n        run git as a user other than what the minion runs as\n\n    identity : none\n        a path to a private key to use over ssh\n\n    https_user : None\n        HTTP Basic Auth username for HTTPS (only) clones\n\n        .. versionadded:: 2015.5.0\n\n    https_pass : None\n        HTTP Basic Auth password for HTTPS (only) clones\n\n        .. versionadded:: 2015.5.0\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' git.ls_remote /pat/to/repo origin master\n\n    '''\n    _check_git()\n    repository = _add_http_basic_auth(repository, https_user, https_pass)\n    cmd = ' '.join([\"git\", \"ls-remote\", \"-h\", str(repository), str(branch), \"| cut -f 1\"])\n    return _git_run(cmd, cwd=cwd, runas=user, identity=identity)\n", "target": 0}
{"idx": 866, "func": "import os\nimport os.path\nimport mimetypes\n\nimport requests\nfrom zope.interface import implements\nfrom pyramid.interfaces import ITemplateRenderer\n\n\nclass ReleaseFileRenderer(object):\n    implements(ITemplateRenderer)\n\n    def __init__(self, repository_root):\n        self.repository_root = repository_root\n\n    def __call__(self, value, system):\n\n        if 'request' in system:\n            request = system['request']\n\n            mime, encoding = mimetypes.guess_type(value['filename'])\n            request.response_content_type = mime\n            if encoding:\n                request.response_encoding = encoding\n\n            f = os.path.join(self.repository_root,\n                             value['filename'][0].lower(),\n                             value['filename'])\n\n            if not os.path.exists(f):\n                dir_ = os.path.join(self.repository_root,\n                             value['filename'][0].lower())\n                if not os.path.exists(dir_):\n                    os.makedirs(dir_, 0750)\n\n                if value['url'].startswith('https://pypi.python.org'):\n                    verify = os.path.join(os.path.dirname(__file__), 'pypi.pem')\n                else:\n                    verify = value['url'].startswith('https:')\n\n                resp = requests.get(value['url'], verify=verify)\n                with open(f, 'wb') as rf:\n                    rf.write(resp.content)\n                return resp.content\n            else:\n                data = ''\n                with open(f, 'rb') as rf:\n                    data = ''\n                    while True:\n                        content = rf.read(2<<16)\n                        if not content:\n                            break\n                        data += content\n                return data\n\n\ndef renderer_factory(info):\n    return ReleaseFileRenderer(info.settings['pyshop.repository'])\n", "target": 0}
{"idx": 867, "func": "\"\"\"Tornado handlers for logging into the notebook.\"\"\"\n\n# Copyright (c) Jupyter Development Team.\n# Distributed under the terms of the Modified BSD License.\n\nimport re\nimport os\n\ntry:\n    from urllib.parse import urlparse # Py 3\nexcept ImportError:\n    from urlparse import urlparse # Py 2\nimport uuid\n\nfrom tornado.escape import url_escape\n\nfrom .security import passwd_check, set_password\n\nfrom ..base.handlers import IPythonHandler\n\n\nclass LoginHandler(IPythonHandler):\n    \"\"\"The basic tornado login handler\n\n    authenticates with a hashed password from the configuration.\n    \"\"\"\n    def _render(self, message=None):\n        self.write(self.render_template('login.html',\n                next=url_escape(self.get_argument('next', default=self.base_url)),\n                message=message,\n        ))\n\n    def _redirect_safe(self, url, default=None):\n        \"\"\"Redirect if url is on our PATH\n\n        Full-domain redirects are allowed if they pass our CORS origin checks.\n\n        Otherwise use default (self.base_url if unspecified).\n        \"\"\"\n        if default is None:\n            default = self.base_url\n        if not url.startswith(self.base_url):\n            # require that next_url be absolute path within our path\n            allow = False\n            # OR pass our cross-origin check\n            if '://' in url:\n                # if full URL, run our cross-origin check:\n                parsed = urlparse(url.lower())\n                origin = '%s://%s' % (parsed.scheme, parsed.netloc)\n                if self.allow_origin:\n                    allow = self.allow_origin == origin\n                elif self.allow_origin_pat:\n                    allow = bool(self.allow_origin_pat.match(origin))\n            if not allow:\n                # not allowed, use default\n                self.log.warning(\"Not allowing login redirect to %r\" % url)\n                url = default\n        self.redirect(url)\n\n    def get(self):\n        if self.current_user:\n            next_url = self.get_argument('next', default=self.base_url)\n            self._redirect_safe(next_url)\n        else:\n            self._render()\n\n    @property\n    def hashed_password(self):\n        return self.password_from_settings(self.settings)\n\n    def passwd_check(self, a, b):\n        return passwd_check(a, b)\n    \n    def post(self):\n        typed_password = self.get_argument('password', default=u'')\n        new_password = self.get_argument('new_password', default=u'')\n\n\n        \n        if self.get_login_available(self.settings):\n            if self.passwd_check(self.hashed_password, typed_password) and not new_password:\n                self.set_login_cookie(self, uuid.uuid4().hex)\n            elif self.token and self.token == typed_password:\n                self.set_login_cookie(self, uuid.uuid4().hex)\n                if new_password and self.settings.get('allow_password_change'):\n                    config_dir = self.settings.get('config_dir')\n                    config_file = os.path.join(config_dir, 'jupyter_notebook_config.json')\n                    set_password(new_password, config_file=config_file)\n                    self.log.info(\"Wrote hashed password to %s\" % config_file)\n            else:\n                self.set_status(401)\n                self._render(message={'error': 'Invalid credentials'})\n                return\n\n\n        next_url = self.get_argument('next', default=self.base_url)\n        self._redirect_safe(next_url)\n\n    @classmethod\n    def set_login_cookie(cls, handler, user_id=None):\n        \"\"\"Call this on handlers to set the login cookie for success\"\"\"\n        cookie_options = handler.settings.get('cookie_options', {})\n        cookie_options.setdefault('httponly', True)\n        # tornado <4.2 has a bug that considers secure==True as soon as\n        # 'secure' kwarg is passed to set_secure_cookie\n        if handler.settings.get('secure_cookie', handler.request.protocol == 'https'):\n            cookie_options.setdefault('secure', True)\n        cookie_options.setdefault('path', handler.base_url)\n        handler.set_secure_cookie(handler.cookie_name, user_id, **cookie_options)\n        return user_id\n\n    auth_header_pat = re.compile('token\\s+(.+)', re.IGNORECASE)\n\n    @classmethod\n    def get_token(cls, handler):\n        \"\"\"Get the user token from a request\n\n        Default:\n\n        - in URL parameters: ?token=<token>\n        - in header: Authorization: token <token>\n        \"\"\"\n\n        user_token = handler.get_argument('token', '')\n        if not user_token:\n            # get it from Authorization header\n            m = cls.auth_header_pat.match(handler.request.headers.get('Authorization', ''))\n            if m:\n                user_token = m.group(1)\n        return user_token\n\n    @classmethod\n    def should_check_origin(cls, handler):\n        \"\"\"Should the Handler check for CORS origin validation?\n\n        Origin check should be skipped for token-authenticated requests.\n\n        Returns:\n        - True, if Handler must check for valid CORS origin.\n        - False, if Handler should skip origin check since requests are token-authenticated.\n        \"\"\"\n        return not cls.is_token_authenticated(handler)\n\n    @classmethod\n    def is_token_authenticated(cls, handler):\n        \"\"\"Returns True if handler has been token authenticated. Otherwise, False.\n\n        Login with a token is used to signal certain things, such as:\n\n        - permit access to REST API\n        - xsrf protection\n        - skip origin-checks for scripts\n        \"\"\"\n        if getattr(handler, '_user_id', None) is None:\n            # ensure get_user has been called, so we know if we're token-authenticated\n            handler.get_current_user()\n        return getattr(handler, '_token_authenticated', False)\n\n    @classmethod\n    def get_user(cls, handler):\n        \"\"\"Called by handlers.get_current_user for identifying the current user.\n\n        See tornado.web.RequestHandler.get_current_user for details.\n        \"\"\"\n        # Can't call this get_current_user because it will collide when\n        # called on LoginHandler itself.\n        if getattr(handler, '_user_id', None):\n            return handler._user_id\n        user_id = cls.get_user_token(handler)\n        if user_id is None:\n            get_secure_cookie_kwargs  = handler.settings.get('get_secure_cookie_kwargs', {})\n            user_id = handler.get_secure_cookie(handler.cookie_name, **get_secure_cookie_kwargs )\n        else:\n            cls.set_login_cookie(handler, user_id)\n            # Record that the current request has been authenticated with a token.\n            # Used in is_token_authenticated above.\n            handler._token_authenticated = True\n        if user_id is None:\n            # If an invalid cookie was sent, clear it to prevent unnecessary\n            # extra warnings. But don't do this on a request with *no* cookie,\n            # because that can erroneously log you out (see gh-3365)\n            if handler.get_cookie(handler.cookie_name) is not None:\n                handler.log.warning(\"Clearing invalid/expired login cookie %s\", handler.cookie_name)\n                handler.clear_login_cookie()\n            if not handler.login_available:\n                # Completely insecure! No authentication at all.\n                # No need to warn here, though; validate_security will have already done that.\n                user_id = 'anonymous'\n\n        # cache value for future retrievals on the same request\n        handler._user_id = user_id\n        return user_id\n\n    @classmethod\n    def get_user_token(cls, handler):\n        \"\"\"Identify the user based on a token in the URL or Authorization header\n        \n        Returns:\n        - uuid if authenticated\n        - None if not\n        \"\"\"\n        token = handler.token\n        if not token:\n            return\n        # check login token from URL argument or Authorization header\n        user_token = cls.get_token(handler)\n        authenticated = False\n        if user_token == token:\n            # token-authenticated, set the login cookie\n            handler.log.debug(\"Accepting token-authenticated connection from %s\", handler.request.remote_ip)\n            authenticated = True\n\n        if authenticated:\n            return uuid.uuid4().hex\n        else:\n            return None\n\n\n    @classmethod\n    def validate_security(cls, app, ssl_options=None):\n        \"\"\"Check the notebook application's security.\n\n        Show messages, or abort if necessary, based on the security configuration.\n        \"\"\"\n        if not app.ip:\n            warning = \"WARNING: The notebook server is listening on all IP addresses\"\n            if ssl_options is None:\n                app.log.warning(warning + \" and not using encryption. This \"\n                    \"is not recommended.\")\n            if not app.password and not app.token:\n                app.log.warning(warning + \" and not using authentication. \"\n                    \"This is highly insecure and not recommended.\")\n        else:\n            if not app.password and not app.token:\n                app.log.warning(\n                    \"All authentication is disabled.\"\n                    \"  Anyone who can connect to this server will be able to run code.\")\n\n    @classmethod\n    def password_from_settings(cls, settings):\n        \"\"\"Return the hashed password from the tornado settings.\n\n        If there is no configured password, an empty string will be returned.\n        \"\"\"\n        return settings.get('password', u'')\n\n    @classmethod\n    def get_login_available(cls, settings):\n        \"\"\"Whether this LoginHandler is needed - and therefore whether the login page should be displayed.\"\"\"\n        return bool(cls.password_from_settings(settings) or settings.get('token'))\n", "target": 1}
{"idx": 868, "func": "from configparser import RawConfigParser\nfrom attic.remote import cache_if_remote\nimport msgpack\nimport os\nfrom binascii import hexlify\nimport shutil\n\nfrom .helpers import Error, get_cache_dir, decode_dict, st_mtime_ns, unhexlify, UpgradableLock, int_to_bigint, \\\n    bigint_to_int\nfrom .hashindex import ChunkIndex\n\n\nclass Cache(object):\n    \"\"\"Client Side cache\n    \"\"\"\n    class RepositoryReplay(Error):\n        \"\"\"Cache is newer than repository, refusing to continue\"\"\"\n\n    def __init__(self, repository, key, manifest, path=None, sync=True):\n        self.timestamp = None\n        self.txn_active = False\n        self.repository = repository\n        self.key = key\n        self.manifest = manifest\n        self.path = path or os.path.join(get_cache_dir(), hexlify(repository.id).decode('ascii'))\n        if not os.path.exists(self.path):\n            self.create()\n        self.open()\n        if sync and self.manifest.id != self.manifest_id:\n            # If repository is older than the cache something fishy is going on\n            if self.timestamp and self.timestamp > manifest.timestamp:\n                raise self.RepositoryReplay()\n            self.sync()\n            self.commit()\n\n    def __del__(self):\n        self.close()\n\n    def create(self):\n        \"\"\"Create a new empty cache at `path`\n        \"\"\"\n        os.makedirs(self.path)\n        with open(os.path.join(self.path, 'README'), 'w') as fd:\n            fd.write('This is an Attic cache')\n        config = RawConfigParser()\n        config.add_section('cache')\n        config.set('cache', 'version', '1')\n        config.set('cache', 'repository', hexlify(self.repository.id).decode('ascii'))\n        config.set('cache', 'manifest', '')\n        with open(os.path.join(self.path, 'config'), 'w') as fd:\n            config.write(fd)\n        ChunkIndex().write(os.path.join(self.path, 'chunks').encode('utf-8'))\n        with open(os.path.join(self.path, 'files'), 'w') as fd:\n            pass  # empty file\n\n    def open(self):\n        if not os.path.isdir(self.path):\n            raise Exception('%s Does not look like an Attic cache' % self.path)\n        self.lock = UpgradableLock(os.path.join(self.path, 'config'), exclusive=True)\n        self.rollback()\n        self.config = RawConfigParser()\n        self.config.read(os.path.join(self.path, 'config'))\n        if self.config.getint('cache', 'version') != 1:\n            raise Exception('%s Does not look like an Attic cache')\n        self.id = self.config.get('cache', 'repository')\n        self.manifest_id = unhexlify(self.config.get('cache', 'manifest'))\n        self.timestamp = self.config.get('cache', 'timestamp', fallback=None)\n        self.chunks = ChunkIndex.read(os.path.join(self.path, 'chunks').encode('utf-8'))\n        self.files = None\n\n    def close(self):\n        self.lock.release()\n\n    def _read_files(self):\n        self.files = {}\n        self._newest_mtime = 0\n        with open(os.path.join(self.path, 'files'), 'rb') as fd:\n            u = msgpack.Unpacker(use_list=True)\n            while True:\n                data = fd.read(64 * 1024)\n                if not data:\n                    break\n                u.feed(data)\n                for path_hash, item in u:\n                    item[0] += 1\n                    self.files[path_hash] = msgpack.packb(item)\n\n    def begin_txn(self):\n        # Initialize transaction snapshot\n        txn_dir = os.path.join(self.path, 'txn.tmp')\n        os.mkdir(txn_dir)\n        shutil.copy(os.path.join(self.path, 'config'), txn_dir)\n        shutil.copy(os.path.join(self.path, 'chunks'), txn_dir)\n        shutil.copy(os.path.join(self.path, 'files'), txn_dir)\n        os.rename(os.path.join(self.path, 'txn.tmp'),\n                  os.path.join(self.path, 'txn.active'))\n        self.txn_active = True\n\n    def commit(self):\n        \"\"\"Commit transaction\n        \"\"\"\n        if not self.txn_active:\n            return\n        if self.files is not None:\n            with open(os.path.join(self.path, 'files'), 'wb') as fd:\n                for path_hash, item in self.files.items():\n                    # Discard cached files with the newest mtime to avoid\n                    # issues with filesystem snapshots and mtime precision\n                    item = msgpack.unpackb(item)\n                    if item[0] < 10 and bigint_to_int(item[3]) < self._newest_mtime:\n                        msgpack.pack((path_hash, item), fd)\n        self.config.set('cache', 'manifest', hexlify(self.manifest.id).decode('ascii'))\n        self.config.set('cache', 'timestamp', self.manifest.timestamp)\n        with open(os.path.join(self.path, 'config'), 'w') as fd:\n            self.config.write(fd)\n        self.chunks.write(os.path.join(self.path, 'chunks').encode('utf-8'))\n        os.rename(os.path.join(self.path, 'txn.active'),\n                  os.path.join(self.path, 'txn.tmp'))\n        shutil.rmtree(os.path.join(self.path, 'txn.tmp'))\n        self.txn_active = False\n\n    def rollback(self):\n        \"\"\"Roll back partial and aborted transactions\n        \"\"\"\n        # Remove partial transaction\n        if os.path.exists(os.path.join(self.path, 'txn.tmp')):\n            shutil.rmtree(os.path.join(self.path, 'txn.tmp'))\n        # Roll back active transaction\n        txn_dir = os.path.join(self.path, 'txn.active')\n        if os.path.exists(txn_dir):\n            shutil.copy(os.path.join(txn_dir, 'config'), self.path)\n            shutil.copy(os.path.join(txn_dir, 'chunks'), self.path)\n            shutil.copy(os.path.join(txn_dir, 'files'), self.path)\n            os.rename(txn_dir, os.path.join(self.path, 'txn.tmp'))\n            if os.path.exists(os.path.join(self.path, 'txn.tmp')):\n                shutil.rmtree(os.path.join(self.path, 'txn.tmp'))\n        self.txn_active = False\n\n    def sync(self):\n        \"\"\"Initializes cache by fetching and reading all archive indicies\n        \"\"\"\n        def add(id, size, csize):\n            try:\n                count, size, csize = self.chunks[id]\n                self.chunks[id] = count + 1, size, csize\n            except KeyError:\n                self.chunks[id] = 1, size, csize\n        self.begin_txn()\n        print('Initializing cache...')\n        self.chunks.clear()\n        unpacker = msgpack.Unpacker()\n        repository = cache_if_remote(self.repository)\n        for name, info in self.manifest.archives.items():\n            archive_id = info[b'id']\n            cdata = repository.get(archive_id)\n            data = self.key.decrypt(archive_id, cdata)\n            add(archive_id, len(data), len(cdata))\n            archive = msgpack.unpackb(data)\n            if archive[b'version'] != 1:\n                raise Exception('Unknown archive metadata version')\n            decode_dict(archive, (b'name',))\n            print('Analyzing archive:', archive[b'name'])\n            for key, chunk in zip(archive[b'items'], repository.get_many(archive[b'items'])):\n                data = self.key.decrypt(key, chunk)\n                add(key, len(data), len(chunk))\n                unpacker.feed(data)\n                for item in unpacker:\n                    if b'chunks' in item:\n                        for chunk_id, size, csize in item[b'chunks']:\n                            add(chunk_id, size, csize)\n\n    def add_chunk(self, id, data, stats):\n        if not self.txn_active:\n            self.begin_txn()\n        if self.seen_chunk(id):\n            return self.chunk_incref(id, stats)\n        size = len(data)\n        data = self.key.encrypt(data)\n        csize = len(data)\n        self.repository.put(id, data, wait=False)\n        self.chunks[id] = (1, size, csize)\n        stats.update(size, csize, True)\n        return id, size, csize\n\n    def seen_chunk(self, id):\n        return self.chunks.get(id, (0, 0, 0))[0]\n\n    def chunk_incref(self, id, stats):\n        if not self.txn_active:\n            self.begin_txn()\n        count, size, csize = self.chunks[id]\n        self.chunks[id] = (count + 1, size, csize)\n        stats.update(size, csize, False)\n        return id, size, csize\n\n    def chunk_decref(self, id, stats):\n        if not self.txn_active:\n            self.begin_txn()\n        count, size, csize = self.chunks[id]\n        if count == 1:\n            del self.chunks[id]\n            self.repository.delete(id, wait=False)\n            stats.update(-size, -csize, True)\n        else:\n            self.chunks[id] = (count - 1, size, csize)\n            stats.update(-size, -csize, False)\n\n    def file_known_and_unchanged(self, path_hash, st):\n        if self.files is None:\n            self._read_files()\n        entry = self.files.get(path_hash)\n        if not entry:\n            return None\n        entry = msgpack.unpackb(entry)\n        if entry[2] == st.st_size and bigint_to_int(entry[3]) == st_mtime_ns(st) and entry[1] == st.st_ino:\n            # reset entry age\n            entry[0] = 0\n            self.files[path_hash] = msgpack.packb(entry)\n            return entry[4]\n        else:\n            return None\n\n    def memorize_file(self, path_hash, st, ids):\n        # Entry: Age, inode, size, mtime, chunk ids\n        mtime_ns = st_mtime_ns(st)\n        self.files[path_hash] = msgpack.packb((0, st.st_ino, st.st_size, int_to_bigint(mtime_ns), ids))\n        self._newest_mtime = max(self._newest_mtime, mtime_ns)\n", "target": 1}
{"idx": 869, "func": "\"\"\"\n.. module: security_monkey.sso.views\n    :platform: Unix\n    :copyright: (c) 2015 by Netflix Inc., see AUTHORS for more\n    :license: Apache, see LICENSE for more details.\n.. moduleauthor:: Patrick Kelley <patrick@netflix.com>\n\"\"\"\nimport jwt\nimport base64\nimport requests\n\nfrom flask import Blueprint, current_app, redirect, request\n\nfrom flask.ext.restful import reqparse, Resource, Api\nfrom flask.ext.principal import Identity, identity_changed\nfrom flask_login import login_user\n\ntry:\n    from onelogin.saml2.auth import OneLogin_Saml2_Auth\n    from onelogin.saml2.utils import OneLogin_Saml2_Utils\n    onelogin_import_success = True\nexcept ImportError:\n    onelogin_import_success = False\n\nfrom .service import fetch_token_header_payload, get_rsa_public_key\n\nfrom security_monkey.datastore import User\nfrom security_monkey import db, rbac\n\nfrom urlparse import urlparse\n\nmod = Blueprint('sso', __name__)\napi = Api(mod)\n\n\nfrom flask_security.utils import validate_redirect_url\n\n\nclass Ping(Resource):\n    \"\"\"\n    This class serves as an example of how one might implement an SSO provider for use with Security Monkey. In\n    this example we use a OpenIDConnect authentication flow, that is essentially OAuth2 underneath.\n    \"\"\"\n    decorators = [rbac.allow([\"anonymous\"], [\"GET\", \"POST\"])]\n    def __init__(self):\n        self.reqparse = reqparse.RequestParser()\n        super(Ping, self).__init__()\n\n    def get(self):\n        return self.post()\n\n    def post(self):\n        if \"ping\" not in current_app.config.get(\"ACTIVE_PROVIDERS\"):\n            return \"Ping is not enabled in the config.  See the ACTIVE_PROVIDERS section.\", 404\n\n        default_state = 'clientId,{client_id},redirectUri,{redirectUri},return_to,{return_to}'.format(\n            client_id=current_app.config.get('PING_CLIENT_ID'),\n            redirectUri=current_app.config.get('PING_REDIRECT_URI'),\n            return_to=current_app.config.get('WEB_PATH')\n        )\n        self.reqparse.add_argument('code', type=str, required=True)\n        self.reqparse.add_argument('state', type=str, required=False, default=default_state)\n\n        args = self.reqparse.parse_args()\n        client_id = args['state'].split(',')[1]\n        redirect_uri = args['state'].split(',')[3]\n        return_to = args['state'].split(',')[5]\n\n        if not validate_redirect_url(return_to):\n            return_to = current_app.config.get('WEB_PATH')\n\n        # take the information we have received from the provider to create a new request\n        params = {\n            'client_id': client_id,\n            'grant_type': 'authorization_code',\n            'scope': 'openid email profile address',\n            'redirect_uri': redirect_uri,\n            'code': args['code']\n        }\n\n        # you can either discover these dynamically or simply configure them\n        access_token_url = current_app.config.get('PING_ACCESS_TOKEN_URL')\n        user_api_url = current_app.config.get('PING_USER_API_URL')\n\n        # the secret and cliendId will be given to you when you signup for the provider\n        basic = base64.b64encode(bytes('{0}:{1}'.format(client_id, current_app.config.get(\"PING_SECRET\"))))\n        headers = {'Authorization': 'Basic {0}'.format(basic.decode('utf-8'))}\n\n        # exchange authorization code for access token.\n        r = requests.post(access_token_url, headers=headers, params=params)\n        id_token = r.json()['id_token']\n        access_token = r.json()['access_token']\n\n        # fetch token public key\n        header_data = fetch_token_header_payload(id_token)[0]\n        jwks_url = current_app.config.get('PING_JWKS_URL')\n\n        # retrieve the key material as specified by the token header\n        r = requests.get(jwks_url)\n        for key in r.json()['keys']:\n            if key['kid'] == header_data['kid']:\n                secret = get_rsa_public_key(key['n'], key['e'])\n                algo = header_data['alg']\n                break\n        else:\n            return dict(message='Key not found'), 403\n\n        # validate your token based on the key it was signed with\n        try:\n            current_app.logger.debug(id_token)\n            current_app.logger.debug(secret)\n            current_app.logger.debug(algo)\n            jwt.decode(id_token, secret.decode('utf-8'), algorithms=[algo], audience=client_id)\n        except jwt.DecodeError:\n            return dict(message='Token is invalid'), 403\n        except jwt.ExpiredSignatureError:\n            return dict(message='Token has expired'), 403\n        except jwt.InvalidTokenError:\n            return dict(message='Token is invalid'), 403\n\n        user_params = dict(access_token=access_token, schema='profile')\n\n        # retrieve information about the current user.\n        r = requests.get(user_api_url, params=user_params)\n        profile = r.json()\n\n        user = User.query.filter(User.email==profile['email']).first()\n\n        # if we get an sso user create them an account\n        if not user:\n            user = User(\n                email=profile['email'],\n                active=True,\n                role='View'\n                # profile_picture=profile.get('thumbnailPhotoUrl')\n            )\n            db.session.add(user)\n            db.session.commit()\n            db.session.refresh(user)\n\n        # Tell Flask-Principal the identity changed\n        identity_changed.send(current_app._get_current_object(), identity=Identity(user.id))\n        login_user(user)\n\n        return redirect(return_to, code=302)\n\n\nclass Google(Resource):\n    decorators = [rbac.allow([\"anonymous\"], [\"GET\", \"POST\"])]\n    def __init__(self):\n        self.reqparse = reqparse.RequestParser()\n        super(Google, self).__init__()\n\n    def get(self):\n        return self.post()\n\n    def post(self):\n        if \"google\" not in current_app.config.get(\"ACTIVE_PROVIDERS\"):\n            return \"Google is not enabled in the config.  See the ACTIVE_PROVIDERS section.\", 404\n\n        default_state = 'clientId,{client_id},redirectUri,{redirectUri},return_to,{return_to}'.format(\n            client_id=current_app.config.get(\"GOOGLE_CLIENT_ID\"),\n            redirectUri=api.url_for(Google),\n            return_to=current_app.config.get('WEB_PATH')\n        )\n        self.reqparse.add_argument('code', type=str, required=True)\n        self.reqparse.add_argument('state', type=str, required=False, default=default_state)\n\n        args = self.reqparse.parse_args()\n        client_id = args['state'].split(',')[1]\n        redirect_uri = args['state'].split(',')[3]\n        return_to = args['state'].split(',')[5]\n\n        if not validate_redirect_url(return_to):\n            return_to = current_app.config.get('WEB_PATH')\n\n        access_token_url = 'https://accounts.google.com/o/oauth2/token'\n        people_api_url = 'https://www.googleapis.com/plus/v1/people/me/openIdConnect'\n\n        args = self.reqparse.parse_args()\n\n        # Step 1. Exchange authorization code for access token\n        payload = {\n            'client_id': client_id,\n            'grant_type': 'authorization_code',\n            'redirect_uri': redirect_uri,\n            'code': args['code'],\n            'client_secret': current_app.config.get('GOOGLE_SECRET')\n        }\n\n        r = requests.post(access_token_url, data=payload)\n        token = r.json()\n\n        # Step 1bis. Validate (some information of) the id token (if necessary)\n        google_hosted_domain = current_app.config.get(\"GOOGLE_HOSTED_DOMAIN\")\n        if google_hosted_domain is not None:\n            current_app.logger.debug('We need to verify that the token was issued for this hosted domain: %s ' % (google_hosted_domain))\n\n\t    # Get the JSON Web Token\n            id_token = r.json()['id_token']\n            current_app.logger.debug('The id_token is: %s' % (id_token))\n\n            # Extract the payload\n            (header_data, payload_data) = fetch_token_header_payload(id_token)\n            current_app.logger.debug('id_token.header_data: %s' % (header_data))\n            current_app.logger.debug('id_token.payload_data: %s' % (payload_data))\n\n            token_hd = payload_data.get('hd')\n            if token_hd != google_hosted_domain:\n                current_app.logger.debug('Verification failed: %s != %s' % (token_hd, google_hosted_domain))\n                return dict(message='Token is invalid %s' % token), 403\n            current_app.logger.debug('Verification passed')\n\n        # Step 2. Retrieve information about the current user\n        headers = {'Authorization': 'Bearer {0}'.format(token['access_token'])}\n\n        r = requests.get(people_api_url, headers=headers)\n        profile = r.json()\n\n        user = User.query.filter(User.email == profile['email']).first()\n\n        # if we get an sso user create them an account\n        if not user:\n            user = User(\n                email=profile['email'],\n                active=True,\n                role='View'\n                # profile_picture=profile.get('thumbnailPhotoUrl')\n            )\n            db.session.add(user)\n            db.session.commit()\n            db.session.refresh(user)\n\n        # Tell Flask-Principal the identity changed\n        identity_changed.send(current_app._get_current_object(), identity=Identity(user.id))\n        login_user(user)\n\n        return redirect(return_to, code=302)\n\n\nclass OneLogin(Resource):\n    decorators = [rbac.allow([\"anonymous\"], [\"GET\", \"POST\"])]\n    def __init__(self):\n        self.reqparse = reqparse.RequestParser()\n        self.req = OneLogin.prepare_from_flask_request(request)\n        super(OneLogin, self).__init__()\n\n    @staticmethod\n    def prepare_from_flask_request(req):\n        url_data = urlparse(req.url)\n        return {\n            'http_host': req.host,\n            'server_port': url_data.port,\n            'script_name': req.path,\n            'get_data': req.args.copy(),\n            'post_data': req.form.copy(),\n            'https': (\"on\" if current_app.config.get(\"ONELOGIN_HTTPS\") else \"off\")\n    }\n\n    def get(self):\n        return self.post()\n\n    def _consumer(self, auth):\n        auth.process_response()\n        errors = auth.get_errors()\n        if not errors:\n            if auth.is_authenticated():\n                return True\n            else:\n                return False\n        else:\n            current_app.logger.error('Error processing %s' % (', '.join(errors)))\n            return False\n\n    def post(self):\n        if \"onelogin\" not in current_app.config.get(\"ACTIVE_PROVIDERS\"):\n            return \"Onelogin is not enabled in the config.  See the ACTIVE_PROVIDERS section.\", 404\n        auth = OneLogin_Saml2_Auth(self.req, current_app.config.get(\"ONELOGIN_SETTINGS\"))\n\n        self.reqparse.add_argument('return_to', required=False, default=current_app.config.get('WEB_PATH'))\n        self.reqparse.add_argument('acs', required=False)\n        self.reqparse.add_argument('sls', required=False)\n\n        args = self.reqparse.parse_args()\n\n        return_to = args['return_to']\n\n        if args['acs'] != None:\n            # valids the SAML response and checks if successfully authenticated\n            if self._consumer(auth):\n                email = auth.get_attribute(current_app.config.get(\"ONELOGIN_EMAIL_FIELD\"))[0]\n                user = User.query.filter(User.email == email).first()\n\n                # if we get an sso user create them an account\n                if not user:\n                    user = User(\n                        email=email,\n                        active=True,\n                        role=current_app.config.get('ONELOGIN_DEFAULT_ROLE')\n                        # profile_picture=profile.get('thumbnailPhotoUrl')\n                    )\n                    db.session.add(user)\n                    db.session.commit()\n                    db.session.refresh(user)\n\n                # Tell Flask-Principal the identity changed\n                identity_changed.send(current_app._get_current_object(), identity=Identity(user.id))\n                login_user(user)\n\n                self_url = OneLogin_Saml2_Utils.get_self_url(self.req)\n                if 'RelayState' in request.form and self_url != request.form['RelayState']:\n                    return redirect(auth.redirect_to(request.form['RelayState']), code=302)\n                else:  \n                    return redirect(current_app.config.get('BASE_URL'), code=302)\n            else:\n                return dict(message='OneLogin authentication failed.'), 403\n        elif args['sls'] != None:\n            return dict(message='OneLogin SLS not implemented yet.'), 405\n        else:\n            return redirect(auth.login(return_to=return_to))\n\n\nclass Providers(Resource):\n    decorators = [rbac.allow([\"anonymous\"], [\"GET\"])]\n    def __init__(self):\n        super(Providers, self).__init__()\n\n    def get(self):\n        active_providers = []\n\n        for provider in current_app.config.get(\"ACTIVE_PROVIDERS\"):\n            provider = provider.lower()\n\n            if provider == \"ping\":\n                active_providers.append({\n                    'name': current_app.config.get(\"PING_NAME\"),\n                    'url': current_app.config.get('PING_REDIRECT_URI'),\n                    'redirectUri': current_app.config.get(\"PING_REDIRECT_URI\"),\n                    'clientId': current_app.config.get(\"PING_CLIENT_ID\"),\n                    'responseType': 'code',\n                    'scope': ['openid', 'profile', 'email'],\n                    'scopeDelimiter': ' ',\n                    'authorizationEndpoint': current_app.config.get(\"PING_AUTH_ENDPOINT\"),\n                    'requiredUrlParams': ['scope'],\n                    'type': '2.0'\n                })\n            elif provider == \"google\":\n                google_provider = {\n                    'name': 'google',\n                    'clientId': current_app.config.get(\"GOOGLE_CLIENT_ID\"),\n                    'url': api.url_for(Google, _external=True, _scheme='https'),\n                    'redirectUri': api.url_for(Google, _external=True, _scheme='https'),\n                    'authorizationEndpoint': current_app.config.get(\"GOOGLE_AUTH_ENDPOINT\"),\n                    'scope': ['openid email'],\n                    'responseType': 'code'\n                }\n                google_hosted_domain = current_app.config.get(\"GOOGLE_HOSTED_DOMAIN\")\n                if google_hosted_domain is not None:\n                    google_provider['hd'] = google_hosted_domain\n                active_providers.append(google_provider)\n            elif provider == \"onelogin\":\n                active_providers.append({\n                    'name': 'OneLogin',\n                    'authorizationEndpoint': api.url_for(OneLogin)\n                })\n            else:\n                raise Exception(\"Unknown authentication provider: {0}\".format(provider))\n\n        return active_providers\n\n\napi.add_resource(Ping, '/auth/ping', endpoint='ping')\napi.add_resource(Google, '/auth/google', endpoint='google')\napi.add_resource(Providers, '/auth/providers', endpoint='providers')\n\nif onelogin_import_success:\n    api.add_resource(OneLogin, '/auth/onelogin', endpoint='onelogin')\n", "target": 1}
{"idx": 870, "func": "# vim: tabstop=4 shiftwidth=4 softtabstop=4\n\n# Copyright 2010-2011 OpenStack, LLC\n# All Rights Reserved.\n#\n#    Licensed under the Apache License, Version 2.0 (the \"License\"); you may\n#    not use this file except in compliance with the License. You may obtain\n#    a copy of the License at\n#\n#         http://www.apache.org/licenses/LICENSE-2.0\n#\n#    Unless required by applicable law or agreed to in writing, software\n#    distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n#    License for the specific language governing permissions and limitations\n#    under the License.\n\n\"\"\"Common utilities used in testing\"\"\"\n\nimport errno\nimport functools\nimport os\nimport random\nimport socket\nimport StringIO\nimport subprocess\nimport unittest\n\nimport nose.plugins.skip\n\nfrom glance.common import config\nfrom glance.common import utils\nfrom glance.common import wsgi\nfrom glance import context\nfrom glance.openstack.common import cfg\n\nCONF = cfg.CONF\n\n\ndef get_isolated_test_env():\n    \"\"\"\n    Returns a tuple of (test_id, test_dir) that is unique\n    for an isolated test environment. Also ensure the test_dir\n    is created.\n    \"\"\"\n    test_id = random.randint(0, 100000)\n    test_tmp_dir = os.getenv('GLANCE_TEST_TMP_DIR', '/tmp')\n    test_dir = os.path.join(test_tmp_dir, \"test.%d\" % test_id)\n    utils.safe_mkdirs(test_dir)\n    return test_id, test_dir\n\n\nclass BaseTestCase(unittest.TestCase):\n\n    def setUp(self):\n        super(BaseTestCase, self).setUp()\n\n        #NOTE(bcwaldon): parse_args has to be called to register certain\n        # command-line options - specifically we need config_dir for\n        # the following policy tests\n        config.parse_args(args=[])\n\n    def tearDown(self):\n        super(BaseTestCase, self).tearDown()\n        CONF.reset()\n\n    def config(self, **kw):\n        \"\"\"\n        Override some configuration values.\n\n        The keyword arguments are the names of configuration options to\n        override and their values.\n\n        If a group argument is supplied, the overrides are applied to\n        the specified configuration option group.\n\n        All overrides are automatically cleared at the end of the current\n        test by the tearDown() method.\n        \"\"\"\n        group = kw.pop('group', None)\n        for k, v in kw.iteritems():\n            CONF.set_override(k, v, group)\n\n\nclass skip_test(object):\n    \"\"\"Decorator that skips a test.\"\"\"\n    def __init__(self, msg):\n        self.message = msg\n\n    def __call__(self, func):\n        def _skipper(*args, **kw):\n            \"\"\"Wrapped skipper function.\"\"\"\n            raise nose.SkipTest(self.message)\n        _skipper.__name__ = func.__name__\n        _skipper.__doc__ = func.__doc__\n        return _skipper\n\n\nclass skip_if(object):\n    \"\"\"Decorator that skips a test if condition is true.\"\"\"\n    def __init__(self, condition, msg):\n        self.condition = condition\n        self.message = msg\n\n    def __call__(self, func):\n        def _skipper(*args, **kw):\n            \"\"\"Wrapped skipper function.\"\"\"\n            if self.condition:\n                raise nose.SkipTest(self.message)\n            func(*args, **kw)\n        _skipper.__name__ = func.__name__\n        _skipper.__doc__ = func.__doc__\n        return _skipper\n\n\nclass skip_unless(object):\n    \"\"\"Decorator that skips a test if condition is not true.\"\"\"\n    def __init__(self, condition, msg):\n        self.condition = condition\n        self.message = msg\n\n    def __call__(self, func):\n        def _skipper(*args, **kw):\n            \"\"\"Wrapped skipper function.\"\"\"\n            if not self.condition:\n                raise nose.SkipTest(self.message)\n            func(*args, **kw)\n        _skipper.__name__ = func.__name__\n        _skipper.__doc__ = func.__doc__\n        return _skipper\n\n\nclass requires(object):\n    \"\"\"Decorator that initiates additional test setup/teardown.\"\"\"\n    def __init__(self, setup=None, teardown=None):\n        self.setup = setup\n        self.teardown = teardown\n\n    def __call__(self, func):\n        def _runner(*args, **kw):\n            if self.setup:\n                self.setup(args[0])\n            func(*args, **kw)\n            if self.teardown:\n                self.teardown(args[0])\n        _runner.__name__ = func.__name__\n        _runner.__doc__ = func.__doc__\n        return _runner\n\n\nclass depends_on_exe(object):\n    \"\"\"Decorator to skip test if an executable is unavailable\"\"\"\n    def __init__(self, exe):\n        self.exe = exe\n\n    def __call__(self, func):\n        def _runner(*args, **kw):\n            cmd = 'which %s' % self.exe\n            exitcode, out, err = execute(cmd, raise_error=False)\n            if exitcode != 0:\n                args[0].disabled_message = 'test requires exe: %s' % self.exe\n                args[0].disabled = True\n            func(*args, **kw)\n        _runner.__name__ = func.__name__\n        _runner.__doc__ = func.__doc__\n        return _runner\n\n\ndef skip_if_disabled(func):\n    \"\"\"Decorator that skips a test if test case is disabled.\"\"\"\n    @functools.wraps(func)\n    def wrapped(*a, **kwargs):\n        func.__test__ = False\n        test_obj = a[0]\n        message = getattr(test_obj, 'disabled_message',\n                          'Test disabled')\n        if getattr(test_obj, 'disabled', False):\n            raise nose.SkipTest(message)\n        func(*a, **kwargs)\n    return wrapped\n\n\ndef execute(cmd,\n            raise_error=True,\n            no_venv=False,\n            exec_env=None,\n            expect_exit=True,\n            expected_exitcode=0,\n            context=None):\n    \"\"\"\n    Executes a command in a subprocess. Returns a tuple\n    of (exitcode, out, err), where out is the string output\n    from stdout and err is the string output from stderr when\n    executing the command.\n\n    :param cmd: Command string to execute\n    :param raise_error: If returncode is not 0 (success), then\n                        raise a RuntimeError? Default: True)\n    :param no_venv: Disable the virtual environment\n    :param exec_env: Optional dictionary of additional environment\n                     variables; values may be callables, which will\n                     be passed the current value of the named\n                     environment variable\n    :param expect_exit: Optional flag true iff timely exit is expected\n    :param expected_exitcode: expected exitcode from the launcher\n    :param context: additional context for error message\n    \"\"\"\n\n    env = os.environ.copy()\n    if exec_env is not None:\n        for env_name, env_val in exec_env.items():\n            if callable(env_val):\n                env[env_name] = env_val(env.get(env_name))\n            else:\n                env[env_name] = env_val\n\n    # If we're asked to omit the virtualenv, and if one is set up,\n    # restore the various environment variables\n    if no_venv and 'VIRTUAL_ENV' in env:\n        # Clip off the first element of PATH\n        env['PATH'] = env['PATH'].split(os.pathsep, 1)[-1]\n        del env['VIRTUAL_ENV']\n\n    # Make sure that we use the programs in the\n    # current source directory's bin/ directory.\n    path_ext = [os.path.join(os.getcwd(), 'bin')]\n\n    # Also jack in the path cmd comes from, if it's absolute\n    executable = cmd.split()[0]\n    if os.path.isabs(executable):\n        path_ext.append(os.path.dirname(executable))\n\n    env['PATH'] = ':'.join(path_ext) + ':' + env['PATH']\n    process = subprocess.Popen(cmd,\n                               shell=True,\n                               stdin=subprocess.PIPE,\n                               stdout=subprocess.PIPE,\n                               stderr=subprocess.PIPE,\n                               env=env)\n    if expect_exit:\n        result = process.communicate()\n        (out, err) = result\n        exitcode = process.returncode\n    else:\n        out = ''\n        err = ''\n        exitcode = 0\n\n    if exitcode != expected_exitcode and raise_error:\n        msg = \"Command %(cmd)s did not succeed. Returned an exit \"\\\n              \"code of %(exitcode)d.\"\\\n              \"\\n\\nSTDOUT: %(out)s\"\\\n              \"\\n\\nSTDERR: %(err)s\" % locals()\n        if context:\n            msg += \"\\n\\nCONTEXT: %s\" % context\n        raise RuntimeError(msg)\n    return exitcode, out, err\n\n\ndef find_executable(cmdname):\n    \"\"\"\n    Searches the path for a given cmdname.  Returns an absolute\n    filename if an executable with the given name exists in the path,\n    or None if one does not.\n\n    :param cmdname: The bare name of the executable to search for\n    \"\"\"\n\n    # Keep an eye out for the possibility of an absolute pathname\n    if os.path.isabs(cmdname):\n        return cmdname\n\n    # Get a list of the directories to search\n    path = ([os.path.join(os.getcwd(), 'bin')] +\n            os.environ['PATH'].split(os.pathsep))\n\n    # Search through each in turn\n    for elem in path:\n        full_path = os.path.join(elem, cmdname)\n        if os.access(full_path, os.X_OK):\n            return full_path\n\n    # No dice...\n    return None\n\n\ndef get_unused_port():\n    \"\"\"\n    Returns an unused port on localhost.\n    \"\"\"\n    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    s.bind(('localhost', 0))\n    addr, port = s.getsockname()\n    s.close()\n    return port\n\n\ndef xattr_writes_supported(path):\n    \"\"\"\n    Returns True if the we can write a file to the supplied\n    path and subsequently write a xattr to that file.\n    \"\"\"\n    try:\n        import xattr\n    except ImportError:\n        return False\n\n    def set_xattr(path, key, value):\n        xattr.setxattr(path, \"user.%s\" % key, str(value))\n\n    # We do a quick attempt to write a user xattr to a temporary file\n    # to check that the filesystem is even enabled to support xattrs\n    fake_filepath = os.path.join(path, 'testing-checkme')\n    result = True\n    with open(fake_filepath, 'wb') as fake_file:\n        fake_file.write(\"XXX\")\n        fake_file.flush()\n    try:\n        set_xattr(fake_filepath, 'hits', '1')\n    except IOError, e:\n        if e.errno == errno.EOPNOTSUPP:\n            result = False\n    else:\n        # Cleanup after ourselves...\n        if os.path.exists(fake_filepath):\n            os.unlink(fake_filepath)\n\n    return result\n\n\ndef minimal_headers(name, public=True):\n    headers = {\n        'Content-Type': 'application/octet-stream',\n        'X-Image-Meta-Name': name,\n        'X-Image-Meta-disk_format': 'raw',\n        'X-Image-Meta-container_format': 'ovf',\n    }\n    if public:\n        headers['X-Image-Meta-Is-Public'] = 'True'\n    return headers\n\n\ndef minimal_add_command(port, name, suffix='', public=True):\n    visibility = 'is_public=True' if public else ''\n    return (\"bin/glance --port=%d add %s\"\n            \" disk_format=raw container_format=ovf\"\n            \" name=%s %s\" % (port, visibility, name, suffix))\n\n\nclass FakeAuthMiddleware(wsgi.Middleware):\n\n    def __init__(self, app, is_admin=False):\n        super(FakeAuthMiddleware, self).__init__(app)\n        self.is_admin = is_admin\n\n    def process_request(self, req):\n        auth_tok = req.headers.get('X-Auth-Token')\n        user = None\n        tenant = None\n        roles = []\n        if auth_tok:\n            user, tenant, role = auth_tok.split(':')\n            if tenant.lower() == 'none':\n                tenant = None\n            roles = [role]\n            req.headers['X-User-Id'] = user\n            req.headers['X-Tenant-Id'] = tenant\n            req.headers['X-Roles'] = role\n            req.headers['X-Identity-Status'] = 'Confirmed'\n        kwargs = {\n            'user': user,\n            'tenant': tenant,\n            'roles': roles,\n            'is_admin': self.is_admin,\n        }\n\n        req.context = context.RequestContext(**kwargs)\n\n\nclass FakeHTTPResponse(object):\n    def __init__(self, status=200, headers=None, data=None, *args, **kwargs):\n        data = data or 'I am a teapot, short and stout\\n'\n        self.data = StringIO.StringIO(data)\n        self.read = self.data.read\n        self.status = status\n        self.headers = headers or {'content-length': len(data)}\n\n    def getheader(self, name, default=None):\n        return self.headers.get(name.lower(), default)\n\n    def getheaders(self):\n        return self.headers or {}\n\n    def read(self, amt):\n        self.data.read(amt)\n", "target": 1}
{"idx": 871, "func": "import getopt\nfrom subprocess import Popen, PIPE\nimport pipes\nimport Bcfg2.Server.Admin\n\nclass Viz(Bcfg2.Server.Admin.MetadataCore):\n    __shorthelp__ = \"Produce graphviz diagrams of metadata structures\"\n    __longhelp__ = (__shorthelp__ + \"\\n\\nbcfg2-admin viz [--includehosts] \"\n                                    \"[--includebundles] [--includekey] \"\n                                    \"[-o output.png] [--raw]\")\n    __usage__ = (\"bcfg2-admin viz [options]\\n\\n\"\n                 \"     %-25s%s\\n\"\n                 \"     %-25s%s\\n\"\n                 \"     %-25s%s\\n\"\n                 \"     %-25s%s\\n\" %\n                (\"-H, --includehosts\",\n                 \"include hosts in the viz output\",\n                 \"-b, --includebundles\",\n                 \"include bundles in the viz output\",\n                 \"-k, --includekey\",\n                 \"show a key for different digraph shapes\",\n                 \"-o, --outfile <file>\",\n                 \"write viz output to an output file\"))\n\n    colors = ['steelblue1', 'chartreuse', 'gold', 'magenta',\n              'indianred1', 'limegreen', 'orange1', 'lightblue2',\n              'green1', 'blue1', 'yellow1', 'darkturquoise', 'gray66']\n    plugin_blacklist = ['DBStats', 'Snapshots', 'Cfg', 'Pkgmgr', 'Packages',\n                        'Rules', 'Account', 'Decisions', 'Deps', 'Git', 'Svn',\n                        'Fossil', 'Bzr', 'Bundler', 'TGenshi', 'SGenshi', 'Base']\n\n    def __init__(self, cfile):\n\n        Bcfg2.Server.Admin.MetadataCore.__init__(self, cfile,\n                                                 self.__usage__,\n                                                 pblacklist=self.plugin_blacklist)\n\n    def __call__(self, args):\n        Bcfg2.Server.Admin.MetadataCore.__call__(self, args)\n        # First get options to the 'viz' subcommand\n        try:\n            opts, args = getopt.getopt(args, 'Hbko:',\n                                       ['includehosts', 'includebundles',\n                                        'includekey', 'outfile='])\n        except getopt.GetoptError, msg:\n            print msg\n\n        #FIXME: is this for --raw?\n        #rset = False\n        hset = False\n        bset = False\n        kset = False\n        outputfile = False\n        for opt, arg in opts:\n            if opt in (\"-H\", \"--includehosts\"):\n                hset = True\n            elif opt in (\"-b\", \"--includebundles\"):\n                bset = True\n            elif opt in (\"-k\", \"--includekey\"):\n                kset = True\n            elif opt in (\"-o\", \"--outfile\"):\n                outputfile = arg\n\n        data = self.Visualize(self.get_repo_path(), hset, bset,\n                              kset, outputfile)\n        if data:\n            print(data)\n        raise SystemExit, 0\n\n    def Visualize(self, repopath, hosts=False,\n                  bundles=False, key=False, output=False):\n        \"\"\"Build visualization of groups file.\"\"\"\n        if output:\n            format = output.split('.')[-1]\n        else:\n            format = 'png'\n\n        cmd = [\"dot\", \"-T\", format]\n        if output:\n            cmd.extend([\"-o\", output])\n        try:\n            dotpipe = Popen(cmd, stdin=PIPE, stdout=PIPE, close_fds=True)\n        except OSError:\n            # on some systems (RHEL 6), you cannot run dot with\n            # shell=True.  on others (Gentoo with Python 2.7), you\n            # must.  In yet others (RHEL 5), either way works.  I have\n            # no idea what the difference is, but it's kind of a PITA.\n            cmd = [\"dot\", \"-T\", pipes.quote(format)]\n            if output:\n                cmd.extend([\"-o\", pipes.quote(output)])\n            dotpipe = Popen(cmd, shell=True,\n                            stdin=PIPE, stdout=PIPE, close_fds=True)\n        try:\n            dotpipe.stdin.write(\"digraph groups {\\n\")\n        except:\n            print \"write to dot process failed. Is graphviz installed?\"\n            raise SystemExit(1)\n        dotpipe.stdin.write('\\trankdir=\"LR\";\\n')\n        dotpipe.stdin.write(self.metadata.viz(hosts, bundles,\n                                                key, self.colors))\n        if key:\n            dotpipe.stdin.write(\"\\tsubgraph cluster_key {\\n\")\n            dotpipe.stdin.write('''\\tstyle=\"filled\";\\n''')\n            dotpipe.stdin.write('''\\tcolor=\"lightblue\";\\n''')\n            dotpipe.stdin.write('''\\tBundle [ shape=\"septagon\" ];\\n''')\n            dotpipe.stdin.write('''\\tGroup [shape=\"ellipse\"];\\n''')\n            dotpipe.stdin.write('''\\tProfile [style=\"bold\", shape=\"ellipse\"];\\n''')\n            dotpipe.stdin.write('''\\tHblock [label=\"Host1|Host2|Host3\", shape=\"record\"];\\n''')\n            dotpipe.stdin.write('''\\tlabel=\"Key\";\\n''')\n            dotpipe.stdin.write(\"\\t}\\n\")\n        dotpipe.stdin.write(\"}\\n\")\n        dotpipe.stdin.close()\n        return dotpipe.stdout.read()\n", "target": 0}
{"idx": 872, "func": "# vim: ft=python fileencoding=utf-8 sts=4 sw=4 et:\n\n# Copyright 2016-2018 Florian Bruhin (The Compiler) <mail@qutebrowser.org>\n#\n# This file is part of qutebrowser.\n#\n# qutebrowser is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# qutebrowser is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with qutebrowser.  If not, see <http://www.gnu.org/licenses/>.\n\n\"\"\"Wrapper over a QWebEngineView.\"\"\"\n\nimport math\nimport functools\nimport re\nimport html as html_utils\n\nfrom PyQt5.QtCore import (pyqtSignal, pyqtSlot, Qt, QEvent, QPoint, QPointF,\n                          QUrl, QTimer, QObject)\nfrom PyQt5.QtGui import QKeyEvent, QIcon\nfrom PyQt5.QtNetwork import QAuthenticator\nfrom PyQt5.QtWidgets import QApplication\nfrom PyQt5.QtWebEngineWidgets import QWebEnginePage, QWebEngineScript\n\nfrom qutebrowser.config import configdata, config\nfrom qutebrowser.browser import browsertab, mouse, shared, webelem\nfrom qutebrowser.browser.webengine import (webview, webengineelem, tabhistory,\n                                           interceptor, webenginequtescheme,\n                                           cookies, webenginedownloads,\n                                           webenginesettings, certificateerror)\nfrom qutebrowser.misc import miscwidgets\nfrom qutebrowser.utils import (usertypes, qtutils, log, javascript, utils,\n                               message, objreg, jinja, debug)\nfrom qutebrowser.qt import sip\n\n\n_qute_scheme_handler = None\n\n\ndef init():\n    \"\"\"Initialize QtWebEngine-specific modules.\"\"\"\n    # For some reason we need to keep a reference, otherwise the scheme handler\n    # won't work...\n    # https://www.riverbankcomputing.com/pipermail/pyqt/2016-September/038075.html\n    global _qute_scheme_handler\n\n    app = QApplication.instance()\n    log.init.debug(\"Initializing qute://* handler...\")\n    _qute_scheme_handler = webenginequtescheme.QuteSchemeHandler(parent=app)\n    _qute_scheme_handler.install(webenginesettings.default_profile)\n    _qute_scheme_handler.install(webenginesettings.private_profile)\n\n    log.init.debug(\"Initializing request interceptor...\")\n    host_blocker = objreg.get('host-blocker')\n    args = objreg.get('args')\n    req_interceptor = interceptor.RequestInterceptor(\n        host_blocker, args=args, parent=app)\n    req_interceptor.install(webenginesettings.default_profile)\n    req_interceptor.install(webenginesettings.private_profile)\n\n    log.init.debug(\"Initializing QtWebEngine downloads...\")\n    download_manager = webenginedownloads.DownloadManager(parent=app)\n    download_manager.install(webenginesettings.default_profile)\n    download_manager.install(webenginesettings.private_profile)\n    objreg.register('webengine-download-manager', download_manager)\n\n    log.init.debug(\"Initializing cookie filter...\")\n    cookies.install_filter(webenginesettings.default_profile)\n    cookies.install_filter(webenginesettings.private_profile)\n\n    # Clear visited links on web history clear\n    hist = objreg.get('web-history')\n    for p in [webenginesettings.default_profile,\n              webenginesettings.private_profile]:\n        hist.history_cleared.connect(p.clearAllVisitedLinks)\n        hist.url_cleared.connect(lambda url, profile=p:\n                                 profile.clearVisitedLinks([url]))\n\n\n# Mapping worlds from usertypes.JsWorld to QWebEngineScript world IDs.\n_JS_WORLD_MAP = {\n    usertypes.JsWorld.main: QWebEngineScript.MainWorld,\n    usertypes.JsWorld.application: QWebEngineScript.ApplicationWorld,\n    usertypes.JsWorld.user: QWebEngineScript.UserWorld,\n    usertypes.JsWorld.jseval: QWebEngineScript.UserWorld + 1,\n}\n\n\nclass WebEngineAction(browsertab.AbstractAction):\n\n    \"\"\"QtWebEngine implementations related to web actions.\"\"\"\n\n    action_class = QWebEnginePage\n    action_base = QWebEnginePage.WebAction\n\n    def exit_fullscreen(self):\n        self._widget.triggerPageAction(QWebEnginePage.ExitFullScreen)\n\n    def save_page(self):\n        \"\"\"Save the current page.\"\"\"\n        self._widget.triggerPageAction(QWebEnginePage.SavePage)\n\n    def show_source(self, pygments=False):\n        if pygments:\n            self._show_source_pygments()\n            return\n\n        try:\n            self._widget.triggerPageAction(QWebEnginePage.ViewSource)\n        except AttributeError:\n            # Qt < 5.8\n            tb = objreg.get('tabbed-browser', scope='window',\n                            window=self._tab.win_id)\n            urlstr = self._tab.url().toString(QUrl.RemoveUserInfo)\n            # The original URL becomes the path of a view-source: URL\n            # (without a host), but query/fragment should stay.\n            url = QUrl('view-source:' + urlstr)\n            tb.tabopen(url, background=False, related=True)\n\n\nclass WebEnginePrinting(browsertab.AbstractPrinting):\n\n    \"\"\"QtWebEngine implementations related to printing.\"\"\"\n\n    def check_pdf_support(self):\n        return True\n\n    def check_printer_support(self):\n        if not hasattr(self._widget.page(), 'print'):\n            raise browsertab.WebTabError(\n                \"Printing is unsupported with QtWebEngine on Qt < 5.8\")\n\n    def check_preview_support(self):\n        raise browsertab.WebTabError(\n            \"Print previews are unsupported with QtWebEngine\")\n\n    def to_pdf(self, filename):\n        self._widget.page().printToPdf(filename)\n\n    def to_printer(self, printer, callback=None):\n        if callback is None:\n            callback = lambda _ok: None\n        self._widget.page().print(printer, callback)\n\n\nclass WebEngineSearch(browsertab.AbstractSearch):\n\n    \"\"\"QtWebEngine implementations related to searching on the page.\n\n    Attributes:\n        _flags: The QWebEnginePage.FindFlags of the last search.\n        _pending_searches: How many searches have been started but not called\n                           back yet.\n    \"\"\"\n\n    def __init__(self, tab, parent=None):\n        super().__init__(tab, parent)\n        self._flags = QWebEnginePage.FindFlags(0)\n        self._pending_searches = 0\n\n    def _find(self, text, flags, callback, caller):\n        \"\"\"Call findText on the widget.\"\"\"\n        self.search_displayed = True\n        self._pending_searches += 1\n\n        def wrapped_callback(found):\n            \"\"\"Wrap the callback to do debug logging.\"\"\"\n            self._pending_searches -= 1\n            if self._pending_searches > 0:\n                # See https://github.com/qutebrowser/qutebrowser/issues/2442\n                # and https://github.com/qt/qtwebengine/blob/5.10/src/core/web_contents_adapter.cpp#L924-L934\n                log.webview.debug(\"Ignoring cancelled search callback with \"\n                                  \"{} pending searches\".format(\n                                      self._pending_searches))\n                return\n\n            if sip.isdeleted(self._widget):\n                # This happens when starting a search, and closing the tab\n                # before results arrive.\n                log.webview.debug(\"Ignoring finished search for deleted \"\n                                  \"widget\")\n                return\n\n            found_text = 'found' if found else \"didn't find\"\n            if flags:\n                flag_text = 'with flags {}'.format(debug.qflags_key(\n                    QWebEnginePage, flags, klass=QWebEnginePage.FindFlag))\n            else:\n                flag_text = ''\n            log.webview.debug(' '.join([caller, found_text, text, flag_text])\n                              .strip())\n\n            if callback is not None:\n                callback(found)\n            self.finished.emit(found)\n\n        self._widget.findText(text, flags, wrapped_callback)\n\n    def search(self, text, *, ignore_case='never', reverse=False,\n               result_cb=None):\n        # Don't go to next entry on duplicate search\n        if self.text == text and self.search_displayed:\n            log.webview.debug(\"Ignoring duplicate search request\"\n                              \" for {}\".format(text))\n            return\n\n        self.text = text\n        self._flags = QWebEnginePage.FindFlags(0)\n        if self._is_case_sensitive(ignore_case):\n            self._flags |= QWebEnginePage.FindCaseSensitively\n        if reverse:\n            self._flags |= QWebEnginePage.FindBackward\n\n        self._find(text, self._flags, result_cb, 'search')\n\n    def clear(self):\n        if self.search_displayed:\n            self.cleared.emit()\n        self.search_displayed = False\n        self._widget.findText('')\n\n    def prev_result(self, *, result_cb=None):\n        # The int() here makes sure we get a copy of the flags.\n        flags = QWebEnginePage.FindFlags(int(self._flags))\n        if flags & QWebEnginePage.FindBackward:\n            flags &= ~QWebEnginePage.FindBackward\n        else:\n            flags |= QWebEnginePage.FindBackward\n        self._find(self.text, flags, result_cb, 'prev_result')\n\n    def next_result(self, *, result_cb=None):\n        self._find(self.text, self._flags, result_cb, 'next_result')\n\n\nclass WebEngineCaret(browsertab.AbstractCaret):\n\n    \"\"\"QtWebEngine implementations related to moving the cursor/selection.\"\"\"\n\n    def _flags(self):\n        \"\"\"Get flags to pass to JS.\"\"\"\n        flags = set()\n        if qtutils.version_check('5.7.1', compiled=False):\n            flags.add('filter-prefix')\n        if utils.is_windows:\n            flags.add('windows')\n        return list(flags)\n\n    @pyqtSlot(usertypes.KeyMode)\n    def _on_mode_entered(self, mode):\n        if mode != usertypes.KeyMode.caret:\n            return\n\n        if self._tab.search.search_displayed:\n            # We are currently in search mode.\n            # convert the search to a blue selection so we can operate on it\n            # https://bugreports.qt.io/browse/QTBUG-60673\n            self._tab.search.clear()\n\n        self._tab.run_js_async(\n            javascript.assemble('caret', 'setFlags', self._flags()))\n\n        self._js_call('setInitialCursor', callback=self._selection_cb)\n\n    def _selection_cb(self, enabled):\n        \"\"\"Emit selection_toggled based on setInitialCursor.\"\"\"\n        if enabled is None:\n            log.webview.debug(\"Ignoring selection status None\")\n            return\n        self.selection_toggled.emit(enabled)\n\n    @pyqtSlot(usertypes.KeyMode)\n    def _on_mode_left(self, mode):\n        if mode != usertypes.KeyMode.caret:\n            return\n\n        self.drop_selection()\n        self._js_call('disableCaret')\n\n    def move_to_next_line(self, count=1):\n        self._js_call('moveDown', count)\n\n    def move_to_prev_line(self, count=1):\n        self._js_call('moveUp', count)\n\n    def move_to_next_char(self, count=1):\n        self._js_call('moveRight', count)\n\n    def move_to_prev_char(self, count=1):\n        self._js_call('moveLeft', count)\n\n    def move_to_end_of_word(self, count=1):\n        self._js_call('moveToEndOfWord', count)\n\n    def move_to_next_word(self, count=1):\n        self._js_call('moveToNextWord', count)\n\n    def move_to_prev_word(self, count=1):\n        self._js_call('moveToPreviousWord', count)\n\n    def move_to_start_of_line(self):\n        self._js_call('moveToStartOfLine')\n\n    def move_to_end_of_line(self):\n        self._js_call('moveToEndOfLine')\n\n    def move_to_start_of_next_block(self, count=1):\n        self._js_call('moveToStartOfNextBlock', count)\n\n    def move_to_start_of_prev_block(self, count=1):\n        self._js_call('moveToStartOfPrevBlock', count)\n\n    def move_to_end_of_next_block(self, count=1):\n        self._js_call('moveToEndOfNextBlock', count)\n\n    def move_to_end_of_prev_block(self, count=1):\n        self._js_call('moveToEndOfPrevBlock', count)\n\n    def move_to_start_of_document(self):\n        self._js_call('moveToStartOfDocument')\n\n    def move_to_end_of_document(self):\n        self._js_call('moveToEndOfDocument')\n\n    def toggle_selection(self):\n        self._js_call('toggleSelection', callback=self.selection_toggled.emit)\n\n    def drop_selection(self):\n        self._js_call('dropSelection')\n\n    def selection(self, callback):\n        # Not using selectedText() as WORKAROUND for\n        # https://bugreports.qt.io/browse/QTBUG-53134\n        # Even on Qt 5.10 selectedText() seems to work poorly, see\n        # https://github.com/qutebrowser/qutebrowser/issues/3523\n        self._tab.run_js_async(javascript.assemble('caret', 'getSelection'),\n                               callback)\n\n    def _follow_selected_cb_wrapped(self, js_elem, tab):\n        try:\n            self._follow_selected_cb(js_elem, tab)\n        finally:\n            self.follow_selected_done.emit()\n\n    def _follow_selected_cb(self, js_elem, tab):\n        \"\"\"Callback for javascript which clicks the selected element.\n\n        Args:\n            js_elem: The element serialized from javascript.\n            tab: Open in a new tab.\n        \"\"\"\n        if js_elem is None:\n            return\n\n        if js_elem == \"focused\":\n            # we had a focused element, not a selected one. Just send <enter>\n            self._follow_enter(tab)\n            return\n\n        assert isinstance(js_elem, dict), js_elem\n        elem = webengineelem.WebEngineElement(js_elem, tab=self._tab)\n        if tab:\n            click_type = usertypes.ClickTarget.tab\n        else:\n            click_type = usertypes.ClickTarget.normal\n\n        # Only click if we see a link\n        if elem.is_link():\n            log.webview.debug(\"Found link in selection, clicking. ClickTarget \"\n                              \"{}, elem {}\".format(click_type, elem))\n            try:\n                elem.click(click_type)\n            except webelem.Error as e:\n                message.error(str(e))\n\n    def follow_selected(self, *, tab=False):\n        if self._tab.search.search_displayed:\n            # We are currently in search mode.\n            # let's click the link via a fake-click\n            # https://bugreports.qt.io/browse/QTBUG-60673\n            self._tab.search.clear()\n\n            log.webview.debug(\"Clicking a searched link via fake key press.\")\n            # send a fake enter, clicking the orange selection box\n            self._follow_enter(tab)\n        else:\n            # click an existing blue selection\n            js_code = javascript.assemble('webelem',\n                                          'find_selected_focused_link')\n            self._tab.run_js_async(\n                js_code,\n                lambda jsret: self._follow_selected_cb_wrapped(jsret, tab))\n\n    def _js_call(self, command, *args, callback=None):\n        code = javascript.assemble('caret', command, *args)\n        self._tab.run_js_async(code, callback)\n\n\nclass WebEngineScroller(browsertab.AbstractScroller):\n\n    \"\"\"QtWebEngine implementations related to scrolling.\"\"\"\n\n    def __init__(self, tab, parent=None):\n        super().__init__(tab, parent)\n        self._args = objreg.get('args')\n        self._pos_perc = (0, 0)\n        self._pos_px = QPoint()\n        self._at_bottom = False\n\n    def _init_widget(self, widget):\n        super()._init_widget(widget)\n        page = widget.page()\n        page.scrollPositionChanged.connect(self._update_pos)\n\n    def _repeated_key_press(self, key, count=1, modifier=Qt.NoModifier):\n        \"\"\"Send count fake key presses to this scroller's WebEngineTab.\"\"\"\n        for _ in range(min(count, 1000)):\n            self._tab.key_press(key, modifier)\n\n    @pyqtSlot(QPointF)\n    def _update_pos(self, pos):\n        \"\"\"Update the scroll position attributes when it changed.\"\"\"\n        self._pos_px = pos.toPoint()\n        contents_size = self._widget.page().contentsSize()\n\n        scrollable_x = contents_size.width() - self._widget.width()\n        if scrollable_x == 0:\n            perc_x = 0\n        else:\n            try:\n                perc_x = min(100, round(100 / scrollable_x * pos.x()))\n            except ValueError:\n                # https://github.com/qutebrowser/qutebrowser/issues/3219\n                log.misc.debug(\"Got ValueError!\")\n                log.misc.debug(\"contents_size.width(): {}\".format(\n                    contents_size.width()))\n                log.misc.debug(\"self._widget.width(): {}\".format(\n                    self._widget.width()))\n                log.misc.debug(\"scrollable_x: {}\".format(scrollable_x))\n                log.misc.debug(\"pos.x(): {}\".format(pos.x()))\n                raise\n\n        scrollable_y = contents_size.height() - self._widget.height()\n        if scrollable_y == 0:\n            perc_y = 0\n        else:\n            perc_y = min(100, round(100 / scrollable_y * pos.y()))\n\n        self._at_bottom = math.ceil(pos.y()) >= scrollable_y\n\n        if (self._pos_perc != (perc_x, perc_y) or\n                'no-scroll-filtering' in self._args.debug_flags):\n            self._pos_perc = perc_x, perc_y\n            self.perc_changed.emit(*self._pos_perc)\n\n    def pos_px(self):\n        return self._pos_px\n\n    def pos_perc(self):\n        return self._pos_perc\n\n    def to_perc(self, x=None, y=None):\n        js_code = javascript.assemble('scroll', 'to_perc', x, y)\n        self._tab.run_js_async(js_code)\n\n    def to_point(self, point):\n        js_code = javascript.assemble('window', 'scroll', point.x(), point.y())\n        self._tab.run_js_async(js_code)\n\n    def to_anchor(self, name):\n        url = self._tab.url()\n        url.setFragment(name)\n        self._tab.openurl(url)\n\n    def delta(self, x=0, y=0):\n        self._tab.run_js_async(javascript.assemble('window', 'scrollBy', x, y))\n\n    def delta_page(self, x=0, y=0):\n        js_code = javascript.assemble('scroll', 'delta_page', x, y)\n        self._tab.run_js_async(js_code)\n\n    def up(self, count=1):\n        self._repeated_key_press(Qt.Key_Up, count)\n\n    def down(self, count=1):\n        self._repeated_key_press(Qt.Key_Down, count)\n\n    def left(self, count=1):\n        self._repeated_key_press(Qt.Key_Left, count)\n\n    def right(self, count=1):\n        self._repeated_key_press(Qt.Key_Right, count)\n\n    def top(self):\n        self._tab.key_press(Qt.Key_Home)\n\n    def bottom(self):\n        self._tab.key_press(Qt.Key_End)\n\n    def page_up(self, count=1):\n        self._repeated_key_press(Qt.Key_PageUp, count)\n\n    def page_down(self, count=1):\n        self._repeated_key_press(Qt.Key_PageDown, count)\n\n    def at_top(self):\n        return self.pos_px().y() == 0\n\n    def at_bottom(self):\n        return self._at_bottom\n\n\nclass WebEngineHistory(browsertab.AbstractHistory):\n\n    \"\"\"QtWebEngine implementations related to page history.\"\"\"\n\n    def current_idx(self):\n        return self._history.currentItemIndex()\n\n    def can_go_back(self):\n        return self._history.canGoBack()\n\n    def can_go_forward(self):\n        return self._history.canGoForward()\n\n    def _item_at(self, i):\n        return self._history.itemAt(i)\n\n    def _go_to_item(self, item):\n        self._tab.predicted_navigation.emit(item.url())\n        self._history.goToItem(item)\n\n    def serialize(self):\n        if not qtutils.version_check('5.9', compiled=False):\n            # WORKAROUND for\n            # https://github.com/qutebrowser/qutebrowser/issues/2289\n            # Don't use the history's currentItem here, because of\n            # https://bugreports.qt.io/browse/QTBUG-59599 and because it doesn't\n            # contain view-source.\n            scheme = self._tab.url().scheme()\n            if scheme in ['view-source', 'chrome']:\n                raise browsertab.WebTabError(\"Can't serialize special URL!\")\n        return qtutils.serialize(self._history)\n\n    def deserialize(self, data):\n        return qtutils.deserialize(data, self._history)\n\n    def load_items(self, items):\n        if items:\n            self._tab.predicted_navigation.emit(items[-1].url)\n\n        stream, _data, cur_data = tabhistory.serialize(items)\n        qtutils.deserialize_stream(stream, self._history)\n\n        @pyqtSlot()\n        def _on_load_finished():\n            self._tab.scroller.to_point(cur_data['scroll-pos'])\n            self._tab.load_finished.disconnect(_on_load_finished)\n\n        if cur_data is not None:\n            if 'zoom' in cur_data:\n                self._tab.zoom.set_factor(cur_data['zoom'])\n            if ('scroll-pos' in cur_data and\n                    self._tab.scroller.pos_px() == QPoint(0, 0)):\n                self._tab.load_finished.connect(_on_load_finished)\n\n\nclass WebEngineZoom(browsertab.AbstractZoom):\n\n    \"\"\"QtWebEngine implementations related to zooming.\"\"\"\n\n    def _set_factor_internal(self, factor):\n        self._widget.setZoomFactor(factor)\n\n\nclass WebEngineElements(browsertab.AbstractElements):\n\n    \"\"\"QtWebEngine implemementations related to elements on the page.\"\"\"\n\n    def _js_cb_multiple(self, callback, js_elems):\n        \"\"\"Handle found elements coming from JS and call the real callback.\n\n        Args:\n            callback: The callback to call with the found elements.\n                      Called with None if there was an error.\n            js_elems: The elements serialized from javascript.\n        \"\"\"\n        if js_elems is None:\n            callback(None)\n            return\n\n        elems = []\n        for js_elem in js_elems:\n            elem = webengineelem.WebEngineElement(js_elem, tab=self._tab)\n            elems.append(elem)\n        callback(elems)\n\n    def _js_cb_single(self, callback, js_elem):\n        \"\"\"Handle a found focus elem coming from JS and call the real callback.\n\n        Args:\n            callback: The callback to call with the found element.\n                      Called with a WebEngineElement or None.\n            js_elem: The element serialized from javascript.\n        \"\"\"\n        debug_str = ('None' if js_elem is None\n                     else utils.elide(repr(js_elem), 1000))\n        log.webview.debug(\"Got element from JS: {}\".format(debug_str))\n\n        if js_elem is None:\n            callback(None)\n        else:\n            elem = webengineelem.WebEngineElement(js_elem, tab=self._tab)\n            callback(elem)\n\n    def find_css(self, selector, callback, *, only_visible=False):\n        js_code = javascript.assemble('webelem', 'find_css', selector,\n                                      only_visible)\n        js_cb = functools.partial(self._js_cb_multiple, callback)\n        self._tab.run_js_async(js_code, js_cb)\n\n    def find_id(self, elem_id, callback):\n        js_code = javascript.assemble('webelem', 'find_id', elem_id)\n        js_cb = functools.partial(self._js_cb_single, callback)\n        self._tab.run_js_async(js_code, js_cb)\n\n    def find_focused(self, callback):\n        js_code = javascript.assemble('webelem', 'find_focused')\n        js_cb = functools.partial(self._js_cb_single, callback)\n        self._tab.run_js_async(js_code, js_cb)\n\n    def find_at_pos(self, pos, callback):\n        assert pos.x() >= 0, pos\n        assert pos.y() >= 0, pos\n        pos /= self._tab.zoom.factor()\n        js_code = javascript.assemble('webelem', 'find_at_pos',\n                                      pos.x(), pos.y())\n        js_cb = functools.partial(self._js_cb_single, callback)\n        self._tab.run_js_async(js_code, js_cb)\n\n\nclass WebEngineAudio(browsertab.AbstractAudio):\n\n    \"\"\"QtWebEngine implemementations related to audio/muting.\n\n    Attributes:\n        _overridden: Whether the user toggled muting manually.\n                     If that's the case, we leave it alone.\n    \"\"\"\n\n    def __init__(self, tab, parent=None):\n        super().__init__(tab, parent)\n        self._overridden = False\n\n    def _connect_signals(self):\n        page = self._widget.page()\n        page.audioMutedChanged.connect(self.muted_changed)\n        page.recentlyAudibleChanged.connect(self.recently_audible_changed)\n        self._tab.url_changed.connect(self._on_url_changed)\n        config.instance.changed.connect(self._on_config_changed)\n\n    def set_muted(self, muted: bool, override: bool = False):\n        self._overridden = override\n        page = self._widget.page()\n        page.setAudioMuted(muted)\n\n    def is_muted(self):\n        page = self._widget.page()\n        return page.isAudioMuted()\n\n    def is_recently_audible(self):\n        page = self._widget.page()\n        return page.recentlyAudible()\n\n    @pyqtSlot(QUrl)\n    def _on_url_changed(self, url):\n        if self._overridden:\n            return\n        mute = config.instance.get('content.mute', url=url)\n        self.set_muted(mute)\n\n    @config.change_filter('content.mute')\n    def _on_config_changed(self):\n        self._on_url_changed(self._tab.url())\n\n\nclass _WebEnginePermissions(QObject):\n\n    \"\"\"Handling of various permission-related signals.\"\"\"\n\n    _abort_questions = pyqtSignal()\n\n    def __init__(self, tab, parent=None):\n        super().__init__(parent)\n        self._tab = tab\n        self._widget = None\n\n    def connect_signals(self):\n        \"\"\"Connect related signals from the QWebEnginePage.\"\"\"\n        page = self._widget.page()\n        page.fullScreenRequested.connect(\n            self._on_fullscreen_requested)\n        page.featurePermissionRequested.connect(\n            self._on_feature_permission_requested)\n\n        if qtutils.version_check('5.11'):\n            page.quotaRequested.connect(\n                self._on_quota_requested)\n            page.registerProtocolHandlerRequested.connect(\n                self._on_register_protocol_handler_requested)\n\n        self._tab.shutting_down.connect(self._abort_questions)\n        self._tab.load_started.connect(self._abort_questions)\n\n    @pyqtSlot('QWebEngineFullScreenRequest')\n    def _on_fullscreen_requested(self, request):\n        request.accept()\n        on = request.toggleOn()\n\n        self._tab.data.fullscreen = on\n        self._tab.fullscreen_requested.emit(on)\n        if on:\n            notification = miscwidgets.FullscreenNotification(self._widget)\n            notification.show()\n            notification.set_timeout(3000)\n\n    @pyqtSlot(QUrl, 'QWebEnginePage::Feature')\n    def _on_feature_permission_requested(self, url, feature):\n        \"\"\"Ask the user for approval for geolocation/media/etc..\"\"\"\n        options = {\n            QWebEnginePage.Geolocation: 'content.geolocation',\n            QWebEnginePage.MediaAudioCapture: 'content.media_capture',\n            QWebEnginePage.MediaVideoCapture: 'content.media_capture',\n            QWebEnginePage.MediaAudioVideoCapture: 'content.media_capture',\n        }\n        messages = {\n            QWebEnginePage.Geolocation: 'access your location',\n            QWebEnginePage.MediaAudioCapture: 'record audio',\n            QWebEnginePage.MediaVideoCapture: 'record video',\n            QWebEnginePage.MediaAudioVideoCapture: 'record audio/video',\n        }\n        try:\n            options.update({\n                QWebEnginePage.MouseLock:\n                    'content.mouse_lock',\n            })\n            messages.update({\n                QWebEnginePage.MouseLock:\n                    'hide your mouse pointer',\n            })\n        except AttributeError:\n            # Added in Qt 5.8\n            pass\n        try:\n            options.update({\n                QWebEnginePage.DesktopVideoCapture:\n                    'content.desktop_capture',\n                QWebEnginePage.DesktopAudioVideoCapture:\n                    'content.desktop_capture',\n            })\n            messages.update({\n                QWebEnginePage.DesktopVideoCapture:\n                    'capture your desktop',\n                QWebEnginePage.DesktopAudioVideoCapture:\n                    'capture your desktop and audio',\n            })\n        except AttributeError:\n            # Added in Qt 5.10\n            pass\n\n        assert options.keys() == messages.keys()\n\n        page = self._widget.page()\n\n        if feature not in options:\n            log.webview.error(\"Unhandled feature permission {}\".format(\n                debug.qenum_key(QWebEnginePage, feature)))\n            page.setFeaturePermission(url, feature,\n                                      QWebEnginePage.PermissionDeniedByUser)\n            return\n\n        yes_action = functools.partial(\n            page.setFeaturePermission, url, feature,\n            QWebEnginePage.PermissionGrantedByUser)\n        no_action = functools.partial(\n            page.setFeaturePermission, url, feature,\n            QWebEnginePage.PermissionDeniedByUser)\n\n        question = shared.feature_permission(\n            url=url, option=options[feature], msg=messages[feature],\n            yes_action=yes_action, no_action=no_action,\n            abort_on=[self._abort_questions])\n\n        if question is not None:\n            page.featurePermissionRequestCanceled.connect(\n                functools.partial(self._on_feature_permission_cancelled,\n                                  question, url, feature))\n\n    def _on_feature_permission_cancelled(self, question, url, feature,\n                                         cancelled_url, cancelled_feature):\n        \"\"\"Slot invoked when a feature permission request was cancelled.\n\n        To be used with functools.partial.\n        \"\"\"\n        if url == cancelled_url and feature == cancelled_feature:\n            try:\n                question.abort()\n            except RuntimeError:\n                # The question could already be deleted, e.g. because it was\n                # aborted after a loadStarted signal.\n                pass\n\n    def _on_quota_requested(self, request):\n        size = utils.format_size(request.requestedSize())\n        shared.feature_permission(\n            url=request.origin(),\n            option='content.persistent_storage',\n            msg='use {} of persistent storage'.format(size),\n            yes_action=request.accept, no_action=request.reject,\n            abort_on=[self._abort_questions],\n            blocking=True)\n\n    def _on_register_protocol_handler_requested(self, request):\n        shared.feature_permission(\n            url=request.origin(),\n            option='content.register_protocol_handler',\n            msg='open all {} links'.format(request.scheme()),\n            yes_action=request.accept, no_action=request.reject,\n            abort_on=[self._abort_questions],\n            blocking=True)\n\n\nclass _WebEngineScripts(QObject):\n\n    def __init__(self, tab, parent=None):\n        super().__init__(parent)\n        self._tab = tab\n        self._widget = None\n        self._greasemonkey = objreg.get('greasemonkey')\n\n    def connect_signals(self):\n        \"\"\"Connect signals to our private slots.\"\"\"\n        config.instance.changed.connect(self._on_config_changed)\n\n        self._tab.search.cleared.connect(functools.partial(\n            self._update_stylesheet, searching=False))\n        self._tab.search.finished.connect(self._update_stylesheet)\n\n    @pyqtSlot(str)\n    def _on_config_changed(self, option):\n        if option in ['scrolling.bar', 'content.user_stylesheets']:\n            self._init_stylesheet()\n            self._update_stylesheet()\n\n    @pyqtSlot(bool)\n    def _update_stylesheet(self, searching=False):\n        \"\"\"Update the custom stylesheet in existing tabs.\"\"\"\n        css = shared.get_user_stylesheet(searching=searching)\n        code = javascript.assemble('stylesheet', 'set_css', css)\n        self._tab.run_js_async(code)\n\n    def _inject_early_js(self, name, js_code, *,\n                         world=QWebEngineScript.ApplicationWorld,\n                         subframes=False):\n        \"\"\"Inject the given script to run early on a page load.\n\n        This runs the script both on DocumentCreation and DocumentReady as on\n        some internal pages, DocumentCreation will not work.\n\n        That is a WORKAROUND for https://bugreports.qt.io/browse/QTBUG-66011\n        \"\"\"\n        scripts = self._widget.page().scripts()\n        for injection in ['creation', 'ready']:\n            injection_points = {\n                'creation': QWebEngineScript.DocumentCreation,\n                'ready': QWebEngineScript.DocumentReady,\n            }\n            script = QWebEngineScript()\n            script.setInjectionPoint(injection_points[injection])\n            script.setSourceCode(js_code)\n            script.setWorldId(world)\n            script.setRunsOnSubFrames(subframes)\n            script.setName('_qute_{}_{}'.format(name, injection))\n            scripts.insert(script)\n\n    def _remove_early_js(self, name):\n        \"\"\"Remove an early QWebEngineScript.\"\"\"\n        scripts = self._widget.page().scripts()\n        for injection in ['creation', 'ready']:\n            full_name = '_qute_{}_{}'.format(name, injection)\n            script = scripts.findScript(full_name)\n            if not script.isNull():\n                scripts.remove(script)\n\n    def init(self):\n        \"\"\"Initialize global qutebrowser JavaScript.\"\"\"\n        js_code = javascript.wrap_global(\n            'scripts',\n            utils.read_file('javascript/scroll.js'),\n            utils.read_file('javascript/webelem.js'),\n            utils.read_file('javascript/caret.js'),\n        )\n        self._inject_early_js('js',\n                              utils.read_file('javascript/print.js'),\n                              subframes=True,\n                              world=QWebEngineScript.MainWorld)\n        # FIXME:qtwebengine what about subframes=True?\n        self._inject_early_js('js', js_code, subframes=True)\n        self._init_stylesheet()\n\n        # The Greasemonkey metadata block support in QtWebEngine only starts at\n        # Qt 5.8. With 5.7.1, we need to inject the scripts ourselves in\n        # response to urlChanged.\n        if not qtutils.version_check('5.8'):\n            self._tab.url_changed.connect(\n                self._inject_greasemonkey_scripts_for_url)\n        else:\n            self._greasemonkey.scripts_reloaded.connect(\n                self._inject_all_greasemonkey_scripts)\n            self._inject_all_greasemonkey_scripts()\n\n    def _init_stylesheet(self):\n        \"\"\"Initialize custom stylesheets.\n\n        Partially inspired by QupZilla:\n        https://github.com/QupZilla/qupzilla/blob/v2.0/src/lib/app/mainapplication.cpp#L1063-L1101\n        \"\"\"\n        self._remove_early_js('stylesheet')\n        css = shared.get_user_stylesheet()\n        js_code = javascript.wrap_global(\n            'stylesheet',\n            utils.read_file('javascript/stylesheet.js'),\n            javascript.assemble('stylesheet', 'set_css', css),\n        )\n        self._inject_early_js('stylesheet', js_code, subframes=True)\n\n    @pyqtSlot(QUrl)\n    def _inject_greasemonkey_scripts_for_url(self, url):\n        matching_scripts = self._greasemonkey.scripts_for(url)\n        self._inject_greasemonkey_scripts(\n            matching_scripts.start, QWebEngineScript.DocumentCreation, True)\n        self._inject_greasemonkey_scripts(\n            matching_scripts.end, QWebEngineScript.DocumentReady, False)\n        self._inject_greasemonkey_scripts(\n            matching_scripts.idle, QWebEngineScript.Deferred, False)\n\n    @pyqtSlot()\n    def _inject_all_greasemonkey_scripts(self):\n        scripts = self._greasemonkey.all_scripts()\n        self._inject_greasemonkey_scripts(scripts)\n\n    def _inject_greasemonkey_scripts(self, scripts=None, injection_point=None,\n                                     remove_first=True):\n        \"\"\"Register user JavaScript files with the current tab.\n\n        Args:\n            scripts: A list of GreasemonkeyScripts, or None to add all\n                     known by the Greasemonkey subsystem.\n            injection_point: The QWebEngineScript::InjectionPoint stage\n                             to inject the script into, None to use\n                             auto-detection.\n            remove_first: Whether to remove all previously injected\n                          scripts before adding these ones.\n        \"\"\"\n        if sip.isdeleted(self._widget):\n            return\n\n        # Since we are inserting scripts into a per-tab collection,\n        # rather than just injecting scripts on page load, we need to\n        # make sure we replace existing scripts, not just add new ones.\n        # While, taking care not to remove any other scripts that might\n        # have been added elsewhere, like the one for stylesheets.\n        page_scripts = self._widget.page().scripts()\n        if remove_first:\n            for script in page_scripts.toList():\n                if script.name().startswith(\"GM-\"):\n                    log.greasemonkey.debug('Removing script: {}'\n                                           .format(script.name()))\n                    removed = page_scripts.remove(script)\n                    assert removed, script.name()\n\n        if not scripts:\n            return\n\n        for script in scripts:\n            new_script = QWebEngineScript()\n            try:\n                world = int(script.jsworld)\n            except ValueError:\n                try:\n                    world = _JS_WORLD_MAP[usertypes.JsWorld[\n                        script.jsworld.lower()]]\n                except KeyError:\n                    log.greasemonkey.error(\n                        \"script {} has invalid value for '@qute-js-world'\"\n                        \": {}\".format(script.name, script.jsworld))\n                    continue\n            new_script.setWorldId(world)\n            new_script.setSourceCode(script.code())\n            new_script.setName(\"GM-{}\".format(script.name))\n            new_script.setRunsOnSubFrames(script.runs_on_sub_frames)\n            # Override the @run-at value parsed by QWebEngineScript if desired.\n            if injection_point:\n                new_script.setInjectionPoint(injection_point)\n            log.greasemonkey.debug('adding script: {}'\n                                   .format(new_script.name()))\n            page_scripts.insert(new_script)\n\n\nclass WebEngineTab(browsertab.AbstractTab):\n\n    \"\"\"A QtWebEngine tab in the browser.\n\n    Signals:\n        _load_finished_fake:\n            Used in place of unreliable loadFinished\n    \"\"\"\n\n    # WORKAROUND for https://bugreports.qt.io/browse/QTBUG-65223\n    _load_finished_fake = pyqtSignal(bool)\n\n    def __init__(self, *, win_id, mode_manager, private, parent=None):\n        super().__init__(win_id=win_id, mode_manager=mode_manager,\n                         private=private, parent=parent)\n        widget = webview.WebEngineView(tabdata=self.data, win_id=win_id,\n                                       private=private)\n        self.history = WebEngineHistory(tab=self)\n        self.scroller = WebEngineScroller(tab=self, parent=self)\n        self.caret = WebEngineCaret(mode_manager=mode_manager,\n                                    tab=self, parent=self)\n        self.zoom = WebEngineZoom(tab=self, parent=self)\n        self.search = WebEngineSearch(tab=self, parent=self)\n        self.printing = WebEnginePrinting(tab=self)\n        self.elements = WebEngineElements(tab=self)\n        self.action = WebEngineAction(tab=self)\n        self.audio = WebEngineAudio(tab=self, parent=self)\n        self._permissions = _WebEnginePermissions(tab=self, parent=self)\n        self._scripts = _WebEngineScripts(tab=self, parent=self)\n        # We're assigning settings in _set_widget\n        self.settings = webenginesettings.WebEngineSettings(settings=None)\n        self._set_widget(widget)\n        self._connect_signals()\n        self.backend = usertypes.Backend.QtWebEngine\n        self._child_event_filter = None\n        self._saved_zoom = None\n        self._reload_url = None\n        self._scripts.init()\n\n    def _set_widget(self, widget):\n        # pylint: disable=protected-access\n        super()._set_widget(widget)\n        self._permissions._widget = widget\n        self._scripts._widget = widget\n\n    def _install_event_filter(self):\n        fp = self._widget.focusProxy()\n        if fp is not None:\n            fp.installEventFilter(self._mouse_event_filter)\n        self._child_event_filter = mouse.ChildEventFilter(\n            eventfilter=self._mouse_event_filter, widget=self._widget,\n            win_id=self.win_id, parent=self)\n        self._widget.installEventFilter(self._child_event_filter)\n\n    @pyqtSlot()\n    def _restore_zoom(self):\n        if sip.isdeleted(self._widget):\n            # https://github.com/qutebrowser/qutebrowser/issues/3498\n            return\n        if self._saved_zoom is None:\n            return\n        self.zoom.set_factor(self._saved_zoom)\n        self._saved_zoom = None\n\n    def openurl(self, url, *, predict=True):\n        \"\"\"Open the given URL in this tab.\n\n        Arguments:\n            url: The QUrl to open.\n            predict: If set to False, predicted_navigation is not emitted.\n        \"\"\"\n        if sip.isdeleted(self._widget):\n            # https://github.com/qutebrowser/qutebrowser/issues/3896\n            return\n        self._saved_zoom = self.zoom.factor()\n        self._openurl_prepare(url, predict=predict)\n        self._widget.load(url)\n\n    def url(self, requested=False):\n        page = self._widget.page()\n        if requested:\n            return page.requestedUrl()\n        else:\n            return page.url()\n\n    def dump_async(self, callback, *, plain=False):\n        if plain:\n            self._widget.page().toPlainText(callback)\n        else:\n            self._widget.page().toHtml(callback)\n\n    def run_js_async(self, code, callback=None, *, world=None):\n        if world is None:\n            world_id = QWebEngineScript.ApplicationWorld\n        elif isinstance(world, int):\n            world_id = world\n        else:\n            world_id = _JS_WORLD_MAP[world]\n\n        if callback is None:\n            self._widget.page().runJavaScript(code, world_id)\n        else:\n            self._widget.page().runJavaScript(code, world_id, callback)\n\n    def shutdown(self):\n        self.shutting_down.emit()\n        self.action.exit_fullscreen()\n        self._widget.shutdown()\n\n    def reload(self, *, force=False):\n        if force:\n            action = QWebEnginePage.ReloadAndBypassCache\n        else:\n            action = QWebEnginePage.Reload\n        self._widget.triggerPageAction(action)\n\n    def stop(self):\n        self._widget.stop()\n\n    def title(self):\n        return self._widget.title()\n\n    def icon(self):\n        return self._widget.icon()\n\n    def set_html(self, html, base_url=QUrl()):\n        # FIXME:qtwebengine\n        # check this and raise an exception if too big:\n        # Warning: The content will be percent encoded before being sent to the\n        # renderer via IPC. This may increase its size. The maximum size of the\n        # percent encoded content is 2 megabytes minus 30 bytes.\n        self._widget.setHtml(html, base_url)\n\n    def networkaccessmanager(self):\n        return None\n\n    def user_agent(self):\n        return None\n\n    def clear_ssl_errors(self):\n        raise browsertab.UnsupportedOperationError\n\n    def key_press(self, key, modifier=Qt.NoModifier):\n        press_evt = QKeyEvent(QEvent.KeyPress, key, modifier, 0, 0, 0)\n        release_evt = QKeyEvent(QEvent.KeyRelease, key, modifier,\n                                0, 0, 0)\n        self.send_event(press_evt)\n        self.send_event(release_evt)\n\n    def _show_error_page(self, url, error):\n        \"\"\"Show an error page in the tab.\"\"\"\n        log.misc.debug(\"Showing error page for {}\".format(error))\n        url_string = url.toDisplayString()\n        error_page = jinja.render(\n            'error.html',\n            title=\"Error loading page: {}\".format(url_string),\n            url=url_string, error=error)\n        self.set_html(error_page)\n\n    @pyqtSlot()\n    def _on_history_trigger(self):\n        try:\n            self._widget.page()\n        except RuntimeError:\n            # Looks like this slot can be triggered on destroyed tabs:\n            # https://crashes.qutebrowser.org/view/3abffbed (Qt 5.9.1)\n            # wrapped C/C++ object of type WebEngineView has been deleted\n            log.misc.debug(\"Ignoring history trigger for destroyed tab\")\n            return\n\n        url = self.url()\n        requested_url = self.url(requested=True)\n\n        # Don't save the title if it's generated from the URL\n        title = self.title()\n        title_url = QUrl(url)\n        title_url.setScheme('')\n        if title == title_url.toDisplayString(QUrl.RemoveScheme).strip('/'):\n            title = \"\"\n\n        # Don't add history entry if the URL is invalid anyways\n        if not url.isValid():\n            log.misc.debug(\"Ignoring invalid URL being added to history\")\n            return\n\n        self.add_history_item.emit(url, requested_url, title)\n\n    @pyqtSlot(QUrl, 'QAuthenticator*', 'QString')\n    def _on_proxy_authentication_required(self, url, authenticator,\n                                          proxy_host):\n        \"\"\"Called when a proxy needs authentication.\"\"\"\n        msg = \"<b>{}</b> requires a username and password.\".format(\n            html_utils.escape(proxy_host))\n        urlstr = url.toString(QUrl.RemovePassword | QUrl.FullyEncoded)\n        answer = message.ask(\n            title=\"Proxy authentication required\", text=msg,\n            mode=usertypes.PromptMode.user_pwd,\n            abort_on=[self.shutting_down, self.load_started], url=urlstr)\n        if answer is not None:\n            authenticator.setUser(answer.user)\n            authenticator.setPassword(answer.password)\n        else:\n            try:\n                # pylint: disable=no-member, useless-suppression\n                sip.assign(authenticator, QAuthenticator())\n                # pylint: enable=no-member, useless-suppression\n            except AttributeError:\n                self._show_error_page(url, \"Proxy authentication required\")\n\n    @pyqtSlot(QUrl, 'QAuthenticator*')\n    def _on_authentication_required(self, url, authenticator):\n        netrc_success = False\n        if not self.data.netrc_used:\n            self.data.netrc_used = True\n            netrc_success = shared.netrc_authentication(url, authenticator)\n        if not netrc_success:\n            abort_on = [self.shutting_down, self.load_started]\n            answer = shared.authentication_required(url, authenticator,\n                                                    abort_on)\n        if not netrc_success and answer is None:\n            try:\n                # pylint: disable=no-member, useless-suppression\n                sip.assign(authenticator, QAuthenticator())\n                # pylint: enable=no-member, useless-suppression\n            except AttributeError:\n                # WORKAROUND for\n                # https://www.riverbankcomputing.com/pipermail/pyqt/2016-December/038400.html\n                self._show_error_page(url, \"Authentication required\")\n\n    @pyqtSlot()\n    def _on_load_started(self):\n        \"\"\"Clear search when a new load is started if needed.\"\"\"\n        # WORKAROUND for\n        # https://bugreports.qt.io/browse/QTBUG-61506\n        # (seems to be back in later Qt versions as well)\n        self.search.clear()\n        super()._on_load_started()\n        self.data.netrc_used = False\n\n    @pyqtSlot(QWebEnginePage.RenderProcessTerminationStatus, int)\n    def _on_render_process_terminated(self, status, exitcode):\n        \"\"\"Show an error when the renderer process terminated.\"\"\"\n        if (status == QWebEnginePage.AbnormalTerminationStatus and\n                exitcode == 256):\n            # WORKAROUND for https://bugreports.qt.io/browse/QTBUG-58697\n            status = QWebEnginePage.CrashedTerminationStatus\n\n        status_map = {\n            QWebEnginePage.NormalTerminationStatus:\n                browsertab.TerminationStatus.normal,\n            QWebEnginePage.AbnormalTerminationStatus:\n                browsertab.TerminationStatus.abnormal,\n            QWebEnginePage.CrashedTerminationStatus:\n                browsertab.TerminationStatus.crashed,\n            QWebEnginePage.KilledTerminationStatus:\n                browsertab.TerminationStatus.killed,\n            -1:\n                browsertab.TerminationStatus.unknown,\n        }\n        self.renderer_process_terminated.emit(status_map[status], exitcode)\n\n    @pyqtSlot(int)\n    def _on_load_progress_workaround(self, perc):\n        \"\"\"Use loadProgress(100) to emit loadFinished(True).\n\n        See https://bugreports.qt.io/browse/QTBUG-65223\n        \"\"\"\n        if perc == 100 and self.load_status() != usertypes.LoadStatus.error:\n            self._load_finished_fake.emit(True)\n\n    @pyqtSlot(bool)\n    def _on_load_finished_workaround(self, ok):\n        \"\"\"Use only loadFinished(False).\n\n        See https://bugreports.qt.io/browse/QTBUG-65223\n        \"\"\"\n        if not ok:\n            self._load_finished_fake.emit(False)\n\n    def _error_page_workaround(self, html):\n        \"\"\"Check if we're displaying a Chromium error page.\n\n        This gets only called if we got loadFinished(False) without JavaScript,\n        so we can display at least some error page.\n\n        WORKAROUND for https://bugreports.qt.io/browse/QTBUG-66643\n        Needs to check the page content as a WORKAROUND for\n        https://bugreports.qt.io/browse/QTBUG-66661\n        \"\"\"\n        match = re.search(r'\"errorCode\":\"([^\"]*)\"', html)\n        if match is None:\n            return\n        self._show_error_page(self.url(), error=match.group(1))\n\n    @pyqtSlot(bool)\n    def _on_load_finished(self, ok):\n        \"\"\"Display a static error page if JavaScript is disabled.\"\"\"\n        super()._on_load_finished(ok)\n        js_enabled = self.settings.test_attribute('content.javascript.enabled')\n        if not ok and not js_enabled:\n            self.dump_async(self._error_page_workaround)\n\n        if ok and self._reload_url is not None:\n            # WORKAROUND for https://bugreports.qt.io/browse/QTBUG-66656\n            log.config.debug(\n                \"Loading {} again because of config change\".format(\n                    self._reload_url.toDisplayString()))\n            QTimer.singleShot(100, functools.partial(self.openurl,\n                                                     self._reload_url,\n                                                     predict=False))\n            self._reload_url = None\n\n        if not qtutils.version_check('5.10', compiled=False):\n            # We can't do this when we have the loadFinished workaround as that\n            # sometimes clears icons without loading a new page.\n            # In general, this is handled by Qt, but when loading takes long,\n            # the old icon is still displayed.\n            self.icon_changed.emit(QIcon())\n\n    @pyqtSlot(certificateerror.CertificateErrorWrapper)\n    def _on_ssl_errors(self, error):\n        url = error.url()\n        self._insecure_hosts.add(url.host())\n\n        log.webview.debug(\"Certificate error: {}\".format(error))\n\n        if error.is_overridable():\n            error.ignore = shared.ignore_certificate_errors(\n                url, [error], abort_on=[self.shutting_down, self.load_started])\n        else:\n            log.webview.error(\"Non-overridable certificate error: \"\n                              \"{}\".format(error))\n\n        log.webview.debug(\"ignore {}, URL {}, requested {}\".format(\n            error.ignore, url, self.url(requested=True)))\n\n        # WORKAROUND for https://bugreports.qt.io/browse/QTBUG-56207\n        # We can't really know when to show an error page, as the error might\n        # have happened when loading some resource.\n        # However, self.url() is not available yet and the requested URL\n        # might not match the URL we get from the error - so we just apply a\n        # heuristic here.\n        if (not qtutils.version_check('5.9') and\n                not error.ignore and\n                url.matches(self.url(requested=True), QUrl.RemoveScheme)):\n            self._show_error_page(url, str(error))\n\n    @pyqtSlot(QUrl)\n    def _on_predicted_navigation(self, url):\n        \"\"\"If we know we're going to visit an URL soon, change the settings.\n\n        This is a WORKAROUND for https://bugreports.qt.io/browse/QTBUG-66656\n        \"\"\"\n        super()._on_predicted_navigation(url)\n        if not qtutils.version_check('5.11.1', compiled=False):\n            self.settings.update_for_url(url)\n\n    @pyqtSlot(usertypes.NavigationRequest)\n    def _on_navigation_request(self, navigation):\n        super()._on_navigation_request(navigation)\n\n        if navigation.url == QUrl('qute://print'):\n            try:\n                self.printing.show_dialog()\n            except browsertab.WebTabError as e:\n                message.error(str(e))\n            navigation.accepted = False\n\n        if not navigation.accepted or not navigation.is_main_frame:\n            return\n\n        settings_needing_reload = {\n            'content.plugins',\n            'content.javascript.enabled',\n            'content.javascript.can_access_clipboard',\n            'content.print_element_backgrounds',\n            'input.spatial_navigation',\n        }\n        assert settings_needing_reload.issubset(configdata.DATA)\n\n        changed = self.settings.update_for_url(navigation.url)\n        reload_needed = changed & settings_needing_reload\n\n        # On Qt < 5.11, we don't don't need a reload when type == link_clicked.\n        # On Qt 5.11.0, we always need a reload.\n        # On Qt > 5.11.0, we never need a reload:\n        # https://codereview.qt-project.org/#/c/229525/1\n        # WORKAROUND for https://bugreports.qt.io/browse/QTBUG-66656\n        if qtutils.version_check('5.11.1', compiled=False):\n            reload_needed = False\n        elif not qtutils.version_check('5.11.0', exact=True, compiled=False):\n            if navigation.navigation_type == navigation.Type.link_clicked:\n                reload_needed = False\n\n        if reload_needed:\n            self._reload_url = navigation.url\n\n    def _connect_signals(self):\n        view = self._widget\n        page = view.page()\n\n        page.windowCloseRequested.connect(self.window_close_requested)\n        page.linkHovered.connect(self.link_hovered)\n        page.loadProgress.connect(self._on_load_progress)\n        page.loadStarted.connect(self._on_load_started)\n        page.certificate_error.connect(self._on_ssl_errors)\n        page.authenticationRequired.connect(self._on_authentication_required)\n        page.proxyAuthenticationRequired.connect(\n            self._on_proxy_authentication_required)\n        page.contentsSizeChanged.connect(self.contents_size_changed)\n        page.navigation_request.connect(self._on_navigation_request)\n\n        view.titleChanged.connect(self.title_changed)\n        view.urlChanged.connect(self._on_url_changed)\n        view.renderProcessTerminated.connect(\n            self._on_render_process_terminated)\n        view.iconChanged.connect(self.icon_changed)\n        # WORKAROUND for https://bugreports.qt.io/browse/QTBUG-65223\n        if qtutils.version_check('5.10', compiled=False):\n            page.loadProgress.connect(self._on_load_progress_workaround)\n            self._load_finished_fake.connect(self._on_history_trigger)\n            self._load_finished_fake.connect(self._restore_zoom)\n            self._load_finished_fake.connect(self._on_load_finished)\n            page.loadFinished.connect(self._on_load_finished_workaround)\n        else:\n            # for older Qt versions which break with the above\n            page.loadProgress.connect(self._on_load_progress)\n            page.loadFinished.connect(self._on_history_trigger)\n            page.loadFinished.connect(self._restore_zoom)\n            page.loadFinished.connect(self._on_load_finished)\n\n        self.predicted_navigation.connect(self._on_predicted_navigation)\n\n        # pylint: disable=protected-access\n        self.audio._connect_signals()\n        self._permissions.connect_signals()\n        self._scripts.connect_signals()\n\n    def event_target(self):\n        return self._widget.render_widget()\n", "target": 0}
{"idx": 873, "func": "#\n# multibytecodec_support.py\n#   Common Unittest Routines for CJK codecs\n#\n\nimport codecs\nimport os\nimport re\nimport sys\nimport unittest\nfrom http.client import HTTPException\nfrom test import support\nfrom io import BytesIO\n\nclass TestBase:\n    encoding        = ''   # codec name\n    codec           = None # codec tuple (with 4 elements)\n    tstring         = None # must set. 2 strings to test StreamReader\n\n    codectests      = None # must set. codec test tuple\n    roundtriptest   = 1    # set if roundtrip is possible with unicode\n    has_iso10646    = 0    # set if this encoding contains whole iso10646 map\n    xmlcharnametest = None # string to test xmlcharrefreplace\n    unmappedunicode = '\\udeee' # a unicode code point that is not mapped.\n\n    def setUp(self):\n        if self.codec is None:\n            self.codec = codecs.lookup(self.encoding)\n        self.encode = self.codec.encode\n        self.decode = self.codec.decode\n        self.reader = self.codec.streamreader\n        self.writer = self.codec.streamwriter\n        self.incrementalencoder = self.codec.incrementalencoder\n        self.incrementaldecoder = self.codec.incrementaldecoder\n\n    def test_chunkcoding(self):\n        tstring_lines = []\n        for b in self.tstring:\n            lines = b.split(b\"\\n\")\n            last = lines.pop()\n            assert last == b\"\"\n            lines = [line + b\"\\n\" for line in lines]\n            tstring_lines.append(lines)\n        for native, utf8 in zip(*tstring_lines):\n            u = self.decode(native)[0]\n            self.assertEqual(u, utf8.decode('utf-8'))\n            if self.roundtriptest:\n                self.assertEqual(native, self.encode(u)[0])\n\n    def test_errorhandle(self):\n        for source, scheme, expected in self.codectests:\n            if isinstance(source, bytes):\n                func = self.decode\n            else:\n                func = self.encode\n            if expected:\n                result = func(source, scheme)[0]\n                if func is self.decode:\n                    self.assertTrue(type(result) is str, type(result))\n                    self.assertEqual(result, expected,\n                                     '%a.decode(%r, %r)=%a != %a'\n                                     % (source, self.encoding, scheme, result,\n                                        expected))\n                else:\n                    self.assertTrue(type(result) is bytes, type(result))\n                    self.assertEqual(result, expected,\n                                     '%a.encode(%r, %r)=%a != %a'\n                                     % (source, self.encoding, scheme, result,\n                                        expected))\n            else:\n                self.assertRaises(UnicodeError, func, source, scheme)\n\n    def test_xmlcharrefreplace(self):\n        if self.has_iso10646:\n            self.skipTest('encoding contains full ISO 10646 map')\n\n        s = \"\\u0b13\\u0b23\\u0b60 nd eggs\"\n        self.assertEqual(\n            self.encode(s, \"xmlcharrefreplace\")[0],\n            b\"&#2835;&#2851;&#2912; nd eggs\"\n        )\n\n    def test_customreplace_encode(self):\n        if self.has_iso10646:\n            self.skipTest('encoding contains full ISO 10646 map')\n\n        from html.entities import codepoint2name\n\n        def xmlcharnamereplace(exc):\n            if not isinstance(exc, UnicodeEncodeError):\n                raise TypeError(\"don't know how to handle %r\" % exc)\n            l = []\n            for c in exc.object[exc.start:exc.end]:\n                if ord(c) in codepoint2name:\n                    l.append(\"&%s;\" % codepoint2name[ord(c)])\n                else:\n                    l.append(\"&#%d;\" % ord(c))\n            return (\"\".join(l), exc.end)\n\n        codecs.register_error(\"test.xmlcharnamereplace\", xmlcharnamereplace)\n\n        if self.xmlcharnametest:\n            sin, sout = self.xmlcharnametest\n        else:\n            sin = \"\\xab\\u211c\\xbb = \\u2329\\u1234\\u232a\"\n            sout = b\"&laquo;&real;&raquo; = &lang;&#4660;&rang;\"\n        self.assertEqual(self.encode(sin,\n                                    \"test.xmlcharnamereplace\")[0], sout)\n\n    def test_callback_returns_bytes(self):\n        def myreplace(exc):\n            return (b\"1234\", exc.end)\n        codecs.register_error(\"test.cjktest\", myreplace)\n        enc = self.encode(\"abc\" + self.unmappedunicode + \"def\", \"test.cjktest\")[0]\n        self.assertEqual(enc, b\"abc1234def\")\n\n    def test_callback_wrong_objects(self):\n        def myreplace(exc):\n            return (ret, exc.end)\n        codecs.register_error(\"test.cjktest\", myreplace)\n\n        for ret in ([1, 2, 3], [], None, object()):\n            self.assertRaises(TypeError, self.encode, self.unmappedunicode,\n                              'test.cjktest')\n\n    def test_callback_long_index(self):\n        def myreplace(exc):\n            return ('x', int(exc.end))\n        codecs.register_error(\"test.cjktest\", myreplace)\n        self.assertEqual(self.encode('abcd' + self.unmappedunicode + 'efgh',\n                                     'test.cjktest'), (b'abcdxefgh', 9))\n\n        def myreplace(exc):\n            return ('x', sys.maxsize + 1)\n        codecs.register_error(\"test.cjktest\", myreplace)\n        self.assertRaises(IndexError, self.encode, self.unmappedunicode,\n                          'test.cjktest')\n\n    def test_callback_None_index(self):\n        def myreplace(exc):\n            return ('x', None)\n        codecs.register_error(\"test.cjktest\", myreplace)\n        self.assertRaises(TypeError, self.encode, self.unmappedunicode,\n                          'test.cjktest')\n\n    def test_callback_backward_index(self):\n        def myreplace(exc):\n            if myreplace.limit > 0:\n                myreplace.limit -= 1\n                return ('REPLACED', 0)\n            else:\n                return ('TERMINAL', exc.end)\n        myreplace.limit = 3\n        codecs.register_error(\"test.cjktest\", myreplace)\n        self.assertEqual(self.encode('abcd' + self.unmappedunicode + 'efgh',\n                                     'test.cjktest'),\n                (b'abcdREPLACEDabcdREPLACEDabcdREPLACEDabcdTERMINALefgh', 9))\n\n    def test_callback_forward_index(self):\n        def myreplace(exc):\n            return ('REPLACED', exc.end + 2)\n        codecs.register_error(\"test.cjktest\", myreplace)\n        self.assertEqual(self.encode('abcd' + self.unmappedunicode + 'efgh',\n                                     'test.cjktest'), (b'abcdREPLACEDgh', 9))\n\n    def test_callback_index_outofbound(self):\n        def myreplace(exc):\n            return ('TERM', 100)\n        codecs.register_error(\"test.cjktest\", myreplace)\n        self.assertRaises(IndexError, self.encode, self.unmappedunicode,\n                          'test.cjktest')\n\n    def test_incrementalencoder(self):\n        UTF8Reader = codecs.getreader('utf-8')\n        for sizehint in [None] + list(range(1, 33)) + \\\n                        [64, 128, 256, 512, 1024]:\n            istream = UTF8Reader(BytesIO(self.tstring[1]))\n            ostream = BytesIO()\n            encoder = self.incrementalencoder()\n            while 1:\n                if sizehint is not None:\n                    data = istream.read(sizehint)\n                else:\n                    data = istream.read()\n\n                if not data:\n                    break\n                e = encoder.encode(data)\n                ostream.write(e)\n\n            self.assertEqual(ostream.getvalue(), self.tstring[0])\n\n    def test_incrementaldecoder(self):\n        UTF8Writer = codecs.getwriter('utf-8')\n        for sizehint in [None, -1] + list(range(1, 33)) + \\\n                        [64, 128, 256, 512, 1024]:\n            istream = BytesIO(self.tstring[0])\n            ostream = UTF8Writer(BytesIO())\n            decoder = self.incrementaldecoder()\n            while 1:\n                data = istream.read(sizehint)\n                if not data:\n                    break\n                else:\n                    u = decoder.decode(data)\n                    ostream.write(u)\n\n            self.assertEqual(ostream.getvalue(), self.tstring[1])\n\n    def test_incrementalencoder_error_callback(self):\n        inv = self.unmappedunicode\n\n        e = self.incrementalencoder()\n        self.assertRaises(UnicodeEncodeError, e.encode, inv, True)\n\n        e.errors = 'ignore'\n        self.assertEqual(e.encode(inv, True), b'')\n\n        e.reset()\n        def tempreplace(exc):\n            return ('called', exc.end)\n        codecs.register_error('test.incremental_error_callback', tempreplace)\n        e.errors = 'test.incremental_error_callback'\n        self.assertEqual(e.encode(inv, True), b'called')\n\n        # again\n        e.errors = 'ignore'\n        self.assertEqual(e.encode(inv, True), b'')\n\n    def test_streamreader(self):\n        UTF8Writer = codecs.getwriter('utf-8')\n        for name in [\"read\", \"readline\", \"readlines\"]:\n            for sizehint in [None, -1] + list(range(1, 33)) + \\\n                            [64, 128, 256, 512, 1024]:\n                istream = self.reader(BytesIO(self.tstring[0]))\n                ostream = UTF8Writer(BytesIO())\n                func = getattr(istream, name)\n                while 1:\n                    data = func(sizehint)\n                    if not data:\n                        break\n                    if name == \"readlines\":\n                        ostream.writelines(data)\n                    else:\n                        ostream.write(data)\n\n                self.assertEqual(ostream.getvalue(), self.tstring[1])\n\n    def test_streamwriter(self):\n        readfuncs = ('read', 'readline', 'readlines')\n        UTF8Reader = codecs.getreader('utf-8')\n        for name in readfuncs:\n            for sizehint in [None] + list(range(1, 33)) + \\\n                            [64, 128, 256, 512, 1024]:\n                istream = UTF8Reader(BytesIO(self.tstring[1]))\n                ostream = self.writer(BytesIO())\n                func = getattr(istream, name)\n                while 1:\n                    if sizehint is not None:\n                        data = func(sizehint)\n                    else:\n                        data = func()\n\n                    if not data:\n                        break\n                    if name == \"readlines\":\n                        ostream.writelines(data)\n                    else:\n                        ostream.write(data)\n\n                self.assertEqual(ostream.getvalue(), self.tstring[0])\n\n    def test_streamwriter_reset_no_pending(self):\n        # Issue #23247: Calling reset() on a fresh StreamWriter instance\n        # (without pending data) must not crash\n        stream = BytesIO()\n        writer = self.writer(stream)\n        writer.reset()\n\n    def test_incrementalencoder_del_segfault(self):\n        e = self.incrementalencoder()\n        with self.assertRaises(AttributeError):\n            del e.errors\n\n\nclass TestBase_Mapping(unittest.TestCase):\n    pass_enctest = []\n    pass_dectest = []\n    supmaps = []\n    codectests = []\n\n    def setUp(self):\n        try:\n            self.open_mapping_file().close() # test it to report the error early\n        except (OSError, HTTPException):\n            self.skipTest(\"Could not retrieve \"+self.mapfileurl)\n\n    def open_mapping_file(self):\n        return support.open_urlresource(self.mapfileurl)\n\n    def test_mapping_file(self):\n        if self.mapfileurl.endswith('.xml'):\n            self._test_mapping_file_ucm()\n        else:\n            self._test_mapping_file_plain()\n\n    def _test_mapping_file_plain(self):\n        unichrs = lambda s: ''.join(map(chr, map(eval, s.split('+'))))\n        urt_wa = {}\n\n        with self.open_mapping_file() as f:\n            for line in f:\n                if not line:\n                    break\n                data = line.split('#')[0].strip().split()\n                if len(data) != 2:\n                    continue\n\n                csetval = eval(data[0])\n                if csetval <= 0x7F:\n                    csetch = bytes([csetval & 0xff])\n                elif csetval >= 0x1000000:\n                    csetch = bytes([(csetval >> 24), ((csetval >> 16) & 0xff),\n                                    ((csetval >> 8) & 0xff), (csetval & 0xff)])\n                elif csetval >= 0x10000:\n                    csetch = bytes([(csetval >> 16), ((csetval >> 8) & 0xff),\n                                    (csetval & 0xff)])\n                elif csetval >= 0x100:\n                    csetch = bytes([(csetval >> 8), (csetval & 0xff)])\n                else:\n                    continue\n\n                unich = unichrs(data[1])\n                if ord(unich) == 0xfffd or unich in urt_wa:\n                    continue\n                urt_wa[unich] = csetch\n\n                self._testpoint(csetch, unich)\n\n    def _test_mapping_file_ucm(self):\n        with self.open_mapping_file() as f:\n            ucmdata = f.read()\n        uc = re.findall('<a u=\"([A-F0-9]{4})\" b=\"([0-9A-F ]+)\"/>', ucmdata)\n        for uni, coded in uc:\n            unich = chr(int(uni, 16))\n            codech = bytes.fromhex(coded)\n            self._testpoint(codech, unich)\n\n    def test_mapping_supplemental(self):\n        for mapping in self.supmaps:\n            self._testpoint(*mapping)\n\n    def _testpoint(self, csetch, unich):\n        if (csetch, unich) not in self.pass_enctest:\n            self.assertEqual(unich.encode(self.encoding), csetch)\n        if (csetch, unich) not in self.pass_dectest:\n            self.assertEqual(str(csetch, self.encoding), unich)\n\n    def test_errorhandle(self):\n        for source, scheme, expected in self.codectests:\n            if isinstance(source, bytes):\n                func = source.decode\n            else:\n                func = source.encode\n            if expected:\n                if isinstance(source, bytes):\n                    result = func(self.encoding, scheme)\n                    self.assertTrue(type(result) is str, type(result))\n                    self.assertEqual(result, expected,\n                                     '%a.decode(%r, %r)=%a != %a'\n                                     % (source, self.encoding, scheme, result,\n                                        expected))\n                else:\n                    result = func(self.encoding, scheme)\n                    self.assertTrue(type(result) is bytes, type(result))\n                    self.assertEqual(result, expected,\n                                     '%a.encode(%r, %r)=%a != %a'\n                                     % (source, self.encoding, scheme, result,\n                                        expected))\n            else:\n                self.assertRaises(UnicodeError, func, self.encoding, scheme)\n\ndef load_teststring(name):\n    dir = os.path.join(os.path.dirname(__file__), 'cjkencodings')\n    with open(os.path.join(dir, name + '.txt'), 'rb') as f:\n        encoded = f.read()\n    with open(os.path.join(dir, name + '-utf8.txt'), 'rb') as f:\n        utf8 = f.read()\n    return encoded, utf8\n", "target": 1}
{"idx": 874, "func": "# vim: tabstop=4 shiftwidth=4 softtabstop=4\n\n# Copyright 2010 OpenStack LLC.\n# All Rights Reserved.\n#\n#    Licensed under the Apache License, Version 2.0 (the \"License\"); you may\n#    not use this file except in compliance with the License. You may obtain\n#    a copy of the License at\n#\n#         http://www.apache.org/licenses/LICENSE-2.0\n#\n#    Unless required by applicable law or agreed to in writing, software\n#    distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n#    License for the specific language governing permissions and limitations\n#    under the License.\n\n\"\"\"\n/images endpoint for Glance v1 API\n\"\"\"\n\nimport errno\nimport logging\nimport sys\nimport traceback\n\nfrom webob.exc import (HTTPError,\n                       HTTPNotFound,\n                       HTTPConflict,\n                       HTTPBadRequest,\n                       HTTPForbidden,\n                       HTTPRequestEntityTooLarge,\n                       HTTPServiceUnavailable,\n                      )\n\nfrom glance.api import policy\nimport glance.api.v1\nfrom glance.api.v1 import controller\nfrom glance.api.v1 import filters\nfrom glance.common import cfg\nfrom glance.common import exception\nfrom glance.common import wsgi\nfrom glance.common import utils\nimport glance.store\nimport glance.store.filesystem\nimport glance.store.http\nimport glance.store.rbd\nimport glance.store.s3\nimport glance.store.swift\nfrom glance.store import (get_from_backend,\n                          get_size_from_backend,\n                          schedule_delete_from_backend,\n                          get_store_from_location,\n                          get_store_from_scheme)\nfrom glance import registry\nfrom glance import notifier\n\n\nlogger = logging.getLogger(__name__)\nSUPPORTED_PARAMS = glance.api.v1.SUPPORTED_PARAMS\nSUPPORTED_FILTERS = glance.api.v1.SUPPORTED_FILTERS\n\n\n# 1 PiB, which is a *huge* image by anyone's measure.  This is just to protect\n# against client programming errors (or DoS attacks) in the image metadata.\n# We have a known limit of 1 << 63 in the database -- images.size is declared\n# as a BigInteger.\nIMAGE_SIZE_CAP = 1 << 50\n\n\nclass Controller(controller.BaseController):\n    \"\"\"\n    WSGI controller for images resource in Glance v1 API\n\n    The images resource API is a RESTful web service for image data. The API\n    is as follows::\n\n        GET /images -- Returns a set of brief metadata about images\n        GET /images/detail -- Returns a set of detailed metadata about\n                              images\n        HEAD /images/<ID> -- Return metadata about an image with id <ID>\n        GET /images/<ID> -- Return image data for image with id <ID>\n        POST /images -- Store image data and return metadata about the\n                        newly-stored image\n        PUT /images/<ID> -- Update image metadata and/or upload image\n                            data for a previously-reserved image\n        DELETE /images/<ID> -- Delete the image with id <ID>\n    \"\"\"\n\n    default_store_opt = cfg.StrOpt('default_store', default='file')\n\n    def __init__(self, conf):\n        self.conf = conf\n        self.conf.register_opt(self.default_store_opt)\n        glance.store.create_stores(conf)\n        self.verify_store_or_exit(self.conf.default_store)\n        self.notifier = notifier.Notifier(conf)\n        registry.configure_registry_client(conf)\n        self.policy = policy.Enforcer(conf)\n\n    def _enforce(self, req, action):\n        \"\"\"Authorize an action against our policies\"\"\"\n        try:\n            self.policy.enforce(req.context, action, {})\n        except exception.Forbidden:\n            raise HTTPForbidden()\n\n    def index(self, req):\n        \"\"\"\n        Returns the following information for all public, available images:\n\n            * id -- The opaque image identifier\n            * name -- The name of the image\n            * disk_format -- The disk image format\n            * container_format -- The \"container\" format of the image\n            * checksum -- MD5 checksum of the image data\n            * size -- Size of image data in bytes\n\n        :param req: The WSGI/Webob Request object\n        :retval The response body is a mapping of the following form::\n\n            {'images': [\n                {'id': <ID>,\n                 'name': <NAME>,\n                 'disk_format': <DISK_FORMAT>,\n                 'container_format': <DISK_FORMAT>,\n                 'checksum': <CHECKSUM>\n                 'size': <SIZE>}, ...\n            ]}\n        \"\"\"\n        self._enforce(req, 'get_images')\n        params = self._get_query_params(req)\n        try:\n            images = registry.get_images_list(req.context, **params)\n        except exception.Invalid, e:\n            raise HTTPBadRequest(explanation=\"%s\" % e)\n\n        return dict(images=images)\n\n    def detail(self, req):\n        \"\"\"\n        Returns detailed information for all public, available images\n\n        :param req: The WSGI/Webob Request object\n        :retval The response body is a mapping of the following form::\n\n            {'images': [\n                {'id': <ID>,\n                 'name': <NAME>,\n                 'size': <SIZE>,\n                 'disk_format': <DISK_FORMAT>,\n                 'container_format': <CONTAINER_FORMAT>,\n                 'checksum': <CHECKSUM>,\n                 'min_disk': <MIN_DISK>,\n                 'min_ram': <MIN_RAM>,\n                 'store': <STORE>,\n                 'status': <STATUS>,\n                 'created_at': <TIMESTAMP>,\n                 'updated_at': <TIMESTAMP>,\n                 'deleted_at': <TIMESTAMP>|<NONE>,\n                 'properties': {'distro': 'Ubuntu 10.04 LTS', ...}}, ...\n            ]}\n        \"\"\"\n        self._enforce(req, 'get_images')\n        params = self._get_query_params(req)\n        try:\n            images = registry.get_images_detail(req.context, **params)\n            # Strip out the Location attribute. Temporary fix for\n            # LP Bug #755916. This information is still coming back\n            # from the registry, since the API server still needs access\n            # to it, however we do not return this potential security\n            # information to the API end user...\n            for image in images:\n                del image['location']\n        except exception.Invalid, e:\n            raise HTTPBadRequest(explanation=\"%s\" % e)\n        return dict(images=images)\n\n    def _get_query_params(self, req):\n        \"\"\"\n        Extracts necessary query params from request.\n\n        :param req: the WSGI Request object\n        :retval dict of parameters that can be used by registry client\n        \"\"\"\n        params = {'filters': self._get_filters(req)}\n\n        for PARAM in SUPPORTED_PARAMS:\n            if PARAM in req.params:\n                params[PARAM] = req.params.get(PARAM)\n        return params\n\n    def _get_filters(self, req):\n        \"\"\"\n        Return a dictionary of query param filters from the request\n\n        :param req: the Request object coming from the wsgi layer\n        :retval a dict of key/value filters\n        \"\"\"\n        query_filters = {}\n        for param in req.params:\n            if param in SUPPORTED_FILTERS or param.startswith('property-'):\n                query_filters[param] = req.params.get(param)\n                if not filters.validate(param, query_filters[param]):\n                    raise HTTPBadRequest('Bad value passed to filter %s '\n                                         'got %s' % (param,\n                                                     query_filters[param]))\n        return query_filters\n\n    def meta(self, req, id):\n        \"\"\"\n        Returns metadata about an image in the HTTP headers of the\n        response object\n\n        :param req: The WSGI/Webob Request object\n        :param id: The opaque image identifier\n        :retval similar to 'show' method but without image_data\n\n        :raises HTTPNotFound if image metadata is not available to user\n        \"\"\"\n        self._enforce(req, 'get_image')\n        image_meta = self.get_image_meta_or_404(req, id)\n        del image_meta['location']\n        return {\n            'image_meta': image_meta\n        }\n\n    @staticmethod\n    def _validate_source(source, req):\n        \"\"\"\n        External sources (as specified via the location or copy-from headers)\n        are supported only over non-local store types, i.e. S3, Swift, HTTP.\n        Note the absence of file:// for security reasons, see LP bug #942118.\n        If the above constraint is violated, we reject with 400 \"Bad Request\".\n        \"\"\"\n        if source:\n            for scheme in ['s3', 'swift', 'http']:\n                if source.lower().startswith(scheme):\n                    return source\n            msg = _(\"External sourcing not supported for store %s\") % source\n            logger.error(msg)\n            raise HTTPBadRequest(msg, request=req, content_type=\"text/plain\")\n\n    @staticmethod\n    def _copy_from(req):\n        return req.headers.get('x-glance-api-copy-from')\n\n    @staticmethod\n    def _external_source(image_meta, req):\n        source = image_meta.get('location', Controller._copy_from(req))\n        return Controller._validate_source(source, req)\n\n    @staticmethod\n    def _get_from_store(where):\n        try:\n            image_data, image_size = get_from_backend(where)\n        except exception.NotFound, e:\n            raise HTTPNotFound(explanation=\"%s\" % e)\n        image_size = int(image_size) if image_size else None\n        return image_data, image_size\n\n    def show(self, req, id):\n        \"\"\"\n        Returns an iterator that can be used to retrieve an image's\n        data along with the image metadata.\n\n        :param req: The WSGI/Webob Request object\n        :param id: The opaque image identifier\n\n        :raises HTTPNotFound if image is not available to user\n        \"\"\"\n        self._enforce(req, 'get_image')\n        image_meta = self.get_active_image_meta_or_404(req, id)\n\n        if image_meta.get('size') == 0:\n            image_iterator = iter([])\n        else:\n            image_iterator, size = self._get_from_store(image_meta['location'])\n            image_meta['size'] = size or image_meta['size']\n\n        del image_meta['location']\n        return {\n            'image_iterator': image_iterator,\n            'image_meta': image_meta,\n        }\n\n    def _reserve(self, req, image_meta):\n        \"\"\"\n        Adds the image metadata to the registry and assigns\n        an image identifier if one is not supplied in the request\n        headers. Sets the image's status to `queued`.\n\n        :param req: The WSGI/Webob Request object\n        :param id: The opaque image identifier\n        :param image_meta: The image metadata\n\n        :raises HTTPConflict if image already exists\n        :raises HTTPBadRequest if image metadata is not valid\n        \"\"\"\n        location = self._external_source(image_meta, req)\n\n        image_meta['status'] = ('active' if image_meta.get('size') == 0\n                                else 'queued')\n\n        if location:\n            store = get_store_from_location(location)\n            # check the store exists before we hit the registry, but we\n            # don't actually care what it is at this point\n            self.get_store_or_400(req, store)\n\n            # retrieve the image size from remote store (if not provided)\n            image_meta['size'] = self._get_size(image_meta, location)\n        else:\n            # Ensure that the size attribute is set to zero for directly\n            # uploadable images (if not provided). The size will be set\n            # to a non-zero value during upload\n            image_meta['size'] = image_meta.get('size', 0)\n\n        try:\n            image_meta = registry.add_image_metadata(req.context, image_meta)\n            return image_meta\n        except exception.Duplicate:\n            msg = (_(\"An image with identifier %s already exists\")\n                  % image_meta['id'])\n            logger.error(msg)\n            raise HTTPConflict(msg, request=req, content_type=\"text/plain\")\n        except exception.Invalid, e:\n            msg = (_(\"Failed to reserve image. Got error: %(e)s\") % locals())\n            for line in msg.split('\\n'):\n                logger.error(line)\n            raise HTTPBadRequest(msg, request=req, content_type=\"text/plain\")\n        except exception.Forbidden:\n            msg = _(\"Forbidden to reserve image.\")\n            logger.error(msg)\n            raise HTTPForbidden(msg, request=req, content_type=\"text/plain\")\n\n    def _upload(self, req, image_meta):\n        \"\"\"\n        Uploads the payload of the request to a backend store in\n        Glance. If the `x-image-meta-store` header is set, Glance\n        will attempt to use that store, if not, Glance will use the\n        store set by the flag `default_store`.\n\n        :param req: The WSGI/Webob Request object\n        :param image_meta: Mapping of metadata about image\n\n        :raises HTTPConflict if image already exists\n        :retval The location where the image was stored\n        \"\"\"\n\n        copy_from = self._copy_from(req)\n        if copy_from:\n            image_data, image_size = self._get_from_store(copy_from)\n            image_meta['size'] = image_size or image_meta['size']\n        else:\n            try:\n                req.get_content_type('application/octet-stream')\n            except exception.InvalidContentType:\n                self._safe_kill(req, image_meta['id'])\n                msg = _(\"Content-Type must be application/octet-stream\")\n                logger.error(msg)\n                raise HTTPBadRequest(explanation=msg)\n\n            image_data = req.body_file\n\n            if req.content_length:\n                image_size = int(req.content_length)\n            elif 'x-image-meta-size' in req.headers:\n                image_size = int(req.headers['x-image-meta-size'])\n            else:\n                logger.debug(_(\"Got request with no content-length and no \"\n                               \"x-image-meta-size header\"))\n                image_size = 0\n\n        store_name = req.headers.get('x-image-meta-store',\n                                     self.conf.default_store)\n\n        store = self.get_store_or_400(req, store_name)\n\n        image_id = image_meta['id']\n        logger.debug(_(\"Setting image %s to status 'saving'\"), image_id)\n        registry.update_image_metadata(req.context, image_id,\n                                       {'status': 'saving'})\n        try:\n            logger.debug(_(\"Uploading image data for image %(image_id)s \"\n                         \"to %(store_name)s store\"), locals())\n\n            if image_size > IMAGE_SIZE_CAP:\n                max_image_size = IMAGE_SIZE_CAP\n                msg = _(\"Denying attempt to upload image larger than \"\n                        \"%(max_image_size)d. Supplied image size was \"\n                        \"%(image_size)d\") % locals()\n                logger.warn(msg)\n                raise HTTPBadRequest(msg, request=req)\n\n            location, size, checksum = store.add(image_meta['id'],\n                                                 image_data,\n                                                 image_size)\n\n            # Verify any supplied checksum value matches checksum\n            # returned from store when adding image\n            supplied_checksum = image_meta.get('checksum')\n            if supplied_checksum and supplied_checksum != checksum:\n                msg = _(\"Supplied checksum (%(supplied_checksum)s) and \"\n                       \"checksum generated from uploaded image \"\n                       \"(%(checksum)s) did not match. Setting image \"\n                       \"status to 'killed'.\") % locals()\n                logger.error(msg)\n                self._safe_kill(req, image_id)\n                raise HTTPBadRequest(msg, content_type=\"text/plain\",\n                                     request=req)\n\n            # Update the database with the checksum returned\n            # from the backend store\n            logger.debug(_(\"Updating image %(image_id)s data. \"\n                         \"Checksum set to %(checksum)s, size set \"\n                         \"to %(size)d\"), locals())\n            update_data = {'checksum': checksum,\n                           'size': size}\n            image_meta = registry.update_image_metadata(req.context,\n                                                        image_id,\n                                                        update_data)\n            self.notifier.info('image.upload', image_meta)\n\n            return location\n\n        except exception.Duplicate, e:\n            msg = _(\"Attempt to upload duplicate image: %s\") % e\n            logger.error(msg)\n            self._safe_kill(req, image_id)\n            self.notifier.error('image.upload', msg)\n            raise HTTPConflict(msg, request=req)\n\n        except exception.Forbidden, e:\n            msg = _(\"Forbidden upload attempt: %s\") % e\n            logger.error(msg)\n            self._safe_kill(req, image_id)\n            self.notifier.error('image.upload', msg)\n            raise HTTPForbidden(msg, request=req, content_type=\"text/plain\")\n\n        except exception.StorageFull, e:\n            msg = _(\"Image storage media is full: %s\") % e\n            logger.error(msg)\n            self._safe_kill(req, image_id)\n            self.notifier.error('image.upload', msg)\n            raise HTTPRequestEntityTooLarge(msg, request=req,\n                                            content_type='text/plain')\n\n        except exception.StorageWriteDenied, e:\n            msg = _(\"Insufficient permissions on image storage media: %s\") % e\n            logger.error(msg)\n            self._safe_kill(req, image_id)\n            self.notifier.error('image.upload', msg)\n            raise HTTPServiceUnavailable(msg, request=req,\n                                         content_type='text/plain')\n\n        except HTTPError, e:\n            self._safe_kill(req, image_id)\n            self.notifier.error('image.upload', e.explanation)\n            raise\n\n        except Exception, e:\n            tb_info = traceback.format_exc()\n            logger.error(tb_info)\n\n            self._safe_kill(req, image_id)\n\n            msg = _(\"Error uploading image: (%(class_name)s): \"\n                    \"%(exc)s\") % ({'class_name': e.__class__.__name__,\n                    'exc': str(e)})\n\n            self.notifier.error('image.upload', msg)\n            raise HTTPBadRequest(msg, request=req)\n\n    def _activate(self, req, image_id, location):\n        \"\"\"\n        Sets the image status to `active` and the image's location\n        attribute.\n\n        :param req: The WSGI/Webob Request object\n        :param image_id: Opaque image identifier\n        :param location: Location of where Glance stored this image\n        \"\"\"\n        image_meta = {}\n        image_meta['location'] = location\n        image_meta['status'] = 'active'\n\n        try:\n            return registry.update_image_metadata(req.context,\n                                                  image_id,\n                                                  image_meta)\n        except exception.Invalid, e:\n            msg = (_(\"Failed to activate image. Got error: %(e)s\")\n                   % locals())\n            for line in msg.split('\\n'):\n                logger.error(line)\n            self.notifier.error('image.update', msg)\n            raise HTTPBadRequest(msg, request=req, content_type=\"text/plain\")\n\n    def _kill(self, req, image_id):\n        \"\"\"\n        Marks the image status to `killed`.\n\n        :param req: The WSGI/Webob Request object\n        :param image_id: Opaque image identifier\n        \"\"\"\n        registry.update_image_metadata(req.context, image_id,\n                                       {'status': 'killed'})\n\n    def _safe_kill(self, req, image_id):\n        \"\"\"\n        Mark image killed without raising exceptions if it fails.\n\n        Since _kill is meant to be called from exceptions handlers, it should\n        not raise itself, rather it should just log its error.\n\n        :param req: The WSGI/Webob Request object\n        :param image_id: Opaque image identifier\n        \"\"\"\n        try:\n            self._kill(req, image_id)\n        except Exception, e:\n            logger.error(_(\"Unable to kill image %(id)s: \"\n                           \"%(exc)s\") % ({'id': image_id,\n                           'exc': repr(e)}))\n\n    def _upload_and_activate(self, req, image_meta):\n        \"\"\"\n        Safely uploads the image data in the request payload\n        and activates the image in the registry after a successful\n        upload.\n\n        :param req: The WSGI/Webob Request object\n        :param image_meta: Mapping of metadata about image\n\n        :retval Mapping of updated image data\n        \"\"\"\n        image_id = image_meta['id']\n        # This is necessary because of a bug in Webob 1.0.2 - 1.0.7\n        # See: https://bitbucket.org/ianb/webob/\n        # issue/12/fix-for-issue-6-broke-chunked-transfer\n        req.is_body_readable = True\n        location = self._upload(req, image_meta)\n        return self._activate(req, image_id, location)\n\n    def _get_size(self, image_meta, location):\n        # retrieve the image size from remote store (if not provided)\n        return image_meta.get('size', 0) or get_size_from_backend(location)\n\n    def _handle_source(self, req, image_id, image_meta, image_data):\n        if image_data or self._copy_from(req):\n            image_meta = self._upload_and_activate(req, image_meta)\n        else:\n            location = image_meta.get('location')\n            if location:\n                image_meta = self._activate(req, image_id, location)\n        return image_meta\n\n    def create(self, req, image_meta, image_data):\n        \"\"\"\n        Adds a new image to Glance. Four scenarios exist when creating an\n        image:\n\n        1. If the image data is available directly for upload, create can be\n           passed the image data as the request body and the metadata as the\n           request headers. The image will initially be 'queued', during\n           upload it will be in the 'saving' status, and then 'killed' or\n           'active' depending on whether the upload completed successfully.\n\n        2. If the image data exists somewhere else, you can upload indirectly\n           from the external source using the x-glance-api-copy-from header.\n           Once the image is uploaded, the external store is not subsequently\n           consulted, i.e. the image content is served out from the configured\n           glance image store.  State transitions are as for option #1.\n\n        3. If the image data exists somewhere else, you can reference the\n           source using the x-image-meta-location header. The image content\n           will be served out from the external store, i.e. is never uploaded\n           to the configured glance image store.\n\n        4. If the image data is not available yet, but you'd like reserve a\n           spot for it, you can omit the data and a record will be created in\n           the 'queued' state. This exists primarily to maintain backwards\n           compatibility with OpenStack/Rackspace API semantics.\n\n        The request body *must* be encoded as application/octet-stream,\n        otherwise an HTTPBadRequest is returned.\n\n        Upon a successful save of the image data and metadata, a response\n        containing metadata about the image is returned, including its\n        opaque identifier.\n\n        :param req: The WSGI/Webob Request object\n        :param image_meta: Mapping of metadata about image\n        :param image_data: Actual image data that is to be stored\n\n        :raises HTTPBadRequest if x-image-meta-location is missing\n                and the request body is not application/octet-stream\n                image data.\n        \"\"\"\n        self._enforce(req, 'add_image')\n        if image_meta.get('is_public'):\n            self._enforce(req, 'publicize_image')\n        if req.context.read_only:\n            msg = _(\"Read-only access\")\n            logger.debug(msg)\n            raise HTTPForbidden(msg, request=req,\n                                content_type=\"text/plain\")\n\n        image_meta = self._reserve(req, image_meta)\n        id = image_meta['id']\n\n        image_meta = self._handle_source(req, id, image_meta, image_data)\n\n        # Prevent client from learning the location, as it\n        # could contain security credentials\n        image_meta.pop('location', None)\n\n        return {'image_meta': image_meta}\n\n    def update(self, req, id, image_meta, image_data):\n        \"\"\"\n        Updates an existing image with the registry.\n\n        :param request: The WSGI/Webob Request object\n        :param id: The opaque image identifier\n\n        :retval Returns the updated image information as a mapping\n        \"\"\"\n        self._enforce(req, 'modify_image')\n        if image_meta.get('is_public'):\n            self._enforce(req, 'publicize_image')\n        if req.context.read_only:\n            msg = _(\"Read-only access\")\n            logger.debug(msg)\n            raise HTTPForbidden(msg, request=req,\n                                content_type=\"text/plain\")\n\n        orig_image_meta = self.get_image_meta_or_404(req, id)\n        orig_status = orig_image_meta['status']\n\n        # The default behaviour for a PUT /images/<IMAGE_ID> is to\n        # override any properties that were previously set. This, however,\n        # leads to a number of issues for the common use case where a caller\n        # registers an image with some properties and then almost immediately\n        # uploads an image file along with some more properties. Here, we\n        # check for a special header value to be false in order to force\n        # properties NOT to be purged. However we also disable purging of\n        # properties if an image file is being uploaded...\n        purge_props = req.headers.get('x-glance-registry-purge-props', True)\n        purge_props = (utils.bool_from_string(purge_props) and\n                       image_data is None)\n\n        if image_data is not None and orig_status != 'queued':\n            raise HTTPConflict(_(\"Cannot upload to an unqueued image\"))\n\n        # Only allow the Location|Copy-From fields to be modified if the\n        # image is in queued status, which indicates that the user called\n        # POST /images but originally supply neither a Location|Copy-From\n        # field NOR image data\n        location = self._external_source(image_meta, req)\n        reactivating = orig_status != 'queued' and location\n        activating = orig_status == 'queued' and (location or image_data)\n\n        if reactivating:\n            msg = _(\"Attempted to update Location field for an image \"\n                    \"not in queued status.\")\n            raise HTTPBadRequest(msg, request=req, content_type=\"text/plain\")\n\n        try:\n            if location:\n                image_meta['size'] = self._get_size(image_meta, location)\n\n            image_meta = registry.update_image_metadata(req.context,\n                                                        id,\n                                                        image_meta,\n                                                        purge_props)\n\n            if activating:\n                image_meta = self._handle_source(req, id, image_meta,\n                                                 image_data)\n        except exception.Invalid, e:\n            msg = (_(\"Failed to update image metadata. Got error: %(e)s\")\n                   % locals())\n            for line in msg.split('\\n'):\n                logger.error(line)\n            self.notifier.error('image.update', msg)\n            raise HTTPBadRequest(msg, request=req, content_type=\"text/plain\")\n        except exception.NotFound, e:\n            msg = (\"Failed to find image to update: %(e)s\" % locals())\n            for line in msg.split('\\n'):\n                logger.info(line)\n            self.notifier.info('image.update', msg)\n            raise HTTPNotFound(msg, request=req, content_type=\"text/plain\")\n        except exception.Forbidden, e:\n            msg = (\"Forbidden to update image: %(e)s\" % locals())\n            for line in msg.split('\\n'):\n                logger.info(line)\n            self.notifier.info('image.update', msg)\n            raise HTTPForbidden(msg, request=req, content_type=\"text/plain\")\n        else:\n            self.notifier.info('image.update', image_meta)\n\n        # Prevent client from learning the location, as it\n        # could contain security credentials\n        image_meta.pop('location', None)\n\n        return {'image_meta': image_meta}\n\n    def delete(self, req, id):\n        \"\"\"\n        Deletes the image and all its chunks from the Glance\n\n        :param req: The WSGI/Webob Request object\n        :param id: The opaque image identifier\n\n        :raises HttpBadRequest if image registry is invalid\n        :raises HttpNotFound if image or any chunk is not available\n        :raises HttpUnauthorized if image or any chunk is not\n                deleteable by the requesting user\n        \"\"\"\n        self._enforce(req, 'delete_image')\n        if req.context.read_only:\n            msg = _(\"Read-only access\")\n            logger.debug(msg)\n            raise HTTPForbidden(msg, request=req,\n                                content_type=\"text/plain\")\n\n        image = self.get_image_meta_or_404(req, id)\n        if image['protected']:\n            msg = _(\"Image is protected\")\n            logger.debug(msg)\n            raise HTTPForbidden(msg, request=req,\n                                content_type=\"text/plain\")\n\n        # The image's location field may be None in the case\n        # of a saving or queued image, therefore don't ask a backend\n        # to delete the image if the backend doesn't yet store it.\n        # See https://bugs.launchpad.net/glance/+bug/747799\n        try:\n            if image['location']:\n                schedule_delete_from_backend(image['location'], self.conf,\n                                             req.context, id)\n            registry.delete_image_metadata(req.context, id)\n        except exception.NotFound, e:\n            msg = (\"Failed to find image to delete: %(e)s\" % locals())\n            for line in msg.split('\\n'):\n                logger.info(line)\n            self.notifier.info('image.delete', msg)\n            raise HTTPNotFound(msg, request=req, content_type=\"text/plain\")\n        except exception.Forbidden, e:\n            msg = (\"Forbidden to delete image: %(e)s\" % locals())\n            for line in msg.split('\\n'):\n                logger.info(line)\n            self.notifier.info('image.delete', msg)\n            raise HTTPForbidden(msg, request=req, content_type=\"text/plain\")\n        else:\n            self.notifier.info('image.delete', id)\n\n    def get_store_or_400(self, request, store_name):\n        \"\"\"\n        Grabs the storage backend for the supplied store name\n        or raises an HTTPBadRequest (400) response\n\n        :param request: The WSGI/Webob Request object\n        :param store_name: The backend store name\n\n        :raises HTTPNotFound if store does not exist\n        \"\"\"\n        try:\n            return get_store_from_scheme(store_name)\n        except exception.UnknownScheme:\n            msg = (_(\"Requested store %s not available on this Glance server\")\n                   % store_name)\n            logger.error(msg)\n            raise HTTPBadRequest(msg, request=request,\n                                 content_type='text/plain')\n\n    def verify_store_or_exit(self, store_name):\n        \"\"\"\n        Verifies availability of the storage backend for the\n        given store name or exits\n\n        :param store_name: The backend store name\n        \"\"\"\n        try:\n            get_store_from_scheme(store_name)\n        except exception.UnknownScheme:\n            msg = (_(\"Default store %s not available on this Glance server\\n\")\n                   % store_name)\n            logger.error(msg)\n            # message on stderr will only be visible if started directly via\n            # bin/glance-api, as opposed to being daemonized by glance-control\n            sys.stderr.write(msg)\n            sys.exit(255)\n\n\nclass ImageDeserializer(wsgi.JSONRequestDeserializer):\n    \"\"\"Handles deserialization of specific controller method requests.\"\"\"\n\n    def _deserialize(self, request):\n        result = {}\n        try:\n            result['image_meta'] = utils.get_image_meta_from_headers(request)\n        except exception.Invalid:\n            image_size_str = request.headers['x-image-meta-size']\n            msg = _(\"Incoming image size of %s was not convertible to \"\n                    \"an integer.\") % image_size_str\n            raise HTTPBadRequest(msg, request=request)\n\n        image_meta = result['image_meta']\n        if 'size' in image_meta:\n            incoming_image_size = image_meta['size']\n            if incoming_image_size > IMAGE_SIZE_CAP:\n                max_image_size = IMAGE_SIZE_CAP\n                msg = _(\"Denying attempt to upload image larger than \"\n                        \"%(max_image_size)d. Supplied image size was \"\n                        \"%(incoming_image_size)d\") % locals()\n                logger.warn(msg)\n                raise HTTPBadRequest(msg, request=request)\n\n        data = request.body_file if self.has_body(request) else None\n        result['image_data'] = data\n        return result\n\n    def create(self, request):\n        return self._deserialize(request)\n\n    def update(self, request):\n        return self._deserialize(request)\n\n\nclass ImageSerializer(wsgi.JSONResponseSerializer):\n    \"\"\"Handles serialization of specific controller method responses.\"\"\"\n\n    def __init__(self, conf):\n        self.conf = conf\n        self.notifier = notifier.Notifier(conf)\n\n    def _inject_location_header(self, response, image_meta):\n        location = self._get_image_location(image_meta)\n        response.headers['Location'] = location\n\n    def _inject_checksum_header(self, response, image_meta):\n        response.headers['ETag'] = image_meta['checksum']\n\n    def _inject_image_meta_headers(self, response, image_meta):\n        \"\"\"\n        Given a response and mapping of image metadata, injects\n        the Response with a set of HTTP headers for the image\n        metadata. Each main image metadata field is injected\n        as a HTTP header with key 'x-image-meta-<FIELD>' except\n        for the properties field, which is further broken out\n        into a set of 'x-image-meta-property-<KEY>' headers\n\n        :param response: The Webob Response object\n        :param image_meta: Mapping of image metadata\n        \"\"\"\n        headers = utils.image_meta_to_http_headers(image_meta)\n\n        for k, v in headers.items():\n            response.headers[k] = v\n\n    def _get_image_location(self, image_meta):\n        \"\"\"Build a relative url to reach the image defined by image_meta.\"\"\"\n        return \"/v1/images/%s\" % image_meta['id']\n\n    def meta(self, response, result):\n        image_meta = result['image_meta']\n        self._inject_image_meta_headers(response, image_meta)\n        self._inject_location_header(response, image_meta)\n        self._inject_checksum_header(response, image_meta)\n        return response\n\n    def image_send_notification(self, bytes_written, expected_size,\n                                image_meta, request):\n        \"\"\"Send an image.send message to the notifier.\"\"\"\n        try:\n            context = request.context\n            payload = {\n                'bytes_sent': bytes_written,\n                'image_id': image_meta['id'],\n                'owner_id': image_meta['owner'],\n                'receiver_tenant_id': context.tenant,\n                'receiver_user_id': context.user,\n                'destination_ip': request.remote_addr,\n            }\n            if bytes_written != expected_size:\n                self.notifier.error('image.send', payload)\n            else:\n                self.notifier.info('image.send', payload)\n        except Exception, err:\n            msg = _(\"An error occurred during image.send\"\n                    \" notification: %(err)s\") % locals()\n            logger.error(msg)\n\n    def show(self, response, result):\n        image_meta = result['image_meta']\n        image_id = image_meta['id']\n\n        # We use a secondary iterator here to wrap the\n        # iterator coming back from the store driver in\n        # order to check for disconnections from the backend\n        # storage connections and log an error if the size of\n        # the transferred image is not the same as the expected\n        # size of the image file. See LP Bug #882585.\n        def checked_iter(image_id, expected_size, image_iter):\n            bytes_written = 0\n\n            def notify_image_sent_hook(env):\n                self.image_send_notification(bytes_written, expected_size,\n                                             image_meta, response.request)\n\n            # Add hook to process after response is fully sent\n            if 'eventlet.posthooks' in response.request.environ:\n                response.request.environ['eventlet.posthooks'].append(\n                    (notify_image_sent_hook, (), {}))\n\n            try:\n                for chunk in image_iter:\n                    yield chunk\n                    bytes_written += len(chunk)\n            except Exception, err:\n                msg = _(\"An error occurred reading from backend storage \"\n                        \"for image %(image_id): %(err)s\") % locals()\n                logger.error(msg)\n                raise\n\n            if expected_size != bytes_written:\n                msg = _(\"Backend storage for image %(image_id)s \"\n                        \"disconnected after writing only %(bytes_written)d \"\n                        \"bytes\") % locals()\n                logger.error(msg)\n                raise IOError(errno.EPIPE, _(\"Corrupt image download for \"\n                                             \"image %(image_id)s\") % locals())\n\n        image_iter = result['image_iterator']\n        # image_meta['size'] is a str\n        expected_size = int(image_meta['size'])\n        response.app_iter = checked_iter(image_id, expected_size, image_iter)\n        # Using app_iter blanks content-length, so we set it here...\n        response.headers['Content-Length'] = image_meta['size']\n        response.headers['Content-Type'] = 'application/octet-stream'\n\n        self._inject_image_meta_headers(response, image_meta)\n        self._inject_location_header(response, image_meta)\n        self._inject_checksum_header(response, image_meta)\n\n        return response\n\n    def update(self, response, result):\n        image_meta = result['image_meta']\n        response.body = self.to_json(dict(image=image_meta))\n        response.headers['Content-Type'] = 'application/json'\n        self._inject_location_header(response, image_meta)\n        self._inject_checksum_header(response, image_meta)\n        return response\n\n    def create(self, response, result):\n        image_meta = result['image_meta']\n        response.status = 201\n        response.headers['Content-Type'] = 'application/json'\n        response.body = self.to_json(dict(image=image_meta))\n        self._inject_location_header(response, image_meta)\n        self._inject_checksum_header(response, image_meta)\n        return response\n\n\ndef create_resource(conf):\n    \"\"\"Images resource factory method\"\"\"\n    deserializer = ImageDeserializer()\n    serializer = ImageSerializer(conf)\n    return wsgi.Resource(Controller(conf), deserializer, serializer)\n", "target": 1}
{"idx": 875, "func": "# vim: ft=python fileencoding=utf-8 sts=4 sw=4 et:\n\n# Copyright 2016-2019 Florian Bruhin (The Compiler) <mail@qutebrowser.org>\n#\n# This file is part of qutebrowser.\n#\n# qutebrowser is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# qutebrowser is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with qutebrowser.  If not, see <http://www.gnu.org/licenses/>.\n\n\"\"\"Base class for a wrapper over QWebView/QWebEngineView.\"\"\"\n\nimport enum\nimport itertools\nimport typing\n\nimport attr\nfrom PyQt5.QtCore import (pyqtSignal, pyqtSlot, QUrl, QObject, QSizeF, Qt,\n                          QEvent, QPoint)\nfrom PyQt5.QtGui import QKeyEvent, QIcon\nfrom PyQt5.QtWidgets import QWidget, QApplication, QDialog\nfrom PyQt5.QtPrintSupport import QPrintDialog, QPrinter\nfrom PyQt5.QtNetwork import QNetworkAccessManager\n\nimport pygments\nimport pygments.lexers\nimport pygments.formatters\n\nfrom qutebrowser.keyinput import modeman\nfrom qutebrowser.config import config\nfrom qutebrowser.utils import (utils, objreg, usertypes, log, qtutils,\n                               urlutils, message)\nfrom qutebrowser.misc import miscwidgets, objects\nfrom qutebrowser.browser import mouse, hints\nfrom qutebrowser.qt import sip\nMYPY = False\nif MYPY:\n    # pylint can't interpret type comments with Python 3.7\n    # pylint: disable=unused-import,useless-suppression\n    from qutebrowser.browser import webelem\n    from qutebrowser.browser.inspector import AbstractWebInspector\n\n\ntab_id_gen = itertools.count(0)\n\n\ndef create(win_id: int,\n           private: bool,\n           parent: QWidget = None) -> 'AbstractTab':\n    \"\"\"Get a QtWebKit/QtWebEngine tab object.\n\n    Args:\n        win_id: The window ID where the tab will be shown.\n        private: Whether the tab is a private/off the record tab.\n        parent: The Qt parent to set.\n    \"\"\"\n    # Importing modules here so we don't depend on QtWebEngine without the\n    # argument and to avoid circular imports.\n    mode_manager = modeman.instance(win_id)\n    if objects.backend == usertypes.Backend.QtWebEngine:\n        from qutebrowser.browser.webengine import webenginetab\n        tab_class = webenginetab.WebEngineTab\n    else:\n        from qutebrowser.browser.webkit import webkittab\n        tab_class = webkittab.WebKitTab\n    return tab_class(win_id=win_id, mode_manager=mode_manager, private=private,\n                     parent=parent)\n\n\ndef init() -> None:\n    \"\"\"Initialize backend-specific modules.\"\"\"\n    if objects.backend == usertypes.Backend.QtWebEngine:\n        from qutebrowser.browser.webengine import webenginetab\n        webenginetab.init()\n\n\nclass WebTabError(Exception):\n\n    \"\"\"Base class for various errors.\"\"\"\n\n\nclass UnsupportedOperationError(WebTabError):\n\n    \"\"\"Raised when an operation is not supported with the given backend.\"\"\"\n\n\nTerminationStatus = enum.Enum('TerminationStatus', [\n    'normal',\n    'abnormal',  # non-zero exit status\n    'crashed',   # e.g. segfault\n    'killed',\n    'unknown',\n])\n\n\n@attr.s\nclass TabData:\n\n    \"\"\"A simple namespace with a fixed set of attributes.\n\n    Attributes:\n        keep_icon: Whether the (e.g. cloned) icon should not be cleared on page\n                   load.\n        inspector: The QWebInspector used for this webview.\n        viewing_source: Set if we're currently showing a source view.\n                        Only used when sources are shown via pygments.\n        open_target: Where to open the next link.\n                     Only used for QtWebKit.\n        override_target: Override for open_target for fake clicks (like hints).\n                         Only used for QtWebKit.\n        pinned: Flag to pin the tab.\n        fullscreen: Whether the tab has a video shown fullscreen currently.\n        netrc_used: Whether netrc authentication was performed.\n        input_mode: current input mode for the tab.\n    \"\"\"\n\n    keep_icon = attr.ib(False)  # type: bool\n    viewing_source = attr.ib(False)  # type: bool\n    inspector = attr.ib(None)  # type: typing.Optional[AbstractWebInspector]\n    open_target = attr.ib(\n        usertypes.ClickTarget.normal)  # type: usertypes.ClickTarget\n    override_target = attr.ib(None)  # type: usertypes.ClickTarget\n    pinned = attr.ib(False)  # type: bool\n    fullscreen = attr.ib(False)  # type: bool\n    netrc_used = attr.ib(False)  # type: bool\n    input_mode = attr.ib(usertypes.KeyMode.normal)  # type: usertypes.KeyMode\n\n    def should_show_icon(self) -> bool:\n        return (config.val.tabs.favicons.show == 'always' or\n                config.val.tabs.favicons.show == 'pinned' and self.pinned)\n\n\nclass AbstractAction:\n\n    \"\"\"Attribute ``action`` of AbstractTab for Qt WebActions.\"\"\"\n\n    # The class actions are defined on (QWeb{Engine,}Page)\n    action_class = None  # type: type\n    # The type of the actions (QWeb{Engine,}Page.WebAction)\n    action_base = None  # type: type\n\n    def __init__(self, tab: 'AbstractTab') -> None:\n        self._widget = typing.cast(QWidget, None)\n        self._tab = tab\n\n    def exit_fullscreen(self) -> None:\n        \"\"\"Exit the fullscreen mode.\"\"\"\n        raise NotImplementedError\n\n    def save_page(self) -> None:\n        \"\"\"Save the current page.\"\"\"\n        raise NotImplementedError\n\n    def run_string(self, name: str) -> None:\n        \"\"\"Run a webaction based on its name.\"\"\"\n        member = getattr(self.action_class, name, None)\n        if not isinstance(member, self.action_base):\n            raise WebTabError(\"{} is not a valid web action!\".format(name))\n        self._widget.triggerPageAction(member)\n\n    def show_source(\n            self,\n            pygments: bool = False  # pylint: disable=redefined-outer-name\n    ) -> None:\n        \"\"\"Show the source of the current page in a new tab.\"\"\"\n        raise NotImplementedError\n\n    def _show_source_pygments(self) -> None:\n\n        def show_source_cb(source: str) -> None:\n            \"\"\"Show source as soon as it's ready.\"\"\"\n            # WORKAROUND for https://github.com/PyCQA/pylint/issues/491\n            # pylint: disable=no-member\n            lexer = pygments.lexers.HtmlLexer()\n            formatter = pygments.formatters.HtmlFormatter(\n                full=True, linenos='table')\n            # pylint: enable=no-member\n            highlighted = pygments.highlight(source, lexer, formatter)\n\n            tb = objreg.get('tabbed-browser', scope='window',\n                            window=self._tab.win_id)\n            new_tab = tb.tabopen(background=False, related=True)\n            new_tab.set_html(highlighted, self._tab.url())\n            new_tab.data.viewing_source = True\n\n        self._tab.dump_async(show_source_cb)\n\n\nclass AbstractPrinting:\n\n    \"\"\"Attribute ``printing`` of AbstractTab for printing the page.\"\"\"\n\n    def __init__(self, tab: 'AbstractTab') -> None:\n        self._widget = None\n        self._tab = tab\n\n    def check_pdf_support(self) -> None:\n        \"\"\"Check whether writing to PDFs is supported.\n\n        If it's not supported (by the current Qt version), a WebTabError is\n        raised.\n        \"\"\"\n        raise NotImplementedError\n\n    def check_printer_support(self) -> None:\n        \"\"\"Check whether writing to a printer is supported.\n\n        If it's not supported (by the current Qt version), a WebTabError is\n        raised.\n        \"\"\"\n        raise NotImplementedError\n\n    def check_preview_support(self) -> None:\n        \"\"\"Check whether showing a print preview is supported.\n\n        If it's not supported (by the current Qt version), a WebTabError is\n        raised.\n        \"\"\"\n        raise NotImplementedError\n\n    def to_pdf(self, filename: str) -> bool:\n        \"\"\"Print the tab to a PDF with the given filename.\"\"\"\n        raise NotImplementedError\n\n    def to_printer(self, printer: QPrinter,\n                   callback: typing.Callable[[bool], None] = None) -> None:\n        \"\"\"Print the tab.\n\n        Args:\n            printer: The QPrinter to print to.\n            callback: Called with a boolean\n                      (True if printing succeeded, False otherwise)\n        \"\"\"\n        raise NotImplementedError\n\n    def show_dialog(self) -> None:\n        \"\"\"Print with a QPrintDialog.\"\"\"\n        self.check_printer_support()\n\n        def print_callback(ok: bool) -> None:\n            \"\"\"Called when printing finished.\"\"\"\n            if not ok:\n                message.error(\"Printing failed!\")\n            diag.deleteLater()\n\n        def do_print() -> None:\n            \"\"\"Called when the dialog was closed.\"\"\"\n            self.to_printer(diag.printer(), print_callback)\n\n        diag = QPrintDialog(self._tab)\n        if utils.is_mac:\n            # For some reason we get a segfault when using open() on macOS\n            ret = diag.exec_()\n            if ret == QDialog.Accepted:\n                do_print()\n        else:\n            diag.open(do_print)\n\n\nclass AbstractSearch(QObject):\n\n    \"\"\"Attribute ``search`` of AbstractTab for doing searches.\n\n    Attributes:\n        text: The last thing this view was searched for.\n        search_displayed: Whether we're currently displaying search results in\n                          this view.\n        _flags: The flags of the last search (needs to be set by subclasses).\n        _widget: The underlying WebView widget.\n    \"\"\"\n\n    #: Signal emitted when a search was finished\n    #: (True if the text was found, False otherwise)\n    finished = pyqtSignal(bool)\n    #: Signal emitted when an existing search was cleared.\n    cleared = pyqtSignal()\n\n    _Callback = typing.Callable[[bool], None]\n\n    def __init__(self, tab: 'AbstractTab', parent: QWidget = None):\n        super().__init__(parent)\n        self._tab = tab\n        self._widget = None\n        self.text = None  # type: typing.Optional[str]\n        self.search_displayed = False\n\n    def _is_case_sensitive(self, ignore_case: usertypes.IgnoreCase) -> bool:\n        \"\"\"Check if case-sensitivity should be used.\n\n        This assumes self.text is already set properly.\n\n        Arguments:\n            ignore_case: The ignore_case value from the config.\n        \"\"\"\n        assert self.text is not None\n        mapping = {\n            usertypes.IgnoreCase.smart: not self.text.islower(),\n            usertypes.IgnoreCase.never: True,\n            usertypes.IgnoreCase.always: False,\n        }\n        return mapping[ignore_case]\n\n    def search(self, text: str, *,\n               ignore_case: usertypes.IgnoreCase = usertypes.IgnoreCase.never,\n               reverse: bool = False,\n               result_cb: _Callback = None) -> None:\n        \"\"\"Find the given text on the page.\n\n        Args:\n            text: The text to search for.\n            ignore_case: Search case-insensitively.\n            reverse: Reverse search direction.\n            result_cb: Called with a bool indicating whether a match was found.\n        \"\"\"\n        raise NotImplementedError\n\n    def clear(self) -> None:\n        \"\"\"Clear the current search.\"\"\"\n        raise NotImplementedError\n\n    def prev_result(self, *, result_cb: _Callback = None) -> None:\n        \"\"\"Go to the previous result of the current search.\n\n        Args:\n            result_cb: Called with a bool indicating whether a match was found.\n        \"\"\"\n        raise NotImplementedError\n\n    def next_result(self, *, result_cb: _Callback = None) -> None:\n        \"\"\"Go to the next result of the current search.\n\n        Args:\n            result_cb: Called with a bool indicating whether a match was found.\n        \"\"\"\n        raise NotImplementedError\n\n\nclass AbstractZoom(QObject):\n\n    \"\"\"Attribute ``zoom`` of AbstractTab for controlling zoom.\"\"\"\n\n    def __init__(self, tab: 'AbstractTab', parent: QWidget = None) -> None:\n        super().__init__(parent)\n        self._tab = tab\n        self._widget = None\n        # Whether zoom was changed from the default.\n        self._default_zoom_changed = False\n        self._init_neighborlist()\n        config.instance.changed.connect(self._on_config_changed)\n        self._zoom_factor = float(config.val.zoom.default) / 100\n\n    @pyqtSlot(str)\n    def _on_config_changed(self, option: str) -> None:\n        if option in ['zoom.levels', 'zoom.default']:\n            if not self._default_zoom_changed:\n                factor = float(config.val.zoom.default) / 100\n                self.set_factor(factor)\n            self._init_neighborlist()\n\n    def _init_neighborlist(self) -> None:\n        \"\"\"Initialize self._neighborlist.\n\n        It is a NeighborList with the zoom levels.\"\"\"\n        levels = config.val.zoom.levels\n        self._neighborlist = usertypes.NeighborList(\n            levels, mode=usertypes.NeighborList.Modes.edge)\n        self._neighborlist.fuzzyval = config.val.zoom.default\n\n    def apply_offset(self, offset: int) -> None:\n        \"\"\"Increase/Decrease the zoom level by the given offset.\n\n        Args:\n            offset: The offset in the zoom level list.\n\n        Return:\n            The new zoom percentage.\n        \"\"\"\n        level = self._neighborlist.getitem(offset)\n        self.set_factor(float(level) / 100, fuzzyval=False)\n        return level\n\n    def _set_factor_internal(self, factor: float) -> None:\n        raise NotImplementedError\n\n    def set_factor(self, factor: float, *, fuzzyval: bool = True) -> None:\n        \"\"\"Zoom to a given zoom factor.\n\n        Args:\n            factor: The zoom factor as float.\n            fuzzyval: Whether to set the NeighborLists fuzzyval.\n        \"\"\"\n        if fuzzyval:\n            self._neighborlist.fuzzyval = int(factor * 100)\n        if factor < 0:\n            raise ValueError(\"Can't zoom to factor {}!\".format(factor))\n\n        default_zoom_factor = float(config.val.zoom.default) / 100\n        self._default_zoom_changed = (factor != default_zoom_factor)\n\n        self._zoom_factor = factor\n        self._set_factor_internal(factor)\n\n    def factor(self) -> float:\n        return self._zoom_factor\n\n    def apply_default(self) -> None:\n        self._set_factor_internal(float(config.val.zoom.default) / 100)\n\n    def reapply(self) -> None:\n        self._set_factor_internal(self._zoom_factor)\n\n\nclass AbstractCaret(QObject):\n\n    \"\"\"Attribute ``caret`` of AbstractTab for caret browsing.\"\"\"\n\n    #: Signal emitted when the selection was toggled.\n    #: (argument - whether the selection is now active)\n    selection_toggled = pyqtSignal(bool)\n    #: Emitted when a ``follow_selection`` action is done.\n    follow_selected_done = pyqtSignal()\n\n    def __init__(self,\n                 tab: 'AbstractTab',\n                 mode_manager: modeman.ModeManager,\n                 parent: QWidget = None) -> None:\n        super().__init__(parent)\n        self._tab = tab\n        self._widget = None\n        self.selection_enabled = False\n        mode_manager.entered.connect(self._on_mode_entered)\n        mode_manager.left.connect(self._on_mode_left)\n\n    def _on_mode_entered(self, mode: usertypes.KeyMode) -> None:\n        raise NotImplementedError\n\n    def _on_mode_left(self, mode: usertypes.KeyMode) -> None:\n        raise NotImplementedError\n\n    def move_to_next_line(self, count: int = 1) -> None:\n        raise NotImplementedError\n\n    def move_to_prev_line(self, count: int = 1) -> None:\n        raise NotImplementedError\n\n    def move_to_next_char(self, count: int = 1) -> None:\n        raise NotImplementedError\n\n    def move_to_prev_char(self, count: int = 1) -> None:\n        raise NotImplementedError\n\n    def move_to_end_of_word(self, count: int = 1) -> None:\n        raise NotImplementedError\n\n    def move_to_next_word(self, count: int = 1) -> None:\n        raise NotImplementedError\n\n    def move_to_prev_word(self, count: int = 1) -> None:\n        raise NotImplementedError\n\n    def move_to_start_of_line(self) -> None:\n        raise NotImplementedError\n\n    def move_to_end_of_line(self) -> None:\n        raise NotImplementedError\n\n    def move_to_start_of_next_block(self, count: int = 1) -> None:\n        raise NotImplementedError\n\n    def move_to_start_of_prev_block(self, count: int = 1) -> None:\n        raise NotImplementedError\n\n    def move_to_end_of_next_block(self, count: int = 1) -> None:\n        raise NotImplementedError\n\n    def move_to_end_of_prev_block(self, count: int = 1) -> None:\n        raise NotImplementedError\n\n    def move_to_start_of_document(self) -> None:\n        raise NotImplementedError\n\n    def move_to_end_of_document(self) -> None:\n        raise NotImplementedError\n\n    def toggle_selection(self) -> None:\n        raise NotImplementedError\n\n    def drop_selection(self) -> None:\n        raise NotImplementedError\n\n    def selection(self, callback: typing.Callable[[str], None]) -> None:\n        raise NotImplementedError\n\n    def _follow_enter(self, tab: bool) -> None:\n        \"\"\"Follow a link by faking an enter press.\"\"\"\n        if tab:\n            self._tab.fake_key_press(Qt.Key_Enter, modifier=Qt.ControlModifier)\n        else:\n            self._tab.fake_key_press(Qt.Key_Enter)\n\n    def follow_selected(self, *, tab: bool = False) -> None:\n        raise NotImplementedError\n\n\nclass AbstractScroller(QObject):\n\n    \"\"\"Attribute ``scroller`` of AbstractTab to manage scroll position.\"\"\"\n\n    #: Signal emitted when the scroll position changed (int, int)\n    perc_changed = pyqtSignal(int, int)\n    #: Signal emitted before the user requested a jump.\n    #: Used to set the special ' mark so the user can return.\n    before_jump_requested = pyqtSignal()\n\n    def __init__(self, tab: 'AbstractTab', parent: QWidget = None):\n        super().__init__(parent)\n        self._tab = tab\n        self._widget = None  # type: typing.Optional[QWidget]\n        self.perc_changed.connect(self._log_scroll_pos_change)\n\n    @pyqtSlot()\n    def _log_scroll_pos_change(self) -> None:\n        log.webview.vdebug(  # type: ignore\n            \"Scroll position changed to {}\".format(self.pos_px()))\n\n    def _init_widget(self, widget: QWidget) -> None:\n        self._widget = widget\n\n    def pos_px(self) -> int:\n        raise NotImplementedError\n\n    def pos_perc(self) -> int:\n        raise NotImplementedError\n\n    def to_perc(self, x: int = None, y: int = None) -> None:\n        raise NotImplementedError\n\n    def to_point(self, point: QPoint) -> None:\n        raise NotImplementedError\n\n    def to_anchor(self, name: str) -> None:\n        raise NotImplementedError\n\n    def delta(self, x: int = 0, y: int = 0) -> None:\n        raise NotImplementedError\n\n    def delta_page(self, x: float = 0, y: float = 0) -> None:\n        raise NotImplementedError\n\n    def up(self, count: int = 1) -> None:\n        raise NotImplementedError\n\n    def down(self, count: int = 1) -> None:\n        raise NotImplementedError\n\n    def left(self, count: int = 1) -> None:\n        raise NotImplementedError\n\n    def right(self, count: int = 1) -> None:\n        raise NotImplementedError\n\n    def top(self) -> None:\n        raise NotImplementedError\n\n    def bottom(self) -> None:\n        raise NotImplementedError\n\n    def page_up(self, count: int = 1) -> None:\n        raise NotImplementedError\n\n    def page_down(self, count: int = 1) -> None:\n        raise NotImplementedError\n\n    def at_top(self) -> bool:\n        raise NotImplementedError\n\n    def at_bottom(self) -> bool:\n        raise NotImplementedError\n\n\nclass AbstractHistoryPrivate:\n\n    \"\"\"Private API related to the history.\"\"\"\n\n    def __init__(self, tab: 'AbstractTab'):\n        self._tab = tab\n        self._history = None\n\n    def serialize(self) -> bytes:\n        \"\"\"Serialize into an opaque format understood by self.deserialize.\"\"\"\n        raise NotImplementedError\n\n    def deserialize(self, data: bytes) -> None:\n        \"\"\"Deserialize from a format produced by self.serialize.\"\"\"\n        raise NotImplementedError\n\n    def load_items(self, items: typing.Sequence) -> None:\n        \"\"\"Deserialize from a list of WebHistoryItems.\"\"\"\n        raise NotImplementedError\n\n\nclass AbstractHistory:\n\n    \"\"\"The history attribute of a AbstractTab.\"\"\"\n\n    def __init__(self, tab: 'AbstractTab') -> None:\n        self._tab = tab\n        self._history = None\n        self.private_api = AbstractHistoryPrivate(tab)\n\n    def __len__(self) -> int:\n        raise NotImplementedError\n\n    def __iter__(self) -> typing.Iterable:\n        raise NotImplementedError\n\n    def _check_count(self, count: int) -> None:\n        \"\"\"Check whether the count is positive.\"\"\"\n        if count < 0:\n            raise WebTabError(\"count needs to be positive!\")\n\n    def current_idx(self) -> int:\n        raise NotImplementedError\n\n    def back(self, count: int = 1) -> None:\n        \"\"\"Go back in the tab's history.\"\"\"\n        self._check_count(count)\n        idx = self.current_idx() - count\n        if idx >= 0:\n            self._go_to_item(self._item_at(idx))\n        else:\n            self._go_to_item(self._item_at(0))\n            raise WebTabError(\"At beginning of history.\")\n\n    def forward(self, count: int = 1) -> None:\n        \"\"\"Go forward in the tab's history.\"\"\"\n        self._check_count(count)\n        idx = self.current_idx() + count\n        if idx < len(self):\n            self._go_to_item(self._item_at(idx))\n        else:\n            self._go_to_item(self._item_at(len(self) - 1))\n            raise WebTabError(\"At end of history.\")\n\n    def can_go_back(self) -> bool:\n        raise NotImplementedError\n\n    def can_go_forward(self) -> bool:\n        raise NotImplementedError\n\n    def _item_at(self, i: int) -> typing.Any:\n        raise NotImplementedError\n\n    def _go_to_item(self, item: typing.Any) -> None:\n        raise NotImplementedError\n\n\nclass AbstractElements:\n\n    \"\"\"Finding and handling of elements on the page.\"\"\"\n\n    _MultiCallback = typing.Callable[\n        [typing.Sequence['webelem.AbstractWebElement']], None]\n    _SingleCallback = typing.Callable[\n        [typing.Optional['webelem.AbstractWebElement']], None]\n    _ErrorCallback = typing.Callable[[Exception], None]\n\n    def __init__(self, tab: 'AbstractTab') -> None:\n        self._widget = None\n        self._tab = tab\n\n    def find_css(self, selector: str,\n                 callback: _MultiCallback,\n                 error_cb: _ErrorCallback, *,\n                 only_visible: bool = False) -> None:\n        \"\"\"Find all HTML elements matching a given selector async.\n\n        If there's an error, the callback is called with a webelem.Error\n        instance.\n\n        Args:\n            callback: The callback to be called when the search finished.\n            error_cb: The callback to be called when an error occurred.\n            selector: The CSS selector to search for.\n            only_visible: Only show elements which are visible on screen.\n        \"\"\"\n        raise NotImplementedError\n\n    def find_id(self, elem_id: str, callback: _SingleCallback) -> None:\n        \"\"\"Find the HTML element with the given ID async.\n\n        Args:\n            callback: The callback to be called when the search finished.\n                      Called with a WebEngineElement or None.\n            elem_id: The ID to search for.\n        \"\"\"\n        raise NotImplementedError\n\n    def find_focused(self, callback: _SingleCallback) -> None:\n        \"\"\"Find the focused element on the page async.\n\n        Args:\n            callback: The callback to be called when the search finished.\n                      Called with a WebEngineElement or None.\n        \"\"\"\n        raise NotImplementedError\n\n    def find_at_pos(self, pos: QPoint, callback: _SingleCallback) -> None:\n        \"\"\"Find the element at the given position async.\n\n        This is also called \"hit test\" elsewhere.\n\n        Args:\n            pos: The QPoint to get the element for.\n            callback: The callback to be called when the search finished.\n                      Called with a WebEngineElement or None.\n        \"\"\"\n        raise NotImplementedError\n\n\nclass AbstractAudio(QObject):\n\n    \"\"\"Handling of audio/muting for this tab.\"\"\"\n\n    muted_changed = pyqtSignal(bool)\n    recently_audible_changed = pyqtSignal(bool)\n\n    def __init__(self, tab: 'AbstractTab', parent: QWidget = None) -> None:\n        super().__init__(parent)\n        self._widget = None  # type: typing.Optional[QWidget]\n        self._tab = tab\n\n    def set_muted(self, muted: bool, override: bool = False) -> None:\n        \"\"\"Set this tab as muted or not.\n\n        Arguments:\n            override: If set to True, muting/unmuting was done manually and\n                      overrides future automatic mute/unmute changes based on\n                      the URL.\n        \"\"\"\n        raise NotImplementedError\n\n    def is_muted(self) -> bool:\n        raise NotImplementedError\n\n    def is_recently_audible(self) -> bool:\n        \"\"\"Whether this tab has had audio playing recently.\"\"\"\n        raise NotImplementedError\n\n\nclass AbstractTabPrivate:\n\n    \"\"\"Tab-related methods which are only needed in the core.\n\n    Those methods are not part of the API which is exposed to extensions, and\n    should ideally be removed at some point in the future.\n    \"\"\"\n\n    def __init__(self, mode_manager: modeman.ModeManager,\n                 tab: 'AbstractTab') -> None:\n        self._widget = None  # type: typing.Optional[QWidget]\n        self._tab = tab\n        self._mode_manager = mode_manager\n\n    def event_target(self) -> QWidget:\n        \"\"\"Return the widget events should be sent to.\"\"\"\n        raise NotImplementedError\n\n    def handle_auto_insert_mode(self, ok: bool) -> None:\n        \"\"\"Handle `input.insert_mode.auto_load` after loading finished.\"\"\"\n        if not config.val.input.insert_mode.auto_load or not ok:\n            return\n\n        cur_mode = self._mode_manager.mode\n        if cur_mode == usertypes.KeyMode.insert:\n            return\n\n        def _auto_insert_mode_cb(elem: 'webelem.AbstractWebElement') -> None:\n            \"\"\"Called from JS after finding the focused element.\"\"\"\n            if elem is None:\n                log.webview.debug(\"No focused element!\")\n                return\n            if elem.is_editable():\n                modeman.enter(self._tab.win_id, usertypes.KeyMode.insert,\n                              'load finished', only_if_normal=True)\n\n        self._tab.elements.find_focused(_auto_insert_mode_cb)\n\n    def clear_ssl_errors(self) -> None:\n        raise NotImplementedError\n\n    def networkaccessmanager(self) -> typing.Optional[QNetworkAccessManager]:\n        \"\"\"Get the QNetworkAccessManager for this tab.\n\n        This is only implemented for QtWebKit.\n        For QtWebEngine, always returns None.\n        \"\"\"\n        raise NotImplementedError\n\n    def user_agent(self) -> typing.Optional[str]:\n        \"\"\"Get the user agent for this tab.\n\n        This is only implemented for QtWebKit.\n        For QtWebEngine, always returns None.\n        \"\"\"\n        raise NotImplementedError\n\n    def shutdown(self) -> None:\n        raise NotImplementedError\n\n\nclass AbstractTab(QWidget):\n\n    \"\"\"An adapter for QWebView/QWebEngineView representing a single tab.\"\"\"\n\n    #: Signal emitted when a website requests to close this tab.\n    window_close_requested = pyqtSignal()\n    #: Signal emitted when a link is hovered (the hover text)\n    link_hovered = pyqtSignal(str)\n    #: Signal emitted when a page started loading\n    load_started = pyqtSignal()\n    #: Signal emitted when a page is loading (progress percentage)\n    load_progress = pyqtSignal(int)\n    #: Signal emitted when a page finished loading (success as bool)\n    load_finished = pyqtSignal(bool)\n    #: Signal emitted when a page's favicon changed (icon as QIcon)\n    icon_changed = pyqtSignal(QIcon)\n    #: Signal emitted when a page's title changed (new title as str)\n    title_changed = pyqtSignal(str)\n    #: Signal emitted when a new tab should be opened (url as QUrl)\n    new_tab_requested = pyqtSignal(QUrl)\n    #: Signal emitted when a page's URL changed (url as QUrl)\n    url_changed = pyqtSignal(QUrl)\n    #: Signal emitted when a tab's content size changed\n    #: (new size as QSizeF)\n    contents_size_changed = pyqtSignal(QSizeF)\n    #: Signal emitted when a page requested full-screen (bool)\n    fullscreen_requested = pyqtSignal(bool)\n    #: Signal emitted before load starts (URL as QUrl)\n    before_load_started = pyqtSignal(QUrl)\n\n    # Signal emitted when a page's load status changed\n    # (argument: usertypes.LoadStatus)\n    load_status_changed = pyqtSignal(usertypes.LoadStatus)\n    # Signal emitted before shutting down\n    shutting_down = pyqtSignal()\n    # Signal emitted when a history item should be added\n    history_item_triggered = pyqtSignal(QUrl, QUrl, str)\n    # Signal emitted when the underlying renderer process terminated.\n    # arg 0: A TerminationStatus member.\n    # arg 1: The exit code.\n    renderer_process_terminated = pyqtSignal(TerminationStatus, int)\n\n    # Hosts for which a certificate error happened. Shared between all tabs.\n    #\n    # Note that we remember hosts here, without scheme/port:\n    # QtWebEngine/Chromium also only remembers hostnames, and certificates are\n    # for a given hostname anyways.\n    _insecure_hosts = set()  # type: typing.Set[str]\n\n    def __init__(self, *, win_id: int, private: bool,\n                 parent: QWidget = None) -> None:\n        self.is_private = private\n        self.win_id = win_id\n        self.tab_id = next(tab_id_gen)\n        super().__init__(parent)\n\n        self.registry = objreg.ObjectRegistry()\n        tab_registry = objreg.get('tab-registry', scope='window',\n                                  window=win_id)\n        tab_registry[self.tab_id] = self\n        objreg.register('tab', self, registry=self.registry)\n\n        self.data = TabData()\n        self._layout = miscwidgets.WrapperLayout(self)\n        self._widget = None  # type: typing.Optional[QWidget]\n        self._progress = 0\n        self._load_status = usertypes.LoadStatus.none\n        self._mouse_event_filter = mouse.MouseEventFilter(\n            self, parent=self)\n        self.backend = None\n\n        # FIXME:qtwebengine  Should this be public api via self.hints?\n        #                    Also, should we get it out of objreg?\n        hintmanager = hints.HintManager(win_id, self.tab_id, parent=self)\n        objreg.register('hintmanager', hintmanager, scope='tab',\n                        window=self.win_id, tab=self.tab_id)\n\n        self.before_load_started.connect(self._on_before_load_started)\n\n    def _set_widget(self, widget: QWidget) -> None:\n        # pylint: disable=protected-access\n        self._widget = widget\n        self._layout.wrap(self, widget)\n        self.history._history = widget.history()\n        self.history.private_api._history = widget.history()\n        self.scroller._init_widget(widget)\n        self.caret._widget = widget\n        self.zoom._widget = widget\n        self.search._widget = widget\n        self.printing._widget = widget\n        self.action._widget = widget\n        self.elements._widget = widget\n        self.audio._widget = widget\n        self.private_api._widget = widget\n        self.settings._settings = widget.settings()\n\n        self._install_event_filter()\n        self.zoom.apply_default()\n\n    def _install_event_filter(self) -> None:\n        raise NotImplementedError\n\n    def _set_load_status(self, val: usertypes.LoadStatus) -> None:\n        \"\"\"Setter for load_status.\"\"\"\n        if not isinstance(val, usertypes.LoadStatus):\n            raise TypeError(\"Type {} is no LoadStatus member!\".format(val))\n        log.webview.debug(\"load status for {}: {}\".format(repr(self), val))\n        self._load_status = val\n        self.load_status_changed.emit(val)\n\n    def send_event(self, evt: QEvent) -> None:\n        \"\"\"Send the given event to the underlying widget.\n\n        The event will be sent via QApplication.postEvent.\n        Note that a posted event must not be re-used in any way!\n        \"\"\"\n        # This only gives us some mild protection against re-using events, but\n        # it's certainly better than a segfault.\n        if getattr(evt, 'posted', False):\n            raise utils.Unreachable(\"Can't re-use an event which was already \"\n                                    \"posted!\")\n\n        recipient = self.private_api.event_target()\n        if recipient is None:\n            # https://github.com/qutebrowser/qutebrowser/issues/3888\n            log.webview.warning(\"Unable to find event target!\")\n            return\n\n        evt.posted = True\n        QApplication.postEvent(recipient, evt)\n\n    def navigation_blocked(self) -> bool:\n        \"\"\"Test if navigation is allowed on the current tab.\"\"\"\n        return self.data.pinned and config.val.tabs.pinned.frozen\n\n    @pyqtSlot(QUrl)\n    def _on_before_load_started(self, url: QUrl) -> None:\n        \"\"\"Adjust the title if we are going to visit a URL soon.\"\"\"\n        qtutils.ensure_valid(url)\n        url_string = url.toDisplayString()\n        log.webview.debug(\"Going to start loading: {}\".format(url_string))\n        self.title_changed.emit(url_string)\n\n    @pyqtSlot(QUrl)\n    def _on_url_changed(self, url: QUrl) -> None:\n        \"\"\"Update title when URL has changed and no title is available.\"\"\"\n        if url.isValid() and not self.title():\n            self.title_changed.emit(url.toDisplayString())\n        self.url_changed.emit(url)\n\n    @pyqtSlot()\n    def _on_load_started(self) -> None:\n        self._progress = 0\n        self.data.viewing_source = False\n        self._set_load_status(usertypes.LoadStatus.loading)\n        self.load_started.emit()\n\n    @pyqtSlot(usertypes.NavigationRequest)\n    def _on_navigation_request(\n            self,\n            navigation: usertypes.NavigationRequest\n    ) -> None:\n        \"\"\"Handle common acceptNavigationRequest code.\"\"\"\n        url = utils.elide(navigation.url.toDisplayString(), 100)\n        log.webview.debug(\"navigation request: url {}, type {}, is_main_frame \"\n                          \"{}\".format(url,\n                                      navigation.navigation_type,\n                                      navigation.is_main_frame))\n\n        if not navigation.url.isValid():\n            # Also a WORKAROUND for missing IDNA 2008 support in QUrl, see\n            # https://bugreports.qt.io/browse/QTBUG-60364\n\n            if navigation.navigation_type == navigation.Type.link_clicked:\n                msg = urlutils.get_errstring(navigation.url,\n                                             \"Invalid link clicked\")\n                message.error(msg)\n                self.data.open_target = usertypes.ClickTarget.normal\n\n            log.webview.debug(\"Ignoring invalid URL {} in \"\n                              \"acceptNavigationRequest: {}\".format(\n                                  navigation.url.toDisplayString(),\n                                  navigation.url.errorString()))\n            navigation.accepted = False\n\n    @pyqtSlot(bool)\n    def _on_load_finished(self, ok: bool) -> None:\n        assert self._widget is not None\n        if sip.isdeleted(self._widget):\n            # https://github.com/qutebrowser/qutebrowser/issues/3498\n            return\n\n        try:\n            sess_manager = objreg.get('session-manager')\n        except KeyError:\n            # https://github.com/qutebrowser/qutebrowser/issues/4311\n            return\n\n        sess_manager.save_autosave()\n\n        if ok:\n            if self.url().scheme() == 'https':\n                if self.url().host() in self._insecure_hosts:\n                    self._set_load_status(usertypes.LoadStatus.warn)\n                else:\n                    self._set_load_status(usertypes.LoadStatus.success_https)\n            else:\n                self._set_load_status(usertypes.LoadStatus.success)\n        elif ok:\n            self._set_load_status(usertypes.LoadStatus.warn)\n        else:\n            self._set_load_status(usertypes.LoadStatus.error)\n\n        self.load_finished.emit(ok)\n\n        if not self.title():\n            self.title_changed.emit(self.url().toDisplayString())\n\n        self.zoom.reapply()\n\n    @pyqtSlot()\n    def _on_history_trigger(self) -> None:\n        \"\"\"Emit history_item_triggered based on backend-specific signal.\"\"\"\n        raise NotImplementedError\n\n    @pyqtSlot(int)\n    def _on_load_progress(self, perc: int) -> None:\n        self._progress = perc\n        self.load_progress.emit(perc)\n\n    def url(self, *, requested: bool = False) -> QUrl:\n        raise NotImplementedError\n\n    def progress(self) -> int:\n        return self._progress\n\n    def load_status(self) -> usertypes.LoadStatus:\n        return self._load_status\n\n    def _load_url_prepare(self, url: QUrl, *,\n                          emit_before_load_started: bool = True) -> None:\n        qtutils.ensure_valid(url)\n        if emit_before_load_started:\n            self.before_load_started.emit(url)\n\n    def load_url(self, url: QUrl, *,\n                 emit_before_load_started: bool = True) -> None:\n        raise NotImplementedError\n\n    def reload(self, *, force: bool = False) -> None:\n        raise NotImplementedError\n\n    def stop(self) -> None:\n        raise NotImplementedError\n\n    def fake_key_press(self,\n                       key: Qt.Key,\n                       modifier: Qt.KeyboardModifier = Qt.NoModifier) -> None:\n        \"\"\"Send a fake key event to this tab.\"\"\"\n        press_evt = QKeyEvent(QEvent.KeyPress, key, modifier, 0, 0, 0)\n        release_evt = QKeyEvent(QEvent.KeyRelease, key, modifier,\n                                0, 0, 0)\n        self.send_event(press_evt)\n        self.send_event(release_evt)\n\n    def dump_async(self,\n                   callback: typing.Callable[[str], None], *,\n                   plain: bool = False) -> None:\n        \"\"\"Dump the current page's html asynchronously.\n\n        The given callback will be called with the result when dumping is\n        complete.\n        \"\"\"\n        raise NotImplementedError\n\n    def run_js_async(\n            self,\n            code: str,\n            callback: typing.Callable[[typing.Any], None] = None, *,\n            world: typing.Union[usertypes.JsWorld, int] = None\n    ) -> None:\n        \"\"\"Run javascript async.\n\n        The given callback will be called with the result when running JS is\n        complete.\n\n        Args:\n            code: The javascript code to run.\n            callback: The callback to call with the result, or None.\n            world: A world ID (int or usertypes.JsWorld member) to run the JS\n                   in the main world or in another isolated world.\n        \"\"\"\n        raise NotImplementedError\n\n    def title(self) -> str:\n        raise NotImplementedError\n\n    def icon(self) -> None:\n        raise NotImplementedError\n\n    def set_html(self, html: str, base_url: QUrl = QUrl()) -> None:\n        raise NotImplementedError\n\n    def __repr__(self) -> str:\n        try:\n            qurl = self.url()\n            url = qurl.toDisplayString(QUrl.EncodeUnicode)  # type: ignore\n        except (AttributeError, RuntimeError) as exc:\n            url = '<{}>'.format(exc.__class__.__name__)\n        else:\n            url = utils.elide(url, 100)\n        return utils.get_repr(self, tab_id=self.tab_id, url=url)\n\n    def is_deleted(self) -> bool:\n        assert self._widget is not None\n        return sip.isdeleted(self._widget)\n", "target": 0}
{"idx": 876, "func": "# -*- coding: utf-8 -*-\n# Copyright 2014 - 2016 OpenMarket Ltd\n# Copyright 2017 - 2018 New Vector Ltd\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nfrom twisted.internet import defer, reactor\nfrom twisted.python.failure import Failure\n\nfrom synapse.api.constants import EventTypes, Membership, MAX_DEPTH\nfrom synapse.api.errors import AuthError, Codes, SynapseError\nfrom synapse.crypto.event_signing import add_hashes_and_signatures\nfrom synapse.events.utils import serialize_event\nfrom synapse.events.validator import EventValidator\nfrom synapse.types import (\n    UserID, RoomAlias, RoomStreamToken,\n)\nfrom synapse.util.async import run_on_reactor, ReadWriteLock, Limiter\nfrom synapse.util.logcontext import preserve_fn, run_in_background\nfrom synapse.util.metrics import measure_func\nfrom synapse.util.frozenutils import frozendict_json_encoder\nfrom synapse.util.stringutils import random_string\nfrom synapse.visibility import filter_events_for_client\nfrom synapse.replication.http.send_event import send_event_to_master\n\nfrom ._base import BaseHandler\n\nfrom canonicaljson import encode_canonical_json\n\nimport logging\nimport simplejson\n\nlogger = logging.getLogger(__name__)\n\n\nclass PurgeStatus(object):\n    \"\"\"Object tracking the status of a purge request\n\n    This class contains information on the progress of a purge request, for\n    return by get_purge_status.\n\n    Attributes:\n        status (int): Tracks whether this request has completed. One of\n            STATUS_{ACTIVE,COMPLETE,FAILED}\n    \"\"\"\n\n    STATUS_ACTIVE = 0\n    STATUS_COMPLETE = 1\n    STATUS_FAILED = 2\n\n    STATUS_TEXT = {\n        STATUS_ACTIVE: \"active\",\n        STATUS_COMPLETE: \"complete\",\n        STATUS_FAILED: \"failed\",\n    }\n\n    def __init__(self):\n        self.status = PurgeStatus.STATUS_ACTIVE\n\n    def asdict(self):\n        return {\n            \"status\": PurgeStatus.STATUS_TEXT[self.status]\n        }\n\n\nclass MessageHandler(BaseHandler):\n\n    def __init__(self, hs):\n        super(MessageHandler, self).__init__(hs)\n        self.hs = hs\n        self.state = hs.get_state_handler()\n        self.clock = hs.get_clock()\n\n        self.pagination_lock = ReadWriteLock()\n        self._purges_in_progress_by_room = set()\n        # map from purge id to PurgeStatus\n        self._purges_by_id = {}\n\n    def start_purge_history(self, room_id, topological_ordering,\n                            delete_local_events=False):\n        \"\"\"Start off a history purge on a room.\n\n        Args:\n            room_id (str): The room to purge from\n\n            topological_ordering (int): minimum topo ordering to preserve\n            delete_local_events (bool): True to delete local events as well as\n                remote ones\n\n        Returns:\n            str: unique ID for this purge transaction.\n        \"\"\"\n        if room_id in self._purges_in_progress_by_room:\n            raise SynapseError(\n                400,\n                \"History purge already in progress for %s\" % (room_id, ),\n            )\n\n        purge_id = random_string(16)\n\n        # we log the purge_id here so that it can be tied back to the\n        # request id in the log lines.\n        logger.info(\"[purge] starting purge_id %s\", purge_id)\n\n        self._purges_by_id[purge_id] = PurgeStatus()\n        run_in_background(\n            self._purge_history,\n            purge_id, room_id, topological_ordering, delete_local_events,\n        )\n        return purge_id\n\n    @defer.inlineCallbacks\n    def _purge_history(self, purge_id, room_id, topological_ordering,\n                       delete_local_events):\n        \"\"\"Carry out a history purge on a room.\n\n        Args:\n            purge_id (str): The id for this purge\n            room_id (str): The room to purge from\n            topological_ordering (int): minimum topo ordering to preserve\n            delete_local_events (bool): True to delete local events as well as\n                remote ones\n\n        Returns:\n            Deferred\n        \"\"\"\n        self._purges_in_progress_by_room.add(room_id)\n        try:\n            with (yield self.pagination_lock.write(room_id)):\n                yield self.store.purge_history(\n                    room_id, topological_ordering, delete_local_events,\n                )\n            logger.info(\"[purge] complete\")\n            self._purges_by_id[purge_id].status = PurgeStatus.STATUS_COMPLETE\n        except Exception:\n            logger.error(\"[purge] failed: %s\", Failure().getTraceback().rstrip())\n            self._purges_by_id[purge_id].status = PurgeStatus.STATUS_FAILED\n        finally:\n            self._purges_in_progress_by_room.discard(room_id)\n\n            # remove the purge from the list 24 hours after it completes\n            def clear_purge():\n                del self._purges_by_id[purge_id]\n            reactor.callLater(24 * 3600, clear_purge)\n\n    def get_purge_status(self, purge_id):\n        \"\"\"Get the current status of an active purge\n\n        Args:\n            purge_id (str): purge_id returned by start_purge_history\n\n        Returns:\n            PurgeStatus|None\n        \"\"\"\n        return self._purges_by_id.get(purge_id)\n\n    @defer.inlineCallbacks\n    def get_messages(self, requester, room_id=None, pagin_config=None,\n                     as_client_event=True, event_filter=None):\n        \"\"\"Get messages in a room.\n\n        Args:\n            requester (Requester): The user requesting messages.\n            room_id (str): The room they want messages from.\n            pagin_config (synapse.api.streams.PaginationConfig): The pagination\n                config rules to apply, if any.\n            as_client_event (bool): True to get events in client-server format.\n            event_filter (Filter): Filter to apply to results or None\n        Returns:\n            dict: Pagination API results\n        \"\"\"\n        user_id = requester.user.to_string()\n\n        if pagin_config.from_token:\n            room_token = pagin_config.from_token.room_key\n        else:\n            pagin_config.from_token = (\n                yield self.hs.get_event_sources().get_current_token_for_room(\n                    room_id=room_id\n                )\n            )\n            room_token = pagin_config.from_token.room_key\n\n        room_token = RoomStreamToken.parse(room_token)\n\n        pagin_config.from_token = pagin_config.from_token.copy_and_replace(\n            \"room_key\", str(room_token)\n        )\n\n        source_config = pagin_config.get_source_config(\"room\")\n\n        with (yield self.pagination_lock.read(room_id)):\n            membership, member_event_id = yield self._check_in_room_or_world_readable(\n                room_id, user_id\n            )\n\n            if source_config.direction == 'b':\n                # if we're going backwards, we might need to backfill. This\n                # requires that we have a topo token.\n                if room_token.topological:\n                    max_topo = room_token.topological\n                else:\n                    max_topo = yield self.store.get_max_topological_token(\n                        room_id, room_token.stream\n                    )\n\n                if membership == Membership.LEAVE:\n                    # If they have left the room then clamp the token to be before\n                    # they left the room, to save the effort of loading from the\n                    # database.\n                    leave_token = yield self.store.get_topological_token_for_event(\n                        member_event_id\n                    )\n                    leave_token = RoomStreamToken.parse(leave_token)\n                    if leave_token.topological < max_topo:\n                        source_config.from_key = str(leave_token)\n\n                yield self.hs.get_handlers().federation_handler.maybe_backfill(\n                    room_id, max_topo\n                )\n\n            events, next_key = yield self.store.paginate_room_events(\n                room_id=room_id,\n                from_key=source_config.from_key,\n                to_key=source_config.to_key,\n                direction=source_config.direction,\n                limit=source_config.limit,\n                event_filter=event_filter,\n            )\n\n            next_token = pagin_config.from_token.copy_and_replace(\n                \"room_key\", next_key\n            )\n\n        if not events:\n            defer.returnValue({\n                \"chunk\": [],\n                \"start\": pagin_config.from_token.to_string(),\n                \"end\": next_token.to_string(),\n            })\n\n        if event_filter:\n            events = event_filter.filter(events)\n\n        events = yield filter_events_for_client(\n            self.store,\n            user_id,\n            events,\n            is_peeking=(member_event_id is None),\n        )\n\n        time_now = self.clock.time_msec()\n\n        chunk = {\n            \"chunk\": [\n                serialize_event(e, time_now, as_client_event)\n                for e in events\n            ],\n            \"start\": pagin_config.from_token.to_string(),\n            \"end\": next_token.to_string(),\n        }\n\n        defer.returnValue(chunk)\n\n    @defer.inlineCallbacks\n    def get_room_data(self, user_id=None, room_id=None,\n                      event_type=None, state_key=\"\", is_guest=False):\n        \"\"\" Get data from a room.\n\n        Args:\n            event : The room path event\n        Returns:\n            The path data content.\n        Raises:\n            SynapseError if something went wrong.\n        \"\"\"\n        membership, membership_event_id = yield self._check_in_room_or_world_readable(\n            room_id, user_id\n        )\n\n        if membership == Membership.JOIN:\n            data = yield self.state_handler.get_current_state(\n                room_id, event_type, state_key\n            )\n        elif membership == Membership.LEAVE:\n            key = (event_type, state_key)\n            room_state = yield self.store.get_state_for_events(\n                [membership_event_id], [key]\n            )\n            data = room_state[membership_event_id].get(key)\n\n        defer.returnValue(data)\n\n    @defer.inlineCallbacks\n    def _check_in_room_or_world_readable(self, room_id, user_id):\n        try:\n            # check_user_was_in_room will return the most recent membership\n            # event for the user if:\n            #  * The user is a non-guest user, and was ever in the room\n            #  * The user is a guest user, and has joined the room\n            # else it will throw.\n            member_event = yield self.auth.check_user_was_in_room(room_id, user_id)\n            defer.returnValue((member_event.membership, member_event.event_id))\n            return\n        except AuthError:\n            visibility = yield self.state_handler.get_current_state(\n                room_id, EventTypes.RoomHistoryVisibility, \"\"\n            )\n            if (\n                visibility and\n                visibility.content[\"history_visibility\"] == \"world_readable\"\n            ):\n                defer.returnValue((Membership.JOIN, None))\n                return\n            raise AuthError(\n                403, \"Guest access not allowed\", errcode=Codes.GUEST_ACCESS_FORBIDDEN\n            )\n\n    @defer.inlineCallbacks\n    def get_state_events(self, user_id, room_id, is_guest=False):\n        \"\"\"Retrieve all state events for a given room. If the user is\n        joined to the room then return the current state. If the user has\n        left the room return the state events from when they left.\n\n        Args:\n            user_id(str): The user requesting state events.\n            room_id(str): The room ID to get all state events from.\n        Returns:\n            A list of dicts representing state events. [{}, {}, {}]\n        \"\"\"\n        membership, membership_event_id = yield self._check_in_room_or_world_readable(\n            room_id, user_id\n        )\n\n        if membership == Membership.JOIN:\n            room_state = yield self.state_handler.get_current_state(room_id)\n        elif membership == Membership.LEAVE:\n            room_state = yield self.store.get_state_for_events(\n                [membership_event_id], None\n            )\n            room_state = room_state[membership_event_id]\n\n        now = self.clock.time_msec()\n        defer.returnValue(\n            [serialize_event(c, now) for c in room_state.values()]\n        )\n\n    @defer.inlineCallbacks\n    def get_joined_members(self, requester, room_id):\n        \"\"\"Get all the joined members in the room and their profile information.\n\n        If the user has left the room return the state events from when they left.\n\n        Args:\n            requester(Requester): The user requesting state events.\n            room_id(str): The room ID to get all state events from.\n        Returns:\n            A dict of user_id to profile info\n        \"\"\"\n        user_id = requester.user.to_string()\n        if not requester.app_service:\n            # We check AS auth after fetching the room membership, as it\n            # requires us to pull out all joined members anyway.\n            membership, _ = yield self._check_in_room_or_world_readable(\n                room_id, user_id\n            )\n            if membership != Membership.JOIN:\n                raise NotImplementedError(\n                    \"Getting joined members after leaving is not implemented\"\n                )\n\n        users_with_profile = yield self.state.get_current_user_in_room(room_id)\n\n        # If this is an AS, double check that they are allowed to see the members.\n        # This can either be because the AS user is in the room or becuase there\n        # is a user in the room that the AS is \"interested in\"\n        if requester.app_service and user_id not in users_with_profile:\n            for uid in users_with_profile:\n                if requester.app_service.is_interested_in_user(uid):\n                    break\n            else:\n                # Loop fell through, AS has no interested users in room\n                raise AuthError(403, \"Appservice not in room\")\n\n        defer.returnValue({\n            user_id: {\n                \"avatar_url\": profile.avatar_url,\n                \"display_name\": profile.display_name,\n            }\n            for user_id, profile in users_with_profile.iteritems()\n        })\n\n\nclass EventCreationHandler(object):\n    def __init__(self, hs):\n        self.hs = hs\n        self.auth = hs.get_auth()\n        self.store = hs.get_datastore()\n        self.state = hs.get_state_handler()\n        self.clock = hs.get_clock()\n        self.validator = EventValidator()\n        self.profile_handler = hs.get_profile_handler()\n        self.event_builder_factory = hs.get_event_builder_factory()\n        self.server_name = hs.hostname\n        self.ratelimiter = hs.get_ratelimiter()\n        self.notifier = hs.get_notifier()\n        self.config = hs.config\n\n        self.http_client = hs.get_simple_http_client()\n\n        # This is only used to get at ratelimit function, and maybe_kick_guest_users\n        self.base_handler = BaseHandler(hs)\n\n        self.pusher_pool = hs.get_pusherpool()\n\n        # We arbitrarily limit concurrent event creation for a room to 5.\n        # This is to stop us from diverging history *too* much.\n        self.limiter = Limiter(max_count=5)\n\n        self.action_generator = hs.get_action_generator()\n\n        self.spam_checker = hs.get_spam_checker()\n\n    @defer.inlineCallbacks\n    def create_event(self, requester, event_dict, token_id=None, txn_id=None,\n                     prev_events_and_hashes=None):\n        \"\"\"\n        Given a dict from a client, create a new event.\n\n        Creates an FrozenEvent object, filling out auth_events, prev_events,\n        etc.\n\n        Adds display names to Join membership events.\n\n        Args:\n            requester\n            event_dict (dict): An entire event\n            token_id (str)\n            txn_id (str)\n\n            prev_events_and_hashes (list[(str, dict[str, str], int)]|None):\n                the forward extremities to use as the prev_events for the\n                new event. For each event, a tuple of (event_id, hashes, depth)\n                where *hashes* is a map from algorithm to hash.\n\n                If None, they will be requested from the database.\n\n        Returns:\n            Tuple of created event (FrozenEvent), Context\n        \"\"\"\n        builder = self.event_builder_factory.new(event_dict)\n\n        self.validator.validate_new(builder)\n\n        if builder.type == EventTypes.Member:\n            membership = builder.content.get(\"membership\", None)\n            target = UserID.from_string(builder.state_key)\n\n            if membership in {Membership.JOIN, Membership.INVITE}:\n                # If event doesn't include a display name, add one.\n                profile = self.profile_handler\n                content = builder.content\n\n                try:\n                    if \"displayname\" not in content:\n                        content[\"displayname\"] = yield profile.get_displayname(target)\n                    if \"avatar_url\" not in content:\n                        content[\"avatar_url\"] = yield profile.get_avatar_url(target)\n                except Exception as e:\n                    logger.info(\n                        \"Failed to get profile information for %r: %s\",\n                        target, e\n                    )\n\n        if token_id is not None:\n            builder.internal_metadata.token_id = token_id\n\n        if txn_id is not None:\n            builder.internal_metadata.txn_id = txn_id\n\n        event, context = yield self.create_new_client_event(\n            builder=builder,\n            requester=requester,\n            prev_events_and_hashes=prev_events_and_hashes,\n        )\n\n        defer.returnValue((event, context))\n\n    @defer.inlineCallbacks\n    def send_nonmember_event(self, requester, event, context, ratelimit=True):\n        \"\"\"\n        Persists and notifies local clients and federation of an event.\n\n        Args:\n            event (FrozenEvent) the event to send.\n            context (Context) the context of the event.\n            ratelimit (bool): Whether to rate limit this send.\n            is_guest (bool): Whether the sender is a guest.\n        \"\"\"\n        if event.type == EventTypes.Member:\n            raise SynapseError(\n                500,\n                \"Tried to send member event through non-member codepath\"\n            )\n\n        user = UserID.from_string(event.sender)\n\n        assert self.hs.is_mine(user), \"User must be our own: %s\" % (user,)\n\n        if event.is_state():\n            prev_state = yield self.deduplicate_state_event(event, context)\n            if prev_state is not None:\n                defer.returnValue(prev_state)\n\n        yield self.handle_new_client_event(\n            requester=requester,\n            event=event,\n            context=context,\n            ratelimit=ratelimit,\n        )\n\n    @defer.inlineCallbacks\n    def deduplicate_state_event(self, event, context):\n        \"\"\"\n        Checks whether event is in the latest resolved state in context.\n\n        If so, returns the version of the event in context.\n        Otherwise, returns None.\n        \"\"\"\n        prev_event_id = context.prev_state_ids.get((event.type, event.state_key))\n        prev_event = yield self.store.get_event(prev_event_id, allow_none=True)\n        if not prev_event:\n            return\n\n        if prev_event and event.user_id == prev_event.user_id:\n            prev_content = encode_canonical_json(prev_event.content)\n            next_content = encode_canonical_json(event.content)\n            if prev_content == next_content:\n                defer.returnValue(prev_event)\n        return\n\n    @defer.inlineCallbacks\n    def create_and_send_nonmember_event(\n        self,\n        requester,\n        event_dict,\n        ratelimit=True,\n        txn_id=None\n    ):\n        \"\"\"\n        Creates an event, then sends it.\n\n        See self.create_event and self.send_nonmember_event.\n        \"\"\"\n\n        # We limit the number of concurrent event sends in a room so that we\n        # don't fork the DAG too much. If we don't limit then we can end up in\n        # a situation where event persistence can't keep up, causing\n        # extremities to pile up, which in turn leads to state resolution\n        # taking longer.\n        with (yield self.limiter.queue(event_dict[\"room_id\"])):\n            event, context = yield self.create_event(\n                requester,\n                event_dict,\n                token_id=requester.access_token_id,\n                txn_id=txn_id\n            )\n\n            spam_error = self.spam_checker.check_event_for_spam(event)\n            if spam_error:\n                if not isinstance(spam_error, basestring):\n                    spam_error = \"Spam is not permitted here\"\n                raise SynapseError(\n                    403, spam_error, Codes.FORBIDDEN\n                )\n\n            yield self.send_nonmember_event(\n                requester,\n                event,\n                context,\n                ratelimit=ratelimit,\n            )\n        defer.returnValue(event)\n\n    @measure_func(\"create_new_client_event\")\n    @defer.inlineCallbacks\n    def create_new_client_event(self, builder, requester=None,\n                                prev_events_and_hashes=None):\n        \"\"\"Create a new event for a local client\n\n        Args:\n            builder (EventBuilder):\n\n            requester (synapse.types.Requester|None):\n\n            prev_events_and_hashes (list[(str, dict[str, str], int)]|None):\n                the forward extremities to use as the prev_events for the\n                new event. For each event, a tuple of (event_id, hashes, depth)\n                where *hashes* is a map from algorithm to hash.\n\n                If None, they will be requested from the database.\n\n        Returns:\n            Deferred[(synapse.events.EventBase, synapse.events.snapshot.EventContext)]\n        \"\"\"\n\n        if prev_events_and_hashes is not None:\n            assert len(prev_events_and_hashes) <= 10, \\\n                \"Attempting to create an event with %i prev_events\" % (\n                    len(prev_events_and_hashes),\n            )\n        else:\n            prev_events_and_hashes = \\\n                yield self.store.get_prev_events_for_room(builder.room_id)\n\n        if prev_events_and_hashes:\n            depth = max([d for _, _, d in prev_events_and_hashes]) + 1\n            # we cap depth of generated events, to ensure that they are not\n            # rejected by other servers (and so that they can be persisted in\n            # the db)\n            depth = min(depth, MAX_DEPTH)\n        else:\n            depth = 1\n\n        prev_events = [\n            (event_id, prev_hashes)\n            for event_id, prev_hashes, _ in prev_events_and_hashes\n        ]\n\n        builder.prev_events = prev_events\n        builder.depth = depth\n\n        context = yield self.state.compute_event_context(builder)\n        if requester:\n            context.app_service = requester.app_service\n\n        if builder.is_state():\n            builder.prev_state = yield self.store.add_event_hashes(\n                context.prev_state_events\n            )\n\n        yield self.auth.add_auth_events(builder, context)\n\n        signing_key = self.hs.config.signing_key[0]\n        add_hashes_and_signatures(\n            builder, self.server_name, signing_key\n        )\n\n        event = builder.build()\n\n        logger.debug(\n            \"Created event %s with state: %s\",\n            event.event_id, context.prev_state_ids,\n        )\n\n        defer.returnValue(\n            (event, context,)\n        )\n\n    @measure_func(\"handle_new_client_event\")\n    @defer.inlineCallbacks\n    def handle_new_client_event(\n        self,\n        requester,\n        event,\n        context,\n        ratelimit=True,\n        extra_users=[],\n    ):\n        \"\"\"Processes a new event. This includes checking auth, persisting it,\n        notifying users, sending to remote servers, etc.\n\n        If called from a worker will hit out to the master process for final\n        processing.\n\n        Args:\n            requester (Requester)\n            event (FrozenEvent)\n            context (EventContext)\n            ratelimit (bool)\n            extra_users (list(UserID)): Any extra users to notify about event\n        \"\"\"\n\n        try:\n            yield self.auth.check_from_context(event, context)\n        except AuthError as err:\n            logger.warn(\"Denying new event %r because %s\", event, err)\n            raise err\n\n        # Ensure that we can round trip before trying to persist in db\n        try:\n            dump = frozendict_json_encoder.encode(event.content)\n            simplejson.loads(dump)\n        except Exception:\n            logger.exception(\"Failed to encode content: %r\", event.content)\n            raise\n\n        yield self.action_generator.handle_push_actions_for_event(\n            event, context\n        )\n\n        try:\n            # If we're a worker we need to hit out to the master.\n            if self.config.worker_app:\n                yield send_event_to_master(\n                    self.http_client,\n                    host=self.config.worker_replication_host,\n                    port=self.config.worker_replication_http_port,\n                    requester=requester,\n                    event=event,\n                    context=context,\n                    ratelimit=ratelimit,\n                    extra_users=extra_users,\n                )\n                return\n\n            yield self.persist_and_notify_client_event(\n                requester,\n                event,\n                context,\n                ratelimit=ratelimit,\n                extra_users=extra_users,\n            )\n        except:  # noqa: E722, as we reraise the exception this is fine.\n            # Ensure that we actually remove the entries in the push actions\n            # staging area, if we calculated them.\n            preserve_fn(self.store.remove_push_actions_from_staging)(event.event_id)\n            raise\n\n    @defer.inlineCallbacks\n    def persist_and_notify_client_event(\n        self,\n        requester,\n        event,\n        context,\n        ratelimit=True,\n        extra_users=[],\n    ):\n        \"\"\"Called when we have fully built the event, have already\n        calculated the push actions for the event, and checked auth.\n\n        This should only be run on master.\n        \"\"\"\n        assert not self.config.worker_app\n\n        if ratelimit:\n            yield self.base_handler.ratelimit(requester)\n\n        yield self.base_handler.maybe_kick_guest_users(event, context)\n\n        if event.type == EventTypes.CanonicalAlias:\n            # Check the alias is acually valid (at this time at least)\n            room_alias_str = event.content.get(\"alias\", None)\n            if room_alias_str:\n                room_alias = RoomAlias.from_string(room_alias_str)\n                directory_handler = self.hs.get_handlers().directory_handler\n                mapping = yield directory_handler.get_association(room_alias)\n\n                if mapping[\"room_id\"] != event.room_id:\n                    raise SynapseError(\n                        400,\n                        \"Room alias %s does not point to the room\" % (\n                            room_alias_str,\n                        )\n                    )\n\n        federation_handler = self.hs.get_handlers().federation_handler\n\n        if event.type == EventTypes.Member:\n            if event.content[\"membership\"] == Membership.INVITE:\n                def is_inviter_member_event(e):\n                    return (\n                        e.type == EventTypes.Member and\n                        e.sender == event.sender\n                    )\n\n                state_to_include_ids = [\n                    e_id\n                    for k, e_id in context.current_state_ids.iteritems()\n                    if k[0] in self.hs.config.room_invite_state_types\n                    or k == (EventTypes.Member, event.sender)\n                ]\n\n                state_to_include = yield self.store.get_events(state_to_include_ids)\n\n                event.unsigned[\"invite_room_state\"] = [\n                    {\n                        \"type\": e.type,\n                        \"state_key\": e.state_key,\n                        \"content\": e.content,\n                        \"sender\": e.sender,\n                    }\n                    for e in state_to_include.itervalues()\n                ]\n\n                invitee = UserID.from_string(event.state_key)\n                if not self.hs.is_mine(invitee):\n                    # TODO: Can we add signature from remote server in a nicer\n                    # way? If we have been invited by a remote server, we need\n                    # to get them to sign the event.\n\n                    returned_invite = yield federation_handler.send_invite(\n                        invitee.domain,\n                        event,\n                    )\n\n                    event.unsigned.pop(\"room_state\", None)\n\n                    # TODO: Make sure the signatures actually are correct.\n                    event.signatures.update(\n                        returned_invite.signatures\n                    )\n\n        if event.type == EventTypes.Redaction:\n            auth_events_ids = yield self.auth.compute_auth_events(\n                event, context.prev_state_ids, for_verification=True,\n            )\n            auth_events = yield self.store.get_events(auth_events_ids)\n            auth_events = {\n                (e.type, e.state_key): e for e in auth_events.values()\n            }\n            if self.auth.check_redaction(event, auth_events=auth_events):\n                original_event = yield self.store.get_event(\n                    event.redacts,\n                    check_redacted=False,\n                    get_prev_content=False,\n                    allow_rejected=False,\n                    allow_none=False\n                )\n                if event.user_id != original_event.user_id:\n                    raise AuthError(\n                        403,\n                        \"You don't have permission to redact events\"\n                    )\n\n        if event.type == EventTypes.Create and context.prev_state_ids:\n            raise AuthError(\n                403,\n                \"Changing the room create event is forbidden\",\n            )\n\n        (event_stream_id, max_stream_id) = yield self.store.persist_event(\n            event, context=context\n        )\n\n        # this intentionally does not yield: we don't care about the result\n        # and don't need to wait for it.\n        preserve_fn(self.pusher_pool.on_new_notifications)(\n            event_stream_id, max_stream_id\n        )\n\n        @defer.inlineCallbacks\n        def _notify():\n            yield run_on_reactor()\n            self.notifier.on_new_room_event(\n                event, event_stream_id, max_stream_id,\n                extra_users=extra_users\n            )\n\n        preserve_fn(_notify)()\n\n        if event.type == EventTypes.Message:\n            presence = self.hs.get_presence_handler()\n            # We don't want to block sending messages on any presence code. This\n            # matters as sometimes presence code can take a while.\n            preserve_fn(presence.bump_presence_active_time)(requester.user)\n", "target": 0}
{"idx": 877, "func": "# vim: tabstop=4 shiftwidth=4 softtabstop=4\n\n# Copyright 2012 OpenStack LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"); you may\n# not use this file except in compliance with the License. You may obtain\n# a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n# License for the specific language governing permissions and limitations\n# under the License.\n\nimport uuid\nimport routes\nimport json\n\nfrom keystone import config\nfrom keystone import catalog\nfrom keystone.common import cms\nfrom keystone.common import logging\nfrom keystone.common import wsgi\nfrom keystone import exception\nfrom keystone import identity\nfrom keystone.openstack.common import timeutils\nfrom keystone import policy\nfrom keystone import token\n\n\nLOG = logging.getLogger(__name__)\n\n\nclass V3Router(wsgi.ComposingRouter):\n    def crud_routes(self, mapper, controller, collection_key, key):\n        collection_path = '/%(collection_key)s' % {\n            'collection_key': collection_key}\n        entity_path = '/%(collection_key)s/{%(key)s_id}' % {\n            'collection_key': collection_key,\n            'key': key}\n\n        mapper.connect(\n            collection_path,\n            controller=controller,\n            action='create_%s' % key,\n            conditions=dict(method=['POST']))\n        mapper.connect(\n            collection_path,\n            controller=controller,\n            action='list_%s' % collection_key,\n            conditions=dict(method=['GET']))\n        mapper.connect(\n            entity_path,\n            controller=controller,\n            action='get_%s' % key,\n            conditions=dict(method=['GET']))\n        mapper.connect(\n            entity_path,\n            controller=controller,\n            action='update_%s' % key,\n            conditions=dict(method=['PATCH']))\n        mapper.connect(\n            entity_path,\n            controller=controller,\n            action='delete_%s' % key,\n            conditions=dict(method=['DELETE']))\n\n    def __init__(self):\n        mapper = routes.Mapper()\n\n        apis = dict(\n            catalog_api=catalog.Manager(),\n            identity_api=identity.Manager(),\n            policy_api=policy.Manager(),\n            token_api=token.Manager())\n\n        # Catalog\n\n        self.crud_routes(\n            mapper,\n            catalog.ServiceControllerV3(**apis),\n            'services',\n            'service')\n\n        self.crud_routes(\n            mapper,\n            catalog.EndpointControllerV3(**apis),\n            'endpoints',\n            'endpoint')\n\n        # Identity\n\n        self.crud_routes(\n            mapper,\n            identity.DomainControllerV3(**apis),\n            'domains',\n            'domain')\n\n        project_controller = identity.ProjectControllerV3(**apis)\n        self.crud_routes(\n            mapper,\n            project_controller,\n            'projects',\n            'project')\n        mapper.connect(\n            '/users/{user_id}/projects',\n            controller=project_controller,\n            action='list_user_projects',\n            conditions=dict(method=['GET']))\n\n        self.crud_routes(\n            mapper,\n            identity.UserControllerV3(**apis),\n            'users',\n            'user')\n\n        self.crud_routes(\n            mapper,\n            identity.CredentialControllerV3(**apis),\n            'credentials',\n            'credential')\n\n        role_controller = identity.RoleControllerV3(**apis)\n        self.crud_routes(\n            mapper,\n            role_controller,\n            'roles',\n            'role')\n        mapper.connect(\n            '/projects/{project_id}/users/{user_id}/roles/{role_id}',\n            controller=role_controller,\n            action='create_grant',\n            conditions=dict(method=['PUT']))\n        mapper.connect(\n            '/projects/{project_id}/users/{user_id}/roles/{role_id}',\n            controller=role_controller,\n            action='check_grant',\n            conditions=dict(method=['HEAD']))\n        mapper.connect(\n            '/projects/{project_id}/users/{user_id}/roles',\n            controller=role_controller,\n            action='list_grants',\n            conditions=dict(method=['GET']))\n        mapper.connect(\n            '/projects/{project_id}/users/{user_id}/roles/{role_id}',\n            controller=role_controller,\n            action='revoke_grant',\n            conditions=dict(method=['DELETE']))\n        mapper.connect(\n            '/domains/{domain_id}/users/{user_id}/roles/{role_id}',\n            controller=role_controller,\n            action='create_grant',\n            conditions=dict(method=['PUT']))\n        mapper.connect(\n            '/domains/{domain_id}/users/{user_id}/roles/{role_id}',\n            controller=role_controller,\n            action='check_grant',\n            conditions=dict(method=['HEAD']))\n        mapper.connect(\n            '/domains/{domain_id}/users/{user_id}/roles',\n            controller=role_controller,\n            action='list_grants',\n            conditions=dict(method=['GET']))\n        mapper.connect(\n            '/domains/{domain_id}/users/{user_id}/roles/{role_id}',\n            controller=role_controller,\n            action='revoke_grant',\n            conditions=dict(method=['DELETE']))\n\n        # Policy\n\n        policy_controller = policy.PolicyControllerV3(**apis)\n        self.crud_routes(\n            mapper,\n            policy_controller,\n            'policies',\n            'policy')\n\n        # Token\n\n        \"\"\"\n        # v2.0 LEGACY\n        mapper.connect('/tokens/{token_id}',\n                       controller=auth_controller,\n                       action='validate_token',\n                       conditions=dict(method=['GET']))\n        mapper.connect('/tokens/{token_id}',\n                       controller=auth_controller,\n                       action='validate_token_head',\n                       conditions=dict(method=['HEAD']))\n        mapper.connect('/tokens/{token_id}',\n                       controller=auth_controller,\n                       action='delete_token',\n                       conditions=dict(method=['DELETE']))\n        mapper.connect('/tokens/{token_id}/endpoints',\n                       controller=auth_controller,\n                       action='endpoints',\n                       conditions=dict(method=['GET']))\n        \"\"\"\n\n        super(V3Router, self).__init__(mapper, [])\n\n\nclass AdminRouter(wsgi.ComposingRouter):\n    def __init__(self):\n        mapper = routes.Mapper()\n\n        version_controller = VersionController('admin')\n        mapper.connect('/',\n                       controller=version_controller,\n                       action='get_version')\n\n        # Token Operations\n        auth_controller = TokenController()\n        mapper.connect('/tokens',\n                       controller=auth_controller,\n                       action='authenticate',\n                       conditions=dict(method=['POST']))\n        mapper.connect('/tokens/revoked',\n                       controller=auth_controller,\n                       action='revocation_list',\n                       conditions=dict(method=['GET']))\n        mapper.connect('/tokens/{token_id}',\n                       controller=auth_controller,\n                       action='validate_token',\n                       conditions=dict(method=['GET']))\n        mapper.connect('/tokens/{token_id}',\n                       controller=auth_controller,\n                       action='validate_token_head',\n                       conditions=dict(method=['HEAD']))\n        mapper.connect('/tokens/{token_id}',\n                       controller=auth_controller,\n                       action='delete_token',\n                       conditions=dict(method=['DELETE']))\n        mapper.connect('/tokens/{token_id}/endpoints',\n                       controller=auth_controller,\n                       action='endpoints',\n                       conditions=dict(method=['GET']))\n\n        # Certificates used to verify auth tokens\n        mapper.connect('/certificates/ca',\n                       controller=auth_controller,\n                       action='ca_cert',\n                       conditions=dict(method=['GET']))\n\n        mapper.connect('/certificates/signing',\n                       controller=auth_controller,\n                       action='signing_cert',\n                       conditions=dict(method=['GET']))\n\n        # Miscellaneous Operations\n        extensions_controller = AdminExtensionsController()\n        mapper.connect('/extensions',\n                       controller=extensions_controller,\n                       action='get_extensions_info',\n                       conditions=dict(method=['GET']))\n        mapper.connect('/extensions/{extension_alias}',\n                       controller=extensions_controller,\n                       action='get_extension_info',\n                       conditions=dict(method=['GET']))\n        identity_router = identity.AdminRouter()\n        routers = [identity_router]\n        super(AdminRouter, self).__init__(mapper, routers)\n\n\nclass PublicRouter(wsgi.ComposingRouter):\n    def __init__(self):\n        mapper = routes.Mapper()\n\n        version_controller = VersionController('public')\n        mapper.connect('/',\n                       controller=version_controller,\n                       action='get_version')\n\n        # Token Operations\n        auth_controller = TokenController()\n        mapper.connect('/tokens',\n                       controller=auth_controller,\n                       action='authenticate',\n                       conditions=dict(method=['POST']))\n\n        mapper.connect('/certificates/ca',\n                       controller=auth_controller,\n                       action='ca_cert',\n                       conditions=dict(method=['GET']))\n\n        mapper.connect('/certificates/signing',\n                       controller=auth_controller,\n                       action='signing_cert',\n                       conditions=dict(method=['GET']))\n\n        # Miscellaneous\n        extensions_controller = PublicExtensionsController()\n        mapper.connect('/extensions',\n                       controller=extensions_controller,\n                       action='get_extensions_info',\n                       conditions=dict(method=['GET']))\n        mapper.connect('/extensions/{extension_alias}',\n                       controller=extensions_controller,\n                       action='get_extension_info',\n                       conditions=dict(method=['GET']))\n\n        identity_router = identity.PublicRouter()\n        routers = [identity_router]\n\n        super(PublicRouter, self).__init__(mapper, routers)\n\n\nclass PublicVersionRouter(wsgi.ComposingRouter):\n    def __init__(self):\n        mapper = routes.Mapper()\n        version_controller = VersionController('public')\n        mapper.connect('/',\n                       controller=version_controller,\n                       action='get_versions')\n        routers = []\n        super(PublicVersionRouter, self).__init__(mapper, routers)\n\n\nclass AdminVersionRouter(wsgi.ComposingRouter):\n    def __init__(self):\n        mapper = routes.Mapper()\n        version_controller = VersionController('admin')\n        mapper.connect('/',\n                       controller=version_controller,\n                       action='get_versions')\n        routers = []\n        super(AdminVersionRouter, self).__init__(mapper, routers)\n\n\nclass VersionController(wsgi.Application):\n    def __init__(self, version_type):\n        self.catalog_api = catalog.Manager()\n        self.url_key = '%sURL' % version_type\n\n        super(VersionController, self).__init__()\n\n    def _get_identity_url(self, context):\n        catalog_ref = self.catalog_api.get_catalog(context=context,\n                                                   user_id=None,\n                                                   tenant_id=None)\n        for region, region_ref in catalog_ref.iteritems():\n            for service, service_ref in region_ref.iteritems():\n                if service == 'identity':\n                    return service_ref[self.url_key]\n\n        raise exception.NotImplemented()\n\n    def _get_versions_list(self, context):\n        \"\"\"The list of versions is dependent on the context.\"\"\"\n        identity_url = self._get_identity_url(context)\n        if not identity_url.endswith('/'):\n            identity_url = identity_url + '/'\n\n        versions = {}\n        versions['v2.0'] = {\n            'id': 'v2.0',\n            'status': 'beta',\n            'updated': '2011-11-19T00:00:00Z',\n            'links': [\n                {\n                    'rel': 'self',\n                    'href': identity_url,\n                }, {\n                    'rel': 'describedby',\n                    'type': 'text/html',\n                    'href': 'http://docs.openstack.org/api/openstack-'\n                            'identity-service/2.0/content/'\n                }, {\n                    'rel': 'describedby',\n                    'type': 'application/pdf',\n                    'href': 'http://docs.openstack.org/api/openstack-'\n                            'identity-service/2.0/identity-dev-guide-'\n                            '2.0.pdf'\n                }\n            ],\n            'media-types': [\n                {\n                    'base': 'application/json',\n                    'type': 'application/vnd.openstack.identity-v2.0'\n                            '+json'\n                }, {\n                    'base': 'application/xml',\n                    'type': 'application/vnd.openstack.identity-v2.0'\n                            '+xml'\n                }\n            ]\n        }\n\n        return versions\n\n    def get_versions(self, context):\n        versions = self._get_versions_list(context)\n        return wsgi.render_response(status=(300, 'Multiple Choices'), body={\n            'versions': {\n                'values': versions.values()\n            }\n        })\n\n    def get_version(self, context):\n        versions = self._get_versions_list(context)\n        return wsgi.render_response(body={\n            'version': versions['v2.0']\n        })\n\n\nclass NoopController(wsgi.Application):\n    def __init__(self):\n        super(NoopController, self).__init__()\n\n    def noop(self, context):\n        return {}\n\n\nclass ExternalAuthNotApplicable(Exception):\n    \"\"\"External authentication is not applicable\"\"\"\n\n\nclass TokenController(wsgi.Application):\n    def __init__(self):\n        self.catalog_api = catalog.Manager()\n        self.identity_api = identity.Manager()\n        self.token_api = token.Manager()\n        self.policy_api = policy.Manager()\n        super(TokenController, self).__init__()\n\n    def ca_cert(self, context, auth=None):\n        ca_file = open(config.CONF.signing.ca_certs, 'r')\n        data = ca_file.read()\n        ca_file.close()\n        return data\n\n    def signing_cert(self, context, auth=None):\n        cert_file = open(config.CONF.signing.certfile, 'r')\n        data = cert_file.read()\n        cert_file.close()\n        return data\n\n    def authenticate(self, context, auth=None):\n        \"\"\"Authenticate credentials and return a token.\n\n        Accept auth as a dict that looks like::\n\n            {\n                \"auth\":{\n                    \"passwordCredentials\":{\n                        \"username\":\"test_user\",\n                        \"password\":\"mypass\"\n                    },\n                    \"tenantName\":\"customer-x\"\n                }\n            }\n\n        In this case, tenant is optional, if not provided the token will be\n        considered \"unscoped\" and can later be used to get a scoped token.\n\n        Alternatively, this call accepts auth with only a token and tenant\n        that will return a token that is scoped to that tenant.\n        \"\"\"\n\n        if auth is None:\n            raise exception.ValidationError(attribute='auth',\n                                            target='request body')\n\n        auth_token_data = None\n\n        if \"token\" in auth:\n            # Try to authenticate using a token\n            auth_token_data, auth_info = self._authenticate_token(\n                context, auth)\n        else:\n            # Try external authentication\n            try:\n                auth_token_data, auth_info = self._authenticate_external(\n                    context, auth)\n            except ExternalAuthNotApplicable:\n                # Try local authentication\n                auth_token_data, auth_info = self._authenticate_local(\n                    context, auth)\n\n        user_ref, tenant_ref, metadata_ref = auth_info\n\n        # If the user is disabled don't allow them to authenticate\n        if not user_ref.get('enabled', True):\n            msg = 'User is disabled: %s' % user_ref['id']\n            LOG.warning(msg)\n            raise exception.Unauthorized(msg)\n\n        # If the tenant is disabled don't allow them to authenticate\n        if tenant_ref and not tenant_ref.get('enabled', True):\n            msg = 'Tenant is disabled: %s' % tenant_ref['id']\n            LOG.warning(msg)\n            raise exception.Unauthorized(msg)\n\n        if tenant_ref:\n            catalog_ref = self.catalog_api.get_catalog(\n                context=context,\n                user_id=user_ref['id'],\n                tenant_id=tenant_ref['id'],\n                metadata=metadata_ref)\n        else:\n            catalog_ref = {}\n\n        auth_token_data['id'] = 'placeholder'\n\n        roles_ref = []\n        for role_id in metadata_ref.get('roles', []):\n            role_ref = self.identity_api.get_role(context, role_id)\n            roles_ref.append(dict(name=role_ref['name']))\n\n        token_data = self._format_token(auth_token_data, roles_ref)\n\n        service_catalog = self._format_catalog(catalog_ref)\n        token_data['access']['serviceCatalog'] = service_catalog\n\n        if config.CONF.signing.token_format == 'UUID':\n            token_id = uuid.uuid4().hex\n        elif config.CONF.signing.token_format == 'PKI':\n            token_id = cms.cms_sign_token(json.dumps(token_data),\n                                          config.CONF.signing.certfile,\n                                          config.CONF.signing.keyfile)\n        else:\n            raise exception.UnexpectedError(\n                'Invalid value for token_format: %s.'\n                '  Allowed values are PKI or UUID.' %\n                config.CONF.signing.token_format)\n        try:\n            self.token_api.create_token(\n                context, token_id, dict(key=token_id,\n                                        id=token_id,\n                                        user=user_ref,\n                                        tenant=tenant_ref,\n                                        metadata=metadata_ref))\n        except Exception as e:\n            # an identical token may have been created already.\n            # if so, return the token_data as it is also identical\n            try:\n                self.token_api.get_token(context=context,\n                                         token_id=token_id)\n            except exception.TokenNotFound:\n                raise e\n\n        token_data['access']['token']['id'] = token_id\n\n        return token_data\n\n    def _authenticate_token(self, context, auth):\n        \"\"\"Try to authenticate using an already existing token.\n\n        Returns auth_token_data, (user_ref, tenant_ref, metadata_ref)\n        \"\"\"\n        if 'token' not in auth:\n            raise exception.ValidationError(\n                attribute='token', target='auth')\n\n        if \"id\" not in auth['token']:\n            raise exception.ValidationError(\n                attribute=\"id\", target=\"token\")\n\n        old_token = auth['token']['id']\n\n        try:\n            old_token_ref = self.token_api.get_token(context=context,\n                                                     token_id=old_token)\n        except exception.NotFound as e:\n            raise exception.Unauthorized(e)\n\n        user_ref = old_token_ref['user']\n        user_id = user_ref['id']\n\n        current_user_ref = self.identity_api.get_user(context=context,\n                                                      user_id=user_id)\n\n        tenant_id = self._get_tenant_id_from_auth(context, auth)\n\n        tenant_ref = self._get_tenant_ref(context, user_id, tenant_id)\n        metadata_ref = self._get_metadata_ref(context, user_id, tenant_id)\n\n        expiry = old_token_ref['expires']\n        auth_token_data = self._get_auth_token_data(current_user_ref,\n                                                    tenant_ref,\n                                                    metadata_ref,\n                                                    expiry)\n\n        return auth_token_data, (current_user_ref, tenant_ref, metadata_ref)\n\n    def _authenticate_local(self, context, auth):\n        \"\"\"Try to authenticate against the identity backend.\n\n        Returns auth_token_data, (user_ref, tenant_ref, metadata_ref)\n        \"\"\"\n        if 'passwordCredentials' not in auth:\n            raise exception.ValidationError(\n                attribute='passwordCredentials', target='auth')\n\n        if \"password\" not in auth['passwordCredentials']:\n            raise exception.ValidationError(\n                attribute='password', target='passwordCredentials')\n\n        password = auth['passwordCredentials']['password']\n\n        if (\"userId\" not in auth['passwordCredentials'] and\n                \"username\" not in auth['passwordCredentials']):\n            raise exception.ValidationError(\n                attribute='username or userId',\n                target='passwordCredentials')\n\n        user_id = auth['passwordCredentials'].get('userId', None)\n        username = auth['passwordCredentials'].get('username', '')\n\n        if username:\n            try:\n                user_ref = self.identity_api.get_user_by_name(\n                    context=context, user_name=username)\n                user_id = user_ref['id']\n            except exception.UserNotFound as e:\n                raise exception.Unauthorized(e)\n\n        tenant_id = self._get_tenant_id_from_auth(context, auth)\n\n        try:\n            auth_info = self.identity_api.authenticate(\n                context=context,\n                user_id=user_id,\n                password=password,\n                tenant_id=tenant_id)\n        except AssertionError as e:\n            raise exception.Unauthorized(e)\n        (user_ref, tenant_ref, metadata_ref) = auth_info\n\n        expiry = self.token_api._get_default_expire_time(context=context)\n        auth_token_data = self._get_auth_token_data(user_ref,\n                                                    tenant_ref,\n                                                    metadata_ref,\n                                                    expiry)\n\n        return auth_token_data, (user_ref, tenant_ref, metadata_ref)\n\n    def _authenticate_external(self, context, auth):\n        \"\"\"Try to authenticate an external user via REMOTE_USER variable.\n\n        Returns auth_token_data, (user_ref, tenant_ref, metadata_ref)\n        \"\"\"\n        if 'REMOTE_USER' not in context:\n            raise ExternalAuthNotApplicable()\n\n        username = context['REMOTE_USER']\n        try:\n            user_ref = self.identity_api.get_user_by_name(\n                context=context, user_name=username)\n            user_id = user_ref['id']\n        except exception.UserNotFound as e:\n            raise exception.Unauthorized(e)\n\n        tenant_id = self._get_tenant_id_from_auth(context, auth)\n\n        tenant_ref = self._get_tenant_ref(context, user_id, tenant_id)\n        metadata_ref = self._get_metadata_ref(context, user_id, tenant_id)\n\n        expiry = self.token_api._get_default_expire_time(context=context)\n        auth_token_data = self._get_auth_token_data(user_ref,\n                                                    tenant_ref,\n                                                    metadata_ref,\n                                                    expiry)\n\n        return auth_token_data, (user_ref, tenant_ref, metadata_ref)\n\n    def _get_auth_token_data(self, user, tenant, metadata, expiry):\n        return dict(dict(user=user,\n                         tenant=tenant,\n                         metadata=metadata,\n                         expires=expiry))\n\n    def _get_tenant_id_from_auth(self, context, auth):\n        \"\"\"Extract tenant information from auth dict.\n\n        Returns a valid tenant_id if it exists, or None if not specified.\n        \"\"\"\n        tenant_id = auth.get('tenantId', None)\n        tenant_name = auth.get('tenantName', None)\n        if tenant_name:\n            try:\n                tenant_ref = self.identity_api.get_tenant_by_name(\n                    context=context, tenant_name=tenant_name)\n                tenant_id = tenant_ref['id']\n            except exception.TenantNotFound as e:\n                raise exception.Unauthorized(e)\n        return tenant_id\n\n    def _get_tenant_ref(self, context, user_id, tenant_id):\n        \"\"\"Returns the tenant_ref for the user's tenant\"\"\"\n        tenant_ref = None\n        if tenant_id:\n            tenants = self.identity_api.get_tenants_for_user(context, user_id)\n            if tenant_id not in tenants:\n                msg = 'User %s is unauthorized for tenant %s' % (\n                    user_id, tenant_id)\n                LOG.warning(msg)\n                raise exception.Unauthorized(msg)\n\n            try:\n                tenant_ref = self.identity_api.get_tenant(context=context,\n                                                          tenant_id=tenant_id)\n            except exception.TenantNotFound as e:\n                exception.Unauthorized(e)\n        return tenant_ref\n\n    def _get_metadata_ref(self, context, user_id, tenant_id):\n        \"\"\"Returns the metadata_ref for a user in a tenant\"\"\"\n        metadata_ref = {}\n        if tenant_id:\n            try:\n                metadata_ref = self.identity_api.get_metadata(\n                    context=context,\n                    user_id=user_id,\n                    tenant_id=tenant_id)\n            except exception.MetadataNotFound:\n                metadata_ref = {}\n\n        return metadata_ref\n\n    def _get_token_ref(self, context, token_id, belongs_to=None):\n        \"\"\"Returns a token if a valid one exists.\n\n        Optionally, limited to a token owned by a specific tenant.\n\n        \"\"\"\n        # TODO(termie): this stuff should probably be moved to middleware\n        self.assert_admin(context)\n\n        if cms.is_ans1_token(token_id):\n            data = json.loads(cms.cms_verify(cms.token_to_cms(token_id),\n                                             config.CONF.signing.certfile,\n                                             config.CONF.signing.ca_certs))\n            data['access']['token']['user'] = data['access']['user']\n            data['access']['token']['metadata'] = data['access']['metadata']\n            if belongs_to:\n                assert data['access']['token']['tenant']['id'] == belongs_to\n            token_ref = data['access']['token']\n        else:\n            token_ref = self.token_api.get_token(context=context,\n                                                 token_id=token_id)\n        return token_ref\n\n    # admin only\n    def validate_token_head(self, context, token_id):\n        \"\"\"Check that a token is valid.\n\n        Optionally, also ensure that it is owned by a specific tenant.\n\n        Identical to ``validate_token``, except does not return a response.\n\n        \"\"\"\n        belongs_to = context['query_string'].get('belongsTo')\n        assert self._get_token_ref(context, token_id, belongs_to)\n\n    # admin only\n    def validate_token(self, context, token_id):\n        \"\"\"Check that a token is valid.\n\n        Optionally, also ensure that it is owned by a specific tenant.\n\n        Returns metadata about the token along any associated roles.\n\n        \"\"\"\n        belongs_to = context['query_string'].get('belongsTo')\n        token_ref = self._get_token_ref(context, token_id, belongs_to)\n\n        # TODO(termie): optimize this call at some point and put it into the\n        #               the return for metadata\n        # fill out the roles in the metadata\n        metadata_ref = token_ref['metadata']\n        roles_ref = []\n        for role_id in metadata_ref.get('roles', []):\n            roles_ref.append(self.identity_api.get_role(context, role_id))\n\n        # Get a service catalog if possible\n        # This is needed for on-behalf-of requests\n        catalog_ref = None\n        if token_ref.get('tenant'):\n            catalog_ref = self.catalog_api.get_catalog(\n                context=context,\n                user_id=token_ref['user']['id'],\n                tenant_id=token_ref['tenant']['id'],\n                metadata=metadata_ref)\n        return self._format_token(token_ref, roles_ref, catalog_ref)\n\n    def delete_token(self, context, token_id):\n        \"\"\"Delete a token, effectively invalidating it for authz.\"\"\"\n        # TODO(termie): this stuff should probably be moved to middleware\n        self.assert_admin(context)\n        self.token_api.delete_token(context=context, token_id=token_id)\n\n    def revocation_list(self, context, auth=None):\n        self.assert_admin(context)\n        tokens = self.token_api.list_revoked_tokens(context)\n\n        for t in tokens:\n            expires = t['expires']\n            if not (expires and isinstance(expires, unicode)):\n                    t['expires'] = timeutils.isotime(expires)\n        data = {'revoked': tokens}\n        json_data = json.dumps(data)\n        signed_text = cms.cms_sign_text(json_data,\n                                        config.CONF.signing.certfile,\n                                        config.CONF.signing.keyfile)\n\n        return {'signed': signed_text}\n\n    def endpoints(self, context, token_id):\n        \"\"\"Return a list of endpoints available to the token.\"\"\"\n        self.assert_admin(context)\n\n        token_ref = self._get_token_ref(context, token_id)\n\n        catalog_ref = None\n        if token_ref.get('tenant'):\n            catalog_ref = self.catalog_api.get_catalog(\n                context=context,\n                user_id=token_ref['user']['id'],\n                tenant_id=token_ref['tenant']['id'],\n                metadata=token_ref['metadata'])\n\n        return self._format_endpoint_list(catalog_ref)\n\n    def _format_authenticate(self, token_ref, roles_ref, catalog_ref):\n        o = self._format_token(token_ref, roles_ref)\n        o['access']['serviceCatalog'] = self._format_catalog(catalog_ref)\n        return o\n\n    def _format_token(self, token_ref, roles_ref, catalog_ref=None):\n        user_ref = token_ref['user']\n        metadata_ref = token_ref['metadata']\n        expires = token_ref['expires']\n        if expires is not None:\n            if not isinstance(expires, unicode):\n                expires = timeutils.isotime(expires)\n        o = {'access': {'token': {'id': token_ref['id'],\n                                  'expires': expires,\n                                  'issued_at': timeutils.strtime()\n                                  },\n                        'user': {'id': user_ref['id'],\n                                 'name': user_ref['name'],\n                                 'username': user_ref['name'],\n                                 'roles': roles_ref,\n                                 'roles_links': metadata_ref.get('roles_links',\n                                                                 [])\n                                 }\n                        }\n             }\n        if 'tenant' in token_ref and token_ref['tenant']:\n            token_ref['tenant']['enabled'] = True\n            o['access']['token']['tenant'] = token_ref['tenant']\n        if catalog_ref is not None:\n            o['access']['serviceCatalog'] = self._format_catalog(catalog_ref)\n        if metadata_ref:\n            if 'is_admin' in metadata_ref:\n                o['access']['metadata'] = {'is_admin':\n                                           metadata_ref['is_admin']}\n            else:\n                o['access']['metadata'] = {'is_admin': 0}\n        if 'roles' in metadata_ref:\n                o['access']['metadata']['roles'] = metadata_ref['roles']\n        return o\n\n    def _format_catalog(self, catalog_ref):\n        \"\"\"Munge catalogs from internal to output format\n        Internal catalogs look like:\n\n        {$REGION: {\n            {$SERVICE: {\n                $key1: $value1,\n                ...\n                }\n            }\n        }\n\n        The legacy api wants them to look like\n\n        [{'name': $SERVICE[name],\n          'type': $SERVICE,\n          'endpoints': [{\n              'tenantId': $tenant_id,\n              ...\n              'region': $REGION,\n              }],\n          'endpoints_links': [],\n         }]\n\n        \"\"\"\n        if not catalog_ref:\n            return {}\n\n        services = {}\n        for region, region_ref in catalog_ref.iteritems():\n            for service, service_ref in region_ref.iteritems():\n                new_service_ref = services.get(service, {})\n                new_service_ref['name'] = service_ref.pop('name')\n                new_service_ref['type'] = service\n                new_service_ref['endpoints_links'] = []\n                service_ref['region'] = region\n\n                endpoints_ref = new_service_ref.get('endpoints', [])\n                endpoints_ref.append(service_ref)\n\n                new_service_ref['endpoints'] = endpoints_ref\n                services[service] = new_service_ref\n\n        return services.values()\n\n    def _format_endpoint_list(self, catalog_ref):\n        \"\"\"Formats a list of endpoints according to Identity API v2.\n\n        The v2.0 API wants an endpoint list to look like::\n\n            {\n                'endpoints': [\n                    {\n                        'id': $endpoint_id,\n                        'name': $SERVICE[name],\n                        'type': $SERVICE,\n                        'tenantId': $tenant_id,\n                        'region': $REGION,\n                    }\n                ],\n                'endpoints_links': [],\n            }\n\n        \"\"\"\n        if not catalog_ref:\n            return {}\n\n        endpoints = []\n        for region_name, region_ref in catalog_ref.iteritems():\n            for service_type, service_ref in region_ref.iteritems():\n                endpoints.append({\n                    'id': service_ref.get('id'),\n                    'name': service_ref.get('name'),\n                    'type': service_type,\n                    'region': region_name,\n                    'publicURL': service_ref.get('publicURL'),\n                    'internalURL': service_ref.get('internalURL'),\n                    'adminURL': service_ref.get('adminURL'),\n                })\n\n        return {'endpoints': endpoints, 'endpoints_links': []}\n\n\nclass ExtensionsController(wsgi.Application):\n    \"\"\"Base extensions controller to be extended by public and admin API's.\"\"\"\n\n    def __init__(self, extensions=None):\n        super(ExtensionsController, self).__init__()\n\n        self.extensions = extensions or {}\n\n    def get_extensions_info(self, context):\n        return {'extensions': {'values': self.extensions.values()}}\n\n    def get_extension_info(self, context, extension_alias):\n        try:\n            return {'extension': self.extensions[extension_alias]}\n        except KeyError:\n            raise exception.NotFound(target=extension_alias)\n\n\nclass PublicExtensionsController(ExtensionsController):\n    pass\n\n\nclass AdminExtensionsController(ExtensionsController):\n    def __init__(self, *args, **kwargs):\n        super(AdminExtensionsController, self).__init__(*args, **kwargs)\n\n        # TODO(dolph): Extensions should obviously provide this information\n        #               themselves, but hardcoding it here allows us to match\n        #               the API spec in the short term with minimal complexity.\n        self.extensions['OS-KSADM'] = {\n            'name': 'Openstack Keystone Admin',\n            'namespace': 'http://docs.openstack.org/identity/api/ext/'\n                         'OS-KSADM/v1.0',\n            'alias': 'OS-KSADM',\n            'updated': '2011-08-19T13:25:27-06:00',\n            'description': 'Openstack extensions to Keystone v2.0 API '\n                           'enabling Admin Operations.',\n            'links': [\n                {\n                    'rel': 'describedby',\n                    # TODO(dolph): link needs to be revised after\n                    #              bug 928059 merges\n                    'type': 'text/html',\n                    'href': 'https://github.com/openstack/identity-api',\n                }\n            ]\n        }\n\n\n@logging.fail_gracefully\ndef public_app_factory(global_conf, **local_conf):\n    conf = global_conf.copy()\n    conf.update(local_conf)\n    return PublicRouter()\n\n\n@logging.fail_gracefully\ndef admin_app_factory(global_conf, **local_conf):\n    conf = global_conf.copy()\n    conf.update(local_conf)\n    return AdminRouter()\n\n\n@logging.fail_gracefully\ndef public_version_app_factory(global_conf, **local_conf):\n    conf = global_conf.copy()\n    conf.update(local_conf)\n    return PublicVersionRouter()\n\n\n@logging.fail_gracefully\ndef admin_version_app_factory(global_conf, **local_conf):\n    conf = global_conf.copy()\n    conf.update(local_conf)\n    return AdminVersionRouter()\n\n\n@logging.fail_gracefully\ndef v3_app_factory(global_conf, **local_conf):\n    conf = global_conf.copy()\n    conf.update(local_conf)\n    return V3Router()\n", "target": 1}
{"idx": 878, "func": "\"\"\"Utility functions for copying and archiving files and directory trees.\n\nXXX The functions here don't copy the resource fork or other metadata on Mac.\n\n\"\"\"\n\nimport os\nimport sys\nimport stat\nfrom os.path import abspath\nimport fnmatch\nimport collections\nimport errno\n\ntry:\n    import zlib\n    del zlib\n    _ZLIB_SUPPORTED = True\nexcept ImportError:\n    _ZLIB_SUPPORTED = False\n\ntry:\n    import bz2\n    del bz2\n    _BZ2_SUPPORTED = True\nexcept ImportError:\n    _BZ2_SUPPORTED = False\n\ntry:\n    from pwd import getpwnam\nexcept ImportError:\n    getpwnam = None\n\ntry:\n    from grp import getgrnam\nexcept ImportError:\n    getgrnam = None\n\n__all__ = [\"copyfileobj\", \"copyfile\", \"copymode\", \"copystat\", \"copy\", \"copy2\",\n           \"copytree\", \"move\", \"rmtree\", \"Error\", \"SpecialFileError\",\n           \"ExecError\", \"make_archive\", \"get_archive_formats\",\n           \"register_archive_format\", \"unregister_archive_format\",\n           \"ignore_patterns\"]\n\nclass Error(EnvironmentError):\n    pass\n\nclass SpecialFileError(EnvironmentError):\n    \"\"\"Raised when trying to do a kind of operation (e.g. copying) which is\n    not supported on a special file (e.g. a named pipe)\"\"\"\n\nclass ExecError(EnvironmentError):\n    \"\"\"Raised when a command could not be executed\"\"\"\n\ntry:\n    WindowsError\nexcept NameError:\n    WindowsError = None\n\ndef copyfileobj(fsrc, fdst, length=16*1024):\n    \"\"\"copy data from file-like object fsrc to file-like object fdst\"\"\"\n    while 1:\n        buf = fsrc.read(length)\n        if not buf:\n            break\n        fdst.write(buf)\n\ndef _samefile(src, dst):\n    # Macintosh, Unix.\n    if hasattr(os.path, 'samefile'):\n        try:\n            return os.path.samefile(src, dst)\n        except OSError:\n            return False\n\n    # All other platforms: check for same pathname.\n    return (os.path.normcase(os.path.abspath(src)) ==\n            os.path.normcase(os.path.abspath(dst)))\n\ndef copyfile(src, dst):\n    \"\"\"Copy data from src to dst\"\"\"\n    if _samefile(src, dst):\n        raise Error(\"`%s` and `%s` are the same file\" % (src, dst))\n\n    for fn in [src, dst]:\n        try:\n            st = os.stat(fn)\n        except OSError:\n            # File most likely does not exist\n            pass\n        else:\n            # XXX What about other special files? (sockets, devices...)\n            if stat.S_ISFIFO(st.st_mode):\n                raise SpecialFileError(\"`%s` is a named pipe\" % fn)\n\n    with open(src, 'rb') as fsrc:\n        with open(dst, 'wb') as fdst:\n            copyfileobj(fsrc, fdst)\n\ndef copymode(src, dst):\n    \"\"\"Copy mode bits from src to dst\"\"\"\n    if hasattr(os, 'chmod'):\n        st = os.stat(src)\n        mode = stat.S_IMODE(st.st_mode)\n        os.chmod(dst, mode)\n\ndef copystat(src, dst):\n    \"\"\"Copy all stat info (mode bits, atime, mtime, flags) from src to dst\"\"\"\n    st = os.stat(src)\n    mode = stat.S_IMODE(st.st_mode)\n    if hasattr(os, 'utime'):\n        os.utime(dst, (st.st_atime, st.st_mtime))\n    if hasattr(os, 'chmod'):\n        os.chmod(dst, mode)\n    if hasattr(os, 'chflags') and hasattr(st, 'st_flags'):\n        try:\n            os.chflags(dst, st.st_flags)\n        except OSError, why:\n            for err in 'EOPNOTSUPP', 'ENOTSUP':\n                if hasattr(errno, err) and why.errno == getattr(errno, err):\n                    break\n            else:\n                raise\n\ndef copy(src, dst):\n    \"\"\"Copy data and mode bits (\"cp src dst\").\n\n    The destination may be a directory.\n\n    \"\"\"\n    if os.path.isdir(dst):\n        dst = os.path.join(dst, os.path.basename(src))\n    copyfile(src, dst)\n    copymode(src, dst)\n\ndef copy2(src, dst):\n    \"\"\"Copy data and all stat info (\"cp -p src dst\").\n\n    The destination may be a directory.\n\n    \"\"\"\n    if os.path.isdir(dst):\n        dst = os.path.join(dst, os.path.basename(src))\n    copyfile(src, dst)\n    copystat(src, dst)\n\ndef ignore_patterns(*patterns):\n    \"\"\"Function that can be used as copytree() ignore parameter.\n\n    Patterns is a sequence of glob-style patterns\n    that are used to exclude files\"\"\"\n    def _ignore_patterns(path, names):\n        ignored_names = []\n        for pattern in patterns:\n            ignored_names.extend(fnmatch.filter(names, pattern))\n        return set(ignored_names)\n    return _ignore_patterns\n\ndef copytree(src, dst, symlinks=False, ignore=None):\n    \"\"\"Recursively copy a directory tree using copy2().\n\n    The destination directory must not already exist.\n    If exception(s) occur, an Error is raised with a list of reasons.\n\n    If the optional symlinks flag is true, symbolic links in the\n    source tree result in symbolic links in the destination tree; if\n    it is false, the contents of the files pointed to by symbolic\n    links are copied.\n\n    The optional ignore argument is a callable. If given, it\n    is called with the `src` parameter, which is the directory\n    being visited by copytree(), and `names` which is the list of\n    `src` contents, as returned by os.listdir():\n\n        callable(src, names) -> ignored_names\n\n    Since copytree() is called recursively, the callable will be\n    called once for each directory that is copied. It returns a\n    list of names relative to the `src` directory that should\n    not be copied.\n\n    XXX Consider this example code rather than the ultimate tool.\n\n    \"\"\"\n    names = os.listdir(src)\n    if ignore is not None:\n        ignored_names = ignore(src, names)\n    else:\n        ignored_names = set()\n\n    os.makedirs(dst)\n    errors = []\n    for name in names:\n        if name in ignored_names:\n            continue\n        srcname = os.path.join(src, name)\n        dstname = os.path.join(dst, name)\n        try:\n            if symlinks and os.path.islink(srcname):\n                linkto = os.readlink(srcname)\n                os.symlink(linkto, dstname)\n            elif os.path.isdir(srcname):\n                copytree(srcname, dstname, symlinks, ignore)\n            else:\n                # Will raise a SpecialFileError for unsupported file types\n                copy2(srcname, dstname)\n        # catch the Error from the recursive copytree so that we can\n        # continue with other files\n        except Error, err:\n            errors.extend(err.args[0])\n        except EnvironmentError, why:\n            errors.append((srcname, dstname, str(why)))\n    try:\n        copystat(src, dst)\n    except OSError, why:\n        if WindowsError is not None and isinstance(why, WindowsError):\n            # Copying file access times may fail on Windows\n            pass\n        else:\n            errors.append((src, dst, str(why)))\n    if errors:\n        raise Error, errors\n\ndef rmtree(path, ignore_errors=False, onerror=None):\n    \"\"\"Recursively delete a directory tree.\n\n    If ignore_errors is set, errors are ignored; otherwise, if onerror\n    is set, it is called to handle the error with arguments (func,\n    path, exc_info) where func is os.listdir, os.remove, or os.rmdir;\n    path is the argument to that function that caused it to fail; and\n    exc_info is a tuple returned by sys.exc_info().  If ignore_errors\n    is false and onerror is None, an exception is raised.\n\n    \"\"\"\n    if ignore_errors:\n        def onerror(*args):\n            pass\n    elif onerror is None:\n        def onerror(*args):\n            raise\n    try:\n        if os.path.islink(path):\n            # symlinks to directories are forbidden, see bug #1669\n            raise OSError(\"Cannot call rmtree on a symbolic link\")\n    except OSError:\n        onerror(os.path.islink, path, sys.exc_info())\n        # can't continue even if onerror hook returns\n        return\n    names = []\n    try:\n        names = os.listdir(path)\n    except os.error, err:\n        onerror(os.listdir, path, sys.exc_info())\n    for name in names:\n        fullname = os.path.join(path, name)\n        try:\n            mode = os.lstat(fullname).st_mode\n        except os.error:\n            mode = 0\n        if stat.S_ISDIR(mode):\n            rmtree(fullname, ignore_errors, onerror)\n        else:\n            try:\n                os.remove(fullname)\n            except os.error, err:\n                onerror(os.remove, fullname, sys.exc_info())\n    try:\n        os.rmdir(path)\n    except os.error:\n        onerror(os.rmdir, path, sys.exc_info())\n\n\ndef _basename(path):\n    # A basename() variant which first strips the trailing slash, if present.\n    # Thus we always get the last component of the path, even for directories.\n    sep = os.path.sep + (os.path.altsep or '')\n    return os.path.basename(path.rstrip(sep))\n\ndef move(src, dst):\n    \"\"\"Recursively move a file or directory to another location. This is\n    similar to the Unix \"mv\" command.\n\n    If the destination is a directory or a symlink to a directory, the source\n    is moved inside the directory. The destination path must not already\n    exist.\n\n    If the destination already exists but is not a directory, it may be\n    overwritten depending on os.rename() semantics.\n\n    If the destination is on our current filesystem, then rename() is used.\n    Otherwise, src is copied to the destination and then removed.\n    A lot more could be done here...  A look at a mv.c shows a lot of\n    the issues this implementation glosses over.\n\n    \"\"\"\n    real_dst = dst\n    if os.path.isdir(dst):\n        if _samefile(src, dst):\n            # We might be on a case insensitive filesystem,\n            # perform the rename anyway.\n            os.rename(src, dst)\n            return\n\n        real_dst = os.path.join(dst, _basename(src))\n        if os.path.exists(real_dst):\n            raise Error, \"Destination path '%s' already exists\" % real_dst\n    try:\n        os.rename(src, real_dst)\n    except OSError:\n        if os.path.isdir(src):\n            if _destinsrc(src, dst):\n                raise Error, \"Cannot move a directory '%s' into itself '%s'.\" % (src, dst)\n            copytree(src, real_dst, symlinks=True)\n            rmtree(src)\n        else:\n            copy2(src, real_dst)\n            os.unlink(src)\n\ndef _destinsrc(src, dst):\n    src = abspath(src)\n    dst = abspath(dst)\n    if not src.endswith(os.path.sep):\n        src += os.path.sep\n    if not dst.endswith(os.path.sep):\n        dst += os.path.sep\n    return dst.startswith(src)\n\ndef _get_gid(name):\n    \"\"\"Returns a gid, given a group name.\"\"\"\n    if getgrnam is None or name is None:\n        return None\n    try:\n        result = getgrnam(name)\n    except KeyError:\n        result = None\n    if result is not None:\n        return result[2]\n    return None\n\ndef _get_uid(name):\n    \"\"\"Returns an uid, given a user name.\"\"\"\n    if getpwnam is None or name is None:\n        return None\n    try:\n        result = getpwnam(name)\n    except KeyError:\n        result = None\n    if result is not None:\n        return result[2]\n    return None\n\ndef _make_tarball(base_name, base_dir, compress=\"gzip\", verbose=0, dry_run=0,\n                  owner=None, group=None, logger=None):\n    \"\"\"Create a (possibly compressed) tar file from all the files under\n    'base_dir'.\n\n    'compress' must be \"gzip\" (the default), \"bzip2\", or None.\n\n    'owner' and 'group' can be used to define an owner and a group for the\n    archive that is being built. If not provided, the current owner and group\n    will be used.\n\n    The output tar file will be named 'base_name' +  \".tar\", possibly plus\n    the appropriate compression extension (\".gz\", or \".bz2\").\n\n    Returns the output filename.\n    \"\"\"\n    if compress is None:\n        tar_compression = ''\n    elif _ZLIB_SUPPORTED and compress == 'gzip':\n        tar_compression = 'gz'\n    elif _BZ2_SUPPORTED and compress == 'bzip2':\n        tar_compression = 'bz2'\n    else:\n        raise ValueError(\"bad value for 'compress', or compression format not \"\n                         \"supported : {0}\".format(compress))\n\n    compress_ext = '.' + tar_compression if compress else ''\n    archive_name = base_name + '.tar' + compress_ext\n    archive_dir = os.path.dirname(archive_name)\n\n    if archive_dir and not os.path.exists(archive_dir):\n        if logger is not None:\n            logger.info(\"creating %s\", archive_dir)\n        if not dry_run:\n            os.makedirs(archive_dir)\n\n\n    # creating the tarball\n    import tarfile  # late import so Python build itself doesn't break\n\n    if logger is not None:\n        logger.info('Creating tar archive')\n\n    uid = _get_uid(owner)\n    gid = _get_gid(group)\n\n    def _set_uid_gid(tarinfo):\n        if gid is not None:\n            tarinfo.gid = gid\n            tarinfo.gname = group\n        if uid is not None:\n            tarinfo.uid = uid\n            tarinfo.uname = owner\n        return tarinfo\n\n    if not dry_run:\n        tar = tarfile.open(archive_name, 'w|%s' % tar_compression)\n        try:\n            tar.add(base_dir, filter=_set_uid_gid)\n        finally:\n            tar.close()\n\n    return archive_name\n\ndef _call_external_zip(base_dir, zip_filename, verbose=False, dry_run=False):\n    # XXX see if we want to keep an external call here\n    if verbose:\n        zipoptions = \"-r\"\n    else:\n        zipoptions = \"-rq\"\n    from distutils.errors import DistutilsExecError\n    from distutils.spawn import spawn\n    try:\n        spawn([\"zip\", zipoptions, zip_filename, base_dir], dry_run=dry_run)\n    except DistutilsExecError:\n        # XXX really should distinguish between \"couldn't find\n        # external 'zip' command\" and \"zip failed\".\n        raise ExecError, \\\n            (\"unable to create zip file '%s': \"\n            \"could neither import the 'zipfile' module nor \"\n            \"find a standalone zip utility\") % zip_filename\n\ndef _make_zipfile(base_name, base_dir, verbose=0, dry_run=0, logger=None):\n    \"\"\"Create a zip file from all the files under 'base_dir'.\n\n    The output zip file will be named 'base_name' + \".zip\".  Uses either the\n    \"zipfile\" Python module (if available) or the InfoZIP \"zip\" utility\n    (if installed and found on the default search path).  If neither tool is\n    available, raises ExecError.  Returns the name of the output zip\n    file.\n    \"\"\"\n    zip_filename = base_name + \".zip\"\n    archive_dir = os.path.dirname(base_name)\n\n    if archive_dir and not os.path.exists(archive_dir):\n        if logger is not None:\n            logger.info(\"creating %s\", archive_dir)\n        if not dry_run:\n            os.makedirs(archive_dir)\n\n    # If zipfile module is not available, try spawning an external 'zip'\n    # command.\n    try:\n        import zlib\n        import zipfile\n    except ImportError:\n        zipfile = None\n\n    if zipfile is None:\n        _call_external_zip(base_dir, zip_filename, verbose, dry_run)\n    else:\n        if logger is not None:\n            logger.info(\"creating '%s' and adding '%s' to it\",\n                        zip_filename, base_dir)\n\n        if not dry_run:\n            with zipfile.ZipFile(zip_filename, \"w\",\n                                 compression=zipfile.ZIP_DEFLATED) as zf:\n                path = os.path.normpath(base_dir)\n                if path != os.curdir:\n                    zf.write(path, path)\n                    if logger is not None:\n                        logger.info(\"adding '%s'\", path)\n                for dirpath, dirnames, filenames in os.walk(base_dir):\n                    for name in sorted(dirnames):\n                        path = os.path.normpath(os.path.join(dirpath, name))\n                        zf.write(path, path)\n                        if logger is not None:\n                            logger.info(\"adding '%s'\", path)\n                    for name in filenames:\n                        path = os.path.normpath(os.path.join(dirpath, name))\n                        if os.path.isfile(path):\n                            zf.write(path, path)\n                            if logger is not None:\n                                logger.info(\"adding '%s'\", path)\n\n    return zip_filename\n\n_ARCHIVE_FORMATS = {\n    'tar':   (_make_tarball, [('compress', None)], \"uncompressed tar file\"),\n    'zip':   (_make_zipfile, [], \"ZIP file\")\n}\n\nif _ZLIB_SUPPORTED:\n    _ARCHIVE_FORMATS['gztar'] = (_make_tarball, [('compress', 'gzip')],\n                                \"gzip'ed tar-file\")\n\nif _BZ2_SUPPORTED:\n    _ARCHIVE_FORMATS['bztar'] = (_make_tarball, [('compress', 'bzip2')],\n                                \"bzip2'ed tar-file\")\n\ndef get_archive_formats():\n    \"\"\"Returns a list of supported formats for archiving and unarchiving.\n\n    Each element of the returned sequence is a tuple (name, description)\n    \"\"\"\n    formats = [(name, registry[2]) for name, registry in\n               _ARCHIVE_FORMATS.items()]\n    formats.sort()\n    return formats\n\ndef register_archive_format(name, function, extra_args=None, description=''):\n    \"\"\"Registers an archive format.\n\n    name is the name of the format. function is the callable that will be\n    used to create archives. If provided, extra_args is a sequence of\n    (name, value) tuples that will be passed as arguments to the callable.\n    description can be provided to describe the format, and will be returned\n    by the get_archive_formats() function.\n    \"\"\"\n    if extra_args is None:\n        extra_args = []\n    if not isinstance(function, collections.Callable):\n        raise TypeError('The %s object is not callable' % function)\n    if not isinstance(extra_args, (tuple, list)):\n        raise TypeError('extra_args needs to be a sequence')\n    for element in extra_args:\n        if not isinstance(element, (tuple, list)) or len(element) !=2 :\n            raise TypeError('extra_args elements are : (arg_name, value)')\n\n    _ARCHIVE_FORMATS[name] = (function, extra_args, description)\n\ndef unregister_archive_format(name):\n    del _ARCHIVE_FORMATS[name]\n\ndef make_archive(base_name, format, root_dir=None, base_dir=None, verbose=0,\n                 dry_run=0, owner=None, group=None, logger=None):\n    \"\"\"Create an archive file (eg. zip or tar).\n\n    'base_name' is the name of the file to create, minus any format-specific\n    extension; 'format' is the archive format: one of \"zip\", \"tar\", \"gztar\",\n    or \"bztar\".  Or any other registered format.\n\n    'root_dir' is a directory that will be the root directory of the\n    archive; ie. we typically chdir into 'root_dir' before creating the\n    archive.  'base_dir' is the directory where we start archiving from;\n    ie. 'base_dir' will be the common prefix of all files and\n    directories in the archive.  'root_dir' and 'base_dir' both default\n    to the current directory.  Returns the name of the archive file.\n\n    'owner' and 'group' are used when creating a tar archive. By default,\n    uses the current owner and group.\n    \"\"\"\n    save_cwd = os.getcwd()\n    if root_dir is not None:\n        if logger is not None:\n            logger.debug(\"changing into '%s'\", root_dir)\n        base_name = os.path.abspath(base_name)\n        if not dry_run:\n            os.chdir(root_dir)\n\n    if base_dir is None:\n        base_dir = os.curdir\n\n    kwargs = {'dry_run': dry_run, 'logger': logger}\n\n    try:\n        format_info = _ARCHIVE_FORMATS[format]\n    except KeyError:\n        raise ValueError, \"unknown archive format '%s'\" % format\n\n    func = format_info[0]\n    for arg, val in format_info[1]:\n        kwargs[arg] = val\n\n    if format != 'zip':\n        kwargs['owner'] = owner\n        kwargs['group'] = group\n\n    try:\n        filename = func(base_name, base_dir, **kwargs)\n    finally:\n        if root_dir is not None:\n            if logger is not None:\n                logger.debug(\"changing back to '%s'\", save_cwd)\n            os.chdir(save_cwd)\n\n    return filename\n", "target": 1}
{"idx": 879, "func": "# vim: ft=python fileencoding=utf-8 sts=4 sw=4 et:\n\n# Copyright 2016-2019 Florian Bruhin (The Compiler) <mail@qutebrowser.org>\n#\n# This file is part of qutebrowser.\n#\n# qutebrowser is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# qutebrowser is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with qutebrowser.  If not, see <http://www.gnu.org/licenses/>.\n\n\"\"\"Wrapper over a QWebEngineView.\"\"\"\n\nimport math\nimport functools\nimport re\nimport html as html_utils\n\nfrom PyQt5.QtCore import (pyqtSignal, pyqtSlot, Qt, QPoint, QPointF, QUrl,\n                          QTimer, QObject)\nfrom PyQt5.QtNetwork import QAuthenticator\nfrom PyQt5.QtWidgets import QApplication\nfrom PyQt5.QtWebEngineWidgets import QWebEnginePage, QWebEngineScript\n\nfrom qutebrowser.config import configdata, config\nfrom qutebrowser.browser import browsertab, mouse, shared, webelem\nfrom qutebrowser.browser.webengine import (webview, webengineelem, tabhistory,\n                                           interceptor, webenginequtescheme,\n                                           cookies, webenginedownloads,\n                                           webenginesettings, certificateerror)\nfrom qutebrowser.misc import miscwidgets\nfrom qutebrowser.utils import (usertypes, qtutils, log, javascript, utils,\n                               message, objreg, jinja, debug)\nfrom qutebrowser.qt import sip\n\n\n_qute_scheme_handler = None\n\n\ndef init():\n    \"\"\"Initialize QtWebEngine-specific modules.\"\"\"\n    # For some reason we need to keep a reference, otherwise the scheme handler\n    # won't work...\n    # https://www.riverbankcomputing.com/pipermail/pyqt/2016-September/038075.html\n    global _qute_scheme_handler\n\n    app = QApplication.instance()\n    log.init.debug(\"Initializing qute://* handler...\")\n    _qute_scheme_handler = webenginequtescheme.QuteSchemeHandler(parent=app)\n    _qute_scheme_handler.install(webenginesettings.default_profile)\n    if webenginesettings.private_profile:\n        _qute_scheme_handler.install(webenginesettings.private_profile)\n\n    log.init.debug(\"Initializing request interceptor...\")\n    args = objreg.get('args')\n    req_interceptor = interceptor.RequestInterceptor(args=args, parent=app)\n    req_interceptor.install(webenginesettings.default_profile)\n    if webenginesettings.private_profile:\n        req_interceptor.install(webenginesettings.private_profile)\n\n    log.init.debug(\"Initializing QtWebEngine downloads...\")\n    download_manager = webenginedownloads.DownloadManager(parent=app)\n    download_manager.install(webenginesettings.default_profile)\n    if webenginesettings.private_profile:\n        download_manager.install(webenginesettings.private_profile)\n    objreg.register('webengine-download-manager', download_manager)\n\n    log.init.debug(\"Initializing cookie filter...\")\n    cookies.install_filter(webenginesettings.default_profile)\n    if webenginesettings.private_profile:\n        cookies.install_filter(webenginesettings.private_profile)\n\n    # Clear visited links on web history clear\n    hist = objreg.get('web-history')\n    for p in [webenginesettings.default_profile,\n              webenginesettings.private_profile]:\n        if not p:\n            continue\n        hist.history_cleared.connect(p.clearAllVisitedLinks)\n        hist.url_cleared.connect(lambda url, profile=p:\n                                 profile.clearVisitedLinks([url]))\n\n\n# Mapping worlds from usertypes.JsWorld to QWebEngineScript world IDs.\n_JS_WORLD_MAP = {\n    usertypes.JsWorld.main: QWebEngineScript.MainWorld,\n    usertypes.JsWorld.application: QWebEngineScript.ApplicationWorld,\n    usertypes.JsWorld.user: QWebEngineScript.UserWorld,\n    usertypes.JsWorld.jseval: QWebEngineScript.UserWorld + 1,\n}\n\n\nclass WebEngineAction(browsertab.AbstractAction):\n\n    \"\"\"QtWebEngine implementations related to web actions.\"\"\"\n\n    action_class = QWebEnginePage\n    action_base = QWebEnginePage.WebAction\n\n    def exit_fullscreen(self):\n        self._widget.triggerPageAction(QWebEnginePage.ExitFullScreen)\n\n    def save_page(self):\n        \"\"\"Save the current page.\"\"\"\n        self._widget.triggerPageAction(QWebEnginePage.SavePage)\n\n    def show_source(self, pygments=False):\n        if pygments:\n            self._show_source_pygments()\n            return\n\n        try:\n            self._widget.triggerPageAction(QWebEnginePage.ViewSource)\n        except AttributeError:\n            # Qt < 5.8\n            tb = objreg.get('tabbed-browser', scope='window',\n                            window=self._tab.win_id)\n            urlstr = self._tab.url().toString(QUrl.RemoveUserInfo)\n            # The original URL becomes the path of a view-source: URL\n            # (without a host), but query/fragment should stay.\n            url = QUrl('view-source:' + urlstr)\n            tb.tabopen(url, background=False, related=True)\n\n\nclass WebEnginePrinting(browsertab.AbstractPrinting):\n\n    \"\"\"QtWebEngine implementations related to printing.\"\"\"\n\n    def check_pdf_support(self):\n        pass\n\n    def check_printer_support(self):\n        if not hasattr(self._widget.page(), 'print'):\n            raise browsertab.WebTabError(\n                \"Printing is unsupported with QtWebEngine on Qt < 5.8\")\n\n    def check_preview_support(self):\n        raise browsertab.WebTabError(\n            \"Print previews are unsupported with QtWebEngine\")\n\n    def to_pdf(self, filename):\n        self._widget.page().printToPdf(filename)\n\n    def to_printer(self, printer, callback=None):\n        if callback is None:\n            callback = lambda _ok: None\n        self._widget.page().print(printer, callback)\n\n\nclass WebEngineSearch(browsertab.AbstractSearch):\n\n    \"\"\"QtWebEngine implementations related to searching on the page.\n\n    Attributes:\n        _flags: The QWebEnginePage.FindFlags of the last search.\n        _pending_searches: How many searches have been started but not called\n                           back yet.\n    \"\"\"\n\n    def __init__(self, tab, parent=None):\n        super().__init__(tab, parent)\n        self._flags = QWebEnginePage.FindFlags(0)\n        self._pending_searches = 0\n\n    def _find(self, text, flags, callback, caller):\n        \"\"\"Call findText on the widget.\"\"\"\n        self.search_displayed = True\n        self._pending_searches += 1\n\n        def wrapped_callback(found):\n            \"\"\"Wrap the callback to do debug logging.\"\"\"\n            self._pending_searches -= 1\n            if self._pending_searches > 0:\n                # See https://github.com/qutebrowser/qutebrowser/issues/2442\n                # and https://github.com/qt/qtwebengine/blob/5.10/src/core/web_contents_adapter.cpp#L924-L934\n                log.webview.debug(\"Ignoring cancelled search callback with \"\n                                  \"{} pending searches\".format(\n                                      self._pending_searches))\n                return\n\n            if sip.isdeleted(self._widget):\n                # This happens when starting a search, and closing the tab\n                # before results arrive.\n                log.webview.debug(\"Ignoring finished search for deleted \"\n                                  \"widget\")\n                return\n\n            found_text = 'found' if found else \"didn't find\"\n            if flags:\n                flag_text = 'with flags {}'.format(debug.qflags_key(\n                    QWebEnginePage, flags, klass=QWebEnginePage.FindFlag))\n            else:\n                flag_text = ''\n            log.webview.debug(' '.join([caller, found_text, text, flag_text])\n                              .strip())\n\n            if callback is not None:\n                callback(found)\n            self.finished.emit(found)\n\n        self._widget.findText(text, flags, wrapped_callback)\n\n    def search(self, text, *, ignore_case=usertypes.IgnoreCase.never,\n               reverse=False, result_cb=None):\n        # Don't go to next entry on duplicate search\n        if self.text == text and self.search_displayed:\n            log.webview.debug(\"Ignoring duplicate search request\"\n                              \" for {}\".format(text))\n            return\n\n        self.text = text\n        self._flags = QWebEnginePage.FindFlags(0)\n        if self._is_case_sensitive(ignore_case):\n            self._flags |= QWebEnginePage.FindCaseSensitively\n        if reverse:\n            self._flags |= QWebEnginePage.FindBackward\n\n        self._find(text, self._flags, result_cb, 'search')\n\n    def clear(self):\n        if self.search_displayed:\n            self.cleared.emit()\n        self.search_displayed = False\n        self._widget.findText('')\n\n    def prev_result(self, *, result_cb=None):\n        # The int() here makes sure we get a copy of the flags.\n        flags = QWebEnginePage.FindFlags(int(self._flags))\n        if flags & QWebEnginePage.FindBackward:\n            flags &= ~QWebEnginePage.FindBackward\n        else:\n            flags |= QWebEnginePage.FindBackward\n        self._find(self.text, flags, result_cb, 'prev_result')\n\n    def next_result(self, *, result_cb=None):\n        self._find(self.text, self._flags, result_cb, 'next_result')\n\n\nclass WebEngineCaret(browsertab.AbstractCaret):\n\n    \"\"\"QtWebEngine implementations related to moving the cursor/selection.\"\"\"\n\n    def _flags(self):\n        \"\"\"Get flags to pass to JS.\"\"\"\n        flags = set()\n        if qtutils.version_check('5.7.1', compiled=False):\n            flags.add('filter-prefix')\n        if utils.is_windows:\n            flags.add('windows')\n        return list(flags)\n\n    @pyqtSlot(usertypes.KeyMode)\n    def _on_mode_entered(self, mode):\n        if mode != usertypes.KeyMode.caret:\n            return\n\n        if self._tab.search.search_displayed:\n            # We are currently in search mode.\n            # convert the search to a blue selection so we can operate on it\n            # https://bugreports.qt.io/browse/QTBUG-60673\n            self._tab.search.clear()\n\n        self._tab.run_js_async(\n            javascript.assemble('caret', 'setFlags', self._flags()))\n\n        self._js_call('setInitialCursor', callback=self._selection_cb)\n\n    def _selection_cb(self, enabled):\n        \"\"\"Emit selection_toggled based on setInitialCursor.\"\"\"\n        if self._mode_manager.mode != usertypes.KeyMode.caret:\n            log.webview.debug(\"Ignoring selection cb due to mode change.\")\n            return\n        if enabled is None:\n            log.webview.debug(\"Ignoring selection status None\")\n            return\n        self.selection_toggled.emit(enabled)\n\n    @pyqtSlot(usertypes.KeyMode)\n    def _on_mode_left(self, mode):\n        if mode != usertypes.KeyMode.caret:\n            return\n\n        self.drop_selection()\n        self._js_call('disableCaret')\n\n    def move_to_next_line(self, count=1):\n        self._js_call('moveDown', count)\n\n    def move_to_prev_line(self, count=1):\n        self._js_call('moveUp', count)\n\n    def move_to_next_char(self, count=1):\n        self._js_call('moveRight', count)\n\n    def move_to_prev_char(self, count=1):\n        self._js_call('moveLeft', count)\n\n    def move_to_end_of_word(self, count=1):\n        self._js_call('moveToEndOfWord', count)\n\n    def move_to_next_word(self, count=1):\n        self._js_call('moveToNextWord', count)\n\n    def move_to_prev_word(self, count=1):\n        self._js_call('moveToPreviousWord', count)\n\n    def move_to_start_of_line(self):\n        self._js_call('moveToStartOfLine')\n\n    def move_to_end_of_line(self):\n        self._js_call('moveToEndOfLine')\n\n    def move_to_start_of_next_block(self, count=1):\n        self._js_call('moveToStartOfNextBlock', count)\n\n    def move_to_start_of_prev_block(self, count=1):\n        self._js_call('moveToStartOfPrevBlock', count)\n\n    def move_to_end_of_next_block(self, count=1):\n        self._js_call('moveToEndOfNextBlock', count)\n\n    def move_to_end_of_prev_block(self, count=1):\n        self._js_call('moveToEndOfPrevBlock', count)\n\n    def move_to_start_of_document(self):\n        self._js_call('moveToStartOfDocument')\n\n    def move_to_end_of_document(self):\n        self._js_call('moveToEndOfDocument')\n\n    def toggle_selection(self):\n        self._js_call('toggleSelection', callback=self.selection_toggled.emit)\n\n    def drop_selection(self):\n        self._js_call('dropSelection')\n\n    def selection(self, callback):\n        # Not using selectedText() as WORKAROUND for\n        # https://bugreports.qt.io/browse/QTBUG-53134\n        # Even on Qt 5.10 selectedText() seems to work poorly, see\n        # https://github.com/qutebrowser/qutebrowser/issues/3523\n        self._tab.run_js_async(javascript.assemble('caret', 'getSelection'),\n                               callback)\n\n    def reverse_selection(self):\n        self._js_call('reverseSelection')\n\n    def _follow_selected_cb_wrapped(self, js_elem, tab):\n        try:\n            self._follow_selected_cb(js_elem, tab)\n        finally:\n            self.follow_selected_done.emit()\n\n    def _follow_selected_cb(self, js_elem, tab):\n        \"\"\"Callback for javascript which clicks the selected element.\n\n        Args:\n            js_elem: The element serialized from javascript.\n            tab: Open in a new tab.\n        \"\"\"\n        if js_elem is None:\n            return\n\n        if js_elem == \"focused\":\n            # we had a focused element, not a selected one. Just send <enter>\n            self._follow_enter(tab)\n            return\n\n        assert isinstance(js_elem, dict), js_elem\n        elem = webengineelem.WebEngineElement(js_elem, tab=self._tab)\n        if tab:\n            click_type = usertypes.ClickTarget.tab\n        else:\n            click_type = usertypes.ClickTarget.normal\n\n        # Only click if we see a link\n        if elem.is_link():\n            log.webview.debug(\"Found link in selection, clicking. ClickTarget \"\n                              \"{}, elem {}\".format(click_type, elem))\n            try:\n                elem.click(click_type)\n            except webelem.Error as e:\n                message.error(str(e))\n\n    def follow_selected(self, *, tab=False):\n        if self._tab.search.search_displayed:\n            # We are currently in search mode.\n            # let's click the link via a fake-click\n            # https://bugreports.qt.io/browse/QTBUG-60673\n            self._tab.search.clear()\n\n            log.webview.debug(\"Clicking a searched link via fake key press.\")\n            # send a fake enter, clicking the orange selection box\n            self._follow_enter(tab)\n        else:\n            # click an existing blue selection\n            js_code = javascript.assemble('webelem',\n                                          'find_selected_focused_link')\n            self._tab.run_js_async(\n                js_code,\n                lambda jsret: self._follow_selected_cb_wrapped(jsret, tab))\n\n    def _js_call(self, command, *args, callback=None):\n        code = javascript.assemble('caret', command, *args)\n        self._tab.run_js_async(code, callback)\n\n\nclass WebEngineScroller(browsertab.AbstractScroller):\n\n    \"\"\"QtWebEngine implementations related to scrolling.\"\"\"\n\n    def __init__(self, tab, parent=None):\n        super().__init__(tab, parent)\n        self._args = objreg.get('args')\n        self._pos_perc = (0, 0)\n        self._pos_px = QPoint()\n        self._at_bottom = False\n\n    def _init_widget(self, widget):\n        super()._init_widget(widget)\n        page = widget.page()\n        page.scrollPositionChanged.connect(self._update_pos)\n\n    def _repeated_key_press(self, key, count=1, modifier=Qt.NoModifier):\n        \"\"\"Send count fake key presses to this scroller's WebEngineTab.\"\"\"\n        for _ in range(min(count, 1000)):\n            self._tab.fake_key_press(key, modifier)\n\n    @pyqtSlot(QPointF)\n    def _update_pos(self, pos):\n        \"\"\"Update the scroll position attributes when it changed.\"\"\"\n        self._pos_px = pos.toPoint()\n        contents_size = self._widget.page().contentsSize()\n\n        scrollable_x = contents_size.width() - self._widget.width()\n        if scrollable_x == 0:\n            perc_x = 0\n        else:\n            try:\n                perc_x = min(100, round(100 / scrollable_x * pos.x()))\n            except ValueError:\n                # https://github.com/qutebrowser/qutebrowser/issues/3219\n                log.misc.debug(\"Got ValueError!\")\n                log.misc.debug(\"contents_size.width(): {}\".format(\n                    contents_size.width()))\n                log.misc.debug(\"self._widget.width(): {}\".format(\n                    self._widget.width()))\n                log.misc.debug(\"scrollable_x: {}\".format(scrollable_x))\n                log.misc.debug(\"pos.x(): {}\".format(pos.x()))\n                raise\n\n        scrollable_y = contents_size.height() - self._widget.height()\n        if scrollable_y == 0:\n            perc_y = 0\n        else:\n            perc_y = min(100, round(100 / scrollable_y * pos.y()))\n\n        self._at_bottom = math.ceil(pos.y()) >= scrollable_y\n\n        if (self._pos_perc != (perc_x, perc_y) or\n                'no-scroll-filtering' in self._args.debug_flags):\n            self._pos_perc = perc_x, perc_y\n            self.perc_changed.emit(*self._pos_perc)\n\n    def pos_px(self):\n        return self._pos_px\n\n    def pos_perc(self):\n        return self._pos_perc\n\n    def to_perc(self, x=None, y=None):\n        js_code = javascript.assemble('scroll', 'to_perc', x, y)\n        self._tab.run_js_async(js_code)\n\n    def to_point(self, point):\n        js_code = javascript.assemble('window', 'scroll', point.x(), point.y())\n        self._tab.run_js_async(js_code)\n\n    def to_anchor(self, name):\n        url = self._tab.url()\n        url.setFragment(name)\n        self._tab.load_url(url)\n\n    def delta(self, x=0, y=0):\n        self._tab.run_js_async(javascript.assemble('window', 'scrollBy', x, y))\n\n    def delta_page(self, x=0, y=0):\n        js_code = javascript.assemble('scroll', 'delta_page', x, y)\n        self._tab.run_js_async(js_code)\n\n    def up(self, count=1):\n        self._repeated_key_press(Qt.Key_Up, count)\n\n    def down(self, count=1):\n        self._repeated_key_press(Qt.Key_Down, count)\n\n    def left(self, count=1):\n        self._repeated_key_press(Qt.Key_Left, count)\n\n    def right(self, count=1):\n        self._repeated_key_press(Qt.Key_Right, count)\n\n    def top(self):\n        self._tab.fake_key_press(Qt.Key_Home)\n\n    def bottom(self):\n        self._tab.fake_key_press(Qt.Key_End)\n\n    def page_up(self, count=1):\n        self._repeated_key_press(Qt.Key_PageUp, count)\n\n    def page_down(self, count=1):\n        self._repeated_key_press(Qt.Key_PageDown, count)\n\n    def at_top(self):\n        return self.pos_px().y() == 0\n\n    def at_bottom(self):\n        return self._at_bottom\n\n\nclass WebEngineHistoryPrivate(browsertab.AbstractHistoryPrivate):\n\n    \"\"\"History-related methods which are not part of the extension API.\"\"\"\n\n    def serialize(self):\n        if not qtutils.version_check('5.9', compiled=False):\n            # WORKAROUND for\n            # https://github.com/qutebrowser/qutebrowser/issues/2289\n            # Don't use the history's currentItem here, because of\n            # https://bugreports.qt.io/browse/QTBUG-59599 and because it doesn't\n            # contain view-source.\n            scheme = self._tab.url().scheme()\n            if scheme in ['view-source', 'chrome']:\n                raise browsertab.WebTabError(\"Can't serialize special URL!\")\n        return qtutils.serialize(self._history)\n\n    def deserialize(self, data):\n        qtutils.deserialize(data, self._history)\n\n    def load_items(self, items):\n        if items:\n            self._tab.before_load_started.emit(items[-1].url)\n\n        stream, _data, cur_data = tabhistory.serialize(items)\n        qtutils.deserialize_stream(stream, self._history)\n\n        @pyqtSlot()\n        def _on_load_finished():\n            self._tab.scroller.to_point(cur_data['scroll-pos'])\n            self._tab.load_finished.disconnect(_on_load_finished)\n\n        if cur_data is not None:\n            if 'zoom' in cur_data:\n                self._tab.zoom.set_factor(cur_data['zoom'])\n            if ('scroll-pos' in cur_data and\n                    self._tab.scroller.pos_px() == QPoint(0, 0)):\n                self._tab.load_finished.connect(_on_load_finished)\n\n\nclass WebEngineHistory(browsertab.AbstractHistory):\n\n    \"\"\"QtWebEngine implementations related to page history.\"\"\"\n\n    def __init__(self, tab):\n        super().__init__(tab)\n        self.private_api = WebEngineHistoryPrivate(tab)\n\n    def __len__(self):\n        return len(self._history)\n\n    def __iter__(self):\n        return iter(self._history.items())\n\n    def current_idx(self):\n        return self._history.currentItemIndex()\n\n    def can_go_back(self):\n        return self._history.canGoBack()\n\n    def can_go_forward(self):\n        return self._history.canGoForward()\n\n    def _item_at(self, i):\n        return self._history.itemAt(i)\n\n    def _go_to_item(self, item):\n        self._tab.before_load_started.emit(item.url())\n        self._history.goToItem(item)\n\n\nclass WebEngineZoom(browsertab.AbstractZoom):\n\n    \"\"\"QtWebEngine implementations related to zooming.\"\"\"\n\n    def _set_factor_internal(self, factor):\n        self._widget.setZoomFactor(factor)\n\n\nclass WebEngineElements(browsertab.AbstractElements):\n\n    \"\"\"QtWebEngine implemementations related to elements on the page.\"\"\"\n\n    def _js_cb_multiple(self, callback, error_cb, js_elems):\n        \"\"\"Handle found elements coming from JS and call the real callback.\n\n        Args:\n            callback: The callback to call with the found elements.\n            error_cb: The callback to call in case of an error.\n            js_elems: The elements serialized from javascript.\n        \"\"\"\n        if js_elems is None:\n            error_cb(webelem.Error(\"Unknown error while getting \"\n                                   \"elements\"))\n            return\n        elif not js_elems['success']:\n            error_cb(webelem.Error(js_elems['error']))\n            return\n\n        elems = []\n        for js_elem in js_elems['result']:\n            elem = webengineelem.WebEngineElement(js_elem, tab=self._tab)\n            elems.append(elem)\n        callback(elems)\n\n    def _js_cb_single(self, callback, js_elem):\n        \"\"\"Handle a found focus elem coming from JS and call the real callback.\n\n        Args:\n            callback: The callback to call with the found element.\n                      Called with a WebEngineElement or None.\n            js_elem: The element serialized from javascript.\n        \"\"\"\n        debug_str = ('None' if js_elem is None\n                     else utils.elide(repr(js_elem), 1000))\n        log.webview.debug(\"Got element from JS: {}\".format(debug_str))\n\n        if js_elem is None:\n            callback(None)\n        else:\n            elem = webengineelem.WebEngineElement(js_elem, tab=self._tab)\n            callback(elem)\n\n    def find_css(self, selector, callback, error_cb, *,\n                 only_visible=False):\n        js_code = javascript.assemble('webelem', 'find_css', selector,\n                                      only_visible)\n        js_cb = functools.partial(self._js_cb_multiple, callback, error_cb)\n        self._tab.run_js_async(js_code, js_cb)\n\n    def find_id(self, elem_id, callback):\n        js_code = javascript.assemble('webelem', 'find_id', elem_id)\n        js_cb = functools.partial(self._js_cb_single, callback)\n        self._tab.run_js_async(js_code, js_cb)\n\n    def find_focused(self, callback):\n        js_code = javascript.assemble('webelem', 'find_focused')\n        js_cb = functools.partial(self._js_cb_single, callback)\n        self._tab.run_js_async(js_code, js_cb)\n\n    def find_at_pos(self, pos, callback):\n        assert pos.x() >= 0, pos\n        assert pos.y() >= 0, pos\n        pos /= self._tab.zoom.factor()\n        js_code = javascript.assemble('webelem', 'find_at_pos',\n                                      pos.x(), pos.y())\n        js_cb = functools.partial(self._js_cb_single, callback)\n        self._tab.run_js_async(js_code, js_cb)\n\n\nclass WebEngineAudio(browsertab.AbstractAudio):\n\n    \"\"\"QtWebEngine implemementations related to audio/muting.\n\n    Attributes:\n        _overridden: Whether the user toggled muting manually.\n                     If that's the case, we leave it alone.\n    \"\"\"\n\n    def __init__(self, tab, parent=None):\n        super().__init__(tab, parent)\n        self._overridden = False\n\n    def _connect_signals(self):\n        page = self._widget.page()\n        page.audioMutedChanged.connect(self.muted_changed)\n        page.recentlyAudibleChanged.connect(self.recently_audible_changed)\n        self._tab.url_changed.connect(self._on_url_changed)\n        config.instance.changed.connect(self._on_config_changed)\n\n    def set_muted(self, muted: bool, override: bool = False) -> None:\n        self._overridden = override\n        assert self._widget is not None\n        page = self._widget.page()\n        page.setAudioMuted(muted)\n\n    def is_muted(self):\n        page = self._widget.page()\n        return page.isAudioMuted()\n\n    def is_recently_audible(self):\n        page = self._widget.page()\n        return page.recentlyAudible()\n\n    @pyqtSlot(QUrl)\n    def _on_url_changed(self, url):\n        if self._overridden:\n            return\n        mute = config.instance.get('content.mute', url=url)\n        self.set_muted(mute)\n\n    @config.change_filter('content.mute')\n    def _on_config_changed(self):\n        self._on_url_changed(self._tab.url())\n\n\nclass _WebEnginePermissions(QObject):\n\n    \"\"\"Handling of various permission-related signals.\"\"\"\n\n    # Using 0 as WORKAROUND for:\n    # https://www.riverbankcomputing.com/pipermail/pyqt/2019-July/041903.html\n\n    _options = {\n        0: 'content.notifications',\n        QWebEnginePage.Geolocation: 'content.geolocation',\n        QWebEnginePage.MediaAudioCapture: 'content.media_capture',\n        QWebEnginePage.MediaVideoCapture: 'content.media_capture',\n        QWebEnginePage.MediaAudioVideoCapture: 'content.media_capture',\n    }\n\n    _messages = {\n        0: 'show notifications',\n        QWebEnginePage.Geolocation: 'access your location',\n        QWebEnginePage.MediaAudioCapture: 'record audio',\n        QWebEnginePage.MediaVideoCapture: 'record video',\n        QWebEnginePage.MediaAudioVideoCapture: 'record audio/video',\n    }\n\n    def __init__(self, tab, parent=None):\n        super().__init__(parent)\n        self._tab = tab\n        self._widget = None\n\n        try:\n            self._options.update({\n                QWebEnginePage.MouseLock:\n                    'content.mouse_lock',\n            })\n            self._messages.update({\n                QWebEnginePage.MouseLock:\n                    'hide your mouse pointer',\n            })\n        except AttributeError:\n            # Added in Qt 5.8\n            pass\n        try:\n            self._options.update({\n                QWebEnginePage.DesktopVideoCapture:\n                    'content.desktop_capture',\n                QWebEnginePage.DesktopAudioVideoCapture:\n                    'content.desktop_capture',\n            })\n            self._messages.update({\n                QWebEnginePage.DesktopVideoCapture:\n                    'capture your desktop',\n                QWebEnginePage.DesktopAudioVideoCapture:\n                    'capture your desktop and audio',\n            })\n        except AttributeError:\n            # Added in Qt 5.10\n            pass\n\n        assert self._options.keys() == self._messages.keys()\n\n    def connect_signals(self):\n        \"\"\"Connect related signals from the QWebEnginePage.\"\"\"\n        page = self._widget.page()\n        page.fullScreenRequested.connect(\n            self._on_fullscreen_requested)\n        page.featurePermissionRequested.connect(\n            self._on_feature_permission_requested)\n\n        if qtutils.version_check('5.11'):\n            page.quotaRequested.connect(\n                self._on_quota_requested)\n            page.registerProtocolHandlerRequested.connect(\n                self._on_register_protocol_handler_requested)\n\n    @pyqtSlot('QWebEngineFullScreenRequest')\n    def _on_fullscreen_requested(self, request):\n        request.accept()\n        on = request.toggleOn()\n\n        self._tab.data.fullscreen = on\n        self._tab.fullscreen_requested.emit(on)\n        if on:\n            notification = miscwidgets.FullscreenNotification(self._widget)\n            notification.show()\n            notification.set_timeout(3000)\n\n    @pyqtSlot(QUrl, 'QWebEnginePage::Feature')\n    def _on_feature_permission_requested(self, url, feature):\n        \"\"\"Ask the user for approval for geolocation/media/etc..\"\"\"\n        page = self._widget.page()\n\n        if feature not in self._options:\n            log.webview.error(\"Unhandled feature permission {}\".format(\n                debug.qenum_key(QWebEnginePage, feature)))\n            page.setFeaturePermission(url, feature,\n                                      QWebEnginePage.PermissionDeniedByUser)\n            return\n\n        yes_action = functools.partial(\n            page.setFeaturePermission, url, feature,\n            QWebEnginePage.PermissionGrantedByUser)\n        no_action = functools.partial(\n            page.setFeaturePermission, url, feature,\n            QWebEnginePage.PermissionDeniedByUser)\n\n        question = shared.feature_permission(\n            url=url.adjusted(QUrl.RemovePath),\n            option=self._options[feature], msg=self._messages[feature],\n            yes_action=yes_action, no_action=no_action,\n            abort_on=[self._tab.abort_questions])\n\n        if question is not None:\n            page.featurePermissionRequestCanceled.connect(\n                functools.partial(self._on_feature_permission_cancelled,\n                                  question, url, feature))\n\n    def _on_feature_permission_cancelled(self, question, url, feature,\n                                         cancelled_url, cancelled_feature):\n        \"\"\"Slot invoked when a feature permission request was cancelled.\n\n        To be used with functools.partial.\n        \"\"\"\n        if url == cancelled_url and feature == cancelled_feature:\n            try:\n                question.abort()\n            except RuntimeError:\n                # The question could already be deleted, e.g. because it was\n                # aborted after a loadStarted signal.\n                pass\n\n    def _on_quota_requested(self, request):\n        size = utils.format_size(request.requestedSize())\n        shared.feature_permission(\n            url=request.origin().adjusted(QUrl.RemovePath),\n            option='content.persistent_storage',\n            msg='use {} of persistent storage'.format(size),\n            yes_action=request.accept, no_action=request.reject,\n            abort_on=[self._tab.abort_questions],\n            blocking=True)\n\n    def _on_register_protocol_handler_requested(self, request):\n        shared.feature_permission(\n            url=request.origin().adjusted(QUrl.RemovePath),\n            option='content.register_protocol_handler',\n            msg='open all {} links'.format(request.scheme()),\n            yes_action=request.accept, no_action=request.reject,\n            abort_on=[self._tab.abort_questions],\n            blocking=True)\n\n\nclass _WebEngineScripts(QObject):\n\n    def __init__(self, tab, parent=None):\n        super().__init__(parent)\n        self._tab = tab\n        self._widget = None\n        self._greasemonkey = objreg.get('greasemonkey')\n\n    def connect_signals(self):\n        \"\"\"Connect signals to our private slots.\"\"\"\n        config.instance.changed.connect(self._on_config_changed)\n\n        self._tab.search.cleared.connect(functools.partial(\n            self._update_stylesheet, searching=False))\n        self._tab.search.finished.connect(self._update_stylesheet)\n\n    @pyqtSlot(str)\n    def _on_config_changed(self, option):\n        if option in ['scrolling.bar', 'content.user_stylesheets']:\n            self._init_stylesheet()\n            self._update_stylesheet()\n\n    @pyqtSlot(bool)\n    def _update_stylesheet(self, searching=False):\n        \"\"\"Update the custom stylesheet in existing tabs.\"\"\"\n        css = shared.get_user_stylesheet(searching=searching)\n        code = javascript.assemble('stylesheet', 'set_css', css)\n        self._tab.run_js_async(code)\n\n    def _inject_early_js(self, name, js_code, *,\n                         world=QWebEngineScript.ApplicationWorld,\n                         subframes=False):\n        \"\"\"Inject the given script to run early on a page load.\n\n        This runs the script both on DocumentCreation and DocumentReady as on\n        some internal pages, DocumentCreation will not work.\n\n        That is a WORKAROUND for https://bugreports.qt.io/browse/QTBUG-66011\n        \"\"\"\n        scripts = self._widget.page().scripts()\n        for injection in ['creation', 'ready']:\n            injection_points = {\n                'creation': QWebEngineScript.DocumentCreation,\n                'ready': QWebEngineScript.DocumentReady,\n            }\n            script = QWebEngineScript()\n            script.setInjectionPoint(injection_points[injection])\n            script.setSourceCode(js_code)\n            script.setWorldId(world)\n            script.setRunsOnSubFrames(subframes)\n            script.setName('_qute_{}_{}'.format(name, injection))\n            scripts.insert(script)\n\n    def _remove_early_js(self, name):\n        \"\"\"Remove an early QWebEngineScript.\"\"\"\n        scripts = self._widget.page().scripts()\n        for injection in ['creation', 'ready']:\n            full_name = '_qute_{}_{}'.format(name, injection)\n            script = scripts.findScript(full_name)\n            if not script.isNull():\n                scripts.remove(script)\n\n    def init(self):\n        \"\"\"Initialize global qutebrowser JavaScript.\"\"\"\n        js_code = javascript.wrap_global(\n            'scripts',\n            utils.read_file('javascript/scroll.js'),\n            utils.read_file('javascript/webelem.js'),\n            utils.read_file('javascript/caret.js'),\n        )\n        if not qtutils.version_check('5.12'):\n            # WORKAROUND for Qt versions < 5.12 not exposing window.print().\n            # Qt 5.12 has a printRequested() signal so we don't need this hack\n            # anymore.\n            self._inject_early_js('js',\n                                  utils.read_file('javascript/print.js'),\n                                  subframes=True,\n                                  world=QWebEngineScript.MainWorld)\n        # FIXME:qtwebengine what about subframes=True?\n        self._inject_early_js('js', js_code, subframes=True)\n        self._init_stylesheet()\n\n        # The Greasemonkey metadata block support in QtWebEngine only starts at\n        # Qt 5.8. With 5.7.1, we need to inject the scripts ourselves in\n        # response to urlChanged.\n        if not qtutils.version_check('5.8'):\n            self._tab.url_changed.connect(\n                self._inject_greasemonkey_scripts_for_url)\n        else:\n            self._greasemonkey.scripts_reloaded.connect(\n                self._inject_all_greasemonkey_scripts)\n            self._inject_all_greasemonkey_scripts()\n\n    def _init_stylesheet(self):\n        \"\"\"Initialize custom stylesheets.\n\n        Partially inspired by QupZilla:\n        https://github.com/QupZilla/qupzilla/blob/v2.0/src/lib/app/mainapplication.cpp#L1063-L1101\n        \"\"\"\n        self._remove_early_js('stylesheet')\n        css = shared.get_user_stylesheet()\n        js_code = javascript.wrap_global(\n            'stylesheet',\n            utils.read_file('javascript/stylesheet.js'),\n            javascript.assemble('stylesheet', 'set_css', css),\n        )\n        self._inject_early_js('stylesheet', js_code, subframes=True)\n\n    @pyqtSlot(QUrl)\n    def _inject_greasemonkey_scripts_for_url(self, url):\n        matching_scripts = self._greasemonkey.scripts_for(url)\n        self._inject_greasemonkey_scripts(\n            matching_scripts.start, QWebEngineScript.DocumentCreation, True)\n        self._inject_greasemonkey_scripts(\n            matching_scripts.end, QWebEngineScript.DocumentReady, False)\n        self._inject_greasemonkey_scripts(\n            matching_scripts.idle, QWebEngineScript.Deferred, False)\n\n    @pyqtSlot()\n    def _inject_all_greasemonkey_scripts(self):\n        scripts = self._greasemonkey.all_scripts()\n        self._inject_greasemonkey_scripts(scripts)\n\n    def _remove_all_greasemonkey_scripts(self):\n        page_scripts = self._widget.page().scripts()\n        for script in page_scripts.toList():\n            if script.name().startswith(\"GM-\"):\n                log.greasemonkey.debug('Removing script: {}'\n                                       .format(script.name()))\n                removed = page_scripts.remove(script)\n                assert removed, script.name()\n\n    def _inject_greasemonkey_scripts(self, scripts=None, injection_point=None,\n                                     remove_first=True):\n        \"\"\"Register user JavaScript files with the current tab.\n\n        Args:\n            scripts: A list of GreasemonkeyScripts, or None to add all\n                     known by the Greasemonkey subsystem.\n            injection_point: The QWebEngineScript::InjectionPoint stage\n                             to inject the script into, None to use\n                             auto-detection.\n            remove_first: Whether to remove all previously injected\n                          scripts before adding these ones.\n        \"\"\"\n        if sip.isdeleted(self._widget):\n            return\n\n        # Since we are inserting scripts into a per-tab collection,\n        # rather than just injecting scripts on page load, we need to\n        # make sure we replace existing scripts, not just add new ones.\n        # While, taking care not to remove any other scripts that might\n        # have been added elsewhere, like the one for stylesheets.\n        page_scripts = self._widget.page().scripts()\n        if remove_first:\n            self._remove_all_greasemonkey_scripts()\n\n        if not scripts:\n            return\n\n        for script in scripts:\n            new_script = QWebEngineScript()\n            try:\n                world = int(script.jsworld)\n                if not 0 <= world <= qtutils.MAX_WORLD_ID:\n                    log.greasemonkey.error(\n                        \"script {} has invalid value for '@qute-js-world'\"\n                        \": {}, should be between 0 and {}\"\n                        .format(\n                            script.name,\n                            script.jsworld,\n                            qtutils.MAX_WORLD_ID))\n                    continue\n            except ValueError:\n                try:\n                    world = _JS_WORLD_MAP[usertypes.JsWorld[\n                        script.jsworld.lower()]]\n                except KeyError:\n                    log.greasemonkey.error(\n                        \"script {} has invalid value for '@qute-js-world'\"\n                        \": {}\".format(script.name, script.jsworld))\n                    continue\n            new_script.setWorldId(world)\n            new_script.setSourceCode(script.code())\n            new_script.setName(\"GM-{}\".format(script.name))\n            new_script.setRunsOnSubFrames(script.runs_on_sub_frames)\n\n            # Override the @run-at value parsed by QWebEngineScript if desired.\n            if injection_point:\n                new_script.setInjectionPoint(injection_point)\n            elif script.needs_document_end_workaround():\n                log.greasemonkey.debug(\"Forcing @run-at document-end for {}\"\n                                       .format(script.name))\n                new_script.setInjectionPoint(QWebEngineScript.DocumentReady)\n\n            log.greasemonkey.debug('adding script: {}'\n                                   .format(new_script.name()))\n            page_scripts.insert(new_script)\n\n\nclass WebEngineTabPrivate(browsertab.AbstractTabPrivate):\n\n    \"\"\"QtWebEngine-related methods which aren't part of the public API.\"\"\"\n\n    def networkaccessmanager(self):\n        return None\n\n    def user_agent(self):\n        return None\n\n    def clear_ssl_errors(self):\n        raise browsertab.UnsupportedOperationError\n\n    def event_target(self):\n        return self._widget.render_widget()\n\n    def shutdown(self):\n        self._tab.shutting_down.emit()\n        self._tab.action.exit_fullscreen()\n        self._widget.shutdown()\n\n\nclass WebEngineTab(browsertab.AbstractTab):\n\n    \"\"\"A QtWebEngine tab in the browser.\n\n    Signals:\n        abort_questions: Emitted when a new load started or we're shutting\n            down.\n    \"\"\"\n\n    abort_questions = pyqtSignal()\n\n    def __init__(self, *, win_id, mode_manager, private, parent=None):\n        super().__init__(win_id=win_id, private=private, parent=parent)\n        widget = webview.WebEngineView(tabdata=self.data, win_id=win_id,\n                                       private=private)\n        self.history = WebEngineHistory(tab=self)\n        self.scroller = WebEngineScroller(tab=self, parent=self)\n        self.caret = WebEngineCaret(mode_manager=mode_manager,\n                                    tab=self, parent=self)\n        self.zoom = WebEngineZoom(tab=self, parent=self)\n        self.search = WebEngineSearch(tab=self, parent=self)\n        self.printing = WebEnginePrinting(tab=self)\n        self.elements = WebEngineElements(tab=self)\n        self.action = WebEngineAction(tab=self)\n        self.audio = WebEngineAudio(tab=self, parent=self)\n        self.private_api = WebEngineTabPrivate(mode_manager=mode_manager,\n                                               tab=self)\n        self._permissions = _WebEnginePermissions(tab=self, parent=self)\n        self._scripts = _WebEngineScripts(tab=self, parent=self)\n        # We're assigning settings in _set_widget\n        self.settings = webenginesettings.WebEngineSettings(settings=None)\n        self._set_widget(widget)\n        self._connect_signals()\n        self.backend = usertypes.Backend.QtWebEngine\n        self._child_event_filter = None\n        self._saved_zoom = None\n        self._reload_url = None\n        self._scripts.init()\n\n    def _set_widget(self, widget):\n        # pylint: disable=protected-access\n        super()._set_widget(widget)\n        self._permissions._widget = widget\n        self._scripts._widget = widget\n\n    def _install_event_filter(self):\n        fp = self._widget.focusProxy()\n        if fp is not None:\n            fp.installEventFilter(self._mouse_event_filter)\n        self._child_event_filter = mouse.ChildEventFilter(\n            eventfilter=self._mouse_event_filter, widget=self._widget,\n            win_id=self.win_id, parent=self)\n        self._widget.installEventFilter(self._child_event_filter)\n\n    @pyqtSlot()\n    def _restore_zoom(self):\n        if sip.isdeleted(self._widget):\n            # https://github.com/qutebrowser/qutebrowser/issues/3498\n            return\n        if self._saved_zoom is None:\n            return\n        self.zoom.set_factor(self._saved_zoom)\n        self._saved_zoom = None\n\n    def load_url(self, url, *, emit_before_load_started=True):\n        \"\"\"Load the given URL in this tab.\n\n        Arguments:\n            url: The QUrl to load.\n            emit_before_load_started: If set to False, before_load_started is\n                                      not emitted.\n        \"\"\"\n        if sip.isdeleted(self._widget):\n            # https://github.com/qutebrowser/qutebrowser/issues/3896\n            return\n        self._saved_zoom = self.zoom.factor()\n        self._load_url_prepare(\n            url, emit_before_load_started=emit_before_load_started)\n        self._widget.load(url)\n\n    def url(self, *, requested=False):\n        page = self._widget.page()\n        if requested:\n            return page.requestedUrl()\n        else:\n            return page.url()\n\n    def dump_async(self, callback, *, plain=False):\n        if plain:\n            self._widget.page().toPlainText(callback)\n        else:\n            self._widget.page().toHtml(callback)\n\n    def run_js_async(self, code, callback=None, *, world=None):\n        if world is None:\n            world_id = QWebEngineScript.ApplicationWorld\n        elif isinstance(world, int):\n            world_id = world\n            if not 0 <= world_id <= qtutils.MAX_WORLD_ID:\n                raise browsertab.WebTabError(\n                    \"World ID should be between 0 and {}\"\n                    .format(qtutils.MAX_WORLD_ID))\n        else:\n            world_id = _JS_WORLD_MAP[world]\n\n        if callback is None:\n            self._widget.page().runJavaScript(code, world_id)\n        else:\n            self._widget.page().runJavaScript(code, world_id, callback)\n\n    def reload(self, *, force=False):\n        if force:\n            action = QWebEnginePage.ReloadAndBypassCache\n        else:\n            action = QWebEnginePage.Reload\n        self._widget.triggerPageAction(action)\n\n    def stop(self):\n        self._widget.stop()\n\n    def title(self):\n        return self._widget.title()\n\n    def icon(self):\n        return self._widget.icon()\n\n    def set_html(self, html, base_url=QUrl()):\n        # FIXME:qtwebengine\n        # check this and raise an exception if too big:\n        # Warning: The content will be percent encoded before being sent to the\n        # renderer via IPC. This may increase its size. The maximum size of the\n        # percent encoded content is 2 megabytes minus 30 bytes.\n        self._widget.setHtml(html, base_url)\n\n    def _show_error_page(self, url, error):\n        \"\"\"Show an error page in the tab.\"\"\"\n        log.misc.debug(\"Showing error page for {}\".format(error))\n        url_string = url.toDisplayString()\n        error_page = jinja.render(\n            'error.html',\n            title=\"Error loading page: {}\".format(url_string),\n            url=url_string, error=error)\n        self.set_html(error_page)\n\n    @pyqtSlot()\n    def _on_history_trigger(self):\n        try:\n            self._widget.page()\n        except RuntimeError:\n            # Looks like this slot can be triggered on destroyed tabs:\n            # https://crashes.qutebrowser.org/view/3abffbed (Qt 5.9.1)\n            # wrapped C/C++ object of type WebEngineView has been deleted\n            log.misc.debug(\"Ignoring history trigger for destroyed tab\")\n            return\n\n        url = self.url()\n        requested_url = self.url(requested=True)\n\n        # Don't save the title if it's generated from the URL\n        title = self.title()\n        title_url = QUrl(url)\n        title_url.setScheme('')\n        if title == title_url.toDisplayString(QUrl.RemoveScheme).strip('/'):\n            title = \"\"\n\n        # Don't add history entry if the URL is invalid anyways\n        if not url.isValid():\n            log.misc.debug(\"Ignoring invalid URL being added to history\")\n            return\n\n        self.history_item_triggered.emit(url, requested_url, title)\n\n    @pyqtSlot(QUrl, 'QAuthenticator*', 'QString')\n    def _on_proxy_authentication_required(self, url, authenticator,\n                                          proxy_host):\n        \"\"\"Called when a proxy needs authentication.\"\"\"\n        msg = \"<b>{}</b> requires a username and password.\".format(\n            html_utils.escape(proxy_host))\n        urlstr = url.toString(QUrl.RemovePassword | QUrl.FullyEncoded)\n        answer = message.ask(\n            title=\"Proxy authentication required\", text=msg,\n            mode=usertypes.PromptMode.user_pwd,\n            abort_on=[self.abort_questions], url=urlstr)\n        if answer is not None:\n            authenticator.setUser(answer.user)\n            authenticator.setPassword(answer.password)\n        else:\n            try:\n                sip.assign(authenticator, QAuthenticator())\n            except AttributeError:\n                self._show_error_page(url, \"Proxy authentication required\")\n\n    @pyqtSlot(QUrl, 'QAuthenticator*')\n    def _on_authentication_required(self, url, authenticator):\n        log.network.debug(\"Authentication requested for {}, netrc_used {}\"\n                          .format(url.toDisplayString(), self.data.netrc_used))\n\n        netrc_success = False\n        if not self.data.netrc_used:\n            self.data.netrc_used = True\n            netrc_success = shared.netrc_authentication(url, authenticator)\n\n        if not netrc_success:\n            log.network.debug(\"Asking for credentials\")\n            answer = shared.authentication_required(\n                url, authenticator, abort_on=[self.abort_questions])\n        if not netrc_success and answer is None:\n            log.network.debug(\"Aborting auth\")\n            try:\n                sip.assign(authenticator, QAuthenticator())\n            except AttributeError:\n                # WORKAROUND for\n                # https://www.riverbankcomputing.com/pipermail/pyqt/2016-December/038400.html\n                self._show_error_page(url, \"Authentication required\")\n\n    @pyqtSlot()\n    def _on_load_started(self):\n        \"\"\"Clear search when a new load is started if needed.\"\"\"\n        # WORKAROUND for\n        # https://bugreports.qt.io/browse/QTBUG-61506\n        # (seems to be back in later Qt versions as well)\n        self.search.clear()\n        super()._on_load_started()\n        self.data.netrc_used = False\n\n    @pyqtSlot(QWebEnginePage.RenderProcessTerminationStatus, int)\n    def _on_render_process_terminated(self, status, exitcode):\n        \"\"\"Show an error when the renderer process terminated.\"\"\"\n        if (status == QWebEnginePage.AbnormalTerminationStatus and\n                exitcode == 256):\n            # WORKAROUND for https://bugreports.qt.io/browse/QTBUG-58697\n            status = QWebEnginePage.CrashedTerminationStatus\n\n        status_map = {\n            QWebEnginePage.NormalTerminationStatus:\n                browsertab.TerminationStatus.normal,\n            QWebEnginePage.AbnormalTerminationStatus:\n                browsertab.TerminationStatus.abnormal,\n            QWebEnginePage.CrashedTerminationStatus:\n                browsertab.TerminationStatus.crashed,\n            QWebEnginePage.KilledTerminationStatus:\n                browsertab.TerminationStatus.killed,\n            -1:\n                browsertab.TerminationStatus.unknown,\n        }\n        self.renderer_process_terminated.emit(status_map[status], exitcode)\n\n    def _error_page_workaround(self, html):\n        \"\"\"Check if we're displaying a Chromium error page.\n\n        This gets only called if we got loadFinished(False) without JavaScript,\n        so we can display at least some error page.\n\n        WORKAROUND for https://bugreports.qt.io/browse/QTBUG-66643\n        Needs to check the page content as a WORKAROUND for\n        https://bugreports.qt.io/browse/QTBUG-66661\n        \"\"\"\n        match = re.search(r'\"errorCode\":\"([^\"]*)\"', html)\n        if match is None:\n            return\n        self._show_error_page(self.url(), error=match.group(1))\n\n    @pyqtSlot(int)\n    def _on_load_progress(self, perc: int) -> None:\n        \"\"\"QtWebEngine-specific loadProgress workarounds.\n\n        WORKAROUND for https://bugreports.qt.io/browse/QTBUG-65223\n        \"\"\"\n        super()._on_load_progress(perc)\n        if (perc == 100 and\n                qtutils.version_check('5.10', compiled=False) and\n                self.load_status() != usertypes.LoadStatus.error):\n            self._update_load_status(ok=True)\n\n    @pyqtSlot(bool)\n    def _on_load_finished(self, ok: bool) -> None:\n        \"\"\"QtWebEngine-specific loadFinished workarounds.\"\"\"\n        super()._on_load_finished(ok)\n\n        # WORKAROUND for https://bugreports.qt.io/browse/QTBUG-65223\n        if qtutils.version_check('5.10', compiled=False):\n            if not ok:\n                self._update_load_status(ok)\n        else:\n            self._update_load_status(ok)\n\n        js_enabled = self.settings.test_attribute('content.javascript.enabled')\n        if not ok and not js_enabled:\n            self.dump_async(self._error_page_workaround)\n\n        if ok and self._reload_url is not None:\n            # WORKAROUND for https://bugreports.qt.io/browse/QTBUG-66656\n            log.config.debug(\n                \"Loading {} again because of config change\".format(\n                    self._reload_url.toDisplayString()))\n            QTimer.singleShot(100, functools.partial(\n                self.load_url, self._reload_url,\n                emit_before_load_started=False))\n            self._reload_url = None\n\n    @pyqtSlot(certificateerror.CertificateErrorWrapper)\n    def _on_ssl_errors(self, error):\n        self._has_ssl_errors = True\n\n        url = error.url()\n        log.webview.debug(\"Certificate error: {}\".format(error))\n\n        if error.is_overridable():\n            error.ignore = shared.ignore_certificate_errors(\n                url, [error], abort_on=[self.abort_questions])\n        else:\n            log.webview.error(\"Non-overridable certificate error: \"\n                              \"{}\".format(error))\n\n        log.webview.debug(\"ignore {}, URL {}, requested {}\".format(\n            error.ignore, url, self.url(requested=True)))\n\n        # WORKAROUND for https://bugreports.qt.io/browse/QTBUG-56207\n        # We can't really know when to show an error page, as the error might\n        # have happened when loading some resource.\n        # However, self.url() is not available yet and the requested URL\n        # might not match the URL we get from the error - so we just apply a\n        # heuristic here.\n        if (not qtutils.version_check('5.9') and\n                not error.ignore and\n                url.matches(self.url(requested=True), QUrl.RemoveScheme)):\n            self._show_error_page(url, str(error))\n\n    @pyqtSlot(QUrl)\n    def _on_before_load_started(self, url):\n        \"\"\"If we know we're going to visit a URL soon, change the settings.\n\n        This is a WORKAROUND for https://bugreports.qt.io/browse/QTBUG-66656\n        \"\"\"\n        super()._on_before_load_started(url)\n        if not qtutils.version_check('5.11.1', compiled=False):\n            self.settings.update_for_url(url)\n\n    @pyqtSlot()\n    def _on_print_requested(self):\n        \"\"\"Slot for window.print() in JS.\"\"\"\n        try:\n            self.printing.show_dialog()\n        except browsertab.WebTabError as e:\n            message.error(str(e))\n\n    @pyqtSlot(usertypes.NavigationRequest)\n    def _on_navigation_request(self, navigation):\n        super()._on_navigation_request(navigation)\n\n        if navigation.url == QUrl('qute://print'):\n            self._on_print_requested()\n            navigation.accepted = False\n\n        if not navigation.accepted or not navigation.is_main_frame:\n            return\n\n        settings_needing_reload = {\n            'content.plugins',\n            'content.javascript.enabled',\n            'content.javascript.can_access_clipboard',\n            'content.print_element_backgrounds',\n            'input.spatial_navigation',\n        }\n        assert settings_needing_reload.issubset(configdata.DATA)\n\n        changed = self.settings.update_for_url(navigation.url)\n        reload_needed = changed & settings_needing_reload\n\n        # On Qt < 5.11, we don't don't need a reload when type == link_clicked.\n        # On Qt 5.11.0, we always need a reload.\n        # On Qt > 5.11.0, we never need a reload:\n        # https://codereview.qt-project.org/#/c/229525/1\n        # WORKAROUND for https://bugreports.qt.io/browse/QTBUG-66656\n        if qtutils.version_check('5.11.1', compiled=False):\n            reload_needed = False\n        elif not qtutils.version_check('5.11.0', exact=True, compiled=False):\n            if navigation.navigation_type == navigation.Type.link_clicked:\n                reload_needed = False\n\n        if reload_needed:\n            self._reload_url = navigation.url\n\n    def _on_select_client_certificate(self, selection):\n        \"\"\"Handle client certificates.\n\n        Currently, we simply pick the first available certificate and show an\n        additional note if there are multiple matches.\n        \"\"\"\n        certificate = selection.certificates()[0]\n        text = ('<b>Subject:</b> {subj}<br/>'\n                '<b>Issuer:</b> {issuer}<br/>'\n                '<b>Serial:</b> {serial}'.format(\n                    subj=html_utils.escape(certificate.subjectDisplayName()),\n                    issuer=html_utils.escape(certificate.issuerDisplayName()),\n                    serial=bytes(certificate.serialNumber()).decode('ascii')))\n        if len(selection.certificates()) > 1:\n            text += ('<br/><br/><b>Note:</b> Multiple matching certificates '\n                     'were found, but certificate selection is not '\n                     'implemented yet!')\n        urlstr = selection.host().host()\n\n        present = message.ask(\n            title='Present client certificate to {}?'.format(urlstr),\n            text=text,\n            mode=usertypes.PromptMode.yesno,\n            abort_on=[self.abort_questions],\n            url=urlstr)\n\n        if present:\n            selection.select(certificate)\n        else:\n            selection.selectNone()\n\n    def _connect_signals(self):\n        view = self._widget\n        page = view.page()\n\n        page.windowCloseRequested.connect(self.window_close_requested)\n        page.linkHovered.connect(self.link_hovered)\n        page.loadProgress.connect(self._on_load_progress)\n        page.loadStarted.connect(self._on_load_started)\n        page.certificate_error.connect(self._on_ssl_errors)\n        page.authenticationRequired.connect(self._on_authentication_required)\n        page.proxyAuthenticationRequired.connect(\n            self._on_proxy_authentication_required)\n        page.contentsSizeChanged.connect(self.contents_size_changed)\n        page.navigation_request.connect(self._on_navigation_request)\n\n        if qtutils.version_check('5.12'):\n            page.printRequested.connect(self._on_print_requested)\n\n        try:\n            # pylint: disable=unused-import\n            from PyQt5.QtWebEngineWidgets import (\n                QWebEngineClientCertificateSelection)\n        except ImportError:\n            pass\n        else:\n            page.selectClientCertificate.connect(\n                self._on_select_client_certificate)\n\n        view.titleChanged.connect(self.title_changed)\n        view.urlChanged.connect(self._on_url_changed)\n        view.renderProcessTerminated.connect(\n            self._on_render_process_terminated)\n        view.iconChanged.connect(self.icon_changed)\n\n        page.loadFinished.connect(self._on_history_trigger)\n        page.loadFinished.connect(self._restore_zoom)\n        page.loadFinished.connect(self._on_load_finished)\n\n        self.before_load_started.connect(self._on_before_load_started)\n        self.shutting_down.connect(self.abort_questions)\n        self.load_started.connect(self.abort_questions)\n\n        # pylint: disable=protected-access\n        self.audio._connect_signals()\n        self._permissions.connect_signals()\n        self._scripts.connect_signals()\n", "target": 1}
{"idx": 880, "func": "#!/usr/bin/python\n# -*- coding: utf-8 -*-\n\n# Copyright: (c) 2019, Patrick Pichler <ppichler+ansible@mgit.at>\n# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)\n\nfrom __future__ import absolute_import, division, print_function\n__metaclass__ = type\n\n\nDOCUMENTATION = r'''\n---\nmodule: openssl_signature\nversion_added: 1.1.0\nshort_description: Sign data with openssl\ndescription:\n    - This module allows one to sign data using a private key.\n    - The module can use the cryptography Python library, or the pyOpenSSL Python\n      library. By default, it tries to detect which one is available. This can be\n      overridden with the I(select_crypto_backend) option. Please note that the PyOpenSSL backend\n      was deprecated in Ansible 2.9 and will be removed in community.crypto 2.0.0.\nrequirements:\n    - Either cryptography >= 1.4 (some key types require newer versions)\n    - Or pyOpenSSL >= 0.11 (Ed25519 and Ed448 keys are not supported with this backend)\nauthor:\n    - Patrick Pichler (@aveexy)\n    - Markus Teufelberger (@MarkusTeufelberger)\noptions:\n    privatekey_path:\n        description:\n            - The path to the private key to use when signing.\n            - Either I(privatekey_path) or I(privatekey_content) must be specified, but not both.\n        type: path\n    privatekey_content:\n        description:\n            - The content of the private key to use when signing the certificate signing request.\n            - Either I(privatekey_path) or I(privatekey_content) must be specified, but not both.\n        type: str\n    privatekey_passphrase:\n        description:\n            - The passphrase for the private key.\n            - This is required if the private key is password protected.\n        type: str\n    path:\n        description:\n            - The file to sign.\n            - This file will only be read and not modified.\n        type: path\n        required: true\n    select_crypto_backend:\n        description:\n            - Determines which crypto backend to use.\n            - The default choice is C(auto), which tries to use C(cryptography) if available, and falls back to C(pyopenssl).\n            - If set to C(pyopenssl), will try to use the L(pyOpenSSL,https://pypi.org/project/pyOpenSSL/) library.\n            - If set to C(cryptography), will try to use the L(cryptography,https://cryptography.io/) library.\n        type: str\n        default: auto\n        choices: [ auto, cryptography, pyopenssl ]\nnotes:\n    - |\n      When using the C(cryptography) backend, the following key types require at least the following C(cryptography) version:\n      RSA keys: C(cryptography) >= 1.4\n      DSA and ECDSA keys: C(cryptography) >= 1.5\n      ed448 and ed25519 keys: C(cryptography) >= 2.6\nseealso:\n    - module: community.crypto.openssl_signature_info\n    - module: community.crypto.openssl_privatekey\n'''\n\nEXAMPLES = r'''\n- name: Sign example file\n  community.crypto.openssl_signature:\n    privatekey_path: private.key\n    path: /tmp/example_file\n  register: sig\n\n- name: Verify signature of example file\n  community.crypto.openssl_signature_info:\n    certificate_path: cert.pem\n    path: /tmp/example_file\n    signature: \"{{ sig.signature }}\"\n  register: verify\n\n- name: Make sure the signature is valid\n  assert:\n    that:\n      - verify.valid\n'''\n\nRETURN = r'''\nsignature:\n    description: Base64 encoded signature.\n    returned: success\n    type: str\n'''\n\nimport os\nimport traceback\nfrom distutils.version import LooseVersion\nimport base64\n\nMINIMAL_PYOPENSSL_VERSION = '0.11'\nMINIMAL_CRYPTOGRAPHY_VERSION = '1.4'\n\nPYOPENSSL_IMP_ERR = None\ntry:\n    import OpenSSL\n    from OpenSSL import crypto\n    PYOPENSSL_VERSION = LooseVersion(OpenSSL.__version__)\nexcept ImportError:\n    PYOPENSSL_IMP_ERR = traceback.format_exc()\n    PYOPENSSL_FOUND = False\nelse:\n    PYOPENSSL_FOUND = True\n\nCRYPTOGRAPHY_IMP_ERR = None\ntry:\n    import cryptography\n    import cryptography.hazmat.primitives.asymmetric.padding\n    import cryptography.hazmat.primitives.hashes\n    CRYPTOGRAPHY_VERSION = LooseVersion(cryptography.__version__)\nexcept ImportError:\n    CRYPTOGRAPHY_IMP_ERR = traceback.format_exc()\n    CRYPTOGRAPHY_FOUND = False\nelse:\n    CRYPTOGRAPHY_FOUND = True\n\nfrom ansible_collections.community.crypto.plugins.module_utils.crypto.basic import (\n    CRYPTOGRAPHY_HAS_DSA_SIGN,\n    CRYPTOGRAPHY_HAS_EC_SIGN,\n    CRYPTOGRAPHY_HAS_ED25519_SIGN,\n    CRYPTOGRAPHY_HAS_ED448_SIGN,\n    CRYPTOGRAPHY_HAS_RSA_SIGN,\n    OpenSSLObjectError,\n)\n\nfrom ansible_collections.community.crypto.plugins.module_utils.crypto.support import (\n    OpenSSLObject,\n    load_privatekey,\n)\n\nfrom ansible.module_utils._text import to_native, to_bytes\nfrom ansible.module_utils.basic import AnsibleModule, missing_required_lib\n\n\nclass SignatureBase(OpenSSLObject):\n\n    def __init__(self, module, backend):\n        super(SignatureBase, self).__init__(\n            path=module.params['path'],\n            state='present',\n            force=False,\n            check_mode=module.check_mode\n        )\n\n        self.backend = backend\n\n        self.privatekey_path = module.params['privatekey_path']\n        self.privatekey_content = module.params['privatekey_content']\n        if self.privatekey_content is not None:\n            self.privatekey_content = self.privatekey_content.encode('utf-8')\n        self.privatekey_passphrase = module.params['privatekey_passphrase']\n\n    def generate(self):\n        # Empty method because OpenSSLObject wants this\n        pass\n\n    def dump(self):\n        # Empty method because OpenSSLObject wants this\n        pass\n\n\n# Implementation with using pyOpenSSL\nclass SignaturePyOpenSSL(SignatureBase):\n\n    def __init__(self, module, backend):\n        super(SignaturePyOpenSSL, self).__init__(module, backend)\n\n    def run(self):\n\n        result = dict()\n\n        try:\n            with open(self.path, \"rb\") as f:\n                _in = f.read()\n\n            private_key = load_privatekey(\n                path=self.privatekey_path,\n                content=self.privatekey_content,\n                passphrase=self.privatekey_passphrase,\n                backend=self.backend,\n            )\n\n            signature = OpenSSL.crypto.sign(private_key, _in, \"sha256\")\n            result['signature'] = base64.b64encode(signature)\n            return result\n        except Exception as e:\n            raise OpenSSLObjectError(e)\n\n\n# Implementation with using cryptography\nclass SignatureCryptography(SignatureBase):\n\n    def __init__(self, module, backend):\n        super(SignatureCryptography, self).__init__(module, backend)\n\n    def run(self):\n        _padding = cryptography.hazmat.primitives.asymmetric.padding.PKCS1v15()\n        _hash = cryptography.hazmat.primitives.hashes.SHA256()\n\n        result = dict()\n\n        try:\n            with open(self.path, \"rb\") as f:\n                _in = f.read()\n\n            private_key = load_privatekey(\n                path=self.privatekey_path,\n                content=self.privatekey_content,\n                passphrase=self.privatekey_passphrase,\n                backend=self.backend,\n            )\n\n            signature = None\n\n            if CRYPTOGRAPHY_HAS_DSA_SIGN:\n                if isinstance(private_key, cryptography.hazmat.primitives.asymmetric.dsa.DSAPrivateKey):\n                    signature = private_key.sign(_in, _hash)\n\n            if CRYPTOGRAPHY_HAS_EC_SIGN:\n                if isinstance(private_key, cryptography.hazmat.primitives.asymmetric.ec.EllipticCurvePrivateKey):\n                    signature = private_key.sign(_in, cryptography.hazmat.primitives.asymmetric.ec.ECDSA(_hash))\n\n            if CRYPTOGRAPHY_HAS_ED25519_SIGN:\n                if isinstance(private_key, cryptography.hazmat.primitives.asymmetric.ed25519.Ed25519PrivateKey):\n                    signature = private_key.sign(_in)\n\n            if CRYPTOGRAPHY_HAS_ED448_SIGN:\n                if isinstance(private_key, cryptography.hazmat.primitives.asymmetric.ed448.Ed448PrivateKey):\n                    signature = private_key.sign(_in)\n\n            if CRYPTOGRAPHY_HAS_RSA_SIGN:\n                if isinstance(private_key, cryptography.hazmat.primitives.asymmetric.rsa.RSAPrivateKey):\n                    signature = private_key.sign(_in, _padding, _hash)\n\n            if signature is None:\n                self.module.fail_json(\n                    msg=\"Unsupported key type. Your cryptography version is {0}\".format(CRYPTOGRAPHY_VERSION)\n                )\n\n            result['signature'] = base64.b64encode(signature)\n            return result\n\n        except Exception as e:\n            raise OpenSSLObjectError(e)\n\n\ndef main():\n    module = AnsibleModule(\n        argument_spec=dict(\n            privatekey_path=dict(type='path'),\n            privatekey_content=dict(type='str', no_log=True),\n            privatekey_passphrase=dict(type='str', no_log=True),\n            path=dict(type='path', required=True),\n            select_crypto_backend=dict(type='str', choices=['auto', 'pyopenssl', 'cryptography'], default='auto'),\n        ),\n        mutually_exclusive=(\n            ['privatekey_path', 'privatekey_content'],\n        ),\n        required_one_of=(\n            ['privatekey_path', 'privatekey_content'],\n        ),\n        supports_check_mode=True,\n    )\n\n    if not os.path.isfile(module.params['path']):\n        module.fail_json(\n            name=module.params['path'],\n            msg='The file {0} does not exist'.format(module.params['path'])\n        )\n\n    backend = module.params['select_crypto_backend']\n    if backend == 'auto':\n        # Detection what is possible\n        can_use_cryptography = CRYPTOGRAPHY_FOUND and CRYPTOGRAPHY_VERSION >= LooseVersion(MINIMAL_CRYPTOGRAPHY_VERSION)\n        can_use_pyopenssl = PYOPENSSL_FOUND and PYOPENSSL_VERSION >= LooseVersion(MINIMAL_PYOPENSSL_VERSION)\n\n        # Decision\n        if can_use_cryptography:\n            backend = 'cryptography'\n        elif can_use_pyopenssl:\n            backend = 'pyopenssl'\n\n        # Success?\n        if backend == 'auto':\n            module.fail_json(msg=(\"Can't detect any of the required Python libraries \"\n                                  \"cryptography (>= {0}) or PyOpenSSL (>= {1})\").format(\n                MINIMAL_CRYPTOGRAPHY_VERSION,\n                MINIMAL_PYOPENSSL_VERSION))\n    try:\n        if backend == 'pyopenssl':\n            if not PYOPENSSL_FOUND:\n                module.fail_json(msg=missing_required_lib('pyOpenSSL >= {0}'.format(MINIMAL_PYOPENSSL_VERSION)),\n                                 exception=PYOPENSSL_IMP_ERR)\n            module.deprecate('The module is using the PyOpenSSL backend. This backend has been deprecated',\n                             version='2.0.0', collection_name='community.crypto')\n            _sign = SignaturePyOpenSSL(module, backend)\n        elif backend == 'cryptography':\n            if not CRYPTOGRAPHY_FOUND:\n                module.fail_json(msg=missing_required_lib('cryptography >= {0}'.format(MINIMAL_CRYPTOGRAPHY_VERSION)),\n                                 exception=CRYPTOGRAPHY_IMP_ERR)\n            _sign = SignatureCryptography(module, backend)\n\n        result = _sign.run()\n\n        module.exit_json(**result)\n    except OpenSSLObjectError as exc:\n        module.fail_json(msg=to_native(exc))\n\n\nif __name__ == '__main__':\n    main()\n", "target": 0}
{"idx": 881, "func": "import yaml\ntry:\n    from ansible.utils.vault import VaultLib\nexcept ImportError:\n    # Ansible 2.0 has changed the vault location\n    from ansible.parsing.vault import VaultLib\n\n\nclass Vault(object):\n    '''R/W an ansible-vault yaml file'''\n\n    def __init__(self, password):\n        self.password = password\n        self.vault = VaultLib(password)\n\n    def load(self, stream):\n        '''read vault steam and return python object'''\n        return yaml.safe_load(self.vault.decrypt(stream))\n\n    def dump(self, data, stream=None):\n        '''encrypt data and print stdout or write to stream'''\n        yaml_text = yaml.dump(\n            data,\n            default_flow_style=False,\n            allow_unicode=True)\n        encrypted = self.vault.encrypt(yaml_text)\n        if stream:\n            stream.write(encrypted)\n        else:\n            return encrypted\n", "target": 0}
{"idx": 882, "func": "# vim: ft=python fileencoding=utf-8 sts=4 sw=4 et:\n\n# Copyright 2016-2020 Florian Bruhin (The Compiler) <mail@qutebrowser.org>\n#\n# This file is part of qutebrowser.\n#\n# qutebrowser is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# qutebrowser is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with qutebrowser.  If not, see <http://www.gnu.org/licenses/>.\n\n\"\"\"Wrapper over our (QtWebKit) WebView.\"\"\"\n\nimport re\nimport functools\nimport xml.etree.ElementTree\n\nfrom PyQt5.QtCore import pyqtSlot, Qt, QUrl, QPoint, QTimer, QSizeF, QSize\nfrom PyQt5.QtGui import QIcon\nfrom PyQt5.QtWebKitWidgets import QWebPage, QWebFrame\nfrom PyQt5.QtWebKit import QWebSettings\nfrom PyQt5.QtPrintSupport import QPrinter\n\nfrom qutebrowser.browser import browsertab, shared\nfrom qutebrowser.browser.webkit import (webview, tabhistory, webkitelem,\n                                        webkitsettings)\nfrom qutebrowser.utils import qtutils, usertypes, utils, log, debug\nfrom qutebrowser.qt import sip\n\n\nclass WebKitAction(browsertab.AbstractAction):\n\n    \"\"\"QtWebKit implementations related to web actions.\"\"\"\n\n    action_class = QWebPage\n    action_base = QWebPage.WebAction\n\n    def exit_fullscreen(self):\n        raise browsertab.UnsupportedOperationError\n\n    def save_page(self):\n        \"\"\"Save the current page.\"\"\"\n        raise browsertab.UnsupportedOperationError\n\n    def show_source(self, pygments=False):\n        self._show_source_pygments()\n\n\nclass WebKitPrinting(browsertab.AbstractPrinting):\n\n    \"\"\"QtWebKit implementations related to printing.\"\"\"\n\n    def check_pdf_support(self):\n        pass\n\n    def check_printer_support(self):\n        pass\n\n    def check_preview_support(self):\n        pass\n\n    def to_pdf(self, filename):\n        printer = QPrinter()\n        printer.setOutputFileName(filename)\n        self.to_printer(printer)\n\n    def to_printer(self, printer, callback=None):\n        self._widget.print(printer)\n        # Can't find out whether there was an error...\n        if callback is not None:\n            callback(True)\n\n\nclass WebKitSearch(browsertab.AbstractSearch):\n\n    \"\"\"QtWebKit implementations related to searching on the page.\"\"\"\n\n    def __init__(self, tab, parent=None):\n        super().__init__(tab, parent)\n        self._flags = QWebPage.FindFlags(0)  # type: ignore\n\n    def _call_cb(self, callback, found, text, flags, caller):\n        \"\"\"Call the given callback if it's non-None.\n\n        Delays the call via a QTimer so the website is re-rendered in between.\n\n        Args:\n            callback: What to call\n            found: If the text was found\n            text: The text searched for\n            flags: The flags searched with\n            caller: Name of the caller.\n        \"\"\"\n        found_text = 'found' if found else \"didn't find\"\n        # Removing FindWrapsAroundDocument to get the same logging as with\n        # QtWebEngine\n        debug_flags = debug.qflags_key(\n            QWebPage, flags & ~QWebPage.FindWrapsAroundDocument,\n            klass=QWebPage.FindFlag)\n        if debug_flags != '0x0000':\n            flag_text = 'with flags {}'.format(debug_flags)\n        else:\n            flag_text = ''\n        log.webview.debug(' '.join([caller, found_text, text, flag_text])\n                          .strip())\n        if callback is not None:\n            QTimer.singleShot(0, functools.partial(callback, found))\n\n        self.finished.emit(found)\n\n    def clear(self):\n        if self.search_displayed:\n            self.cleared.emit()\n        self.search_displayed = False\n        # We first clear the marked text, then the highlights\n        self._widget.findText('')\n        self._widget.findText('', QWebPage.HighlightAllOccurrences)\n\n    def search(self, text, *, ignore_case=usertypes.IgnoreCase.never,\n               reverse=False, wrap=True, result_cb=None):\n        # Don't go to next entry on duplicate search\n        if self.text == text and self.search_displayed:\n            log.webview.debug(\"Ignoring duplicate search request\"\n                              \" for {}\".format(text))\n            return\n\n        # Clear old search results, this is done automatically on QtWebEngine.\n        self.clear()\n\n        self.text = text\n        self.search_displayed = True\n        self._flags = QWebPage.FindFlags(0)  # type: ignore\n        if self._is_case_sensitive(ignore_case):\n            self._flags |= QWebPage.FindCaseSensitively\n        if reverse:\n            self._flags |= QWebPage.FindBackward\n        if wrap:\n            self._flags |= QWebPage.FindWrapsAroundDocument\n        # We actually search *twice* - once to highlight everything, then again\n        # to get a mark so we can navigate.\n        found = self._widget.findText(text, self._flags)\n        self._widget.findText(text,\n                              self._flags | QWebPage.HighlightAllOccurrences)\n        self._call_cb(result_cb, found, text, self._flags, 'search')\n\n    def next_result(self, *, result_cb=None):\n        self.search_displayed = True\n        found = self._widget.findText(self.text, self._flags)\n        self._call_cb(result_cb, found, self.text, self._flags, 'next_result')\n\n    def prev_result(self, *, result_cb=None):\n        self.search_displayed = True\n        # The int() here makes sure we get a copy of the flags.\n        flags = QWebPage.FindFlags(int(self._flags))  # type: ignore\n        if flags & QWebPage.FindBackward:\n            flags &= ~QWebPage.FindBackward\n        else:\n            flags |= QWebPage.FindBackward\n        found = self._widget.findText(self.text, flags)\n        self._call_cb(result_cb, found, self.text, flags, 'prev_result')\n\n\nclass WebKitCaret(browsertab.AbstractCaret):\n\n    \"\"\"QtWebKit implementations related to moving the cursor/selection.\"\"\"\n\n    @pyqtSlot(usertypes.KeyMode)\n    def _on_mode_entered(self, mode):\n        if mode != usertypes.KeyMode.caret:\n            return\n\n        self.selection_enabled = self._widget.hasSelection()\n        self.selection_toggled.emit(self.selection_enabled)\n        settings = self._widget.settings()\n        settings.setAttribute(QWebSettings.CaretBrowsingEnabled, True)\n\n        if self._widget.isVisible():\n            # Sometimes the caret isn't immediately visible, but unfocusing\n            # and refocusing it fixes that.\n            self._widget.clearFocus()\n            self._widget.setFocus(Qt.OtherFocusReason)\n\n            # Move the caret to the first element in the viewport if there\n            # isn't any text which is already selected.\n            #\n            # Note: We can't use hasSelection() here, as that's always\n            # true in caret mode.\n            if not self.selection_enabled:\n                self._widget.page().currentFrame().evaluateJavaScript(\n                    utils.read_file('javascript/position_caret.js'))\n\n    @pyqtSlot(usertypes.KeyMode)\n    def _on_mode_left(self, _mode):\n        settings = self._widget.settings()\n        if settings.testAttribute(QWebSettings.CaretBrowsingEnabled):\n            if self.selection_enabled and self._widget.hasSelection():\n                # Remove selection if it exists\n                self._widget.triggerPageAction(QWebPage.MoveToNextChar)\n            settings.setAttribute(QWebSettings.CaretBrowsingEnabled, False)\n            self.selection_enabled = False\n\n    def move_to_next_line(self, count=1):\n        if not self.selection_enabled:\n            act = QWebPage.MoveToNextLine\n        else:\n            act = QWebPage.SelectNextLine\n        for _ in range(count):\n            self._widget.triggerPageAction(act)\n\n    def move_to_prev_line(self, count=1):\n        if not self.selection_enabled:\n            act = QWebPage.MoveToPreviousLine\n        else:\n            act = QWebPage.SelectPreviousLine\n        for _ in range(count):\n            self._widget.triggerPageAction(act)\n\n    def move_to_next_char(self, count=1):\n        if not self.selection_enabled:\n            act = QWebPage.MoveToNextChar\n        else:\n            act = QWebPage.SelectNextChar\n        for _ in range(count):\n            self._widget.triggerPageAction(act)\n\n    def move_to_prev_char(self, count=1):\n        if not self.selection_enabled:\n            act = QWebPage.MoveToPreviousChar\n        else:\n            act = QWebPage.SelectPreviousChar\n        for _ in range(count):\n            self._widget.triggerPageAction(act)\n\n    def move_to_end_of_word(self, count=1):\n        if not self.selection_enabled:\n            act = [QWebPage.MoveToNextWord]\n            if utils.is_windows:  # pragma: no cover\n                act.append(QWebPage.MoveToPreviousChar)\n        else:\n            act = [QWebPage.SelectNextWord]\n            if utils.is_windows:  # pragma: no cover\n                act.append(QWebPage.SelectPreviousChar)\n        for _ in range(count):\n            for a in act:\n                self._widget.triggerPageAction(a)\n\n    def move_to_next_word(self, count=1):\n        if not self.selection_enabled:\n            act = [QWebPage.MoveToNextWord]\n            if not utils.is_windows:  # pragma: no branch\n                act.append(QWebPage.MoveToNextChar)\n        else:\n            act = [QWebPage.SelectNextWord]\n            if not utils.is_windows:  # pragma: no branch\n                act.append(QWebPage.SelectNextChar)\n        for _ in range(count):\n            for a in act:\n                self._widget.triggerPageAction(a)\n\n    def move_to_prev_word(self, count=1):\n        if not self.selection_enabled:\n            act = QWebPage.MoveToPreviousWord\n        else:\n            act = QWebPage.SelectPreviousWord\n        for _ in range(count):\n            self._widget.triggerPageAction(act)\n\n    def move_to_start_of_line(self):\n        if not self.selection_enabled:\n            act = QWebPage.MoveToStartOfLine\n        else:\n            act = QWebPage.SelectStartOfLine\n        self._widget.triggerPageAction(act)\n\n    def move_to_end_of_line(self):\n        if not self.selection_enabled:\n            act = QWebPage.MoveToEndOfLine\n        else:\n            act = QWebPage.SelectEndOfLine\n        self._widget.triggerPageAction(act)\n\n    def move_to_start_of_next_block(self, count=1):\n        if not self.selection_enabled:\n            act = [QWebPage.MoveToNextLine,\n                   QWebPage.MoveToStartOfBlock]\n        else:\n            act = [QWebPage.SelectNextLine,\n                   QWebPage.SelectStartOfBlock]\n        for _ in range(count):\n            for a in act:\n                self._widget.triggerPageAction(a)\n\n    def move_to_start_of_prev_block(self, count=1):\n        if not self.selection_enabled:\n            act = [QWebPage.MoveToPreviousLine,\n                   QWebPage.MoveToStartOfBlock]\n        else:\n            act = [QWebPage.SelectPreviousLine,\n                   QWebPage.SelectStartOfBlock]\n        for _ in range(count):\n            for a in act:\n                self._widget.triggerPageAction(a)\n\n    def move_to_end_of_next_block(self, count=1):\n        if not self.selection_enabled:\n            act = [QWebPage.MoveToNextLine,\n                   QWebPage.MoveToEndOfBlock]\n        else:\n            act = [QWebPage.SelectNextLine,\n                   QWebPage.SelectEndOfBlock]\n        for _ in range(count):\n            for a in act:\n                self._widget.triggerPageAction(a)\n\n    def move_to_end_of_prev_block(self, count=1):\n        if not self.selection_enabled:\n            act = [QWebPage.MoveToPreviousLine, QWebPage.MoveToEndOfBlock]\n        else:\n            act = [QWebPage.SelectPreviousLine, QWebPage.SelectEndOfBlock]\n        for _ in range(count):\n            for a in act:\n                self._widget.triggerPageAction(a)\n\n    def move_to_start_of_document(self):\n        if not self.selection_enabled:\n            act = QWebPage.MoveToStartOfDocument\n        else:\n            act = QWebPage.SelectStartOfDocument\n        self._widget.triggerPageAction(act)\n\n    def move_to_end_of_document(self):\n        if not self.selection_enabled:\n            act = QWebPage.MoveToEndOfDocument\n        else:\n            act = QWebPage.SelectEndOfDocument\n        self._widget.triggerPageAction(act)\n\n    def toggle_selection(self):\n        self.selection_enabled = not self.selection_enabled\n        self.selection_toggled.emit(self.selection_enabled)\n\n    def drop_selection(self):\n        self._widget.triggerPageAction(QWebPage.MoveToNextChar)\n\n    def selection(self, callback):\n        callback(self._widget.selectedText())\n\n    def reverse_selection(self):\n        self._tab.run_js_async(\"\"\"{\n            const sel = window.getSelection();\n            sel.setBaseAndExtent(\n                sel.extentNode, sel.extentOffset, sel.baseNode,\n                sel.baseOffset\n            );\n        }\"\"\")\n\n    def _follow_selected(self, *, tab=False):\n        if QWebSettings.globalSettings().testAttribute(\n                QWebSettings.JavascriptEnabled):\n            if tab:\n                self._tab.data.override_target = usertypes.ClickTarget.tab\n            self._tab.run_js_async(\"\"\"\n                const aElm = document.activeElement;\n                if (window.getSelection().anchorNode) {\n                    window.getSelection().anchorNode.parentNode.click();\n                } else if (aElm && aElm !== document.body) {\n                    aElm.click();\n                }\n            \"\"\")\n        else:\n            selection = self._widget.selectedHtml()\n            if not selection:\n                # Getting here may mean we crashed, but we can't do anything\n                # about that until this commit is released:\n                # https://github.com/annulen/webkit/commit/0e75f3272d149bc64899c161f150eb341a2417af\n                # TODO find a way to check if something is focused\n                self._follow_enter(tab)\n                return\n            try:\n                selected_element = xml.etree.ElementTree.fromstring(\n                    '<html>{}</html>'.format(selection)).find('a')\n            except xml.etree.ElementTree.ParseError:\n                raise browsertab.WebTabError('Could not parse selected '\n                                             'element!')\n\n            if selected_element is not None:\n                try:\n                    url = selected_element.attrib['href']\n                except KeyError:\n                    raise browsertab.WebTabError('Anchor element without '\n                                                 'href!')\n                url = self._tab.url().resolved(QUrl(url))\n                if tab:\n                    self._tab.new_tab_requested.emit(url)\n                else:\n                    self._tab.load_url(url)\n\n    def follow_selected(self, *, tab=False):\n        try:\n            self._follow_selected(tab=tab)\n        finally:\n            self.follow_selected_done.emit()\n\n\nclass WebKitZoom(browsertab.AbstractZoom):\n\n    \"\"\"QtWebKit implementations related to zooming.\"\"\"\n\n    def _set_factor_internal(self, factor):\n        self._widget.setZoomFactor(factor)\n\n\nclass WebKitScroller(browsertab.AbstractScroller):\n\n    \"\"\"QtWebKit implementations related to scrolling.\"\"\"\n\n    # FIXME:qtwebengine When to use the main frame, when the current one?\n\n    def pos_px(self):\n        return self._widget.page().mainFrame().scrollPosition()\n\n    def pos_perc(self):\n        return self._widget.scroll_pos\n\n    def to_point(self, point):\n        self._widget.page().mainFrame().setScrollPosition(point)\n\n    def to_anchor(self, name):\n        self._widget.page().mainFrame().scrollToAnchor(name)\n\n    def delta(self, x: int = 0, y: int = 0) -> None:\n        qtutils.check_overflow(x, 'int')\n        qtutils.check_overflow(y, 'int')\n        self._widget.page().mainFrame().scroll(x, y)\n\n    def delta_page(self, x: float = 0.0, y: float = 0.0) -> None:\n        if y.is_integer():\n            y = int(y)\n            if y == 0:\n                pass\n            elif y < 0:\n                self.page_up(count=-y)\n            elif y > 0:\n                self.page_down(count=y)\n            y = 0\n        if x == 0 and y == 0:\n            return\n        size = self._widget.page().mainFrame().geometry()\n        self.delta(int(x * size.width()), int(y * size.height()))\n\n    def to_perc(self, x=None, y=None):\n        if x is None and y == 0:\n            self.top()\n        elif x is None and y == 100:\n            self.bottom()\n        else:\n            for val, orientation in [(x, Qt.Horizontal), (y, Qt.Vertical)]:\n                if val is not None:\n                    frame = self._widget.page().mainFrame()\n                    maximum = frame.scrollBarMaximum(orientation)\n                    if maximum == 0:\n                        continue\n                    pos = int(maximum * val / 100)\n                    pos = qtutils.check_overflow(pos, 'int', fatal=False)\n                    frame.setScrollBarValue(orientation, pos)\n\n    def _key_press(self, key, count=1, getter_name=None, direction=None):\n        frame = self._widget.page().mainFrame()\n        getter = None if getter_name is None else getattr(frame, getter_name)\n\n        # FIXME:qtwebengine needed?\n        # self._widget.setFocus()\n\n        for _ in range(min(count, 5000)):\n            # Abort scrolling if the minimum/maximum was reached.\n            if (getter is not None and\n                    frame.scrollBarValue(direction) == getter(direction)):\n                return\n            self._tab.fake_key_press(key)\n\n    def up(self, count=1):\n        self._key_press(Qt.Key_Up, count, 'scrollBarMinimum', Qt.Vertical)\n\n    def down(self, count=1):\n        self._key_press(Qt.Key_Down, count, 'scrollBarMaximum', Qt.Vertical)\n\n    def left(self, count=1):\n        self._key_press(Qt.Key_Left, count, 'scrollBarMinimum', Qt.Horizontal)\n\n    def right(self, count=1):\n        self._key_press(Qt.Key_Right, count, 'scrollBarMaximum', Qt.Horizontal)\n\n    def top(self):\n        self._key_press(Qt.Key_Home)\n\n    def bottom(self):\n        self._key_press(Qt.Key_End)\n\n    def page_up(self, count=1):\n        self._key_press(Qt.Key_PageUp, count, 'scrollBarMinimum', Qt.Vertical)\n\n    def page_down(self, count=1):\n        self._key_press(Qt.Key_PageDown, count, 'scrollBarMaximum',\n                        Qt.Vertical)\n\n    def at_top(self):\n        return self.pos_px().y() == 0\n\n    def at_bottom(self):\n        frame = self._widget.page().currentFrame()\n        return self.pos_px().y() >= frame.scrollBarMaximum(Qt.Vertical)\n\n\nclass WebKitHistoryPrivate(browsertab.AbstractHistoryPrivate):\n\n    \"\"\"History-related methods which are not part of the extension API.\"\"\"\n\n    def serialize(self):\n        return qtutils.serialize(self._history)\n\n    def deserialize(self, data):\n        qtutils.deserialize(data, self._history)\n\n    def load_items(self, items):\n        if items:\n            self._tab.before_load_started.emit(items[-1].url)\n\n        stream, _data, user_data = tabhistory.serialize(items)\n        qtutils.deserialize_stream(stream, self._history)\n        for i, data in enumerate(user_data):\n            self._history.itemAt(i).setUserData(data)\n        cur_data = self._history.currentItem().userData()\n        if cur_data is not None:\n            if 'zoom' in cur_data:\n                self._tab.zoom.set_factor(cur_data['zoom'])\n            if ('scroll-pos' in cur_data and\n                    self._tab.scroller.pos_px() == QPoint(0, 0)):\n                QTimer.singleShot(0, functools.partial(\n                    self._tab.scroller.to_point, cur_data['scroll-pos']))\n\n\nclass WebKitHistory(browsertab.AbstractHistory):\n\n    \"\"\"QtWebKit implementations related to page history.\"\"\"\n\n    def __init__(self, tab):\n        super().__init__(tab)\n        self.private_api = WebKitHistoryPrivate(tab)\n\n    def __len__(self):\n        return len(self._history)\n\n    def __iter__(self):\n        return iter(self._history.items())\n\n    def current_idx(self):\n        return self._history.currentItemIndex()\n\n    def can_go_back(self):\n        return self._history.canGoBack()\n\n    def can_go_forward(self):\n        return self._history.canGoForward()\n\n    def _item_at(self, i):\n        return self._history.itemAt(i)\n\n    def _go_to_item(self, item):\n        self._tab.before_load_started.emit(item.url())\n        self._history.goToItem(item)\n\n\nclass WebKitElements(browsertab.AbstractElements):\n\n    \"\"\"QtWebKit implemementations related to elements on the page.\"\"\"\n\n    def find_css(self, selector, callback, error_cb, *, only_visible=False):\n        utils.unused(error_cb)\n        mainframe = self._widget.page().mainFrame()\n        if mainframe is None:\n            raise browsertab.WebTabError(\"No frame focused!\")\n\n        elems = []\n        frames = webkitelem.get_child_frames(mainframe)\n        for f in frames:\n            for elem in f.findAllElements(selector):\n                elems.append(webkitelem.WebKitElement(elem, tab=self._tab))\n\n        if only_visible:\n            # pylint: disable=protected-access\n            elems = [e for e in elems if e._is_visible(mainframe)]\n            # pylint: enable=protected-access\n\n        callback(elems)\n\n    def find_id(self, elem_id, callback):\n        def find_id_cb(elems):\n            \"\"\"Call the real callback with the found elements.\"\"\"\n            if not elems:\n                callback(None)\n            else:\n                callback(elems[0])\n\n        # Escape non-alphanumeric characters in the selector\n        # https://www.w3.org/TR/CSS2/syndata.html#value-def-identifier\n        elem_id = re.sub(r'[^a-zA-Z0-9_-]', r'\\\\\\g<0>', elem_id)\n        self.find_css('#' + elem_id, find_id_cb, error_cb=lambda exc: None)\n\n    def find_focused(self, callback):\n        frame = self._widget.page().currentFrame()\n        if frame is None:\n            callback(None)\n            return\n\n        elem = frame.findFirstElement('*:focus')\n        if elem.isNull():\n            callback(None)\n        else:\n            callback(webkitelem.WebKitElement(elem, tab=self._tab))\n\n    def find_at_pos(self, pos, callback):\n        assert pos.x() >= 0\n        assert pos.y() >= 0\n        frame = self._widget.page().frameAt(pos)\n        if frame is None:\n            # This happens when we click inside the webview, but not actually\n            # on the QWebPage - for example when clicking the scrollbar\n            # sometimes.\n            log.webview.debug(\"Hit test at {} but frame is None!\".format(pos))\n            callback(None)\n            return\n\n        # You'd think we have to subtract frame.geometry().topLeft() from the\n        # position, but it seems QWebFrame::hitTestContent wants a position\n        # relative to the QWebView, not to the frame. This makes no sense to\n        # me, but it works this way.\n        hitresult = frame.hitTestContent(pos)\n        if hitresult.isNull():\n            # For some reason, the whole hit result can be null sometimes (e.g.\n            # on doodle menu links).\n            log.webview.debug(\"Hit test result is null!\")\n            callback(None)\n            return\n\n        try:\n            elem = webkitelem.WebKitElement(hitresult.element(), tab=self._tab)\n        except webkitelem.IsNullError:\n            # For some reason, the hit result element can be a null element\n            # sometimes (e.g. when clicking the timetable fields on\n            # http://www.sbb.ch/ ).\n            log.webview.debug(\"Hit test result element is null!\")\n            callback(None)\n            return\n\n        callback(elem)\n\n\nclass WebKitAudio(browsertab.AbstractAudio):\n\n    \"\"\"Dummy handling of audio status for QtWebKit.\"\"\"\n\n    def set_muted(self, muted: bool, override: bool = False) -> None:\n        raise browsertab.WebTabError('Muting is not supported on QtWebKit!')\n\n    def is_muted(self):\n        return False\n\n    def is_recently_audible(self):\n        return False\n\n\nclass WebKitTabPrivate(browsertab.AbstractTabPrivate):\n\n    \"\"\"QtWebKit-related methods which aren't part of the public API.\"\"\"\n\n    def networkaccessmanager(self):\n        return self._widget.page().networkAccessManager()\n\n    def clear_ssl_errors(self):\n        self.networkaccessmanager().clear_all_ssl_errors()\n\n    def event_target(self):\n        return self._widget\n\n    def shutdown(self):\n        self._widget.shutdown()\n\n\nclass WebKitTab(browsertab.AbstractTab):\n\n    \"\"\"A QtWebKit tab in the browser.\"\"\"\n\n    def __init__(self, *, win_id, mode_manager, private, parent=None):\n        super().__init__(win_id=win_id, private=private, parent=parent)\n        widget = webview.WebView(win_id=win_id, tab_id=self.tab_id,\n                                 private=private, tab=self)\n        if private:\n            self._make_private(widget)\n        self.history = WebKitHistory(tab=self)\n        self.scroller = WebKitScroller(tab=self, parent=self)\n        self.caret = WebKitCaret(mode_manager=mode_manager,\n                                 tab=self, parent=self)\n        self.zoom = WebKitZoom(tab=self, parent=self)\n        self.search = WebKitSearch(tab=self, parent=self)\n        self.printing = WebKitPrinting(tab=self)\n        self.elements = WebKitElements(tab=self)\n        self.action = WebKitAction(tab=self)\n        self.audio = WebKitAudio(tab=self, parent=self)\n        self.private_api = WebKitTabPrivate(mode_manager=mode_manager,\n                                            tab=self)\n        # We're assigning settings in _set_widget\n        self.settings = webkitsettings.WebKitSettings(settings=None)\n        self._set_widget(widget)\n        self._connect_signals()\n        self.backend = usertypes.Backend.QtWebKit\n\n    def _install_event_filter(self):\n        self._widget.installEventFilter(self._tab_event_filter)\n\n    def _make_private(self, widget):\n        settings = widget.settings()\n        settings.setAttribute(QWebSettings.PrivateBrowsingEnabled, True)\n\n    def load_url(self, url, *, emit_before_load_started=True):\n        self._load_url_prepare(\n            url, emit_before_load_started=emit_before_load_started)\n        self._widget.load(url)\n\n    def url(self, *, requested=False):\n        frame = self._widget.page().mainFrame()\n        if requested:\n            return frame.requestedUrl()\n        else:\n            return frame.url()\n\n    def dump_async(self, callback, *, plain=False):\n        frame = self._widget.page().mainFrame()\n        if plain:\n            callback(frame.toPlainText())\n        else:\n            callback(frame.toHtml())\n\n    def run_js_async(self, code, callback=None, *, world=None):\n        if world is not None and world != usertypes.JsWorld.jseval:\n            log.webview.warning(\"Ignoring world ID {}\".format(world))\n        document_element = self._widget.page().mainFrame().documentElement()\n        result = document_element.evaluateJavaScript(code)\n        if callback is not None:\n            callback(result)\n\n    def icon(self):\n        return self._widget.icon()\n\n    def reload(self, *, force=False):\n        if force:\n            action = QWebPage.ReloadAndBypassCache\n        else:\n            action = QWebPage.Reload\n        self._widget.triggerPageAction(action)\n\n    def stop(self):\n        self._widget.stop()\n\n    def title(self):\n        return self._widget.title()\n\n    @pyqtSlot()\n    def _on_history_trigger(self):\n        url = self.url()\n        requested_url = self.url(requested=True)\n        self.history_item_triggered.emit(url, requested_url, self.title())\n\n    def set_html(self, html, base_url=QUrl()):\n        self._widget.setHtml(html, base_url)\n\n    @pyqtSlot()\n    def _on_load_started(self):\n        super()._on_load_started()\n        nam = self._widget.page().networkAccessManager()\n        nam.netrc_used = False\n        # Make sure the icon is cleared when navigating to a page without one.\n        self.icon_changed.emit(QIcon())\n\n    @pyqtSlot(bool)\n    def _on_load_finished(self, ok: bool) -> None:\n        super()._on_load_finished(ok)\n        self._update_load_status(ok)\n\n    @pyqtSlot()\n    def _on_frame_load_finished(self):\n        \"\"\"Make sure we emit an appropriate status when loading finished.\n\n        While Qt has a bool \"ok\" attribute for loadFinished, it always is True\n        when using error pages... See\n        https://github.com/qutebrowser/qutebrowser/issues/84\n        \"\"\"\n        self._on_load_finished(not self._widget.page().error_occurred)\n\n    @pyqtSlot()\n    def _on_webkit_icon_changed(self):\n        \"\"\"Emit iconChanged with a QIcon like QWebEngineView does.\"\"\"\n        if sip.isdeleted(self._widget):\n            log.webview.debug(\"Got _on_webkit_icon_changed for deleted view!\")\n            return\n        self.icon_changed.emit(self._widget.icon())\n\n    @pyqtSlot(QWebFrame)\n    def _on_frame_created(self, frame):\n        \"\"\"Connect the contentsSizeChanged signal of each frame.\"\"\"\n        # FIXME:qtwebengine those could theoretically regress:\n        # https://github.com/qutebrowser/qutebrowser/issues/152\n        # https://github.com/qutebrowser/qutebrowser/issues/263\n        frame.contentsSizeChanged.connect(self._on_contents_size_changed)\n\n    @pyqtSlot(QSize)\n    def _on_contents_size_changed(self, size):\n        self.contents_size_changed.emit(QSizeF(size))\n\n    @pyqtSlot(usertypes.NavigationRequest)\n    def _on_navigation_request(self, navigation):\n        super()._on_navigation_request(navigation)\n        if not navigation.accepted:\n            return\n\n        log.webview.debug(\"target {} override {}\".format(\n            self.data.open_target, self.data.override_target))\n\n        if self.data.override_target is not None:\n            target = self.data.override_target\n            self.data.override_target = None\n        else:\n            target = self.data.open_target\n\n        if (navigation.navigation_type == navigation.Type.link_clicked and\n                target != usertypes.ClickTarget.normal):\n            tab = shared.get_tab(self.win_id, target)\n            tab.load_url(navigation.url)\n            self.data.open_target = usertypes.ClickTarget.normal\n            navigation.accepted = False\n\n        if navigation.is_main_frame:\n            self.settings.update_for_url(navigation.url)\n\n    @pyqtSlot()\n    def _on_ssl_errors(self):\n        self._has_ssl_errors = True\n\n    def _connect_signals(self):\n        view = self._widget\n        page = view.page()\n        frame = page.mainFrame()\n        page.windowCloseRequested.connect(self.window_close_requested)\n        page.linkHovered.connect(self.link_hovered)\n        page.loadProgress.connect(self._on_load_progress)\n        frame.loadStarted.connect(self._on_load_started)\n        view.scroll_pos_changed.connect(self.scroller.perc_changed)\n        view.titleChanged.connect(self.title_changed)\n        view.urlChanged.connect(self._on_url_changed)\n        view.shutting_down.connect(self.shutting_down)\n        page.networkAccessManager().sslErrors.connect(self._on_ssl_errors)\n        frame.loadFinished.connect(self._on_frame_load_finished)\n        view.iconChanged.connect(self._on_webkit_icon_changed)\n        page.frameCreated.connect(self._on_frame_created)\n        frame.contentsSizeChanged.connect(self._on_contents_size_changed)\n        frame.initialLayoutCompleted.connect(self._on_history_trigger)\n        page.navigation_request.connect(self._on_navigation_request)\n", "target": 1}
{"idx": 883, "func": "from typing import Any, List\n\nimport bleach\n\nfrom .rest_api import ValidationError\n\n\nallowed_tags_strict = [\n    \"a\",\n    \"img\",  # links and images\n    \"br\",\n    \"p\",\n    \"span\",\n    \"blockquote\",  # text layout\n    \"strike\",\n    \"del\",\n    \"ins\",\n    \"strong\",\n    \"u\",\n    \"em\",\n    \"sup\",\n    \"sub\",\n    \"pre\",  # text formatting\n    \"h1\",\n    \"h2\",\n    \"h3\",\n    \"h4\",\n    \"h5\",\n    \"h6\",  # headings\n    \"ol\",\n    \"ul\",\n    \"li\",  # lists\n    \"table\",\n    \"caption\",\n    \"thead\",\n    \"tbody\",\n    \"th\",\n    \"tr\",\n    \"td\",  # tables\n    \"div\",\n]\nallowed_tags_permissive = allowed_tags_strict + [\n    \"video\",\n]\n\n\ndef allow_all(tag: str, name: str, value: str) -> bool:\n    return True\n\n\nallowed_attributes = allow_all\nallowed_styles = [\n    \"color\",\n    \"background-color\",\n    \"height\",\n    \"width\",\n    \"text-align\",\n    \"vertical-align\",\n    \"float\",\n    \"text-decoration\",\n    \"margin\",\n    \"padding\",\n    \"line-height\",\n    \"max-width\",\n    \"min-width\",\n    \"max-height\",\n    \"min-height\",\n    \"overflow\",\n    \"word-break\",\n    \"word-wrap\",\n]\n\n\ndef validate_html_strict(html: str) -> str:\n    \"\"\"\n    This method takes a string and escapes all non-whitelisted html entries.\n    Every field of a model that is loaded trusted in the DOM should be validated.\n    During copy and paste from Word maybe some tabs are spread over the html. Remove them.\n    \"\"\"\n    return base_validate_html(html, allowed_tags_strict)\n\n\ndef validate_html_permissive(html: str) -> str:\n    \"\"\"\n    See validate_html_strict, but allows some more tags, like iframes and videos.\n    Do not use on validation for normal users, only for admins!\n    \"\"\"\n    return base_validate_html(html, allowed_tags_permissive)\n\n\ndef base_validate_html(html: str, allowed_tags: List[str]) -> str:\n    \"\"\"\n    For internal use only.\n    \"\"\"\n    html = html.replace(\"\\t\", \"\")\n    return bleach.clean(\n        html, tags=allowed_tags, attributes=allowed_attributes, styles=allowed_styles\n    )\n\n\ndef validate_json(json: Any, max_depth: int) -> Any:\n    \"\"\"\n    Traverses through the JSON structure (dicts and lists) and runs\n    validate_html_strict on every found string.\n\n    Give max-depth to protect against stack-overflows. This should be the\n    maximum nested depth of the object expected.\n    \"\"\"\n\n    if max_depth == 0:\n        raise ValidationError({\"detail\": \"The JSON is too nested.\"})\n\n    if isinstance(json, dict):\n        return {key: validate_json(value, max_depth - 1) for key, value in json.items()}\n    if isinstance(json, list):\n        return [validate_json(item, max_depth - 1) for item in json]\n    if isinstance(json, str):\n        return validate_html_strict(json)\n\n    return json\n", "target": 1}
{"idx": 884, "func": "# vim: tabstop=4 shiftwidth=4 softtabstop=4\n\n# Copyright 2012 OpenStack LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"); you may\n# not use this file except in compliance with the License. You may obtain\n# a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n# License for the specific language governing permissions and limitations\n# under the License.\n\nimport gettext\nimport os\nimport sys\n\nfrom keystone.common import logging\nfrom keystone.openstack.common import cfg\n\n\ngettext.install('keystone', unicode=1)\n\n\nCONF = cfg.CONF\n\n\ndef setup_logging(conf):\n    \"\"\"\n    Sets up the logging options for a log with supplied name\n\n    :param conf: a cfg.ConfOpts object\n    \"\"\"\n\n    if conf.log_config:\n        # Use a logging configuration file for all settings...\n        if os.path.exists(conf.log_config):\n            logging.config.fileConfig(conf.log_config)\n            return\n        else:\n            raise RuntimeError(_('Unable to locate specified logging '\n                               'config file: %s') % conf.log_config)\n\n    root_logger = logging.root\n    if conf.debug:\n        root_logger.setLevel(logging.DEBUG)\n    elif conf.verbose:\n        root_logger.setLevel(logging.INFO)\n    else:\n        root_logger.setLevel(logging.WARNING)\n\n    formatter = logging.Formatter(conf.log_format, conf.log_date_format)\n\n    if conf.use_syslog:\n        try:\n            facility = getattr(logging.SysLogHandler,\n                               conf.syslog_log_facility)\n        except AttributeError:\n            raise ValueError(_('Invalid syslog facility'))\n\n        handler = logging.SysLogHandler(address='/dev/log',\n                                        facility=facility)\n    elif conf.log_file:\n        logfile = conf.log_file\n        if conf.log_dir:\n            logfile = os.path.join(conf.log_dir, logfile)\n        handler = logging.WatchedFileHandler(logfile)\n    else:\n        handler = logging.StreamHandler(sys.stdout)\n\n    handler.setFormatter(formatter)\n    root_logger.addHandler(handler)\n\n\ndef register_str(*args, **kw):\n    conf = kw.pop('conf', CONF)\n    group = kw.pop('group', None)\n    return conf.register_opt(cfg.StrOpt(*args, **kw), group=group)\n\n\ndef register_cli_str(*args, **kw):\n    conf = kw.pop('conf', CONF)\n    group = kw.pop('group', None)\n    return conf.register_cli_opt(cfg.StrOpt(*args, **kw), group=group)\n\n\ndef register_list(*args, **kw):\n    conf = kw.pop('conf', CONF)\n    group = kw.pop('group', None)\n    return conf.register_opt(cfg.ListOpt(*args, **kw), group=group)\n\n\ndef register_cli_list(*args, **kw):\n    conf = kw.pop('conf', CONF)\n    group = kw.pop('group', None)\n    return conf.register_cli_opt(cfg.ListOpt(*args, **kw), group=group)\n\n\ndef register_bool(*args, **kw):\n    conf = kw.pop('conf', CONF)\n    group = kw.pop('group', None)\n    return conf.register_opt(cfg.BoolOpt(*args, **kw), group=group)\n\n\ndef register_cli_bool(*args, **kw):\n    conf = kw.pop('conf', CONF)\n    group = kw.pop('group', None)\n    return conf.register_cli_opt(cfg.BoolOpt(*args, **kw), group=group)\n\n\ndef register_int(*args, **kw):\n    conf = kw.pop('conf', CONF)\n    group = kw.pop('group', None)\n    return conf.register_opt(cfg.IntOpt(*args, **kw), group=group)\n\n\ndef register_cli_int(*args, **kw):\n    conf = kw.pop('conf', CONF)\n    group = kw.pop('group', None)\n    return conf.register_cli_opt(cfg.IntOpt(*args, **kw), group=group)\n\n\nregister_cli_bool('standard-threads', default=False)\n\nregister_cli_str('pydev-debug-host', default=None)\nregister_cli_int('pydev-debug-port', default=None)\n\nregister_str('admin_token', default='ADMIN')\nregister_str('bind_host', default='0.0.0.0')\nregister_str('compute_port', default=8774)\nregister_str('admin_port', default=35357)\nregister_str('public_port', default=5000)\nregister_str('onready')\nregister_str('auth_admin_prefix', default='')\nregister_str('policy_file', default='policy.json')\nregister_str('policy_default_rule', default=None)\n#default max request size is 112k\nregister_int('max_request_body_size', default=114688)\n\n#ssl options\nregister_bool('enable', group='ssl', default=False)\nregister_str('certfile', group='ssl', default=None)\nregister_str('keyfile', group='ssl', default=None)\nregister_str('ca_certs', group='ssl', default=None)\nregister_bool('cert_required', group='ssl', default=False)\n#signing options\nregister_str('token_format', group='signing',\n             default=\"PKI\")\nregister_str('certfile', group='signing',\n             default=\"/etc/keystone/ssl/certs/signing_cert.pem\")\nregister_str('keyfile', group='signing',\n             default=\"/etc/keystone/ssl/private/signing_key.pem\")\nregister_str('ca_certs', group='signing',\n             default=\"/etc/keystone/ssl/certs/ca.pem\")\nregister_int('key_size', group='signing', default=1024)\nregister_int('valid_days', group='signing', default=3650)\nregister_str('ca_password', group='signing', default=None)\n\n\n# sql options\nregister_str('connection', group='sql', default='sqlite:///keystone.db')\nregister_int('idle_timeout', group='sql', default=200)\n\n\nregister_str('driver', group='catalog',\n             default='keystone.catalog.backends.sql.Catalog')\nregister_str('driver', group='identity',\n             default='keystone.identity.backends.sql.Identity')\nregister_str('driver', group='policy',\n             default='keystone.policy.backends.sql.Policy')\nregister_str('driver', group='token',\n             default='keystone.token.backends.kvs.Token')\nregister_str('driver', group='ec2',\n             default='keystone.contrib.ec2.backends.kvs.Ec2')\nregister_str('driver', group='stats',\n             default='keystone.contrib.stats.backends.kvs.Stats')\n\n\n#ldap\nregister_str('url', group='ldap', default='ldap://localhost')\nregister_str('user', group='ldap', default='dc=Manager,dc=example,dc=com')\nregister_str('password', group='ldap', default='freeipa4all')\nregister_str('suffix', group='ldap', default='cn=example,cn=com')\nregister_bool('use_dumb_member', group='ldap', default=False)\nregister_str('dumb_member', group='ldap', default='cn=dumb,dc=nonexistent')\nregister_bool('allow_subtree_delete', group='ldap', default=False)\n\nregister_str('user_tree_dn', group='ldap', default=None)\nregister_str('user_filter', group='ldap', default=None)\nregister_str('user_objectclass', group='ldap', default='inetOrgPerson')\nregister_str('user_id_attribute', group='ldap', default='cn')\nregister_str('user_name_attribute', group='ldap', default='sn')\nregister_str('user_mail_attribute', group='ldap', default='email')\nregister_str('user_pass_attribute', group='ldap', default='userPassword')\nregister_str('user_enabled_attribute', group='ldap', default='enabled')\nregister_int('user_enabled_mask', group='ldap', default=0)\nregister_str('user_enabled_default', group='ldap', default='True')\nregister_list('user_attribute_ignore', group='ldap',\n              default='tenant_id,tenants')\nregister_bool('user_allow_create', group='ldap', default=True)\nregister_bool('user_allow_update', group='ldap', default=True)\nregister_bool('user_allow_delete', group='ldap', default=True)\n\nregister_str('tenant_tree_dn', group='ldap', default=None)\nregister_str('tenant_filter', group='ldap', default=None)\nregister_str('tenant_objectclass', group='ldap', default='groupOfNames')\nregister_str('tenant_id_attribute', group='ldap', default='cn')\nregister_str('tenant_member_attribute', group='ldap', default='member')\nregister_str('tenant_name_attribute', group='ldap', default='ou')\nregister_str('tenant_desc_attribute', group='ldap', default='desc')\nregister_str('tenant_enabled_attribute', group='ldap', default='enabled')\nregister_list('tenant_attribute_ignore', group='ldap', default='')\nregister_bool('tenant_allow_create', group='ldap', default=True)\nregister_bool('tenant_allow_update', group='ldap', default=True)\nregister_bool('tenant_allow_delete', group='ldap', default=True)\n\nregister_str('role_tree_dn', group='ldap', default=None)\nregister_str('role_filter', group='ldap', default=None)\nregister_str('role_objectclass', group='ldap', default='organizationalRole')\nregister_str('role_id_attribute', group='ldap', default='cn')\nregister_str('role_name_attribute', group='ldap', default='ou')\nregister_str('role_member_attribute', group='ldap', default='roleOccupant')\nregister_list('role_attribute_ignore', group='ldap', default='')\nregister_bool('role_allow_create', group='ldap', default=True)\nregister_bool('role_allow_update', group='ldap', default=True)\nregister_bool('role_allow_delete', group='ldap', default=True)\n\nregister_str('group_tree_dn', group='ldap', default=None)\nregister_str('group_filter', group='ldap', default=None)\nregister_str('group_objectclass', group='ldap', default='groupOfNames')\nregister_str('group_id_attribute', group='ldap', default='cn')\nregister_str('group_name_attribute', group='ldap', default='ou')\nregister_str('group_member_attribute', group='ldap', default='member')\nregister_str('group_desc_attribute', group='ldap', default='desc')\nregister_list('group_attribute_ignore', group='ldap', default='')\nregister_bool('group_allow_create', group='ldap', default=True)\nregister_bool('group_allow_update', group='ldap', default=True)\nregister_bool('group_allow_delete', group='ldap', default=True)\n#pam\nregister_str('url', group='pam', default=None)\nregister_str('userid', group='pam', default=None)\nregister_str('password', group='pam', default=None)\n", "target": 0}
{"idx": 885, "func": "# vim: tabstop=4 shiftwidth=4 softtabstop=4\n\n# Copyright 2010 United States Government as represented by the\n# Administrator of the National Aeronautics and Space Administration.\n# All Rights Reserved.\n#\n#    Licensed under the Apache License, Version 2.0 (the \"License\"); you may\n#    not use this file except in compliance with the License. You may obtain\n#    a copy of the License at\n#\n#         http://www.apache.org/licenses/LICENSE-2.0\n#\n#    Unless required by applicable law or agreed to in writing, software\n#    distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n#    License for the specific language governing permissions and limitations\n#    under the License.\n\n\"\"\"Nova base exception handling.\n\nIncludes decorator for re-raising Nova-type exceptions.\n\nSHOULD include dedicated exception logging.\n\n\"\"\"\n\nimport functools\nimport sys\n\nimport novaclient.exceptions\nimport webob.exc\n\nfrom nova import log as logging\n\nLOG = logging.getLogger(__name__)\n\n\nclass ConvertedException(webob.exc.WSGIHTTPException):\n    def __init__(self, code=0, title=\"\", explanation=\"\"):\n        self.code = code\n        self.title = title\n        self.explanation = explanation\n        super(ConvertedException, self).__init__()\n\n\nclass ProcessExecutionError(IOError):\n    def __init__(self, stdout=None, stderr=None, exit_code=None, cmd=None,\n                 description=None):\n        self.exit_code = exit_code\n        self.stderr = stderr\n        self.stdout = stdout\n        self.cmd = cmd\n        self.description = description\n\n        if description is None:\n            description = _('Unexpected error while running command.')\n        if exit_code is None:\n            exit_code = '-'\n        message = _('%(description)s\\nCommand: %(cmd)s\\n'\n                    'Exit code: %(exit_code)s\\nStdout: %(stdout)r\\n'\n                    'Stderr: %(stderr)r') % locals()\n        IOError.__init__(self, message)\n\n\nclass Error(Exception):\n    pass\n\n\nclass EC2APIError(Error):\n    def __init__(self, message='Unknown', code=None):\n        self.msg = message\n        self.code = code\n        if code:\n            outstr = '%s: %s' % (code, message)\n        else:\n            outstr = '%s' % message\n        super(EC2APIError, self).__init__(outstr)\n\n\nclass DBError(Error):\n    \"\"\"Wraps an implementation specific exception.\"\"\"\n    def __init__(self, inner_exception=None):\n        self.inner_exception = inner_exception\n        super(DBError, self).__init__(str(inner_exception))\n\n\ndef wrap_db_error(f):\n    def _wrap(*args, **kwargs):\n        try:\n            return f(*args, **kwargs)\n        except UnicodeEncodeError:\n            raise InvalidUnicodeParameter()\n        except Exception, e:\n            LOG.exception(_('DB exception wrapped.'))\n            raise DBError(e)\n    _wrap.func_name = f.func_name\n    return _wrap\n\n\ndef wrap_exception(notifier=None, publisher_id=None, event_type=None,\n                   level=None):\n    \"\"\"This decorator wraps a method to catch any exceptions that may\n    get thrown. It logs the exception as well as optionally sending\n    it to the notification system.\n    \"\"\"\n    # TODO(sandy): Find a way to import nova.notifier.api so we don't have\n    # to pass it in as a parameter. Otherwise we get a cyclic import of\n    # nova.notifier.api -> nova.utils -> nova.exception :(\n    # TODO(johannes): Also, it would be nice to use\n    # utils.save_and_reraise_exception() without an import loop\n    def inner(f):\n        def wrapped(*args, **kw):\n            try:\n                return f(*args, **kw)\n            except Exception, e:\n                # Save exception since it can be clobbered during processing\n                # below before we can re-raise\n                exc_info = sys.exc_info()\n\n                if notifier:\n                    payload = dict(args=args, exception=e)\n                    payload.update(kw)\n\n                    # Use a temp vars so we don't shadow\n                    # our outer definitions.\n                    temp_level = level\n                    if not temp_level:\n                        temp_level = notifier.ERROR\n\n                    temp_type = event_type\n                    if not temp_type:\n                        # If f has multiple decorators, they must use\n                        # functools.wraps to ensure the name is\n                        # propagated.\n                        temp_type = f.__name__\n\n                    notifier.notify(publisher_id, temp_type, temp_level,\n                                    payload)\n\n                # re-raise original exception since it may have been clobbered\n                raise exc_info[0], exc_info[1], exc_info[2]\n\n        return functools.wraps(f)(wrapped)\n    return inner\n\n\nclass NovaException(Exception):\n    \"\"\"Base Nova Exception\n\n    To correctly use this class, inherit from it and define\n    a 'message' property. That message will get printf'd\n    with the keyword arguments provided to the constructor.\n\n    \"\"\"\n    message = _(\"An unknown exception occurred.\")\n    code = 500\n    headers = {}\n    safe = False\n\n    def __init__(self, message=None, **kwargs):\n        self.kwargs = kwargs\n\n        if 'code' not in self.kwargs:\n            try:\n                self.kwargs['code'] = self.code\n            except AttributeError:\n                pass\n\n        if not message:\n            try:\n                message = self.message % kwargs\n\n            except Exception as e:\n                # at least get the core message out if something happened\n                message = self.message\n\n        super(NovaException, self).__init__(message)\n\n\nclass DecryptionFailure(NovaException):\n    message = _(\"Failed to decrypt text\")\n\n\nclass ImagePaginationFailed(NovaException):\n    message = _(\"Failed to paginate through images from image service\")\n\n\nclass VirtualInterfaceCreateException(NovaException):\n    message = _(\"Virtual Interface creation failed\")\n\n\nclass VirtualInterfaceMacAddressException(NovaException):\n    message = _(\"5 attempts to create virtual interface\"\n                \"with unique mac address failed\")\n\n\nclass GlanceConnectionFailed(NovaException):\n    message = _(\"Connection to glance failed\") + \": %(reason)s\"\n\n\nclass MelangeConnectionFailed(NovaException):\n    message = _(\"Connection to melange failed\") + \": %(reason)s\"\n\n\nclass NotAuthorized(NovaException):\n    message = _(\"Not authorized.\")\n    code = 403\n\n\nclass AdminRequired(NotAuthorized):\n    message = _(\"User does not have admin privileges\")\n\n\nclass PolicyNotAuthorized(NotAuthorized):\n    message = _(\"Policy doesn't allow %(action)s to be performed.\")\n\n\nclass ImageNotAuthorized(NovaException):\n    message = _(\"Not authorized for image %(image_id)s.\")\n\n\nclass Invalid(NovaException):\n    message = _(\"Unacceptable parameters.\")\n    code = 400\n\n\nclass InvalidSnapshot(Invalid):\n    message = _(\"Invalid snapshot\") + \": %(reason)s\"\n\n\nclass VolumeUnattached(Invalid):\n    message = _(\"Volume %(volume_id)s is not attached to anything\")\n\n\nclass InvalidKeypair(Invalid):\n    message = _(\"Keypair data is invalid\")\n\n\nclass SfJsonEncodeFailure(NovaException):\n    message = _(\"Failed to load data into json format\")\n\n\nclass InvalidRequest(Invalid):\n    message = _(\"The request is invalid.\")\n\n\nclass InvalidSignature(Invalid):\n    message = _(\"Invalid signature %(signature)s for user %(user)s.\")\n\n\nclass InvalidInput(Invalid):\n    message = _(\"Invalid input received\") + \": %(reason)s\"\n\n\nclass InvalidInstanceType(Invalid):\n    message = _(\"Invalid instance type %(instance_type)s.\")\n\n\nclass InvalidVolumeType(Invalid):\n    message = _(\"Invalid volume type\") + \": %(reason)s\"\n\n\nclass InvalidVolume(Invalid):\n    message = _(\"Invalid volume\") + \": %(reason)s\"\n\n\nclass InvalidPortRange(Invalid):\n    message = _(\"Invalid port range %(from_port)s:%(to_port)s. %(msg)s\")\n\n\nclass InvalidIpProtocol(Invalid):\n    message = _(\"Invalid IP protocol %(protocol)s.\")\n\n\nclass InvalidContentType(Invalid):\n    message = _(\"Invalid content type %(content_type)s.\")\n\n\nclass InvalidCidr(Invalid):\n    message = _(\"Invalid cidr %(cidr)s.\")\n\n\nclass InvalidRPCConnectionReuse(Invalid):\n    message = _(\"Invalid reuse of an RPC connection.\")\n\n\nclass InvalidUnicodeParameter(Invalid):\n    message = _(\"Invalid Parameter: \"\n                \"Unicode is not supported by the current database.\")\n\n\n# Cannot be templated as the error syntax varies.\n# msg needs to be constructed when raised.\nclass InvalidParameterValue(Invalid):\n    message = _(\"%(err)s\")\n\n\nclass InvalidAggregateAction(Invalid):\n    message = _(\"Cannot perform action '%(action)s' on aggregate \"\n                \"%(aggregate_id)s. Reason: %(reason)s.\")\n\n\nclass InvalidGroup(Invalid):\n    message = _(\"Group not valid. Reason: %(reason)s\")\n\n\nclass InstanceInvalidState(Invalid):\n    message = _(\"Instance %(instance_uuid)s in %(attr)s %(state)s. Cannot \"\n                \"%(method)s while the instance is in this state.\")\n\n\nclass InvalidBDM(Invalid):\n    message = _(\"Block Device Mapping is Invalid.\")\n\n\nclass InvalidBDMSnapshot(InvalidBDM):\n    message = _(\"Block Device Mapping is Invalid: \"\n                \"failed to get snapshot %(id)s.\")\n\n\nclass InvalidBDMVolume(InvalidBDM):\n    message = _(\"Block Device Mapping is Invalid: \"\n                \"failed to get volume %(id)s.\")\n\n\nclass InstanceNotRunning(Invalid):\n    message = _(\"Instance %(instance_id)s is not running.\")\n\n\nclass InstanceNotSuspended(Invalid):\n    message = _(\"Instance %(instance_id)s is not suspended.\")\n\n\nclass InstanceNotInRescueMode(Invalid):\n    message = _(\"Instance %(instance_id)s is not in rescue mode\")\n\n\nclass InstanceSuspendFailure(Invalid):\n    message = _(\"Failed to suspend instance\") + \": %(reason)s\"\n\n\nclass InstanceResumeFailure(Invalid):\n    message = _(\"Failed to resume server\") + \": %(reason)s.\"\n\n\nclass InstanceRebootFailure(Invalid):\n    message = _(\"Failed to reboot instance\") + \": %(reason)s\"\n\n\nclass InstanceTerminationFailure(Invalid):\n    message = _(\"Failed to terminate instance\") + \": %(reason)s\"\n\n\nclass ServiceUnavailable(Invalid):\n    message = _(\"Service is unavailable at this time.\")\n\n\nclass VolumeServiceUnavailable(ServiceUnavailable):\n    message = _(\"Volume service is unavailable at this time.\")\n\n\nclass ComputeServiceUnavailable(ServiceUnavailable):\n    message = _(\"Compute service is unavailable at this time.\")\n\n\nclass UnableToMigrateToSelf(Invalid):\n    message = _(\"Unable to migrate instance (%(instance_id)s) \"\n                \"to current host (%(host)s).\")\n\n\nclass DestinationHostUnavailable(Invalid):\n    message = _(\"Destination compute host is unavailable at this time.\")\n\n\nclass SourceHostUnavailable(Invalid):\n    message = _(\"Original compute host is unavailable at this time.\")\n\n\nclass InvalidHypervisorType(Invalid):\n    message = _(\"The supplied hypervisor type of is invalid.\")\n\n\nclass DestinationHypervisorTooOld(Invalid):\n    message = _(\"The instance requires a newer hypervisor version than \"\n                \"has been provided.\")\n\n\nclass DestinationDiskExists(Invalid):\n    message = _(\"The supplied disk path (%(path)s) already exists, \"\n                \"it is expected not to exist.\")\n\n\nclass InvalidDevicePath(Invalid):\n    message = _(\"The supplied device path (%(path)s) is invalid.\")\n\n\nclass DeviceIsBusy(Invalid):\n    message = _(\"The supplied device (%(device)s) is busy.\")\n\n\nclass InvalidCPUInfo(Invalid):\n    message = _(\"Unacceptable CPU info\") + \": %(reason)s\"\n\n\nclass InvalidIpAddressError(Invalid):\n    message = _(\"%(address)s is not a valid IP v4/6 address.\")\n\n\nclass InvalidVLANTag(Invalid):\n    message = _(\"VLAN tag is not appropriate for the port group \"\n                \"%(bridge)s. Expected VLAN tag is %(tag)s, \"\n                \"but the one associated with the port group is %(pgroup)s.\")\n\n\nclass InvalidVLANPortGroup(Invalid):\n    message = _(\"vSwitch which contains the port group %(bridge)s is \"\n                \"not associated with the desired physical adapter. \"\n                \"Expected vSwitch is %(expected)s, but the one associated \"\n                \"is %(actual)s.\")\n\n\nclass InvalidDiskFormat(Invalid):\n    message = _(\"Disk format %(disk_format)s is not acceptable\")\n\n\nclass ImageUnacceptable(Invalid):\n    message = _(\"Image %(image_id)s is unacceptable: %(reason)s\")\n\n\nclass InstanceUnacceptable(Invalid):\n    message = _(\"Instance %(instance_id)s is unacceptable: %(reason)s\")\n\n\nclass InvalidEc2Id(Invalid):\n    message = _(\"Ec2 id %(ec2_id)s is unacceptable.\")\n\n\nclass NotFound(NovaException):\n    message = _(\"Resource could not be found.\")\n    code = 404\n\n\nclass FlagNotSet(NotFound):\n    message = _(\"Required flag %(flag)s not set.\")\n\n\nclass VolumeNotFound(NotFound):\n    message = _(\"Volume %(volume_id)s could not be found.\")\n\n\nclass SfAccountNotFound(NotFound):\n    message = _(\"Unable to locate account %(account_name)s on \"\n                \"Solidfire device\")\n\n\nclass VolumeNotFoundForInstance(VolumeNotFound):\n    message = _(\"Volume not found for instance %(instance_id)s.\")\n\n\nclass VolumeMetadataNotFound(NotFound):\n    message = _(\"Volume %(volume_id)s has no metadata with \"\n                \"key %(metadata_key)s.\")\n\n\nclass NoVolumeTypesFound(NotFound):\n    message = _(\"Zero volume types found.\")\n\n\nclass VolumeTypeNotFound(NotFound):\n    message = _(\"Volume type %(volume_type_id)s could not be found.\")\n\n\nclass VolumeTypeNotFoundByName(VolumeTypeNotFound):\n    message = _(\"Volume type with name %(volume_type_name)s \"\n                \"could not be found.\")\n\n\nclass VolumeTypeExtraSpecsNotFound(NotFound):\n    message = _(\"Volume Type %(volume_type_id)s has no extra specs with \"\n                \"key %(extra_specs_key)s.\")\n\n\nclass SnapshotNotFound(NotFound):\n    message = _(\"Snapshot %(snapshot_id)s could not be found.\")\n\n\nclass VolumeIsBusy(NovaException):\n    message = _(\"deleting volume %(volume_name)s that has snapshot\")\n\n\nclass SnapshotIsBusy(NovaException):\n    message = _(\"deleting snapshot %(snapshot_name)s that has \"\n                \"dependent volumes\")\n\n\nclass ISCSITargetNotFoundForVolume(NotFound):\n    message = _(\"No target id found for volume %(volume_id)s.\")\n\n\nclass DiskNotFound(NotFound):\n    message = _(\"No disk at %(location)s\")\n\n\nclass VolumeDriverNotFound(NotFound):\n    message = _(\"Could not find a handler for %(driver_type)s volume.\")\n\n\nclass InvalidImageRef(Invalid):\n    message = _(\"Invalid image href %(image_href)s.\")\n\n\nclass ListingImageRefsNotSupported(Invalid):\n    message = _(\"Some images have been stored via hrefs.\"\n        + \" This version of the api does not support displaying image hrefs.\")\n\n\nclass ImageNotFound(NotFound):\n    message = _(\"Image %(image_id)s could not be found.\")\n\n\nclass KernelNotFoundForImage(ImageNotFound):\n    message = _(\"Kernel not found for image %(image_id)s.\")\n\n\nclass UserNotFound(NotFound):\n    message = _(\"User %(user_id)s could not be found.\")\n\n\nclass ProjectNotFound(NotFound):\n    message = _(\"Project %(project_id)s could not be found.\")\n\n\nclass ProjectMembershipNotFound(NotFound):\n    message = _(\"User %(user_id)s is not a member of project %(project_id)s.\")\n\n\nclass UserRoleNotFound(NotFound):\n    message = _(\"Role %(role_id)s could not be found.\")\n\n\nclass StorageRepositoryNotFound(NotFound):\n    message = _(\"Cannot find SR to read/write VDI.\")\n\n\nclass NetworkInUse(NovaException):\n    message = _(\"Network %(network_id)s is still in use.\")\n\n\nclass NetworkNotCreated(NovaException):\n    message = _(\"%(req)s is required to create a network.\")\n\n\nclass NetworkNotFound(NotFound):\n    message = _(\"Network %(network_id)s could not be found.\")\n\n\nclass NetworkNotFoundForBridge(NetworkNotFound):\n    message = _(\"Network could not be found for bridge %(bridge)s\")\n\n\nclass NetworkNotFoundForUUID(NetworkNotFound):\n    message = _(\"Network could not be found for uuid %(uuid)s\")\n\n\nclass NetworkNotFoundForCidr(NetworkNotFound):\n    message = _(\"Network could not be found with cidr %(cidr)s.\")\n\n\nclass NetworkNotFoundForInstance(NetworkNotFound):\n    message = _(\"Network could not be found for instance %(instance_id)s.\")\n\n\nclass NoNetworksFound(NotFound):\n    message = _(\"No networks defined.\")\n\n\nclass NetworkNotFoundForProject(NotFound):\n    message = _(\"Either Network uuid %(network_uuid)s is not present or \"\n                \"is not assigned to the project %(project_id)s.\")\n\n\nclass NetworkHostNotSet(NovaException):\n    message = _(\"Host is not set to the network (%(network_id)s).\")\n\n\nclass NetworkBusy(NovaException):\n    message = _(\"Network %(network)s has active ports, cannot delete.\")\n\n\nclass DatastoreNotFound(NotFound):\n    message = _(\"Could not find the datastore reference(s) which the VM uses.\")\n\n\nclass FixedIpNotFound(NotFound):\n    message = _(\"No fixed IP associated with id %(id)s.\")\n\n\nclass FixedIpNotFoundForAddress(FixedIpNotFound):\n    message = _(\"Fixed ip not found for address %(address)s.\")\n\n\nclass FixedIpNotFoundForInstance(FixedIpNotFound):\n    message = _(\"Instance %(instance_id)s has zero fixed ips.\")\n\n\nclass FixedIpNotFoundForNetworkHost(FixedIpNotFound):\n    message = _(\"Network host %(host)s has zero fixed ips \"\n                \"in network %(network_id)s.\")\n\n\nclass FixedIpNotFoundForSpecificInstance(FixedIpNotFound):\n    message = _(\"Instance %(instance_id)s doesn't have fixed ip '%(ip)s'.\")\n\n\nclass FixedIpNotFoundForHost(FixedIpNotFound):\n    message = _(\"Host %(host)s has zero fixed ips.\")\n\n\nclass FixedIpNotFoundForNetwork(FixedIpNotFound):\n    message = _(\"Fixed IP address (%(address)s) does not exist in \"\n                \"network (%(network_uuid)s).\")\n\n\nclass FixedIpAlreadyInUse(NovaException):\n    message = _(\"Fixed IP address %(address)s is already in use.\")\n\n\nclass FixedIpInvalid(Invalid):\n    message = _(\"Fixed IP address %(address)s is invalid.\")\n\n\nclass NoMoreFixedIps(NovaException):\n    message = _(\"Zero fixed ips available.\")\n\n\nclass NoFixedIpsDefined(NotFound):\n    message = _(\"Zero fixed ips could be found.\")\n\n\nclass FloatingIpNotFound(NotFound):\n    message = _(\"Floating ip not found for id %(id)s.\")\n\n\nclass FloatingIpDNSExists(Invalid):\n    message = _(\"The DNS entry %(name)s already exists in domain %(domain)s.\")\n\n\nclass FloatingIpNotFoundForAddress(FloatingIpNotFound):\n    message = _(\"Floating ip not found for address %(address)s.\")\n\n\nclass FloatingIpNotFoundForHost(FloatingIpNotFound):\n    message = _(\"Floating ip not found for host %(host)s.\")\n\n\nclass NoMoreFloatingIps(FloatingIpNotFound):\n    message = _(\"Zero floating ips available.\")\n\n\nclass FloatingIpAssociated(NovaException):\n    message = _(\"Floating ip %(address)s is associated.\")\n\n\nclass FloatingIpNotAssociated(NovaException):\n    message = _(\"Floating ip %(address)s is not associated.\")\n\n\nclass NoFloatingIpsDefined(NotFound):\n    message = _(\"Zero floating ips exist.\")\n\n\nclass NoFloatingIpInterface(NotFound):\n    message = _(\"Interface %(interface)s not found.\")\n\n\nclass KeypairNotFound(NotFound):\n    message = _(\"Keypair %(name)s not found for user %(user_id)s\")\n\n\nclass CertificateNotFound(NotFound):\n    message = _(\"Certificate %(certificate_id)s not found.\")\n\n\nclass ServiceNotFound(NotFound):\n    message = _(\"Service %(service_id)s could not be found.\")\n\n\nclass HostNotFound(NotFound):\n    message = _(\"Host %(host)s could not be found.\")\n\n\nclass ComputeHostNotFound(HostNotFound):\n    message = _(\"Compute host %(host)s could not be found.\")\n\n\nclass HostBinaryNotFound(NotFound):\n    message = _(\"Could not find binary %(binary)s on host %(host)s.\")\n\n\nclass AuthTokenNotFound(NotFound):\n    message = _(\"Auth token %(token)s could not be found.\")\n\n\nclass AccessKeyNotFound(NotFound):\n    message = _(\"Access Key %(access_key)s could not be found.\")\n\n\nclass QuotaNotFound(NotFound):\n    message = _(\"Quota could not be found\")\n\n\nclass ProjectQuotaNotFound(QuotaNotFound):\n    message = _(\"Quota for project %(project_id)s could not be found.\")\n\n\nclass SecurityGroupNotFound(NotFound):\n    message = _(\"Security group %(security_group_id)s not found.\")\n\n\nclass SecurityGroupNotFoundForProject(SecurityGroupNotFound):\n    message = _(\"Security group %(security_group_id)s not found \"\n                \"for project %(project_id)s.\")\n\n\nclass SecurityGroupNotFoundForRule(SecurityGroupNotFound):\n    message = _(\"Security group with rule %(rule_id)s not found.\")\n\n\nclass SecurityGroupExistsForInstance(Invalid):\n    message = _(\"Security group %(security_group_id)s is already associated\"\n                \" with the instance %(instance_id)s\")\n\n\nclass SecurityGroupNotExistsForInstance(Invalid):\n    message = _(\"Security group %(security_group_id)s is not associated with\"\n                \" the instance %(instance_id)s\")\n\n\nclass MigrationNotFound(NotFound):\n    message = _(\"Migration %(migration_id)s could not be found.\")\n\n\nclass MigrationNotFoundByStatus(MigrationNotFound):\n    message = _(\"Migration not found for instance %(instance_id)s \"\n                \"with status %(status)s.\")\n\n\nclass ConsolePoolNotFound(NotFound):\n    message = _(\"Console pool %(pool_id)s could not be found.\")\n\n\nclass ConsolePoolNotFoundForHostType(NotFound):\n    message = _(\"Console pool of type %(console_type)s \"\n                \"for compute host %(compute_host)s \"\n                \"on proxy host %(host)s not found.\")\n\n\nclass ConsoleNotFound(NotFound):\n    message = _(\"Console %(console_id)s could not be found.\")\n\n\nclass ConsoleNotFoundForInstance(ConsoleNotFound):\n    message = _(\"Console for instance %(instance_id)s could not be found.\")\n\n\nclass ConsoleNotFoundInPoolForInstance(ConsoleNotFound):\n    message = _(\"Console for instance %(instance_id)s \"\n                \"in pool %(pool_id)s could not be found.\")\n\n\nclass ConsoleTypeInvalid(Invalid):\n    message = _(\"Invalid console type %(console_type)s \")\n\n\nclass NoInstanceTypesFound(NotFound):\n    message = _(\"Zero instance types found.\")\n\n\nclass InstanceTypeNotFound(NotFound):\n    message = _(\"Instance type %(instance_type_id)s could not be found.\")\n\n\nclass InstanceTypeNotFoundByName(InstanceTypeNotFound):\n    message = _(\"Instance type with name %(instance_type_name)s \"\n                \"could not be found.\")\n\n\nclass FlavorNotFound(NotFound):\n    message = _(\"Flavor %(flavor_id)s could not be found.\")\n\n\nclass CellNotFound(NotFound):\n    message = _(\"Cell %(cell_id)s could not be found.\")\n\n\nclass SchedulerHostFilterNotFound(NotFound):\n    message = _(\"Scheduler Host Filter %(filter_name)s could not be found.\")\n\n\nclass SchedulerCostFunctionNotFound(NotFound):\n    message = _(\"Scheduler cost function %(cost_fn_str)s could\"\n                \" not be found.\")\n\n\nclass SchedulerWeightFlagNotFound(NotFound):\n    message = _(\"Scheduler weight flag not found: %(flag_name)s\")\n\n\nclass InstanceMetadataNotFound(NotFound):\n    message = _(\"Instance %(instance_id)s has no metadata with \"\n                \"key %(metadata_key)s.\")\n\n\nclass InstanceTypeExtraSpecsNotFound(NotFound):\n    message = _(\"Instance Type %(instance_type_id)s has no extra specs with \"\n                \"key %(extra_specs_key)s.\")\n\n\nclass LDAPObjectNotFound(NotFound):\n    message = _(\"LDAP object could not be found\")\n\n\nclass LDAPUserNotFound(LDAPObjectNotFound):\n    message = _(\"LDAP user %(user_id)s could not be found.\")\n\n\nclass LDAPGroupNotFound(LDAPObjectNotFound):\n    message = _(\"LDAP group %(group_id)s could not be found.\")\n\n\nclass LDAPGroupMembershipNotFound(NotFound):\n    message = _(\"LDAP user %(user_id)s is not a member of group %(group_id)s.\")\n\n\nclass FileNotFound(NotFound):\n    message = _(\"File %(file_path)s could not be found.\")\n\n\nclass NoFilesFound(NotFound):\n    message = _(\"Zero files could be found.\")\n\n\nclass SwitchNotFoundForNetworkAdapter(NotFound):\n    message = _(\"Virtual switch associated with the \"\n                \"network adapter %(adapter)s not found.\")\n\n\nclass NetworkAdapterNotFound(NotFound):\n    message = _(\"Network adapter %(adapter)s could not be found.\")\n\n\nclass ClassNotFound(NotFound):\n    message = _(\"Class %(class_name)s could not be found: %(exception)s\")\n\n\nclass NotAllowed(NovaException):\n    message = _(\"Action not allowed.\")\n\n\nclass GlobalRoleNotAllowed(NotAllowed):\n    message = _(\"Unable to use global role %(role_id)s\")\n\n\nclass ImageRotationNotAllowed(NovaException):\n    message = _(\"Rotation is not allowed for snapshots\")\n\n\nclass RotationRequiredForBackup(NovaException):\n    message = _(\"Rotation param is required for backup image_type\")\n\n\n#TODO(bcwaldon): EOL this exception!\nclass Duplicate(NovaException):\n    pass\n\n\nclass KeyPairExists(Duplicate):\n    message = _(\"Key pair %(key_name)s already exists.\")\n\n\nclass UserExists(Duplicate):\n    message = _(\"User %(user)s already exists.\")\n\n\nclass LDAPUserExists(UserExists):\n    message = _(\"LDAP user %(user)s already exists.\")\n\n\nclass LDAPGroupExists(Duplicate):\n    message = _(\"LDAP group %(group)s already exists.\")\n\n\nclass LDAPMembershipExists(Duplicate):\n    message = _(\"User %(uid)s is already a member of \"\n                \"the group %(group_dn)s\")\n\n\nclass ProjectExists(Duplicate):\n    message = _(\"Project %(project)s already exists.\")\n\n\nclass InstanceExists(Duplicate):\n    message = _(\"Instance %(name)s already exists.\")\n\n\nclass InstanceTypeExists(Duplicate):\n    message = _(\"Instance Type %(name)s already exists.\")\n\n\nclass VolumeTypeExists(Duplicate):\n    message = _(\"Volume Type %(name)s already exists.\")\n\n\nclass InvalidSharedStorage(NovaException):\n    message = _(\"%(path)s is on shared storage: %(reason)s\")\n\n\nclass MigrationError(NovaException):\n    message = _(\"Migration error\") + \": %(reason)s\"\n\n\nclass MalformedRequestBody(NovaException):\n    message = _(\"Malformed message body: %(reason)s\")\n\n\nclass ConfigNotFound(NotFound):\n    message = _(\"Could not find config at %(path)s\")\n\n\nclass PasteAppNotFound(NotFound):\n    message = _(\"Could not load paste app '%(name)s' from %(path)s\")\n\n\nclass CannotResizeToSameSize(NovaException):\n    message = _(\"When resizing, instances must change size!\")\n\n\nclass ImageTooLarge(NovaException):\n    message = _(\"Image is larger than instance type allows\")\n\n\nclass ZoneRequestError(NovaException):\n    message = _(\"1 or more Zones could not complete the request\")\n\n\nclass InstanceTypeMemoryTooSmall(NovaException):\n    message = _(\"Instance type's memory is too small for requested image.\")\n\n\nclass InstanceTypeDiskTooSmall(NovaException):\n    message = _(\"Instance type's disk is too small for requested image.\")\n\n\nclass InsufficientFreeMemory(NovaException):\n    message = _(\"Insufficient free memory on compute node to start %(uuid)s.\")\n\n\nclass CouldNotFetchMetrics(NovaException):\n    message = _(\"Could not fetch bandwidth/cpu/disk metrics for this host.\")\n\n\nclass NoValidHost(NovaException):\n    message = _(\"No valid host was found. %(reason)s\")\n\n\nclass WillNotSchedule(NovaException):\n    message = _(\"Host %(host)s is not up or doesn't exist.\")\n\n\nclass QuotaError(NovaException):\n    message = _(\"Quota exceeded\") + \": code=%(code)s\"\n    code = 413\n    headers = {'Retry-After': 0}\n    safe = True\n\n\nclass AggregateError(NovaException):\n    message = _(\"Aggregate %(aggregate_id)s: action '%(action)s' \"\n                \"caused an error: %(reason)s.\")\n\n\nclass AggregateNotFound(NotFound):\n    message = _(\"Aggregate %(aggregate_id)s could not be found.\")\n\n\nclass AggregateNameExists(Duplicate):\n    message = _(\"Aggregate %(aggregate_name)s already exists.\")\n\n\nclass AggregateHostNotFound(NotFound):\n    message = _(\"Aggregate %(aggregate_id)s has no host %(host)s.\")\n\n\nclass AggregateMetadataNotFound(NotFound):\n    message = _(\"Aggregate %(aggregate_id)s has no metadata with \"\n                \"key %(metadata_key)s.\")\n\n\nclass AggregateHostConflict(Duplicate):\n    message = _(\"Host %(host)s already member of another aggregate.\")\n\n\nclass AggregateHostExists(Duplicate):\n    message = _(\"Aggregate %(aggregate_id)s already has host %(host)s.\")\n\n\nclass DuplicateSfVolumeNames(Duplicate):\n    message = _(\"Detected more than one volume with name %(vol_name)s\")\n\n\nclass VolumeTypeCreateFailed(NovaException):\n    message = _(\"Cannot create volume_type with \"\n                \"name %(name)s and specs %(extra_specs)s\")\n\n\nclass InstanceTypeCreateFailed(NovaException):\n    message = _(\"Unable to create instance type\")\n\n\nclass SolidFireAPIException(NovaException):\n    message = _(\"Bad response from SolidFire API\")\n\n\nclass SolidFireAPIStatusException(SolidFireAPIException):\n    message = _(\"Error in SolidFire API response: status=%(status)s\")\n\n\nclass SolidFireAPIDataException(SolidFireAPIException):\n    message = _(\"Error in SolidFire API response: data=%(data)s\")\n\n\nclass DuplicateVlan(Duplicate):\n    message = _(\"Detected existing vlan with id %(vlan)d\")\n\n\nclass InstanceNotFound(NotFound):\n    message = _(\"Instance %(instance_id)s could not be found.\")\n\n\nclass InvalidInstanceIDMalformed(Invalid):\n    message = _(\"Invalid id: %(val)s (expecting \\\"i-...\\\").\")\n\n\nclass CouldNotFetchImage(NovaException):\n    message = _(\"Could not fetch image %(image)s\")\n", "target": 0}
{"idx": 886, "func": "# -*- coding: utf-8 -*-\nfrom __future__ import unicode_literals\n\nimport os\nimport tempfile\n\nfrom django import forms\nfrom django.conf.urls import url\nfrom django.contrib import admin\nfrom django.contrib.admin import BooleanFieldListFilter\nfrom django.contrib.admin.views.main import ChangeList\nfrom django.contrib.auth.admin import GroupAdmin, UserAdmin\n# Register core models we need in our tests\nfrom django.contrib.auth.models import Group, User\nfrom django.core.exceptions import ValidationError\nfrom django.core.files.storage import FileSystemStorage\nfrom django.core.mail import EmailMessage\nfrom django.core.servers.basehttp import FileWrapper\nfrom django.forms.models import BaseModelFormSet\nfrom django.http import HttpResponse, StreamingHttpResponse\nfrom django.utils.safestring import mark_safe\nfrom django.utils.six import StringIO\n\nfrom .models import (\n    Actor, AdminOrderedAdminMethod, AdminOrderedCallable, AdminOrderedField,\n    AdminOrderedModelMethod, Album, Answer, Article, BarAccount, Book,\n    Category, Chapter, ChapterXtra1, Child, ChildOfReferer, Choice, City,\n    Collector, Color, Color2, ComplexSortedPerson, CoverLetter, CustomArticle,\n    CyclicOne, CyclicTwo, DependentChild, DooHickey, EmptyModel,\n    EmptyModelHidden, EmptyModelMixin, EmptyModelVisible, ExplicitlyProvidedPK,\n    ExternalSubscriber, Fabric, FancyDoodad, FieldOverridePost,\n    FilteredManager, FooAccount, FoodDelivery, FunkyTag, Gadget, Gallery,\n    GenRelReference, Grommet, ImplicitlyGeneratedPK, Ingredient,\n    InlineReference, InlineReferer, Inquisition, Language, Link,\n    MainPrepopulated, ModelWithStringPrimaryKey, NotReferenced, OldSubscriber,\n    OtherStory, Paper, Parent, ParentWithDependentChildren, ParentWithUUIDPK,\n    Person, Persona, Picture, Pizza, Plot, PlotDetails, PlotProxy,\n    PluggableSearchPerson, Podcast, Post, PrePopulatedPost,\n    PrePopulatedPostLargeSlug, PrePopulatedSubPost, Promo, Question, Recipe,\n    Recommendation, Recommender, ReferencedByGenRel, ReferencedByInline,\n    ReferencedByParent, RelatedPrepopulated, RelatedWithUUIDPKModel, Report,\n    Reservation, Restaurant, RowLevelChangePermissionModel, Section,\n    ShortMessage, Simple, Sketch, State, Story, StumpJoke, Subscriber,\n    SuperVillain, Telegram, Thing, Topping, UnchangeableObject,\n    UndeletableObject, UnorderedObject, UserMessenger, Villain, Vodcast,\n    Whatsit, Widget, Worker, WorkHour,\n)\n\n\ndef callable_year(dt_value):\n    try:\n        return dt_value.year\n    except AttributeError:\n        return None\ncallable_year.admin_order_field = 'date'\n\n\nclass ArticleInline(admin.TabularInline):\n    model = Article\n    fk_name = 'section'\n    prepopulated_fields = {\n        'title': ('content',)\n    }\n    fieldsets = (\n        ('Some fields', {\n            'classes': ('collapse',),\n            'fields': ('title', 'content')\n        }),\n        ('Some other fields', {\n            'classes': ('wide',),\n            'fields': ('date', 'section')\n        })\n    )\n\n\nclass ChapterInline(admin.TabularInline):\n    model = Chapter\n\n\nclass ChapterXtra1Admin(admin.ModelAdmin):\n    list_filter = ('chap',\n                   'chap__title',\n                   'chap__book',\n                   'chap__book__name',\n                   'chap__book__promo',\n                   'chap__book__promo__name',)\n\n\nclass ArticleAdmin(admin.ModelAdmin):\n    list_display = ('content', 'date', callable_year, 'model_year',\n                    'modeladmin_year', 'model_year_reversed', 'section')\n    list_editable = ('section',)\n    list_filter = ('date', 'section')\n    view_on_site = False\n    fieldsets = (\n        ('Some fields', {\n            'classes': ('collapse',),\n            'fields': ('title', 'content')\n        }),\n        ('Some other fields', {\n            'classes': ('wide',),\n            'fields': ('date', 'section', 'sub_section')\n        })\n    )\n\n    def changelist_view(self, request):\n        \"Test that extra_context works\"\n        return super(ArticleAdmin, self).changelist_view(\n            request, extra_context={\n                'extra_var': 'Hello!'\n            }\n        )\n\n    def modeladmin_year(self, obj):\n        return obj.date.year\n    modeladmin_year.admin_order_field = 'date'\n    modeladmin_year.short_description = None\n\n    def delete_model(self, request, obj):\n        EmailMessage(\n            'Greetings from a deleted object',\n            'I hereby inform you that some user deleted me',\n            'from@example.com',\n            ['to@example.com']\n        ).send()\n        return super(ArticleAdmin, self).delete_model(request, obj)\n\n    def save_model(self, request, obj, form, change=True):\n        EmailMessage(\n            'Greetings from a created object',\n            'I hereby inform you that some user created me',\n            'from@example.com',\n            ['to@example.com']\n        ).send()\n        return super(ArticleAdmin, self).save_model(request, obj, form, change)\n\n\nclass ArticleAdmin2(admin.ModelAdmin):\n\n    def has_module_permission(self, request):\n        return False\n\n\nclass RowLevelChangePermissionModelAdmin(admin.ModelAdmin):\n    def has_change_permission(self, request, obj=None):\n        \"\"\" Only allow changing objects with even id number \"\"\"\n        return request.user.is_staff and (obj is not None) and (obj.id % 2 == 0)\n\n\nclass CustomArticleAdmin(admin.ModelAdmin):\n    \"\"\"\n    Tests various hooks for using custom templates and contexts.\n    \"\"\"\n    change_list_template = 'custom_admin/change_list.html'\n    change_form_template = 'custom_admin/change_form.html'\n    add_form_template = 'custom_admin/add_form.html'\n    object_history_template = 'custom_admin/object_history.html'\n    delete_confirmation_template = 'custom_admin/delete_confirmation.html'\n    delete_selected_confirmation_template = 'custom_admin/delete_selected_confirmation.html'\n\n    def changelist_view(self, request):\n        \"Test that extra_context works\"\n        return super(CustomArticleAdmin, self).changelist_view(\n            request, extra_context={\n                'extra_var': 'Hello!'\n            }\n        )\n\n\nclass ThingAdmin(admin.ModelAdmin):\n    list_filter = ('color__warm', 'color__value', 'pub_date',)\n\n\nclass InquisitionAdmin(admin.ModelAdmin):\n    list_display = ('leader', 'country', 'expected', 'sketch')\n\n    def sketch(self, obj):\n        # A method with the same name as a reverse accessor.\n        return 'list-display-sketch'\n\n\nclass SketchAdmin(admin.ModelAdmin):\n    raw_id_fields = ('inquisition', 'defendant0', 'defendant1')\n\n\nclass FabricAdmin(admin.ModelAdmin):\n    list_display = ('surface',)\n    list_filter = ('surface',)\n\n\nclass BasePersonModelFormSet(BaseModelFormSet):\n    def clean(self):\n        for person_dict in self.cleaned_data:\n            person = person_dict.get('id')\n            alive = person_dict.get('alive')\n            if person and alive and person.name == \"Grace Hopper\":\n                raise forms.ValidationError(\"Grace is not a Zombie\")\n\n\nclass PersonAdmin(admin.ModelAdmin):\n    list_display = ('name', 'gender', 'alive')\n    list_editable = ('gender', 'alive')\n    list_filter = ('gender',)\n    search_fields = ('^name',)\n    save_as = True\n\n    def get_changelist_formset(self, request, **kwargs):\n        return super(PersonAdmin, self).get_changelist_formset(request,\n            formset=BasePersonModelFormSet, **kwargs)\n\n    def get_queryset(self, request):\n        # Order by a field that isn't in list display, to be able to test\n        # whether ordering is preserved.\n        return super(PersonAdmin, self).get_queryset(request).order_by('age')\n\n\nclass FooAccountAdmin(admin.StackedInline):\n    model = FooAccount\n    extra = 1\n\n\nclass BarAccountAdmin(admin.StackedInline):\n    model = BarAccount\n    extra = 1\n\n\nclass PersonaAdmin(admin.ModelAdmin):\n    inlines = (\n        FooAccountAdmin,\n        BarAccountAdmin\n    )\n\n\nclass SubscriberAdmin(admin.ModelAdmin):\n    actions = ['mail_admin']\n\n    def mail_admin(self, request, selected):\n        EmailMessage(\n            'Greetings from a ModelAdmin action',\n            'This is the test email from an admin action',\n            'from@example.com',\n            ['to@example.com']\n        ).send()\n\n\ndef external_mail(modeladmin, request, selected):\n    EmailMessage(\n        'Greetings from a function action',\n        'This is the test email from a function action',\n        'from@example.com',\n        ['to@example.com']\n    ).send()\nexternal_mail.short_description = 'External mail (Another awesome action)'\n\n\ndef redirect_to(modeladmin, request, selected):\n    from django.http import HttpResponseRedirect\n    return HttpResponseRedirect('/some-where-else/')\nredirect_to.short_description = 'Redirect to (Awesome action)'\n\n\ndef download(modeladmin, request, selected):\n    buf = StringIO('This is the content of the file')\n    return StreamingHttpResponse(FileWrapper(buf))\ndownload.short_description = 'Download subscription'\n\n\ndef no_perm(modeladmin, request, selected):\n    return HttpResponse(content='No permission to perform this action',\n                        status=403)\nno_perm.short_description = 'No permission to run'\n\n\nclass ExternalSubscriberAdmin(admin.ModelAdmin):\n    actions = [redirect_to, external_mail, download, no_perm]\n\n\nclass PodcastAdmin(admin.ModelAdmin):\n    list_display = ('name', 'release_date')\n    list_editable = ('release_date',)\n    date_hierarchy = 'release_date'\n    ordering = ('name',)\n\n\nclass VodcastAdmin(admin.ModelAdmin):\n    list_display = ('name', 'released')\n    list_editable = ('released',)\n\n    ordering = ('name',)\n\n\nclass ChildInline(admin.StackedInline):\n    model = Child\n\n\nclass ParentAdmin(admin.ModelAdmin):\n    model = Parent\n    inlines = [ChildInline]\n\n    list_editable = ('name',)\n\n    def save_related(self, request, form, formsets, change):\n        super(ParentAdmin, self).save_related(request, form, formsets, change)\n        first_name, last_name = form.instance.name.split()\n        for child in form.instance.child_set.all():\n            if len(child.name.split()) < 2:\n                child.name = child.name + ' ' + last_name\n                child.save()\n\n\nclass EmptyModelAdmin(admin.ModelAdmin):\n    def get_queryset(self, request):\n        return super(EmptyModelAdmin, self).get_queryset(request).filter(pk__gt=1)\n\n\nclass OldSubscriberAdmin(admin.ModelAdmin):\n    actions = None\n\n\ntemp_storage = FileSystemStorage(tempfile.mkdtemp())\nUPLOAD_TO = os.path.join(temp_storage.location, 'test_upload')\n\n\nclass PictureInline(admin.TabularInline):\n    model = Picture\n    extra = 1\n\n\nclass GalleryAdmin(admin.ModelAdmin):\n    inlines = [PictureInline]\n\n\nclass PictureAdmin(admin.ModelAdmin):\n    pass\n\n\nclass LanguageAdmin(admin.ModelAdmin):\n    list_display = ['iso', 'shortlist', 'english_name', 'name']\n    list_editable = ['shortlist']\n\n\nclass RecommendationAdmin(admin.ModelAdmin):\n    show_full_result_count = False\n    search_fields = ('=titletranslation__text', '=recommender__titletranslation__text',)\n\n\nclass WidgetInline(admin.StackedInline):\n    model = Widget\n\n\nclass DooHickeyInline(admin.StackedInline):\n    model = DooHickey\n\n\nclass GrommetInline(admin.StackedInline):\n    model = Grommet\n\n\nclass WhatsitInline(admin.StackedInline):\n    model = Whatsit\n\n\nclass FancyDoodadInline(admin.StackedInline):\n    model = FancyDoodad\n\n\nclass CategoryAdmin(admin.ModelAdmin):\n    list_display = ('id', 'collector', 'order')\n    list_editable = ('order',)\n\n\nclass CategoryInline(admin.StackedInline):\n    model = Category\n\n\nclass CollectorAdmin(admin.ModelAdmin):\n    inlines = [\n        WidgetInline, DooHickeyInline, GrommetInline, WhatsitInline,\n        FancyDoodadInline, CategoryInline\n    ]\n\n\nclass LinkInline(admin.TabularInline):\n    model = Link\n    extra = 1\n\n    readonly_fields = (\"posted\", \"multiline\", \"readonly_link_content\")\n\n    def multiline(self, instance):\n        return \"InlineMultiline\\ntest\\nstring\"\n\n\nclass SubPostInline(admin.TabularInline):\n    model = PrePopulatedSubPost\n\n    prepopulated_fields = {\n        'subslug': ('subtitle',)\n    }\n\n    def get_readonly_fields(self, request, obj=None):\n        if obj and obj.published:\n            return ('subslug',)\n        return self.readonly_fields\n\n    def get_prepopulated_fields(self, request, obj=None):\n        if obj and obj.published:\n            return {}\n        return self.prepopulated_fields\n\n\nclass PrePopulatedPostAdmin(admin.ModelAdmin):\n    list_display = ['title', 'slug']\n    prepopulated_fields = {\n        'slug': ('title',)\n    }\n\n    inlines = [SubPostInline]\n\n    def get_readonly_fields(self, request, obj=None):\n        if obj and obj.published:\n            return ('slug',)\n        return self.readonly_fields\n\n    def get_prepopulated_fields(self, request, obj=None):\n        if obj and obj.published:\n            return {}\n        return self.prepopulated_fields\n\n\nclass PostAdmin(admin.ModelAdmin):\n    list_display = ['title', 'public']\n    readonly_fields = (\n        'posted', 'awesomeness_level', 'coolness', 'value',\n        'multiline', 'multiline_html', lambda obj: \"foo\", 'readonly_content',\n    )\n\n    inlines = [\n        LinkInline\n    ]\n\n    def coolness(self, instance):\n        if instance.pk:\n            return \"%d amount of cool.\" % instance.pk\n        else:\n            return \"Unknown coolness.\"\n\n    def value(self, instance):\n        return 1000\n\n    def multiline(self, instance):\n        return \"Multiline\\ntest\\nstring\"\n\n    def multiline_html(self, instance):\n        return mark_safe(\"Multiline<br>\\nhtml<br>\\ncontent\")\n    multiline_html.allow_tags = True\n\n    value.short_description = 'Value in $US'\n\n\nclass FieldOverridePostForm(forms.ModelForm):\n    model = FieldOverridePost\n\n    class Meta:\n        help_texts = {\n            'posted': 'Overridden help text for the date',\n        }\n        labels = {\n            'public': 'Overridden public label',\n        }\n\n\nclass FieldOverridePostAdmin(PostAdmin):\n    form = FieldOverridePostForm\n\n\nclass CustomChangeList(ChangeList):\n    def get_queryset(self, request):\n        return self.root_queryset.filter(pk=9999)  # Does not exist\n\n\nclass GadgetAdmin(admin.ModelAdmin):\n    def get_changelist(self, request, **kwargs):\n        return CustomChangeList\n\n\nclass ToppingAdmin(admin.ModelAdmin):\n    readonly_fields = ('pizzas',)\n\n\nclass PizzaAdmin(admin.ModelAdmin):\n    readonly_fields = ('toppings',)\n\n\nclass WorkHourAdmin(admin.ModelAdmin):\n    list_display = ('datum', 'employee')\n    list_filter = ('employee',)\n\n\nclass FoodDeliveryAdmin(admin.ModelAdmin):\n    list_display = ('reference', 'driver', 'restaurant')\n    list_editable = ('driver', 'restaurant')\n\n\nclass CoverLetterAdmin(admin.ModelAdmin):\n    \"\"\"\n    A ModelAdmin with a custom get_queryset() method that uses defer(), to test\n    verbose_name display in messages shown after adding/editing CoverLetter\n    instances.\n    Note that the CoverLetter model defines a __unicode__ method.\n    For testing fix for ticket #14529.\n    \"\"\"\n\n    def get_queryset(self, request):\n        return super(CoverLetterAdmin, self).get_queryset(request).defer('date_written')\n\n\nclass PaperAdmin(admin.ModelAdmin):\n    \"\"\"\n    A ModelAdmin with a custom get_queryset() method that uses only(), to test\n    verbose_name display in messages shown after adding/editing Paper\n    instances.\n    For testing fix for ticket #14529.\n    \"\"\"\n\n    def get_queryset(self, request):\n        return super(PaperAdmin, self).get_queryset(request).only('title')\n\n\nclass ShortMessageAdmin(admin.ModelAdmin):\n    \"\"\"\n    A ModelAdmin with a custom get_queryset() method that uses defer(), to test\n    verbose_name display in messages shown after adding/editing ShortMessage\n    instances.\n    For testing fix for ticket #14529.\n    \"\"\"\n\n    def get_queryset(self, request):\n        return super(ShortMessageAdmin, self).get_queryset(request).defer('timestamp')\n\n\nclass TelegramAdmin(admin.ModelAdmin):\n    \"\"\"\n    A ModelAdmin with a custom get_queryset() method that uses only(), to test\n    verbose_name display in messages shown after adding/editing Telegram\n    instances.\n    Note that the Telegram model defines a __unicode__ method.\n    For testing fix for ticket #14529.\n    \"\"\"\n\n    def get_queryset(self, request):\n        return super(TelegramAdmin, self).get_queryset(request).only('title')\n\n\nclass StoryForm(forms.ModelForm):\n    class Meta:\n        widgets = {'title': forms.HiddenInput}\n\n\nclass StoryAdmin(admin.ModelAdmin):\n    list_display = ('id', 'title', 'content')\n    list_display_links = ('title',)  # 'id' not in list_display_links\n    list_editable = ('content', )\n    form = StoryForm\n    ordering = [\"-pk\"]\n\n\nclass OtherStoryAdmin(admin.ModelAdmin):\n    list_display = ('id', 'title', 'content')\n    list_display_links = ('title', 'id')  # 'id' in list_display_links\n    list_editable = ('content', )\n    ordering = [\"-pk\"]\n\n\nclass ComplexSortedPersonAdmin(admin.ModelAdmin):\n    list_display = ('name', 'age', 'is_employee', 'colored_name')\n    ordering = ('name',)\n\n    def colored_name(self, obj):\n        return '<span style=\"color: #%s;\">%s</span>' % ('ff00ff', obj.name)\n    colored_name.allow_tags = True\n    colored_name.admin_order_field = 'name'\n\n\nclass PluggableSearchPersonAdmin(admin.ModelAdmin):\n    list_display = ('name', 'age')\n    search_fields = ('name',)\n\n    def get_search_results(self, request, queryset, search_term):\n        queryset, use_distinct = super(PluggableSearchPersonAdmin, self).get_search_results(request, queryset, search_term)\n        try:\n            search_term_as_int = int(search_term)\n            queryset |= self.model.objects.filter(age=search_term_as_int)\n        except:\n            pass\n        return queryset, use_distinct\n\n\nclass AlbumAdmin(admin.ModelAdmin):\n    list_filter = ['title']\n\n\nclass PrePopulatedPostLargeSlugAdmin(admin.ModelAdmin):\n    prepopulated_fields = {\n        'slug': ('title',)\n    }\n\n\nclass AdminOrderedFieldAdmin(admin.ModelAdmin):\n    ordering = ('order',)\n    list_display = ('stuff', 'order')\n\n\nclass AdminOrderedModelMethodAdmin(admin.ModelAdmin):\n    ordering = ('order',)\n    list_display = ('stuff', 'some_order')\n\n\nclass AdminOrderedAdminMethodAdmin(admin.ModelAdmin):\n    def some_admin_order(self, obj):\n        return obj.order\n    some_admin_order.admin_order_field = 'order'\n    ordering = ('order',)\n    list_display = ('stuff', 'some_admin_order')\n\n\ndef admin_ordered_callable(obj):\n    return obj.order\nadmin_ordered_callable.admin_order_field = 'order'\n\n\nclass AdminOrderedCallableAdmin(admin.ModelAdmin):\n    ordering = ('order',)\n    list_display = ('stuff', admin_ordered_callable)\n\n\nclass ReportAdmin(admin.ModelAdmin):\n    def extra(self, request):\n        return HttpResponse()\n\n    def get_urls(self):\n        # Corner case: Don't call parent implementation\n        return [\n            url(r'^extra/$',\n                self.extra,\n                name='cable_extra'),\n        ]\n\n\nclass CustomTemplateBooleanFieldListFilter(BooleanFieldListFilter):\n    template = 'custom_filter_template.html'\n\n\nclass CustomTemplateFilterColorAdmin(admin.ModelAdmin):\n    list_filter = (('warm', CustomTemplateBooleanFieldListFilter),)\n\n\n# For Selenium Prepopulated tests -------------------------------------\nclass RelatedPrepopulatedInline1(admin.StackedInline):\n    fieldsets = (\n        (None, {\n            'fields': (('pubdate', 'status'), ('name', 'slug1', 'slug2',),)\n        }),\n    )\n    model = RelatedPrepopulated\n    extra = 1\n    prepopulated_fields = {'slug1': ['name', 'pubdate'],\n                           'slug2': ['status', 'name']}\n\n\nclass RelatedPrepopulatedInline2(admin.TabularInline):\n    model = RelatedPrepopulated\n    extra = 1\n    prepopulated_fields = {'slug1': ['name', 'pubdate'],\n                           'slug2': ['status', 'name']}\n\n\nclass MainPrepopulatedAdmin(admin.ModelAdmin):\n    inlines = [RelatedPrepopulatedInline1, RelatedPrepopulatedInline2]\n    fieldsets = (\n        (None, {\n            'fields': (('pubdate', 'status'), ('name', 'slug1', 'slug2',),)\n        }),\n    )\n    prepopulated_fields = {'slug1': ['name', 'pubdate'],\n                           'slug2': ['status', 'name']}\n\n\nclass UnorderedObjectAdmin(admin.ModelAdmin):\n    list_display = ['name']\n    list_editable = ['name']\n    list_per_page = 2\n\n\nclass UndeletableObjectAdmin(admin.ModelAdmin):\n    def change_view(self, *args, **kwargs):\n        kwargs['extra_context'] = {'show_delete': False}\n        return super(UndeletableObjectAdmin, self).change_view(*args, **kwargs)\n\n\nclass UnchangeableObjectAdmin(admin.ModelAdmin):\n    def get_urls(self):\n        # Disable change_view, but leave other urls untouched\n        urlpatterns = super(UnchangeableObjectAdmin, self).get_urls()\n        return [p for p in urlpatterns if not p.name.endswith(\"_change\")]\n\n\ndef callable_on_unknown(obj):\n    return obj.unknown\n\n\nclass AttributeErrorRaisingAdmin(admin.ModelAdmin):\n    list_display = [callable_on_unknown, ]\n\n\nclass CustomManagerAdmin(admin.ModelAdmin):\n    def get_queryset(self, request):\n        return FilteredManager.objects\n\n\nclass MessageTestingAdmin(admin.ModelAdmin):\n    actions = [\"message_debug\", \"message_info\", \"message_success\",\n               \"message_warning\", \"message_error\", \"message_extra_tags\"]\n\n    def message_debug(self, request, selected):\n        self.message_user(request, \"Test debug\", level=\"debug\")\n\n    def message_info(self, request, selected):\n        self.message_user(request, \"Test info\", level=\"info\")\n\n    def message_success(self, request, selected):\n        self.message_user(request, \"Test success\", level=\"success\")\n\n    def message_warning(self, request, selected):\n        self.message_user(request, \"Test warning\", level=\"warning\")\n\n    def message_error(self, request, selected):\n        self.message_user(request, \"Test error\", level=\"error\")\n\n    def message_extra_tags(self, request, selected):\n        self.message_user(request, \"Test tags\", extra_tags=\"extra_tag\")\n\n\nclass ChoiceList(admin.ModelAdmin):\n    list_display = ['choice']\n    readonly_fields = ['choice']\n    fields = ['choice']\n\n\nclass DependentChildAdminForm(forms.ModelForm):\n    \"\"\"\n    Issue #20522\n    Form to test child dependency on parent object's validation\n    \"\"\"\n    def clean(self):\n        parent = self.cleaned_data.get('parent')\n        if parent.family_name and parent.family_name != self.cleaned_data.get('family_name'):\n            raise ValidationError(\"Children must share a family name with their parents \" +\n                                  \"in this contrived test case\")\n        return super(DependentChildAdminForm, self).clean()\n\n\nclass DependentChildInline(admin.TabularInline):\n    model = DependentChild\n    form = DependentChildAdminForm\n\n\nclass ParentWithDependentChildrenAdmin(admin.ModelAdmin):\n    inlines = [DependentChildInline]\n\n\n# Tests for ticket 11277 ----------------------------------\n\nclass FormWithoutHiddenField(forms.ModelForm):\n    first = forms.CharField()\n    second = forms.CharField()\n\n\nclass FormWithoutVisibleField(forms.ModelForm):\n    first = forms.CharField(widget=forms.HiddenInput)\n    second = forms.CharField(widget=forms.HiddenInput)\n\n\nclass FormWithVisibleAndHiddenField(forms.ModelForm):\n    first = forms.CharField(widget=forms.HiddenInput)\n    second = forms.CharField()\n\n\nclass EmptyModelVisibleAdmin(admin.ModelAdmin):\n    form = FormWithoutHiddenField\n    fieldsets = (\n        (None, {\n            'fields': (('first', 'second'),),\n        }),\n    )\n\n\nclass EmptyModelHiddenAdmin(admin.ModelAdmin):\n    form = FormWithoutVisibleField\n    fieldsets = EmptyModelVisibleAdmin.fieldsets\n\n\nclass EmptyModelMixinAdmin(admin.ModelAdmin):\n    form = FormWithVisibleAndHiddenField\n    fieldsets = EmptyModelVisibleAdmin.fieldsets\n\n\nclass CityInlineAdmin(admin.TabularInline):\n    model = City\n    view_on_site = False\n\n\nclass StateAdmin(admin.ModelAdmin):\n    inlines = [CityInlineAdmin]\n\n\nclass RestaurantInlineAdmin(admin.TabularInline):\n    model = Restaurant\n    view_on_site = True\n\n\nclass CityAdmin(admin.ModelAdmin):\n    inlines = [RestaurantInlineAdmin]\n    view_on_site = True\n\n\nclass WorkerAdmin(admin.ModelAdmin):\n    def view_on_site(self, obj):\n        return '/worker/%s/%s/' % (obj.surname, obj.name)\n\n\nclass WorkerInlineAdmin(admin.TabularInline):\n    model = Worker\n\n    def view_on_site(self, obj):\n        return '/worker_inline/%s/%s/' % (obj.surname, obj.name)\n\n\nclass RestaurantAdmin(admin.ModelAdmin):\n    inlines = [WorkerInlineAdmin]\n    view_on_site = False\n\n    def get_changeform_initial_data(self, request):\n        return {'name': 'overridden_value'}\n\n\nclass FunkyTagAdmin(admin.ModelAdmin):\n    list_display = ('name', 'content_object')\n\n\nclass InlineReferenceInline(admin.TabularInline):\n    model = InlineReference\n\n\nclass InlineRefererAdmin(admin.ModelAdmin):\n    inlines = [InlineReferenceInline]\n\n\nclass PlotReadonlyAdmin(admin.ModelAdmin):\n    readonly_fields = ('plotdetails',)\n\n\nclass GetFormsetsArgumentCheckingAdmin(admin.ModelAdmin):\n    fields = ['name']\n\n    def add_view(self, request, *args, **kwargs):\n        request.is_add_view = True\n        return super(GetFormsetsArgumentCheckingAdmin, self).add_view(request, *args, **kwargs)\n\n    def change_view(self, request, *args, **kwargs):\n        request.is_add_view = False\n        return super(GetFormsetsArgumentCheckingAdmin, self).change_view(request, *args, **kwargs)\n\n    def get_formsets_with_inlines(self, request, obj=None):\n        if request.is_add_view and obj is not None:\n            raise Exception(\"'obj' passed to get_formsets_with_inlines wasn't None during add_view\")\n        if not request.is_add_view and obj is None:\n            raise Exception(\"'obj' passed to get_formsets_with_inlines was None during change_view\")\n        return super(GetFormsetsArgumentCheckingAdmin, self).get_formsets_with_inlines(request, obj)\n\n\nsite = admin.AdminSite(name=\"admin\")\nsite.site_url = '/my-site-url/'\nsite.register(Article, ArticleAdmin)\nsite.register(CustomArticle, CustomArticleAdmin)\nsite.register(Section, save_as=True, inlines=[ArticleInline], readonly_fields=['name_property'])\nsite.register(ModelWithStringPrimaryKey)\nsite.register(Color)\nsite.register(Thing, ThingAdmin)\nsite.register(Actor)\nsite.register(Inquisition, InquisitionAdmin)\nsite.register(Sketch, SketchAdmin)\nsite.register(Person, PersonAdmin)\nsite.register(Persona, PersonaAdmin)\nsite.register(Subscriber, SubscriberAdmin)\nsite.register(ExternalSubscriber, ExternalSubscriberAdmin)\nsite.register(OldSubscriber, OldSubscriberAdmin)\nsite.register(Podcast, PodcastAdmin)\nsite.register(Vodcast, VodcastAdmin)\nsite.register(Parent, ParentAdmin)\nsite.register(EmptyModel, EmptyModelAdmin)\nsite.register(Fabric, FabricAdmin)\nsite.register(Gallery, GalleryAdmin)\nsite.register(Picture, PictureAdmin)\nsite.register(Language, LanguageAdmin)\nsite.register(Recommendation, RecommendationAdmin)\nsite.register(Recommender)\nsite.register(Collector, CollectorAdmin)\nsite.register(Category, CategoryAdmin)\nsite.register(Post, PostAdmin)\nsite.register(FieldOverridePost, FieldOverridePostAdmin)\nsite.register(Gadget, GadgetAdmin)\nsite.register(Villain)\nsite.register(SuperVillain)\nsite.register(Plot)\nsite.register(PlotDetails)\nsite.register(PlotProxy, PlotReadonlyAdmin)\nsite.register(CyclicOne)\nsite.register(CyclicTwo)\nsite.register(WorkHour, WorkHourAdmin)\nsite.register(Reservation)\nsite.register(FoodDelivery, FoodDeliveryAdmin)\nsite.register(RowLevelChangePermissionModel, RowLevelChangePermissionModelAdmin)\nsite.register(Paper, PaperAdmin)\nsite.register(CoverLetter, CoverLetterAdmin)\nsite.register(ShortMessage, ShortMessageAdmin)\nsite.register(Telegram, TelegramAdmin)\nsite.register(Story, StoryAdmin)\nsite.register(OtherStory, OtherStoryAdmin)\nsite.register(Report, ReportAdmin)\nsite.register(MainPrepopulated, MainPrepopulatedAdmin)\nsite.register(UnorderedObject, UnorderedObjectAdmin)\nsite.register(UndeletableObject, UndeletableObjectAdmin)\nsite.register(UnchangeableObject, UnchangeableObjectAdmin)\nsite.register(State, StateAdmin)\nsite.register(City, CityAdmin)\nsite.register(Restaurant, RestaurantAdmin)\nsite.register(Worker, WorkerAdmin)\nsite.register(FunkyTag, FunkyTagAdmin)\nsite.register(ReferencedByParent)\nsite.register(ChildOfReferer)\nsite.register(ReferencedByInline)\nsite.register(InlineReferer, InlineRefererAdmin)\nsite.register(ReferencedByGenRel)\nsite.register(GenRelReference)\n\n# We intentionally register Promo and ChapterXtra1 but not Chapter nor ChapterXtra2.\n# That way we cover all four cases:\n#     related ForeignKey object registered in admin\n#     related ForeignKey object not registered in admin\n#     related OneToOne object registered in admin\n#     related OneToOne object not registered in admin\n# when deleting Book so as exercise all four troublesome (w.r.t escaping\n# and calling force_text to avoid problems on Python 2.3) paths through\n# contrib.admin.utils's get_deleted_objects function.\nsite.register(Book, inlines=[ChapterInline])\nsite.register(Promo)\nsite.register(ChapterXtra1, ChapterXtra1Admin)\nsite.register(Pizza, PizzaAdmin)\nsite.register(Topping, ToppingAdmin)\nsite.register(Album, AlbumAdmin)\nsite.register(Question)\nsite.register(Answer)\nsite.register(PrePopulatedPost, PrePopulatedPostAdmin)\nsite.register(ComplexSortedPerson, ComplexSortedPersonAdmin)\nsite.register(FilteredManager, CustomManagerAdmin)\nsite.register(PluggableSearchPerson, PluggableSearchPersonAdmin)\nsite.register(PrePopulatedPostLargeSlug, PrePopulatedPostLargeSlugAdmin)\nsite.register(AdminOrderedField, AdminOrderedFieldAdmin)\nsite.register(AdminOrderedModelMethod, AdminOrderedModelMethodAdmin)\nsite.register(AdminOrderedAdminMethod, AdminOrderedAdminMethodAdmin)\nsite.register(AdminOrderedCallable, AdminOrderedCallableAdmin)\nsite.register(Color2, CustomTemplateFilterColorAdmin)\nsite.register(Simple, AttributeErrorRaisingAdmin)\nsite.register(UserMessenger, MessageTestingAdmin)\nsite.register(Choice, ChoiceList)\nsite.register(ParentWithDependentChildren, ParentWithDependentChildrenAdmin)\nsite.register(EmptyModelHidden, EmptyModelHiddenAdmin)\nsite.register(EmptyModelVisible, EmptyModelVisibleAdmin)\nsite.register(EmptyModelMixin, EmptyModelMixinAdmin)\nsite.register(StumpJoke)\nsite.register(Recipe)\nsite.register(Ingredient)\nsite.register(NotReferenced)\nsite.register(ExplicitlyProvidedPK, GetFormsetsArgumentCheckingAdmin)\nsite.register(ImplicitlyGeneratedPK, GetFormsetsArgumentCheckingAdmin)\n\nsite.register(User, UserAdmin)\nsite.register(Group, GroupAdmin)\n\n# Used to test URL namespaces\nsite2 = admin.AdminSite(name=\"namespaced_admin\")\nsite2.register(User, UserAdmin)\nsite2.register(Group, GroupAdmin)\nsite2.register(ParentWithUUIDPK)\nsite2.register(\n    RelatedWithUUIDPKModel,\n    list_display=['pk', 'parent'],\n    list_editable=['parent'],\n    raw_id_fields=['parent'],\n)\n\nsite7 = admin.AdminSite(name=\"admin7\")\nsite7.register(Article, ArticleAdmin2)\n", "target": 0}
{"idx": 887, "func": "# Copyright 2011 Justin Santa Barbara\n# Copyright 2015 Canonical Ltd\n# All Rights Reserved.\n#\n#    Licensed under the Apache License, Version 2.0 (the \"License\"); you may\n#    not use this file except in compliance with the License. You may obtain\n#    a copy of the License at\n#\n#         http://www.apache.org/licenses/LICENSE-2.0\n#\n#    Unless required by applicable law or agreed to in writing, software\n#    distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n#    License for the specific language governing permissions and limitations\n#    under the License.\n\nimport socket\n\nfrom nova import exception\nfrom nova import i18n\nfrom nova.virt import configdrive\n\nfrom oslo_config import cfg\nfrom oslo_log import log as logging\nfrom oslo_utils import excutils\n\nfrom nova_lxd.nova.virt.lxd import session\nfrom nova_lxd.nova.virt.lxd import utils as container_dir\nfrom nova_lxd.nova.virt.lxd import vif\n\n_ = i18n._\n_LE = i18n._LE\n_LI = i18n._LI\n\nCONF = cfg.CONF\nCONF.import_opt('my_ip', 'nova.netconf')\nLOG = logging.getLogger(__name__)\n\n\nclass LXDContainerConfig(object):\n    \"\"\"LXD configuration methods.\"\"\"\n\n    def __init__(self):\n        self.container_dir = container_dir.LXDContainerDirectories()\n        self.session = session.LXDAPISession()\n        self.vif_driver = vif.LXDGenericDriver()\n\n    def create_container(self, instance):\n        \"\"\"Create a LXD container dictionary so that we can\n           use it to initialize a container\n\n           :param instance: nova instance object\n        \"\"\"\n        LOG.debug('create_container called for instance', instance=instance)\n\n        instance_name = instance.name\n        try:\n\n            # Fetch the container configuration from the current nova\n            # instance object\n            container_config = {\n                'name': instance_name,\n                'profiles': [str(instance.name)],\n                'source': self.get_container_source(instance),\n                'devices': {}\n            }\n\n            # if a configdrive is required, setup the mount point for\n            # the container\n            if configdrive.required_by(instance):\n                configdrive_dir = \\\n                    self.container_dir.get_container_configdrive(\n                        instance.name)\n                config = self.configure_disk_path(configdrive_dir,\n                                                  'var/lib/cloud/data',\n                                                  'configdrive', instance)\n                container_config['devices'].update(config)\n\n            if container_config is None:\n                msg = _('Failed to get container configuration for %s') \\\n                    % instance_name\n                raise exception.NovaException(msg)\n            return container_config\n        except Exception as ex:\n            with excutils.save_and_reraise_exception():\n                LOG.error('Failed to get container configuration'\n                          ' %(instance)s: %(ex)s',\n                          {'instance': instance_name, 'ex': ex},\n                          instance=instance)\n\n    def create_profile(self, instance, network_info):\n        \"\"\"Create a LXD container profile configuration\n\n        :param instance: nova instance object\n        :param network_info: nova network configuration object\n        :return: LXD container profile dictionary\n        \"\"\"\n        LOG.debug('create_container_profile called for instance',\n                  instance=instance)\n        instance_name = instance.name\n        try:\n            config = {}\n            config['name'] = str(instance_name)\n            config['config'] = self.create_config(instance_name, instance)\n\n            # Restrict the size of the \"/\" disk\n            config['devices'] = self.configure_container_root(instance)\n\n            if network_info:\n                config['devices'].update(self.create_network(instance_name,\n                                                             instance,\n                                                             network_info))\n\n            return config\n        except Exception as ex:\n            with excutils.save_and_reraise_exception():\n                LOG.error(\n                    _LE('Failed to create profile %(instance)s: %(ex)s'),\n                    {'instance': instance_name, 'ex': ex}, instance=instance)\n\n    def create_config(self, instance_name, instance):\n        \"\"\"Create the LXD container resources\n\n        :param instance_name: instance name\n        :param instance: nova instance object\n        :return: LXD resources dictionary\n        \"\"\"\n        LOG.debug('create_config called for instance', instance=instance)\n        try:\n            config = {}\n\n            # Update continaer options\n            config.update(self.config_instance_options(config, instance))\n\n            # Set the instance memory limit\n            mem = instance.memory_mb\n            if mem >= 0:\n                config['limits.memory'] = '%sMB' % mem\n\n            # Set the instance vcpu limit\n            vcpus = instance.flavor.vcpus\n            if vcpus >= 0:\n                config['limits.cpu'] = str(vcpus)\n\n            # Configure the console for the instance\n            config['raw.lxc'] = 'lxc.console.logfile=%s\\n' \\\n                % self.container_dir.get_console_path(instance_name)\n\n            return config\n        except Exception as ex:\n            with excutils.save_and_reraise_exception():\n                LOG.error(\n                    _LE('Failed to set container resources %(instance)s: '\n                        '%(ex)s'), {'instance': instance_name, 'ex': ex},\n                    instance=instance)\n\n    def config_instance_options(self, config, instance):\n        LOG.debug('config_instance_options called for instance',\n                  instance=instance)\n\n        # Set the container to autostart when the host reboots\n        config['boot.autostart'] = 'True'\n\n        # Determine if we require a nested container\n        flavor = instance.flavor\n        lxd_nested_allowed = flavor.extra_specs.get(\n            'lxd:nested_allowed', False)\n        if lxd_nested_allowed:\n            config['security.nesting'] = 'True'\n\n        # Determine if we require a privileged container\n        lxd_privileged_allowed = flavor.extra_specs.get(\n            'lxd:privileged_allowed', False)\n        if lxd_privileged_allowed:\n            config['security.privileged'] = 'True'\n\n        lxd_isolated = flavor.extra_specs.get(\n            'lxd:isolated', False)\n        if lxd_isolated:\n            extensions = self.session.get_host_extensions()\n            if 'id_map' in extensions:\n                config['security.idmap.isolated'] = 'True'\n            else:\n                msg = _('Host does not support isolated instances')\n                raise exception.NovaException(msg)\n\n        return config\n\n    def configure_container_root(self, instance):\n        LOG.debug('configure_container_root called for instance',\n                  instance=instance)\n        try:\n            config = {}\n            lxd_config = self.session.get_host_config(instance)\n            if str(lxd_config['storage']) in ['btrfs', 'zfs']:\n                config['root'] = {'path': '/',\n                                  'type': 'disk',\n                                  'size': '%sGB' % str(instance.root_gb)}\n            else:\n                config['root'] = {'path': '/',\n                                  'type': 'disk'}\n            return config\n        except Exception as ex:\n            with excutils.save_and_reraise_exception():\n                LOG.error(_LE('Failed to configure disk for '\n                              '%(instance)s: %(ex)s'),\n                          {'instance': instance.name, 'ex': ex},\n                          instance=instance)\n\n    def create_network(self, instance_name, instance, network_info):\n        \"\"\"Create the LXD container network on the host\n\n        :param instance_name: nova instance name\n        :param instance: nova instance object\n        :param network_info: instance network configuration object\n        :return:network configuration dictionary\n        \"\"\"\n        LOG.debug('create_network called for instance', instance=instance)\n        try:\n            network_devices = {}\n\n            if not network_info:\n                return\n\n            for vifaddr in network_info:\n                cfg = self.vif_driver.get_config(instance, vifaddr)\n                key = str(cfg['bridge'])\n                network_devices[key] = \\\n                    {'nictype': 'bridged',\n                     'hwaddr': str(cfg['mac_address']),\n                     'parent': key,\n                     'type': 'nic'}\n                host_device = self.vif_driver.get_vif_devname(vifaddr)\n                if host_device:\n                    network_devices[key]['host_name'] = host_device\n                return network_devices\n        except Exception as ex:\n            with excutils.save_and_reraise_exception():\n                LOG.error(\n                    _LE('Fail to configure network for %(instance)s: %(ex)s'),\n                    {'instance': instance_name, 'ex': ex}, instance=instance)\n\n    def get_container_source(self, instance):\n        \"\"\"Set the LXD container image for the instance.\n\n        :param instance: nova instance object\n        :return: the container source\n        \"\"\"\n        LOG.debug('get_container_source called for instance',\n                  instance=instance)\n        try:\n            container_source = {'type': 'image',\n                                'alias': str(instance.image_ref)}\n            if container_source is None:\n                msg = _('Failed to determine container source for %s') \\\n                    % instance.name\n                raise exception.NovaException(msg)\n            return container_source\n        except Exception as ex:\n            with excutils.save_and_reraise_exception():\n                LOG.error(\n                    _LE('Failed to configure container source '\n                        '%(instance)s: %(ex)s'),\n                    {'instance': instance.name, 'ex': ex},\n                    instance=instance)\n\n    def get_container_migrate(self, container_migrate, migration,\n                              host, instance):\n        LOG.debug('get_container_migrate called for instance',\n                  instance=instance)\n        try:\n            # Generate the container config\n            host = socket.gethostbyname(host)\n            container_metadata = container_migrate['metadata']\n            container_control = container_metadata['metadata']['control']\n            container_fs = container_metadata['metadata']['fs']\n\n            container_url = 'https://%s:8443%s' \\\n                % (host, container_migrate.get('operation'))\n\n            container_migrate = {\n                'base_image': '',\n                'mode': 'pull',\n                'certificate': str(self.session.host_certificate(instance,\n                                                                 host)),\n                'operation': str(container_url),\n                'secrets': {\n                        'control': str(container_control),\n                        'fs': str(container_fs)\n                },\n                'type': 'migration'\n            }\n\n            return container_migrate\n        except Exception as ex:\n            with excutils.save_and_reraise_exception():\n                LOG.error(_LE('Failed to configure migation source '\n                              '%(instance)s: %(ex)s'),\n                          {'instance': instance.name, 'ex': ex},\n                          instance=instance)\n\n    def configure_disk_path(self, src_path, dest_path, vfs_type, instance):\n        \"\"\"Configure the host mount point for the LXD container\n\n        :param src_path: source path on the house\n        :param dest_path: destination path on the LXD container\n        :param vfs_type: dictionary identifier\n        :param instance: nova instance object\n        :return: container disk paths\n        \"\"\"\n        LOG.debug('configure_disk_path called for instance',\n                  instance=instance)\n        try:\n            config = {}\n            config[vfs_type] = {'path': dest_path,\n                                'source': src_path,\n                                'type': 'disk',\n                                'optional': 'True'}\n            return config\n        except Exception as ex:\n            with excutils.save_and_reraise_exception():\n                LOG.error(_LE('Failed to configure disk for '\n                              '%(instance)s: %(ex)s'),\n                          {'instance': instance.name, 'ex': ex},\n                          instance=instance)\n\n    def create_container_net_device(self, instance, vif):\n        \"\"\"Translate nova network object into a LXD interface\n\n        :param instance: nova instance object\n        :param vif: network instaance object\n        \"\"\"\n        LOG.debug('create_container_net_device called for instance',\n                  insance=instance)\n        try:\n            network_config = self.vif_driver.get_config(instance, vif)\n\n            config = {}\n            config[self.get_network_device(instance)] = {\n                'nictype': 'bridged',\n                'hwaddr': str(vif['address']),\n                'parent': str(network_config['bridge']),\n                'type': 'nic'}\n\n            return config\n        except Exception as ex:\n            LOG.error(_LE('Failed to configure network for '\n                          '%(instance)s: %(ex)s'),\n                      {'instance': instance.name, 'ex': ex},\n                      instance=instance)\n\n    def get_network_device(self, instance):\n        \"\"\"Try to detect which network interfaces are available in a contianer\n\n        :param instance: nova instance object\n        \"\"\"\n        LOG.debug('get_network_device called for instance', instance=instance)\n        data = self.session.container_info(instance)\n        lines = open('/proc/%s/net/dev' % data['init']).readlines()\n        interfaces = []\n        for line in lines[2:]:\n            if line.find(':') < 0:\n                continue\n            face, _ = line.split(':')\n            if 'eth' in face:\n                interfaces.append(face.strip())\n\n        if len(interfaces) == 1:\n            return 'eth1'\n        else:\n            return 'eth%s' % int(len(interfaces) - 1)\n", "target": 0}
{"idx": 888, "func": "# vim: tabstop=4 shiftwidth=4 softtabstop=4\n\n# Copyright 2012 OpenStack LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"); you may\n# not use this file except in compliance with the License. You may obtain\n# a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n# License for the specific language governing permissions and limitations\n# under the License.\n\n\"\"\"Main entry point into the EC2 Credentials service.\n\nThis service allows the creation of access/secret credentials used for\nthe ec2 interop layer of OpenStack.\n\nA user can create as many access/secret pairs, each of which map to a\nspecific tenant.  This is required because OpenStack supports a user\nbelonging to multiple tenants, whereas the signatures created on ec2-style\nrequests don't allow specification of which tenant the user wishs to act\nupon.\n\nTo complete the cycle, we provide a method that OpenStack services can\nuse to validate a signature and get a corresponding openstack token.  This\ntoken allows method calls to other services within the context the\naccess/secret was created.  As an example, nova requests keystone to validate\nthe signature of a request, receives a token, and then makes a request to\nglance to list images needed to perform the requested task.\n\n\"\"\"\n\nimport uuid\n\nfrom keystone import catalog\nfrom keystone import config\nfrom keystone import exception\nfrom keystone import identity\nfrom keystone import policy\nfrom keystone import service\nfrom keystone import token\nfrom keystone.common import manager\nfrom keystone.common import utils\nfrom keystone.common import wsgi\n\n\nCONF = config.CONF\n\n\nclass Manager(manager.Manager):\n    \"\"\"Default pivot point for the EC2 Credentials backend.\n\n    See :mod:`keystone.common.manager.Manager` for more details on how this\n    dynamically calls the backend.\n\n    \"\"\"\n\n    def __init__(self):\n        super(Manager, self).__init__(CONF.ec2.driver)\n\n\nclass Ec2Extension(wsgi.ExtensionRouter):\n    def add_routes(self, mapper):\n        ec2_controller = Ec2Controller()\n        # validation\n        mapper.connect('/ec2tokens',\n                       controller=ec2_controller,\n                       action='authenticate',\n                       conditions=dict(method=['POST']))\n\n        # crud\n        mapper.connect('/users/{user_id}/credentials/OS-EC2',\n                       controller=ec2_controller,\n                       action='create_credential',\n                       conditions=dict(method=['POST']))\n        mapper.connect('/users/{user_id}/credentials/OS-EC2',\n                       controller=ec2_controller,\n                       action='get_credentials',\n                       conditions=dict(method=['GET']))\n        mapper.connect('/users/{user_id}/credentials/OS-EC2/{credential_id}',\n                       controller=ec2_controller,\n                       action='get_credential',\n                       conditions=dict(method=['GET']))\n        mapper.connect('/users/{user_id}/credentials/OS-EC2/{credential_id}',\n                       controller=ec2_controller,\n                       action='delete_credential',\n                       conditions=dict(method=['DELETE']))\n\n\nclass Ec2Controller(wsgi.Application):\n    def __init__(self):\n        self.catalog_api = catalog.Manager()\n        self.identity_api = identity.Manager()\n        self.token_api = token.Manager()\n        self.policy_api = policy.Manager()\n        self.ec2_api = Manager()\n        super(Ec2Controller, self).__init__()\n\n    def check_signature(self, creds_ref, credentials):\n        signer = utils.Ec2Signer(creds_ref['secret'])\n        signature = signer.generate(credentials)\n        if utils.auth_str_equal(credentials['signature'], signature):\n            return\n        # NOTE(vish): Some libraries don't use the port when signing\n        #             requests, so try again without port.\n        elif ':' in credentials['signature']:\n            hostname, _port = credentials['host'].split(':')\n            credentials['host'] = hostname\n            signature = signer.generate(credentials)\n            if not utils.auth_str_equal(credentials.signature, signature):\n                raise exception.Unauthorized(message='Invalid EC2 signature.')\n        else:\n            raise exception.Unauthorized(message='EC2 signature not supplied.')\n\n    def authenticate(self, context, credentials=None,\n                         ec2Credentials=None):\n        \"\"\"Validate a signed EC2 request and provide a token.\n\n        Other services (such as Nova) use this **admin** call to determine\n        if a request they signed received is from a valid user.\n\n        If it is a valid signature, an openstack token that maps\n        to the user/tenant is returned to the caller, along with\n        all the other details returned from a normal token validation\n        call.\n\n        The returned token is useful for making calls to other\n        OpenStack services within the context of the request.\n\n        :param context: standard context\n        :param credentials: dict of ec2 signature\n        :param ec2Credentials: DEPRECATED dict of ec2 signature\n        :returns: token: openstack token equivalent to access key along\n                         with the corresponding service catalog and roles\n        \"\"\"\n\n        # FIXME(ja): validate that a service token was used!\n\n        # NOTE(termie): backwards compat hack\n        if not credentials and ec2Credentials:\n            credentials = ec2Credentials\n\n        if not 'access' in credentials:\n            raise exception.Unauthorized(message='EC2 signature not supplied.')\n\n        creds_ref = self._get_credentials(context,\n                                          credentials['access'])\n        self.check_signature(creds_ref, credentials)\n\n        # TODO(termie): don't create new tokens every time\n        # TODO(termie): this is copied from TokenController.authenticate\n        token_id = uuid.uuid4().hex\n        tenant_ref = self.identity_api.get_tenant(\n                context=context,\n                tenant_id=creds_ref['tenant_id'])\n        user_ref = self.identity_api.get_user(\n                context=context,\n                user_id=creds_ref['user_id'])\n        metadata_ref = self.identity_api.get_metadata(\n                context=context,\n                user_id=user_ref['id'],\n                tenant_id=tenant_ref['id'])\n        catalog_ref = self.catalog_api.get_catalog(\n                context=context,\n                user_id=user_ref['id'],\n                tenant_id=tenant_ref['id'],\n                    metadata=metadata_ref)\n\n        token_ref = self.token_api.create_token(\n                context, token_id, dict(id=token_id,\n                                        user=user_ref,\n                                        tenant=tenant_ref,\n                                        metadata=metadata_ref))\n\n        # TODO(termie): optimize this call at some point and put it into the\n        #               the return for metadata\n        # fill out the roles in the metadata\n        roles_ref = []\n        for role_id in metadata_ref.get('roles', []):\n            roles_ref.append(self.identity_api.get_role(context, role_id))\n\n        # TODO(termie): make this a util function or something\n        # TODO(termie): i don't think the ec2 middleware currently expects a\n        #               full return, but it contains a note saying that it\n        #               would be better to expect a full return\n        token_controller = service.TokenController()\n        return token_controller._format_authenticate(\n                token_ref, roles_ref, catalog_ref)\n\n    def create_credential(self, context, user_id, tenant_id):\n        \"\"\"Create a secret/access pair for use with ec2 style auth.\n\n        Generates a new set of credentials that map the the user/tenant\n        pair.\n\n        :param context: standard context\n        :param user_id: id of user\n        :param tenant_id: id of tenant\n        :returns: credential: dict of ec2 credential\n        \"\"\"\n        if not self._is_admin(context):\n            self._assert_identity(context, user_id)\n\n        self._assert_valid_user_id(context, user_id)\n        self._assert_valid_tenant_id(context, tenant_id)\n\n        cred_ref = {'user_id': user_id,\n                    'tenant_id': tenant_id,\n                    'access': uuid.uuid4().hex,\n                    'secret': uuid.uuid4().hex}\n        self.ec2_api.create_credential(context, cred_ref['access'], cred_ref)\n        return {'credential': cred_ref}\n\n    def get_credentials(self, context, user_id):\n        \"\"\"List all credentials for a user.\n\n        :param context: standard context\n        :param user_id: id of user\n        :returns: credentials: list of ec2 credential dicts\n        \"\"\"\n        if not self._is_admin(context):\n            self._assert_identity(context, user_id)\n        self._assert_valid_user_id(context, user_id)\n        return {'credentials': self.ec2_api.list_credentials(context, user_id)}\n\n    def get_credential(self, context, user_id, credential_id):\n        \"\"\"Retreive a user's access/secret pair by the access key.\n\n        Grab the full access/secret pair for a given access key.\n\n        :param context: standard context\n        :param user_id: id of user\n        :param credential_id: access key for credentials\n        :returns: credential: dict of ec2 credential\n        \"\"\"\n        if not self._is_admin(context):\n            self._assert_identity(context, user_id)\n        self._assert_valid_user_id(context, user_id)\n        creds = self._get_credentials(context, credential_id)\n        return {'credential': creds}\n\n    def delete_credential(self, context, user_id, credential_id):\n        \"\"\"Delete a user's access/secret pair.\n\n        Used to revoke a user's access/secret pair\n\n        :param context: standard context\n        :param user_id: id of user\n        :param credential_id: access key for credentials\n        :returns: bool: success\n        \"\"\"\n        if not self._is_admin(context):\n            self._assert_identity(context, user_id)\n            self._assert_owner(context, user_id, credential_id)\n\n        self._assert_valid_user_id(context, user_id)\n        self._get_credentials(context, credential_id)\n        return self.ec2_api.delete_credential(context, credential_id)\n\n    def _get_credentials(self, context, credential_id):\n        \"\"\"Return credentials from an ID.\n\n        :param context: standard context\n        :param credential_id: id of credential\n        :raises exception.Unauthorized: when credential id is invalid\n        :returns: credential: dict of ec2 credential.\n        \"\"\"\n        creds = self.ec2_api.get_credential(context,\n                                            credential_id)\n        if not creds:\n            raise exception.Unauthorized(message='EC2 access key not found.')\n        return creds\n\n    def _assert_identity(self, context, user_id):\n        \"\"\"Check that the provided token belongs to the user.\n\n        :param context: standard context\n        :param user_id: id of user\n        :raises exception.Forbidden: when token is invalid\n\n        \"\"\"\n        try:\n            token_ref = self.token_api.get_token(context=context,\n                    token_id=context['token_id'])\n        except exception.TokenNotFound:\n            raise exception.Unauthorized()\n        token_user_id = token_ref['user'].get('id')\n        if not token_user_id == user_id:\n            raise exception.Forbidden()\n\n    def _is_admin(self, context):\n        \"\"\"Wrap admin assertion error return statement.\n\n        :param context: standard context\n        :returns: bool: success\n\n        \"\"\"\n        try:\n            self.assert_admin(context)\n            return True\n        except exception.Forbidden:\n            return False\n\n    def _assert_owner(self, context, user_id, credential_id):\n        \"\"\"Ensure the provided user owns the credential.\n\n        :param context: standard context\n        :param user_id: expected credential owner\n        :param credential_id: id of credential object\n        :raises exception.Forbidden: on failure\n\n        \"\"\"\n        cred_ref = self.ec2_api.get_credential(context, credential_id)\n        if not user_id == cred_ref['user_id']:\n            raise exception.Forbidden()\n\n    def _assert_valid_user_id(self, context, user_id):\n        \"\"\"Ensure a valid user id.\n\n        :param context: standard context\n        :param user_id: expected credential owner\n        :raises exception.UserNotFound: on failure\n\n        \"\"\"\n        user_ref = self.identity_api.get_user(\n            context=context,\n            user_id=user_id)\n        if not user_ref:\n            raise exception.UserNotFound(user_id=user_id)\n\n    def _assert_valid_tenant_id(self, context, tenant_id):\n        \"\"\"Ensure a valid tenant id.\n\n        :param context: standard context\n        :param user_id: expected credential owner\n        :raises exception.UserNotFound: on failure\n\n        \"\"\"\n        tenant_ref = self.identity_api.get_tenant(\n            context=context,\n            tenant_id=tenant_id)\n        if not tenant_ref:\n            raise exception.TenantNotFound(tenant_id=tenant_id)\n", "target": 1}
{"idx": 889, "func": "import sys\n\nimport ldap  # pylint: disable=import-error\nfrom flask import current_app, jsonify, request\nfrom flask_cors import cross_origin\n\nfrom alerta.auth.utils import create_token, get_customers\nfrom alerta.exceptions import ApiError\nfrom alerta.models.permission import Permission\nfrom alerta.models.user import User\nfrom alerta.utils.audit import auth_audit_trail\n\nfrom . import auth\n\n\n@auth.route('/auth/login', methods=['OPTIONS', 'POST'])\n@cross_origin(supports_credentials=True)\ndef login():\n    # Allow LDAP server to use a self signed certificate\n    if current_app.config['LDAP_ALLOW_SELF_SIGNED_CERT']:\n        ldap.set_option(ldap.OPT_X_TLS_REQUIRE_CERT, ldap.OPT_X_TLS_ALLOW)\n\n    # Retrieve required fields from client request\n    try:\n        login = request.json.get('username', None) or request.json['email']\n        password = request.json['password']\n    except KeyError:\n        raise ApiError(\"must supply 'username' and 'password'\", 401)\n\n    if not password:\n        raise ApiError('password not allowed to be empty', 401)\n\n    try:\n        if '\\\\' in login:\n            domain, username = login.split('\\\\')\n            email = ''\n            email_verified = False\n        else:\n            username, domain = login.split('@')\n            email = login\n            email_verified = True\n    except ValueError:\n        raise ApiError('expected username with domain', 401)\n\n    # Validate LDAP domain\n    if domain not in current_app.config['LDAP_DOMAINS']:\n        raise ApiError('unauthorized domain', 403)\n\n    userdn = current_app.config['LDAP_DOMAINS'][domain] % username\n\n    # Attempt LDAP AUTH\n    try:\n        trace_level = 2 if current_app.debug else 0\n        ldap_connection = ldap.initialize(current_app.config['LDAP_URL'], trace_level=trace_level)\n        ldap_connection.simple_bind_s(userdn, password)\n    except ldap.INVALID_CREDENTIALS:\n        raise ApiError('invalid username or password', 401)\n    except Exception as e:\n        raise ApiError(str(e), 500)\n\n    # Get email address from LDAP\n    if not email_verified:\n        try:\n            ldap_result = ldap_connection.search_s(userdn, ldap.SCOPE_SUBTREE, '(objectClass=*)', ['mail'])\n            email = ldap_result[0][1]['mail'][0].decode(sys.stdout.encoding)\n            email_verified = True\n        except Exception:\n            email = '{}@{}'.format(username, domain)\n\n    # Create user if not yet there\n    user = User.find_by_username(username=login)\n    if not user:\n        user = User(name=username, login=login, password='', email=email,\n                    roles=[], text='LDAP user', email_verified=email_verified)\n        try:\n            user = user.create()\n        except Exception as e:\n            ApiError(str(e), 500)\n\n    # Assign customers & update last login time\n    groups = list()\n    try:\n        groups_filters = current_app.config.get('LDAP_DOMAINS_GROUP', {})\n        base_dns = current_app.config.get('LDAP_DOMAINS_BASEDN', {})\n        if domain in groups_filters and domain in base_dns:\n            resultID = ldap_connection.search(\n                base_dns[domain],\n                ldap.SCOPE_SUBTREE,\n                groups_filters[domain].format(username=username, email=email, userdn=userdn),\n                ['cn']\n            )\n            resultTypes, results = ldap_connection.result(resultID)\n            for _dn, attributes in results:\n                groups.append(attributes['cn'][0].decode('utf-8'))\n    except ldap.LDAPError as e:\n        raise ApiError(str(e), 500)\n\n    # Check user is active\n    if user.status != 'active':\n        raise ApiError('User {} not active'.format(login), 403)\n    user.update_last_login()\n\n    scopes = Permission.lookup(login=login, roles=user.roles + groups)\n    customers = get_customers(login=login, groups=[user.domain] + groups)\n\n    auth_audit_trail.send(current_app._get_current_object(), event='basic-ldap-login', message='user login via LDAP',\n                          user=login, customers=customers, scopes=scopes, roles=user.roles, groups=groups,\n                          resource_id=user.id, type='user', request=request)\n\n    # Generate token\n    token = create_token(user_id=user.id, name=user.name, login=user.email, provider='ldap',\n                         customers=customers, scopes=scopes, roles=user.roles, groups=groups,\n                         email=user.email, email_verified=user.email_verified)\n    return jsonify(token=token.tokenize)\n", "target": 0}
{"idx": 890, "func": "##############################################################################\n#\n# Copyright (c) 2001 Zope Foundation and Contributors.\n#\n# This software is subject to the provisions of the Zope Public License,\n# Version 2.1 (ZPL).  A copy of the ZPL should accompany this distribution.\n# THIS SOFTWARE IS PROVIDED \"AS IS\" AND ANY AND ALL EXPRESS OR IMPLIED\n# WARRANTIES ARE DISCLAIMED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\n# WARRANTIES OF TITLE, MERCHANTABILITY, AGAINST INFRINGEMENT, AND FITNESS\n# FOR A PARTICULAR PURPOSE.\n#\n##############################################################################\n\"\"\" Basic user registration tool.\n\"\"\"\n\nfrom random import choice\nimport re\n\nfrom AccessControl.requestmethod import postonly\nfrom AccessControl.SecurityInfo import ClassSecurityInfo\nfrom App.class_init import InitializeClass\nfrom App.special_dtml import DTMLFile\nfrom OFS.SimpleItem import SimpleItem\nfrom zope.component import getUtility\nfrom zope.interface import implements\n\nfrom Products.CMFCore.interfaces import IMembershipTool\nfrom Products.CMFCore.interfaces import IRegistrationTool\nfrom Products.CMFCore.permissions import AddPortalMember\nfrom Products.CMFCore.permissions import MailForgottenPassword\nfrom Products.CMFCore.permissions import ManagePortal\nfrom Products.CMFCore.utils import _checkPermission\nfrom Products.CMFCore.utils import _dtmldir\nfrom Products.CMFCore.utils import _limitGrantedRoles\nfrom Products.CMFCore.utils import Message as _\nfrom Products.CMFCore.utils import registerToolInterface\nfrom Products.CMFCore.utils import UniqueObject\n\n\nclass RegistrationTool(UniqueObject, SimpleItem):\n\n    \"\"\" Create and modify users by making calls to portal_membership.\n    \"\"\"\n\n    implements(IRegistrationTool)\n\n    id = 'portal_registration'\n    meta_type = 'CMF Registration Tool'\n    member_id_pattern = ''\n    default_member_id_pattern = \"^[A-Za-z][A-Za-z0-9_]*$\"\n    _ALLOWED_MEMBER_ID_PATTERN = re.compile(default_member_id_pattern)\n\n    security = ClassSecurityInfo()\n\n    manage_options = ( ({'label': 'Overview',\n                         'action': 'manage_overview'},\n                        {'label': 'Configure',\n                         'action': 'manage_configuration'})\n                     + SimpleItem.manage_options\n                     )\n\n    #\n    #   ZMI methods\n    #\n    security.declareProtected(ManagePortal, 'manage_overview')\n    manage_overview = DTMLFile( 'explainRegistrationTool', _dtmldir )\n\n    security.declareProtected(ManagePortal, 'manage_configuration')\n    manage_configuration = DTMLFile('configureRegistrationTool', _dtmldir)\n\n    security.declareProtected(ManagePortal, 'manage_editIDPattern')\n    def manage_editIDPattern(self, pattern, REQUEST=None):\n        \"\"\"Edit the allowable member ID pattern TTW\"\"\"\n        pattern.strip()\n\n        if len(pattern) > 0:\n            self.member_id_pattern = pattern\n            self._ALLOWED_MEMBER_ID_PATTERN = re.compile(pattern)\n        else:\n            self.member_id_pattern = ''\n            self._ALLOWED_MEMBER_ID_PATTERN = re.compile(\n                                                self.default_member_id_pattern)\n\n        if REQUEST is not None:\n            msg = 'Member ID Pattern changed'\n            return self.manage_configuration(manage_tabs_message=msg)\n\n    security.declareProtected(ManagePortal, 'getIDPattern')\n    def getIDPattern(self):\n        \"\"\" Return the currently-used member ID pattern \"\"\"\n        return self.member_id_pattern\n\n    security.declareProtected(ManagePortal, 'getDefaultIDPattern')\n    def getDefaultIDPattern(self):\n        \"\"\" Return the currently-used member ID pattern \"\"\"\n        return self.default_member_id_pattern\n\n\n    #\n    #   'portal_registration' interface methods\n    #\n    security.declarePublic('isRegistrationAllowed')\n    def isRegistrationAllowed(self, REQUEST):\n        '''Returns a boolean value indicating whether the user\n        is allowed to add a member to the portal.\n        '''\n        return _checkPermission(AddPortalMember, self.aq_inner.aq_parent)\n\n    security.declarePublic('testPasswordValidity')\n    def testPasswordValidity(self, password, confirm=None):\n        '''If the password is valid, returns None.  If not, returns\n        a string explaining why.\n        '''\n        return None\n\n    security.declarePublic('testPropertiesValidity')\n    def testPropertiesValidity(self, new_properties, member=None):\n        '''If the properties are valid, returns None.  If not, returns\n        a string explaining why.\n        '''\n        return None\n\n    security.declarePublic('generatePassword')\n    def generatePassword(self):\n        \"\"\" Generate a valid password.\n        \"\"\"\n        # we don't use these to avoid typos: OQ0Il1\n        chars = 'ABCDEFGHJKLMNPRSTUVWXYZabcdefghijkmnopqrstuvwxyz23456789'\n        return ''.join( [ choice(chars) for i in range(6) ] )\n\n    security.declareProtected(AddPortalMember, 'addMember')\n    @postonly\n    def addMember(self, id, password, roles=('Member',), domains='',\n                  properties=None, REQUEST=None):\n        '''Creates a PortalMember and returns it. The properties argument\n        can be a mapping with additional member properties. Raises an\n        exception if the given id already exists, the password does not\n        comply with the policy in effect, or the authenticated user is not\n        allowed to grant one of the roles listed (where Member is a special\n        role that can always be granted); these conditions should be\n        detected before the fact so that a cleaner message can be printed.\n        '''\n        if not self.isMemberIdAllowed(id):\n            raise ValueError(_(u'The login name you selected is already in '\n                               u'use or is not valid. Please choose another.'))\n\n        failMessage = self.testPasswordValidity(password)\n        if failMessage is not None:\n            raise ValueError(failMessage)\n\n        if properties is not None:\n            failMessage = self.testPropertiesValidity(properties)\n            if failMessage is not None:\n                raise ValueError(failMessage)\n\n        # Limit the granted roles.\n        # Anyone is always allowed to grant the 'Member' role.\n        _limitGrantedRoles(roles, self, ('Member',))\n\n        mtool = getUtility(IMembershipTool)\n        mtool.addMember(id, password, roles, domains, properties)\n\n        member = mtool.getMemberById(id)\n        self.afterAdd(member, id, password, properties)\n        return member\n\n    security.declareProtected(AddPortalMember, 'isMemberIdAllowed')\n    def isMemberIdAllowed(self, id):\n        '''Returns 1 if the ID is not in use and is not reserved.\n        '''\n        if len(id) < 1 or id == 'Anonymous User':\n            return 0\n        if not self._ALLOWED_MEMBER_ID_PATTERN.match( id ):\n            return 0\n        mtool = getUtility(IMembershipTool)\n        if mtool.getMemberById(id) is not None:\n            return 0\n        return 1\n\n    security.declarePublic('afterAdd')\n    def afterAdd(self, member, id, password, properties):\n        '''Called by portal_registration.addMember()\n        after a member has been added successfully.'''\n        pass\n\n    security.declareProtected(MailForgottenPassword, 'mailPassword')\n    def mailPassword(self, forgotten_userid, REQUEST):\n        '''Email a forgotten password to a member.  Raises an exception\n        if user ID is not found.\n        '''\n        raise NotImplementedError\n\nInitializeClass(RegistrationTool)\nregisterToolInterface('portal_registration', IRegistrationTool)\n", "target": 1}
{"idx": 891, "func": "import hashlib\nimport json\nimport os\nimport uuid\n\nfrom django import forms\nfrom django.conf import settings\nfrom django.contrib.contenttypes.fields import GenericForeignKey\nfrom django.contrib.contenttypes.models import ContentType\nfrom django.core.exceptions import ValidationError\nfrom django.core.paginator import EmptyPage, PageNotAnInteger, Paginator\nfrom django.core.serializers.json import DjangoJSONEncoder\nfrom django.db import models\nfrom django.shortcuts import redirect, render\nfrom modelcluster.contrib.taggit import ClusterTaggableManager\nfrom modelcluster.fields import ParentalKey, ParentalManyToManyField\nfrom modelcluster.models import ClusterableModel\nfrom taggit.managers import TaggableManager\nfrom taggit.models import TaggedItemBase\n\nfrom wagtail.admin.edit_handlers import (\n    FieldPanel, InlinePanel, MultiFieldPanel, ObjectList, PageChooserPanel, StreamFieldPanel,\n    TabbedInterface)\nfrom wagtail.admin.forms import WagtailAdminPageForm\nfrom wagtail.admin.mail import send_mail\nfrom wagtail.contrib.forms.forms import FormBuilder\nfrom wagtail.contrib.forms.models import (\n    FORM_FIELD_CHOICES, AbstractEmailForm, AbstractFormField, AbstractFormSubmission)\nfrom wagtail.contrib.settings.models import BaseSetting, register_setting\nfrom wagtail.contrib.sitemaps import Sitemap\nfrom wagtail.contrib.table_block.blocks import TableBlock\nfrom wagtail.core.blocks import CharBlock, RichTextBlock, StructBlock\nfrom wagtail.core.fields import RichTextField, StreamField\nfrom wagtail.core.models import Orderable, Page, PageManager, PageQuerySet\nfrom wagtail.documents.edit_handlers import DocumentChooserPanel\nfrom wagtail.documents.models import AbstractDocument, Document\nfrom wagtail.images.blocks import ImageChooserBlock\nfrom wagtail.images.edit_handlers import ImageChooserPanel\nfrom wagtail.images.models import AbstractImage, AbstractRendition, Image\nfrom wagtail.search import index\nfrom wagtail.snippets.edit_handlers import SnippetChooserPanel\nfrom wagtail.snippets.models import register_snippet\nfrom wagtail.utils.decorators import cached_classmethod\n\nfrom .forms import FormClassAdditionalFieldPageForm, ValidatedPageForm\nfrom .views import CustomSubmissionsListView\n\nEVENT_AUDIENCE_CHOICES = (\n    ('public', \"Public\"),\n    ('private', \"Private\"),\n)\n\n\nCOMMON_PANELS = (\n    FieldPanel('slug'),\n    FieldPanel('seo_title'),\n    FieldPanel('show_in_menus'),\n    FieldPanel('search_description'),\n)\n\n\n# Link fields\n\nclass LinkFields(models.Model):\n    link_external = models.URLField(\"External link\", blank=True)\n    link_page = models.ForeignKey(\n        'wagtailcore.Page',\n        null=True,\n        blank=True,\n        related_name='+',\n        on_delete=models.CASCADE\n    )\n    link_document = models.ForeignKey(\n        'wagtaildocs.Document',\n        null=True,\n        blank=True,\n        related_name='+',\n        on_delete=models.CASCADE\n    )\n\n    @property\n    def link(self):\n        if self.link_page:\n            return self.link_page.url\n        elif self.link_document:\n            return self.link_document.url\n        else:\n            return self.link_external\n\n    panels = [\n        FieldPanel('link_external'),\n        PageChooserPanel('link_page'),\n        DocumentChooserPanel('link_document'),\n    ]\n\n    class Meta:\n        abstract = True\n\n\n# Carousel items\n\nclass CarouselItem(LinkFields):\n    image = models.ForeignKey(\n        'wagtailimages.Image',\n        null=True,\n        blank=True,\n        on_delete=models.SET_NULL,\n        related_name='+'\n    )\n    embed_url = models.URLField(\"Embed URL\", blank=True)\n    caption = models.CharField(max_length=255, blank=True)\n\n    panels = [\n        ImageChooserPanel('image'),\n        FieldPanel('embed_url'),\n        FieldPanel('caption'),\n        MultiFieldPanel(LinkFields.panels, \"Link\"),\n    ]\n\n    class Meta:\n        abstract = True\n\n\n# Related links\n\nclass RelatedLink(LinkFields):\n    title = models.CharField(max_length=255, help_text=\"Link title\")\n\n    panels = [\n        FieldPanel('title'),\n        MultiFieldPanel(LinkFields.panels, \"Link\"),\n    ]\n\n    class Meta:\n        abstract = True\n\n\n# Simple page\nclass SimplePage(Page):\n    content = models.TextField()\n\n    content_panels = [\n        FieldPanel('title', classname=\"full title\"),\n        FieldPanel('content'),\n    ]\n\n    def get_admin_display_title(self):\n        return \"%s (simple page)\" % super().get_admin_display_title()\n\n\n# Page with Excluded Fields when copied\nclass PageWithExcludedCopyField(Page):\n    content = models.TextField()\n\n    # Exclude this field from being copied\n    special_field = models.CharField(\n        blank=True, max_length=255, default='Very Special')\n    exclude_fields_in_copy = ['special_field']\n\n    content_panels = [\n        FieldPanel('title', classname=\"full title\"),\n        FieldPanel('special_field'),\n        FieldPanel('content'),\n    ]\n\n\nclass PageWithOldStyleRouteMethod(Page):\n    \"\"\"\n    Prior to Wagtail 0.4, the route() method on Page returned an HttpResponse\n    rather than a Page instance. As subclasses of Page may override route,\n    we need to continue accepting this convention (albeit as a deprecated API).\n    \"\"\"\n    content = models.TextField()\n    template = 'tests/simple_page.html'\n\n    def route(self, request, path_components):\n        return self.serve(request)\n\n\n# File page\nclass FilePage(Page):\n    file_field = models.FileField()\n\n\nFilePage.content_panels = [\n    FieldPanel('title', classname=\"full title\"),\n    FieldPanel('file_field'),\n]\n\n\n# Event page\n\nclass EventPageCarouselItem(Orderable, CarouselItem):\n    page = ParentalKey('tests.EventPage', related_name='carousel_items', on_delete=models.CASCADE)\n\n\nclass EventPageRelatedLink(Orderable, RelatedLink):\n    page = ParentalKey('tests.EventPage', related_name='related_links', on_delete=models.CASCADE)\n\n\nclass EventPageSpeakerAward(Orderable, models.Model):\n    speaker = ParentalKey('tests.EventPageSpeaker', related_name='awards', on_delete=models.CASCADE)\n    name = models.CharField(\"Award name\", max_length=255)\n    date_awarded = models.DateField(null=True, blank=True)\n\n    panels = [\n        FieldPanel('name'),\n        FieldPanel('date_awarded'),\n    ]\n\n\nclass EventPageSpeaker(Orderable, LinkFields, ClusterableModel):\n    page = ParentalKey('tests.EventPage', related_name='speakers', related_query_name='speaker', on_delete=models.CASCADE)\n    first_name = models.CharField(\"Name\", max_length=255, blank=True)\n    last_name = models.CharField(\"Surname\", max_length=255, blank=True)\n    image = models.ForeignKey(\n        'wagtailimages.Image',\n        null=True,\n        blank=True,\n        on_delete=models.SET_NULL,\n        related_name='+'\n    )\n\n    @property\n    def name_display(self):\n        return self.first_name + \" \" + self.last_name\n\n    panels = [\n        FieldPanel('first_name'),\n        FieldPanel('last_name'),\n        ImageChooserPanel('image'),\n        MultiFieldPanel(LinkFields.panels, \"Link\"),\n        InlinePanel('awards', label=\"Awards\"),\n    ]\n\n\nclass EventCategory(models.Model):\n    name = models.CharField(\"Name\", max_length=255)\n\n    def __str__(self):\n        return self.name\n\n\n# Override the standard WagtailAdminPageForm to add validation on start/end dates\n# that appears as a non-field error\n\nclass EventPageForm(WagtailAdminPageForm):\n    def clean(self):\n        cleaned_data = super().clean()\n\n        # Make sure that the event starts before it ends\n        start_date = cleaned_data['date_from']\n        end_date = cleaned_data['date_to']\n        if start_date and end_date and start_date > end_date:\n            raise ValidationError('The end date must be after the start date')\n\n        return cleaned_data\n\n\nclass EventPage(Page):\n    date_from = models.DateField(\"Start date\", null=True)\n    date_to = models.DateField(\n        \"End date\",\n        null=True,\n        blank=True,\n        help_text=\"Not required if event is on a single day\"\n    )\n    time_from = models.TimeField(\"Start time\", null=True, blank=True)\n    time_to = models.TimeField(\"End time\", null=True, blank=True)\n    audience = models.CharField(max_length=255, choices=EVENT_AUDIENCE_CHOICES)\n    location = models.CharField(max_length=255)\n    body = RichTextField(blank=True)\n    cost = models.CharField(max_length=255)\n    signup_link = models.URLField(blank=True)\n    feed_image = models.ForeignKey(\n        'wagtailimages.Image',\n        null=True,\n        blank=True,\n        on_delete=models.SET_NULL,\n        related_name='+'\n    )\n    categories = ParentalManyToManyField(EventCategory, blank=True)\n\n    search_fields = [\n        index.SearchField('get_audience_display'),\n        index.SearchField('location'),\n        index.SearchField('body'),\n        index.FilterField('url_path'),\n    ]\n\n    password_required_template = 'tests/event_page_password_required.html'\n    base_form_class = EventPageForm\n\n\nEventPage.content_panels = [\n    FieldPanel('title', classname=\"full title\"),\n    FieldPanel('date_from'),\n    FieldPanel('date_to'),\n    FieldPanel('time_from'),\n    FieldPanel('time_to'),\n    FieldPanel('location'),\n    FieldPanel('audience'),\n    FieldPanel('cost'),\n    FieldPanel('signup_link'),\n    InlinePanel('carousel_items', label=\"Carousel items\"),\n    FieldPanel('body', classname=\"full\"),\n    InlinePanel('speakers', label=\"Speakers\", heading=\"Speaker lineup\"),\n    InlinePanel('related_links', label=\"Related links\"),\n    FieldPanel('categories'),\n    # InlinePanel related model uses `pk` not `id`\n    InlinePanel('head_counts', label='Head Counts'),\n]\n\nEventPage.promote_panels = [\n    MultiFieldPanel(COMMON_PANELS, \"Common page configuration\"),\n    ImageChooserPanel('feed_image'),\n]\n\n\nclass HeadCountRelatedModelUsingPK(models.Model):\n    \"\"\"Related model that uses a custom primary key (pk) not id\"\"\"\n    custom_id = models.AutoField(primary_key=True)\n    event_page = ParentalKey(\n        EventPage,\n        on_delete=models.CASCADE,\n        related_name='head_counts'\n    )\n    head_count = models.IntegerField()\n    panels = [FieldPanel('head_count')]\n\n\n# Override the standard WagtailAdminPageForm to add field that is not in model\n# so that we can test additional potential issues like comparing versions\nclass FormClassAdditionalFieldPage(Page):\n    location = models.CharField(max_length=255)\n    body = RichTextField(blank=True)\n\n    content_panels = [\n        FieldPanel('title', classname=\"full title\"),\n        FieldPanel('location'),\n        FieldPanel('body'),\n        FieldPanel('code'),  # not in model, see set base_form_class\n    ]\n\n    base_form_class = FormClassAdditionalFieldPageForm\n\n\n# Just to be able to test multi table inheritance\nclass SingleEventPage(EventPage):\n    excerpt = models.TextField(\n        max_length=255,\n        blank=True,\n        null=True,\n        help_text=\"Short text to describe what is this action about\"\n    )\n\n    # Give this page model a custom URL routing scheme\n    def get_url_parts(self, request=None):\n        url_parts = super().get_url_parts(request=request)\n        if url_parts is None:\n            return None\n        else:\n            site_id, root_url, page_path = url_parts\n            return (site_id, root_url, page_path + 'pointless-suffix/')\n\n    def route(self, request, path_components):\n        if path_components == ['pointless-suffix']:\n            # treat this as equivalent to a request for this page\n            return super().route(request, [])\n        else:\n            # fall back to default routing rules\n            return super().route(request, path_components)\n\n    def get_admin_display_title(self):\n        return \"%s (single event)\" % super().get_admin_display_title()\n\n\nSingleEventPage.content_panels = [FieldPanel('excerpt')] + EventPage.content_panels\n\n\n# \"custom\" sitemap object\nclass EventSitemap(Sitemap):\n    pass\n\n\n# Event index (has a separate AJAX template, and a custom template context)\nclass EventIndex(Page):\n    intro = RichTextField(blank=True)\n    ajax_template = 'tests/includes/event_listing.html'\n\n    def get_events(self):\n        return self.get_children().live().type(EventPage)\n\n    def get_paginator(self):\n        return Paginator(self.get_events(), 4)\n\n    def get_context(self, request, page=1):\n        # Pagination\n        paginator = self.get_paginator()\n        try:\n            events = paginator.page(page)\n        except PageNotAnInteger:\n            events = paginator.page(1)\n        except EmptyPage:\n            events = paginator.page(paginator.num_pages)\n\n        # Update context\n        context = super().get_context(request)\n        context['events'] = events\n        return context\n\n    def route(self, request, path_components):\n        if self.live and len(path_components) == 1:\n            try:\n                return self.serve(request, page=int(path_components[0]))\n            except (TypeError, ValueError):\n                pass\n\n        return super().route(request, path_components)\n\n    def get_static_site_paths(self):\n        # Get page count\n        page_count = self.get_paginator().num_pages\n\n        # Yield a path for each page\n        for page in range(page_count):\n            yield '/%d/' % (page + 1)\n\n        # Yield from superclass\n        for path in super().get_static_site_paths():\n            yield path\n\n    def get_sitemap_urls(self, request=None):\n        # Add past events url to sitemap\n        return super().get_sitemap_urls(request=request) + [\n            {\n                'location': self.full_url + 'past/',\n                'lastmod': self.latest_revision_created_at\n            }\n        ]\n\n    def get_cached_paths(self):\n        return super().get_cached_paths() + [\n            '/past/'\n        ]\n\n\nEventIndex.content_panels = [\n    FieldPanel('title', classname=\"full title\"),\n    FieldPanel('intro', classname=\"full\"),\n]\n\n\nclass FormField(AbstractFormField):\n    page = ParentalKey('FormPage', related_name='form_fields', on_delete=models.CASCADE)\n\n\nclass FormPage(AbstractEmailForm):\n    def get_context(self, request):\n        context = super().get_context(request)\n        context['greeting'] = \"hello world\"\n        return context\n\n\nFormPage.content_panels = [\n    FieldPanel('title', classname=\"full title\"),\n    InlinePanel('form_fields', label=\"Form fields\"),\n    MultiFieldPanel([\n        FieldPanel('to_address', classname=\"full\"),\n        FieldPanel('from_address', classname=\"full\"),\n        FieldPanel('subject', classname=\"full\"),\n    ], \"Email\")\n]\n\n\n# FormPage with a non-HTML extension\n\nclass JadeFormField(AbstractFormField):\n    page = ParentalKey('JadeFormPage', related_name='form_fields', on_delete=models.CASCADE)\n\n\nclass JadeFormPage(AbstractEmailForm):\n    template = \"tests/form_page.jade\"\n\n\nJadeFormPage.content_panels = [\n    FieldPanel('title', classname=\"full title\"),\n    InlinePanel('form_fields', label=\"Form fields\"),\n    MultiFieldPanel([\n        FieldPanel('to_address', classname=\"full\"),\n        FieldPanel('from_address', classname=\"full\"),\n        FieldPanel('subject', classname=\"full\"),\n    ], \"Email\")\n]\n\n\n# Form page that redirects to a different page\n\nclass RedirectFormField(AbstractFormField):\n    page = ParentalKey('FormPageWithRedirect', related_name='form_fields', on_delete=models.CASCADE)\n\n\nclass FormPageWithRedirect(AbstractEmailForm):\n    thank_you_redirect_page = models.ForeignKey(\n        'wagtailcore.Page',\n        null=True,\n        blank=True,\n        on_delete=models.SET_NULL,\n        related_name='+',\n    )\n\n    def get_context(self, request):\n        context = super(FormPageWithRedirect, self).get_context(request)\n        context['greeting'] = \"hello world\"\n        return context\n\n    def render_landing_page(self, request, form_submission=None, *args, **kwargs):\n        \"\"\"\n        Renders the landing page OR if a receipt_page_redirect is chosen redirects to this page.\n        \"\"\"\n        if self.thank_you_redirect_page:\n            return redirect(self.thank_you_redirect_page.url, permanent=False)\n\n        return super(FormPageWithRedirect, self).render_landing_page(request, form_submission, *args, **kwargs)\n\n\nFormPageWithRedirect.content_panels = [\n    FieldPanel('title', classname=\"full title\"),\n    PageChooserPanel('thank_you_redirect_page'),\n    InlinePanel('form_fields', label=\"Form fields\"),\n    MultiFieldPanel([\n        FieldPanel('to_address', classname=\"full\"),\n        FieldPanel('from_address', classname=\"full\"),\n        FieldPanel('subject', classname=\"full\"),\n    ], \"Email\")\n]\n\n\n# FormPage with a custom FormSubmission\n\nclass FormPageWithCustomSubmission(AbstractEmailForm):\n    \"\"\"\n    This Form page:\n        * Have custom submission model\n        * Have custom related_name (see `FormFieldWithCustomSubmission.page`)\n        * Saves reference to a user\n        * Doesn't render html form, if submission for current user is present\n    \"\"\"\n\n    intro = RichTextField(blank=True)\n    thank_you_text = RichTextField(blank=True)\n\n    def get_context(self, request, *args, **kwargs):\n        context = super().get_context(request)\n        context['greeting'] = \"hello world\"\n        return context\n\n    def get_form_fields(self):\n        return self.custom_form_fields.all()\n\n    def get_data_fields(self):\n        data_fields = [\n            ('username', 'Username'),\n        ]\n        data_fields += super().get_data_fields()\n\n        return data_fields\n\n    def get_submission_class(self):\n        return CustomFormPageSubmission\n\n    def process_form_submission(self, form):\n        form_submission = self.get_submission_class().objects.create(\n            form_data=json.dumps(form.cleaned_data, cls=DjangoJSONEncoder),\n            page=self, user=form.user\n        )\n\n        if self.to_address:\n            addresses = [x.strip() for x in self.to_address.split(',')]\n            content = '\\n'.join([x[1].label + ': ' + str(form.data.get(x[0])) for x in form.fields.items()])\n            send_mail(self.subject, content, addresses, self.from_address,)\n\n        # process_form_submission should now return the created form_submission\n        return form_submission\n\n    def serve(self, request, *args, **kwargs):\n        if self.get_submission_class().objects.filter(page=self, user__pk=request.user.pk).exists():\n            return render(\n                request,\n                self.template,\n                self.get_context(request)\n            )\n\n        return super().serve(request, *args, **kwargs)\n\n\nFormPageWithCustomSubmission.content_panels = [\n    FieldPanel('title', classname=\"full title\"),\n    FieldPanel('intro', classname=\"full\"),\n    InlinePanel('custom_form_fields', label=\"Form fields\"),\n    FieldPanel('thank_you_text', classname=\"full\"),\n    MultiFieldPanel([\n        FieldPanel('to_address', classname=\"full\"),\n        FieldPanel('from_address', classname=\"full\"),\n        FieldPanel('subject', classname=\"full\"),\n    ], \"Email\")\n]\n\n\nclass FormFieldWithCustomSubmission(AbstractFormField):\n    page = ParentalKey(FormPageWithCustomSubmission, on_delete=models.CASCADE, related_name='custom_form_fields')\n\n\nclass CustomFormPageSubmission(AbstractFormSubmission):\n    user = models.ForeignKey(settings.AUTH_USER_MODEL, on_delete=models.CASCADE)\n\n    def get_data(self):\n        form_data = super().get_data()\n        form_data.update({\n            'username': self.user.username,\n        })\n\n        return form_data\n\n\n# Custom form page with custom submission listing view and form submission\n\nclass FormFieldForCustomListViewPage(AbstractFormField):\n    page = ParentalKey(\n        'FormPageWithCustomSubmissionListView',\n        related_name='form_fields',\n        on_delete=models.CASCADE\n    )\n\n\nclass FormPageWithCustomSubmissionListView(AbstractEmailForm):\n    \"\"\"Form Page with customised submissions listing view\"\"\"\n\n    intro = RichTextField(blank=True)\n    thank_you_text = RichTextField(blank=True)\n\n    submissions_list_view_class = CustomSubmissionsListView\n\n    def get_submission_class(self):\n        return CustomFormPageSubmission\n\n    def get_data_fields(self):\n        data_fields = [\n            ('username', 'Username'),\n        ]\n        data_fields += super().get_data_fields()\n\n        return data_fields\n\n    content_panels = [\n        FieldPanel('title', classname=\"full title\"),\n        FieldPanel('intro', classname=\"full\"),\n        InlinePanel('form_fields', label=\"Form fields\"),\n        FieldPanel('thank_you_text', classname=\"full\"),\n        MultiFieldPanel([\n            FieldPanel('to_address', classname=\"full\"),\n            FieldPanel('from_address', classname=\"full\"),\n            FieldPanel('subject', classname=\"full\"),\n        ], \"Email\")\n    ]\n\n\n# FormPage with cutom FormBuilder\n\nEXTENDED_CHOICES = FORM_FIELD_CHOICES + (('ipaddress', 'IP Address'),)\n\n\nclass ExtendedFormField(AbstractFormField):\n    \"\"\"Override the field_type field with extended choices.\"\"\"\n    page = ParentalKey(\n        'FormPageWithCustomFormBuilder',\n        related_name='form_fields',\n        on_delete=models.CASCADE)\n    field_type = models.CharField(\n        verbose_name='field type', max_length=16, choices=EXTENDED_CHOICES)\n\n\nclass CustomFormBuilder(FormBuilder):\n    \"\"\"\n    A custom FormBuilder that has an 'ipaddress' field with\n    customised create_singleline_field with shorter max_length\n    \"\"\"\n\n    def create_singleline_field(self, field, options):\n        options['max_length'] = 120  # usual default is 255\n        return forms.CharField(**options)\n\n    def create_ipaddress_field(self, field, options):\n        return forms.GenericIPAddressField(**options)\n\n\nclass FormPageWithCustomFormBuilder(AbstractEmailForm):\n    \"\"\"\n    A Form page that has a custom form builder and uses a custom\n    form field model with additional field_type choices.\n    \"\"\"\n\n    form_builder = CustomFormBuilder\n\n    content_panels = [\n        FieldPanel('title', classname=\"full title\"),\n        InlinePanel('form_fields', label=\"Form fields\"),\n        MultiFieldPanel([\n            FieldPanel('to_address', classname=\"full\"),\n            FieldPanel('from_address', classname=\"full\"),\n            FieldPanel('subject', classname=\"full\"),\n        ], \"Email\")\n    ]\n\n\n# Snippets\nclass AdvertPlacement(models.Model):\n    page = ParentalKey('wagtailcore.Page', related_name='advert_placements', on_delete=models.CASCADE)\n    advert = models.ForeignKey('tests.Advert', related_name='+', on_delete=models.CASCADE)\n    colour = models.CharField(max_length=255)\n\n\nclass AdvertTag(TaggedItemBase):\n    content_object = ParentalKey('Advert', related_name='tagged_items', on_delete=models.CASCADE)\n\n\nclass Advert(ClusterableModel):\n    url = models.URLField(null=True, blank=True)\n    text = models.CharField(max_length=255)\n\n    tags = TaggableManager(through=AdvertTag, blank=True)\n\n    panels = [\n        FieldPanel('url'),\n        FieldPanel('text'),\n        FieldPanel('tags'),\n    ]\n\n    def __str__(self):\n        return self.text\n\n\nregister_snippet(Advert)\n\n\nclass AdvertWithCustomPrimaryKey(ClusterableModel):\n    advert_id = models.CharField(max_length=255, primary_key=True)\n    url = models.URLField(null=True, blank=True)\n    text = models.CharField(max_length=255)\n\n    panels = [\n        FieldPanel('url'),\n        FieldPanel('text'),\n    ]\n\n    def __str__(self):\n        return self.text\n\n\nregister_snippet(AdvertWithCustomPrimaryKey)\n\n\nclass AdvertWithCustomUUIDPrimaryKey(ClusterableModel):\n    advert_id = models.UUIDField(primary_key=True, default=uuid.uuid4, editable=False)\n    url = models.URLField(null=True, blank=True)\n    text = models.CharField(max_length=255)\n\n    panels = [\n        FieldPanel('url'),\n        FieldPanel('text'),\n    ]\n\n    def __str__(self):\n        return self.text\n\n\nregister_snippet(AdvertWithCustomUUIDPrimaryKey)\n\n\nclass AdvertWithTabbedInterface(models.Model):\n    url = models.URLField(null=True, blank=True)\n    text = models.CharField(max_length=255)\n    something_else = models.CharField(max_length=255)\n\n    advert_panels = [\n        FieldPanel('url'),\n        FieldPanel('text'),\n    ]\n\n    other_panels = [\n        FieldPanel('something_else'),\n    ]\n\n    edit_handler = TabbedInterface([\n        ObjectList(advert_panels, heading='Advert'),\n        ObjectList(other_panels, heading='Other'),\n    ])\n\n    def __str__(self):\n        return self.text\n\n    class Meta:\n        ordering = ('text',)\n\n\nregister_snippet(AdvertWithTabbedInterface)\n\n\nclass StandardIndex(Page):\n    \"\"\" Index for the site \"\"\"\n    parent_page_types = [Page]\n\n\n# A custom panel setup where all Promote fields are placed in the Content tab instead;\n# we use this to test that the 'promote' tab is left out of the output when empty\nStandardIndex.content_panels = [\n    FieldPanel('title', classname=\"full title\"),\n    FieldPanel('seo_title'),\n    FieldPanel('slug'),\n    InlinePanel('advert_placements', label=\"Adverts\"),\n]\nStandardIndex.promote_panels = []\n\n\nclass StandardChild(Page):\n    pass\n\n\n# Test overriding edit_handler with a custom one\nStandardChild.edit_handler = TabbedInterface([\n    ObjectList(StandardChild.content_panels, heading='Content'),\n    ObjectList(StandardChild.promote_panels, heading='Promote'),\n    ObjectList(StandardChild.settings_panels, heading='Settings', classname='settings'),\n    ObjectList([], heading='Dinosaurs'),\n], base_form_class=WagtailAdminPageForm)\n\n\nclass BusinessIndex(Page):\n    \"\"\" Can be placed anywhere, can only have Business children \"\"\"\n    subpage_types = ['tests.BusinessChild', 'tests.BusinessSubIndex']\n\n\nclass BusinessSubIndex(Page):\n    \"\"\" Can be placed under BusinessIndex, and have BusinessChild children \"\"\"\n\n    # BusinessNowherePage is 'incorrectly' added here as a possible child.\n    # The rules on BusinessNowherePage prevent it from being a child here though.\n    subpage_types = ['tests.BusinessChild', 'tests.BusinessNowherePage']\n    parent_page_types = ['tests.BusinessIndex', 'tests.BusinessChild']\n\n\nclass BusinessChild(Page):\n    \"\"\" Can only be placed under Business indexes, no children allowed \"\"\"\n    subpage_types = []\n    parent_page_types = ['tests.BusinessIndex', BusinessSubIndex]\n\n\nclass BusinessNowherePage(Page):\n    \"\"\" Not allowed to be placed anywhere \"\"\"\n    parent_page_types = []\n\n\nclass TaggedPageTag(TaggedItemBase):\n    content_object = ParentalKey('tests.TaggedPage', related_name='tagged_items', on_delete=models.CASCADE)\n\n\nclass TaggedPage(Page):\n    tags = ClusterTaggableManager(through=TaggedPageTag, blank=True)\n\n\nTaggedPage.content_panels = [\n    FieldPanel('title', classname=\"full title\"),\n    FieldPanel('tags'),\n]\n\n\nclass SingletonPage(Page):\n    @classmethod\n    def can_create_at(cls, parent):\n        # You can only create one of these!\n        return super(SingletonPage, cls).can_create_at(parent) \\\n            and not cls.objects.exists()\n\n\nclass SingletonPageViaMaxCount(Page):\n    max_count = 1\n\n\nclass PageChooserModel(models.Model):\n    page = models.ForeignKey('wagtailcore.Page', help_text='help text', on_delete=models.CASCADE)\n\n\nclass EventPageChooserModel(models.Model):\n    page = models.ForeignKey('tests.EventPage', help_text='more help text', on_delete=models.CASCADE)\n\n\nclass SnippetChooserModel(models.Model):\n    advert = models.ForeignKey(Advert, help_text='help text', on_delete=models.CASCADE)\n\n    panels = [\n        SnippetChooserPanel('advert'),\n    ]\n\n\nclass SnippetChooserModelWithCustomPrimaryKey(models.Model):\n    advertwithcustomprimarykey = models.ForeignKey(AdvertWithCustomPrimaryKey, help_text='help text', on_delete=models.CASCADE)\n\n    panels = [\n        SnippetChooserPanel('advertwithcustomprimarykey'),\n    ]\n\n\nclass CustomImage(AbstractImage):\n    caption = models.CharField(max_length=255, blank=True)\n    fancy_caption = RichTextField(blank=True)\n    not_editable_field = models.CharField(max_length=255, blank=True)\n\n    admin_form_fields = Image.admin_form_fields + (\n        'caption',\n        'fancy_caption',\n    )\n\n\nclass CustomRendition(AbstractRendition):\n    image = models.ForeignKey(CustomImage, related_name='renditions', on_delete=models.CASCADE)\n\n    class Meta:\n        unique_together = (\n            ('image', 'filter_spec', 'focal_point_key'),\n        )\n\n\nclass CustomDocument(AbstractDocument):\n    description = models.TextField(blank=True)\n    fancy_description = RichTextField(blank=True)\n    admin_form_fields = Document.admin_form_fields + (\n        'description',\n        'fancy_description'\n    )\n\n\nclass StreamModel(models.Model):\n    body = StreamField([\n        ('text', CharBlock()),\n        ('rich_text', RichTextBlock()),\n        ('image', ImageChooserBlock()),\n    ])\n\n\nclass ExtendedImageChooserBlock(ImageChooserBlock):\n    \"\"\"\n    Example of Block with custom get_api_representation method.\n    If the request has an 'extended' query param, it returns a dict of id and title,\n    otherwise, it returns the default value.\n    \"\"\"\n    def get_api_representation(self, value, context=None):\n        image_id = super().get_api_representation(value, context=context)\n        if 'request' in context and context['request'].query_params.get('extended', False):\n            return {\n                'id': image_id,\n                'title': value.title\n            }\n        return image_id\n\n\nclass StreamPage(Page):\n    body = StreamField([\n        ('text', CharBlock()),\n        ('rich_text', RichTextBlock()),\n        ('image', ExtendedImageChooserBlock()),\n        ('product', StructBlock([\n            ('name', CharBlock()),\n            ('price', CharBlock()),\n        ])),\n    ])\n\n    api_fields = ('body',)\n\n    content_panels = [\n        FieldPanel('title'),\n        StreamFieldPanel('body'),\n    ]\n\n\nclass DefaultStreamPage(Page):\n    body = StreamField([\n        ('text', CharBlock()),\n        ('rich_text', RichTextBlock()),\n        ('image', ImageChooserBlock()),\n    ], default='')\n\n    content_panels = [\n        FieldPanel('title'),\n        StreamFieldPanel('body'),\n    ]\n\n\nclass MTIBasePage(Page):\n    is_creatable = False\n\n    class Meta:\n        verbose_name = \"MTI Base page\"\n\n\nclass MTIChildPage(MTIBasePage):\n    # Should be creatable by default, no need to set anything\n    pass\n\n\nclass AbstractPage(Page):\n    class Meta:\n        abstract = True\n\n\n@register_setting\nclass TestSetting(BaseSetting):\n    title = models.CharField(max_length=100)\n    email = models.EmailField(max_length=50)\n\n\n@register_setting(icon=\"tag\")\nclass IconSetting(BaseSetting):\n    pass\n\n\nclass NotYetRegisteredSetting(BaseSetting):\n    pass\n\n\n@register_setting\nclass FileUploadSetting(BaseSetting):\n    file = models.FileField()\n\n\nclass BlogCategory(models.Model):\n    name = models.CharField(unique=True, max_length=80)\n\n\nclass BlogCategoryBlogPage(models.Model):\n    category = models.ForeignKey(BlogCategory, related_name=\"+\", on_delete=models.CASCADE)\n    page = ParentalKey('ManyToManyBlogPage', related_name='categories', on_delete=models.CASCADE)\n    panels = [\n        FieldPanel('category'),\n    ]\n\n\nclass ManyToManyBlogPage(Page):\n    \"\"\"\n    A page type with two different kinds of M2M relation.\n    We don't formally support these, but we don't want them to cause\n    hard breakages either.\n    \"\"\"\n    body = RichTextField(blank=True)\n    adverts = models.ManyToManyField(Advert, blank=True)\n    blog_categories = models.ManyToManyField(\n        BlogCategory, through=BlogCategoryBlogPage, blank=True)\n\n    # make first_published_at editable on this page model\n    settings_panels = Page.settings_panels + [\n        FieldPanel('first_published_at'),\n    ]\n\n\nclass OneToOnePage(Page):\n    \"\"\"\n    A Page containing a O2O relation.\n    \"\"\"\n    body = RichTextBlock(blank=True)\n    page_ptr = models.OneToOneField(Page, parent_link=True,\n                                    related_name='+', on_delete=models.CASCADE)\n\n\nclass GenericSnippetPage(Page):\n    \"\"\"\n    A page containing a reference to an arbitrary snippet (or any model for that matter)\n    linked by a GenericForeignKey\n    \"\"\"\n    snippet_content_type = models.ForeignKey(ContentType, on_delete=models.SET_NULL, null=True)\n    snippet_object_id = models.PositiveIntegerField(null=True)\n    snippet_content_object = GenericForeignKey('snippet_content_type', 'snippet_object_id')\n\n\nclass CustomImageFilePath(AbstractImage):\n    def get_upload_to(self, filename):\n        \"\"\"Create a path that's file-system friendly.\n\n        By hashing the file's contents we guarantee an equal distribution\n        of files within our root directories. This also gives us a\n        better chance of uploading images with the same filename, but\n        different contents - this isn't guaranteed as we're only using\n        the first three characters of the checksum.\n        \"\"\"\n        original_filepath = super().get_upload_to(filename)\n        folder_name, filename = original_filepath.split(os.path.sep)\n\n        # Ensure that we consume the entire file, we can't guarantee that\n        # the stream has not be partially (or entirely) consumed by\n        # another process\n        original_position = self.file.tell()\n        self.file.seek(0)\n        hash256 = hashlib.sha256()\n\n        while True:\n            data = self.file.read(256)\n            if not data:\n                break\n            hash256.update(data)\n        checksum = hash256.hexdigest()\n\n        self.file.seek(original_position)\n        return os.path.join(folder_name, checksum[:3], filename)\n\n\nclass CustomPageQuerySet(PageQuerySet):\n    def about_spam(self):\n        return self.filter(title__contains='spam')\n\n\nCustomManager = PageManager.from_queryset(CustomPageQuerySet)\n\n\nclass CustomManagerPage(Page):\n    objects = CustomManager()\n\n\nclass MyBasePage(Page):\n    \"\"\"\n    A base Page model, used to set site-wide defaults and overrides.\n    \"\"\"\n    objects = CustomManager()\n\n    class Meta:\n        abstract = True\n\n\nclass MyCustomPage(MyBasePage):\n    pass\n\n\nclass ValidatedPage(Page):\n    foo = models.CharField(max_length=255)\n\n    base_form_class = ValidatedPageForm\n    content_panels = Page.content_panels + [\n        FieldPanel('foo'),\n    ]\n\n\nclass DefaultRichTextFieldPage(Page):\n    body = RichTextField()\n\n    content_panels = [\n        FieldPanel('title', classname=\"full title\"),\n        FieldPanel('body'),\n    ]\n\n\nclass DefaultRichBlockFieldPage(Page):\n    body = StreamField([\n        ('rich_text', RichTextBlock()),\n    ])\n\n    content_panels = Page.content_panels + [\n        StreamFieldPanel('body')\n    ]\n\n\nclass CustomRichTextFieldPage(Page):\n    body = RichTextField(editor='custom')\n\n    content_panels = [\n        FieldPanel('title', classname=\"full title\"),\n        FieldPanel('body'),\n    ]\n\n\nclass CustomRichBlockFieldPage(Page):\n    body = StreamField([\n        ('rich_text', RichTextBlock(editor='custom')),\n    ])\n\n    content_panels = [\n        FieldPanel('title', classname=\"full title\"),\n        StreamFieldPanel('body'),\n    ]\n\n\nclass RichTextFieldWithFeaturesPage(Page):\n    body = RichTextField(features=['quotation', 'embed', 'made-up-feature'])\n\n    content_panels = [\n        FieldPanel('title', classname=\"full title\"),\n        FieldPanel('body'),\n    ]\n\n\n# a page that only contains RichTextField within an InlinePanel,\n# to test that the inline child's form media gets pulled through\nclass SectionedRichTextPageSection(Orderable):\n    page = ParentalKey('tests.SectionedRichTextPage', related_name='sections', on_delete=models.CASCADE)\n    body = RichTextField()\n\n    panels = [\n        FieldPanel('body')\n    ]\n\n\nclass SectionedRichTextPage(Page):\n    content_panels = [\n        FieldPanel('title', classname=\"full title\"),\n        InlinePanel('sections')\n    ]\n\n\nclass InlineStreamPageSection(Orderable):\n    page = ParentalKey('tests.InlineStreamPage', related_name='sections', on_delete=models.CASCADE)\n    body = StreamField([\n        ('text', CharBlock()),\n        ('rich_text', RichTextBlock()),\n        ('image', ImageChooserBlock()),\n    ])\n    panels = [\n        StreamFieldPanel('body')\n    ]\n\n\nclass InlineStreamPage(Page):\n    content_panels = [\n        FieldPanel('title', classname=\"full title\"),\n        InlinePanel('sections')\n    ]\n\n\nclass TableBlockStreamPage(Page):\n    table = StreamField([('table', TableBlock())])\n\n    content_panels = [StreamFieldPanel('table')]\n\n\nclass UserProfile(models.Model):\n    # Wagtail's schema must be able to coexist alongside a custom UserProfile model\n    user = models.OneToOneField(settings.AUTH_USER_MODEL, on_delete=models.CASCADE)\n    favourite_colour = models.CharField(max_length=255)\n\n\nclass PanelSettings(TestSetting):\n    panels = [\n        FieldPanel('title')\n    ]\n\n\nclass TabbedSettings(TestSetting):\n    edit_handler = TabbedInterface([\n        ObjectList([\n            FieldPanel('title')\n        ], heading='First tab'),\n        ObjectList([\n            FieldPanel('email')\n        ], heading='Second tab'),\n    ])\n\n\nclass AlwaysShowInMenusPage(Page):\n    show_in_menus_default = True\n\n\n# test for AddField migrations on StreamFields using various default values\nclass AddedStreamFieldWithoutDefaultPage(Page):\n    body = StreamField([\n        ('title', CharBlock())\n    ])\n\n\nclass AddedStreamFieldWithEmptyStringDefaultPage(Page):\n    body = StreamField([\n        ('title', CharBlock())\n    ], default='')\n\n\nclass AddedStreamFieldWithEmptyListDefaultPage(Page):\n    body = StreamField([\n        ('title', CharBlock())\n    ], default=[])\n\n\n# test customising edit handler definitions on a per-request basis\nclass PerUserContentPanels(ObjectList):\n    def _replace_children_with_per_user_config(self):\n        self.children = self.instance.basic_content_panels\n        if self.request.user.is_superuser:\n            self.children = self.instance.superuser_content_panels\n        self.children = [\n            child.bind_to(model=self.model, instance=self.instance,\n                          request=self.request, form=self.form)\n            for child in self.children]\n\n    def on_instance_bound(self):\n        # replace list of children when both instance and request are available\n        if self.request:\n            self._replace_children_with_per_user_config()\n        else:\n            super().on_instance_bound()\n\n    def on_request_bound(self):\n        # replace list of children when both instance and request are available\n        if self.instance:\n            self._replace_children_with_per_user_config()\n        else:\n            super().on_request_bound()\n\n\nclass PerUserPageMixin:\n    basic_content_panels = []\n    superuser_content_panels = []\n\n    @cached_classmethod\n    def get_edit_handler(cls):\n        tabs = []\n\n        if cls.basic_content_panels and cls.superuser_content_panels:\n            tabs.append(PerUserContentPanels(heading='Content'))\n        if cls.promote_panels:\n            tabs.append(ObjectList(cls.promote_panels,\n                                   heading='Promote'))\n        if cls.settings_panels:\n            tabs.append(ObjectList(cls.settings_panels,\n                                   heading='Settings',\n                                   classname='settings'))\n\n        edit_handler = TabbedInterface(tabs,\n                                       base_form_class=cls.base_form_class)\n\n        return edit_handler.bind_to(model=cls)\n\n\nclass SecretPage(PerUserPageMixin, Page):\n    boring_data = models.TextField()\n    secret_data = models.TextField()\n\n    basic_content_panels = Page.content_panels + [\n        FieldPanel('boring_data'),\n    ]\n    superuser_content_panels = basic_content_panels + [\n        FieldPanel('secret_data'),\n    ]\n\n\nclass SimpleParentPage(Page):\n    # `BusinessIndex` has been added to bring it in line with other tests\n    subpage_types = ['tests.SimpleChildPage', BusinessIndex]\n\n\nclass SimpleChildPage(Page):\n    # `Page` has been added to bring it in line with other tests\n    parent_page_types = ['tests.SimpleParentPage', Page]\n\n    max_count_per_parent = 1\n\n\nclass PersonPage(Page):\n    first_name = models.CharField(\n        max_length=255,\n        verbose_name='First Name',\n    )\n    last_name = models.CharField(\n        max_length=255,\n        verbose_name='Last Name',\n    )\n\n    content_panels = Page.content_panels + [\n        MultiFieldPanel([\n            FieldPanel('first_name'),\n            FieldPanel('last_name'),\n        ], 'Person'),\n        InlinePanel('addresses', label='Address'),\n    ]\n\n    class Meta:\n        verbose_name = 'Person'\n        verbose_name_plural = 'Persons'\n\n\nclass Address(index.Indexed, ClusterableModel, Orderable):\n    address = models.CharField(\n        max_length=255,\n        verbose_name='Address',\n    )\n    tags = ClusterTaggableManager(\n        through='tests.AddressTag',\n        blank=True,\n    )\n    person = ParentalKey(\n        to='tests.PersonPage',\n        related_name='addresses',\n        verbose_name='Person'\n    )\n\n    panels = [\n        FieldPanel('address'),\n        FieldPanel('tags'),\n    ]\n\n    class Meta:\n        verbose_name = 'Address'\n        verbose_name_plural = 'Addresses'\n\n\nclass AddressTag(TaggedItemBase):\n    content_object = ParentalKey(\n        to='tests.Address',\n        on_delete=models.CASCADE,\n        related_name='tagged_items'\n    )\n", "target": 1}
{"idx": 892, "func": "# Zulip's main markdown implementation.  See docs/subsystems/markdown.md for\n# detailed documentation on our markdown syntax.\nfrom typing import (Any, Callable, Dict, Iterable, List, NamedTuple,\n                    Optional, Set, Tuple, TypeVar, Union, cast)\nfrom mypy_extensions import TypedDict\nfrom typing.re import Match, Pattern\n\nimport markdown\nimport logging\nimport traceback\nimport urllib\nimport urllib.parse\nimport re\nimport os\nimport html\nimport time\nimport functools\nimport ujson\nimport xml.etree.cElementTree as etree\nfrom xml.etree.cElementTree import Element\n\nfrom collections import deque, defaultdict\n\nimport requests\n\nfrom django.conf import settings\nfrom django.db.models import Q\n\nfrom markdown.extensions import codehilite, nl2br, tables\nfrom zerver.lib.bugdown import fenced_code\nfrom zerver.lib.bugdown.fenced_code import FENCE_RE\nfrom zerver.lib.camo import get_camo_url\nfrom zerver.lib.emoji import translate_emoticons, emoticon_regex\nfrom zerver.lib.mention import possible_mentions, \\\n    possible_user_group_mentions, extract_user_group\nfrom zerver.lib.url_encoding import encode_stream\nfrom zerver.lib.thumbnail import user_uploads_or_external\nfrom zerver.lib.timeout import timeout, TimeoutExpired\nfrom zerver.lib.cache import cache_with_key, NotFoundInCache\nfrom zerver.lib.url_preview import preview as link_preview\nfrom zerver.models import (\n    all_realm_filters,\n    get_active_streams,\n    MAX_MESSAGE_LENGTH,\n    Message,\n    Realm,\n    realm_filters_for_realm,\n    UserProfile,\n    UserGroup,\n    UserGroupMembership,\n)\nimport zerver.lib.mention as mention\nfrom zerver.lib.tex import render_tex\nfrom zerver.lib.exceptions import BugdownRenderingException\n\nReturnT = TypeVar('ReturnT')\n\ndef one_time(method: Callable[[], ReturnT]) -> Callable[[], ReturnT]:\n    '''\n        Use this decorator with extreme caution.\n        The function you wrap should have no dependency\n        on any arguments (no args, no kwargs) nor should\n        it depend on any global state.\n    '''\n    val = None\n\n    def cache_wrapper() -> ReturnT:\n        nonlocal val\n        if val is None:\n            val = method()\n        return val\n    return cache_wrapper\n\nFullNameInfo = TypedDict('FullNameInfo', {\n    'id': int,\n    'email': str,\n    'full_name': str,\n})\n\nDbData = Dict[str, Any]\n\n# Format version of the bugdown rendering; stored along with rendered\n# messages so that we can efficiently determine what needs to be re-rendered\nversion = 1\n\n_T = TypeVar('_T')\nElementStringNone = Union[Element, Optional[str]]\n\nAVATAR_REGEX = r'!avatar\\((?P<email>[^)]*)\\)'\nGRAVATAR_REGEX = r'!gravatar\\((?P<email>[^)]*)\\)'\nEMOJI_REGEX = r'(?P<syntax>:[\\w\\-\\+]+:)'\n\ndef verbose_compile(pattern: str) -> Any:\n    return re.compile(\n        \"^(.*?)%s(.*?)$\" % pattern,\n        re.DOTALL | re.UNICODE | re.VERBOSE\n    )\n\ndef normal_compile(pattern: str) -> Any:\n    return re.compile(\n        r\"^(.*?)%s(.*)$\" % pattern,\n        re.DOTALL | re.UNICODE\n    )\n\nSTREAM_LINK_REGEX = r\"\"\"\n                     (?<![^\\s'\"\\(,:<])            # Start after whitespace or specified chars\n                     \\#\\*\\*                       # and after hash sign followed by double asterisks\n                         (?P<stream_name>[^\\*]+)  # stream name can contain anything\n                     \\*\\*                         # ends by double asterisks\n                    \"\"\"\n\n@one_time\ndef get_compiled_stream_link_regex() -> Pattern:\n    return verbose_compile(STREAM_LINK_REGEX)\n\nLINK_REGEX = None  # type: Pattern\n\ndef get_web_link_regex() -> str:\n    # We create this one time, but not at startup.  So the\n    # first message rendered in any process will have some\n    # extra costs.  It's roughly 75ms to run this code, so\n    # caching the value in LINK_REGEX is super important here.\n    global LINK_REGEX\n    if LINK_REGEX is not None:\n        return LINK_REGEX\n\n    tlds = '|'.join(list_of_tlds())\n\n    # A link starts at a word boundary, and ends at space, punctuation, or end-of-input.\n    #\n    # We detect a url either by the `https?://` or by building around the TLD.\n\n    # In lieu of having a recursive regex (which python doesn't support) to match\n    # arbitrary numbers of nested matching parenthesis, we manually build a regexp that\n    # can match up to six\n    # The inner_paren_contents chunk matches the innermore non-parenthesis-holding text,\n    # and the paren_group matches text with, optionally, a matching set of parens\n    inner_paren_contents = r\"[^\\s()\\\"]*\"\n    paren_group = r\"\"\"\n                    [^\\s()\\\"]*?            # Containing characters that won't end the URL\n                    (?: \\( %s \\)           # and more characters in matched parens\n                        [^\\s()\\\"]*?        # followed by more characters\n                    )*                     # zero-or-more sets of paired parens\n                   \"\"\"\n    nested_paren_chunk = paren_group\n    for i in range(6):\n        nested_paren_chunk = nested_paren_chunk % (paren_group,)\n    nested_paren_chunk = nested_paren_chunk % (inner_paren_contents,)\n\n    file_links = r\"| (?:file://(/[^/ ]*)+/?)\" if settings.ENABLE_FILE_LINKS else r\"\"\n    REGEX = r\"\"\"\n        (?<![^\\s'\"\\(,:<])    # Start after whitespace or specified chars\n                             # (Double-negative lookbehind to allow start-of-string)\n        (?P<url>             # Main group\n            (?:(?:           # Domain part\n                https?://[\\w.:@-]+?   # If it has a protocol, anything goes.\n               |(?:                   # Or, if not, be more strict to avoid false-positives\n                    (?:[\\w-]+\\.)+     # One or more domain components, separated by dots\n                    (?:%s)            # TLDs (filled in via format from tlds-alpha-by-domain.txt)\n                )\n            )\n            (?:/             # A path, beginning with /\n                %s           # zero-to-6 sets of paired parens\n            )?)              # Path is optional\n            | (?:[\\w.-]+\\@[\\w.-]+\\.[\\w]+) # Email is separate, since it can't have a path\n            %s               # File path start with file:///, enable by setting ENABLE_FILE_LINKS=True\n            | (?:bitcoin:[13][a-km-zA-HJ-NP-Z1-9]{25,34})  # Bitcoin address pattern, see https://mokagio.github.io/tech-journal/2014/11/21/regex-bitcoin.html\n        )\n        (?=                            # URL must be followed by (not included in group)\n            [!:;\\?\\),\\.\\'\\\"\\>]*         # Optional punctuation characters\n            (?:\\Z|\\s)                  # followed by whitespace or end of string\n        )\n        \"\"\" % (tlds, nested_paren_chunk, file_links)\n    LINK_REGEX = verbose_compile(REGEX)\n    return LINK_REGEX\n\ndef clear_state_for_testing() -> None:\n    # The link regex never changes in production, but our tests\n    # try out both sides of ENABLE_FILE_LINKS, so we need\n    # a way to clear it.\n    global LINK_REGEX\n    LINK_REGEX = None\n\nbugdown_logger = logging.getLogger()\n\ndef rewrite_local_links_to_relative(db_data: Optional[DbData], link: str) -> str:\n    \"\"\" If the link points to a local destination we can just switch to that\n    instead of opening a new tab. \"\"\"\n\n    if db_data:\n        realm_uri_prefix = db_data['realm_uri'] + \"/\"\n        if link.startswith(realm_uri_prefix):\n            # +1 to skip the `/` before the hash link.\n            return link[len(realm_uri_prefix):]\n\n    return link\n\ndef url_embed_preview_enabled(message: Optional[Message]=None,\n                              realm: Optional[Realm]=None,\n                              no_previews: Optional[bool]=False) -> bool:\n    if not settings.INLINE_URL_EMBED_PREVIEW:\n        return False\n\n    if no_previews:\n        return False\n\n    if realm is None:\n        if message is not None:\n            realm = message.get_realm()\n\n    if realm is None:\n        # realm can be None for odd use cases\n        # like generating documentation or running\n        # test code\n        return True\n\n    return realm.inline_url_embed_preview\n\ndef image_preview_enabled(message: Optional[Message]=None,\n                          realm: Optional[Realm]=None,\n                          no_previews: Optional[bool]=False) -> bool:\n    if not settings.INLINE_IMAGE_PREVIEW:\n        return False\n\n    if no_previews:\n        return False\n\n    if realm is None:\n        if message is not None:\n            realm = message.get_realm()\n\n    if realm is None:\n        # realm can be None for odd use cases\n        # like generating documentation or running\n        # test code\n        return True\n\n    return realm.inline_image_preview\n\ndef list_of_tlds() -> List[str]:\n    # HACK we manually blacklist a few domains\n    blacklist = ['PY\\n', \"MD\\n\"]\n\n    # tlds-alpha-by-domain.txt comes from http://data.iana.org/TLD/tlds-alpha-by-domain.txt\n    tlds_file = os.path.join(os.path.dirname(__file__), 'tlds-alpha-by-domain.txt')\n    tlds = [tld.lower().strip() for tld in open(tlds_file, 'r')\n            if tld not in blacklist and not tld[0].startswith('#')]\n    tlds.sort(key=len, reverse=True)\n    return tlds\n\ndef walk_tree(root: Element,\n              processor: Callable[[Element], Optional[_T]],\n              stop_after_first: bool=False) -> List[_T]:\n    results = []\n    queue = deque([root])\n\n    while queue:\n        currElement = queue.popleft()\n        for child in currElement.getchildren():\n            if child.getchildren():\n                queue.append(child)\n\n            result = processor(child)\n            if result is not None:\n                results.append(result)\n                if stop_after_first:\n                    return results\n\n    return results\n\nElementFamily = NamedTuple('ElementFamily', [\n    ('grandparent', Optional[Element]),\n    ('parent', Element),\n    ('child', Element)\n])\n\nResultWithFamily = NamedTuple('ResultWithFamily', [\n    ('family', ElementFamily),\n    ('result', Any)\n])\n\nElementPair = NamedTuple('ElementPair', [\n    ('parent', Optional[Element]),\n    ('value', Element)\n])\n\ndef walk_tree_with_family(root: Element,\n                          processor: Callable[[Element], Optional[_T]]\n                          ) -> List[ResultWithFamily]:\n    results = []\n\n    queue = deque([ElementPair(parent=None, value=root)])\n    while queue:\n        currElementPair = queue.popleft()\n        for child in currElementPair.value.getchildren():\n            if child.getchildren():\n                queue.append(ElementPair(parent=currElementPair, value=child))  # type: ignore  # Lack of Deque support in typing module for Python 3.4.3\n            result = processor(child)\n            if result is not None:\n                if currElementPair.parent is not None:\n                    grandparent_element = cast(ElementPair, currElementPair.parent)\n                    grandparent = grandparent_element.value\n                else:\n                    grandparent = None\n                family = ElementFamily(\n                    grandparent=grandparent,\n                    parent=currElementPair.value,\n                    child=child\n                )\n\n                results.append(ResultWithFamily(\n                    family=family,\n                    result=result\n                ))\n\n    return results\n\n# height is not actually used\ndef add_a(\n        root: Element,\n        url: str,\n        link: str,\n        title: Optional[str]=None,\n        desc: Optional[str]=None,\n        class_attr: str=\"message_inline_image\",\n        data_id: Optional[str]=None,\n        insertion_index: Optional[int]=None,\n        already_thumbnailed: Optional[bool]=False\n) -> None:\n    title = title if title is not None else url_filename(link)\n    title = title if title else \"\"\n    desc = desc if desc is not None else \"\"\n\n    if insertion_index is not None:\n        div = markdown.util.etree.Element(\"div\")\n        root.insert(insertion_index, div)\n    else:\n        div = markdown.util.etree.SubElement(root, \"div\")\n\n    div.set(\"class\", class_attr)\n    a = markdown.util.etree.SubElement(div, \"a\")\n    a.set(\"href\", link)\n    a.set(\"target\", \"_blank\")\n    a.set(\"title\", title)\n    if data_id is not None:\n        a.set(\"data-id\", data_id)\n    img = markdown.util.etree.SubElement(a, \"img\")\n    if settings.THUMBNAIL_IMAGES and (not already_thumbnailed) and user_uploads_or_external(url):\n        # See docs/thumbnailing.md for some high-level documentation.\n        #\n        # We strip leading '/' from relative URLs here to ensure\n        # consistency in what gets passed to /thumbnail\n        url = url.lstrip('/')\n        img.set(\"src\", \"/thumbnail?url={0}&size=thumbnail\".format(\n            urllib.parse.quote(url, safe='')\n        ))\n        img.set('data-src-fullsize', \"/thumbnail?url={0}&size=full\".format(\n            urllib.parse.quote(url, safe='')\n        ))\n    else:\n        img.set(\"src\", url)\n\n    if class_attr == \"message_inline_ref\":\n        summary_div = markdown.util.etree.SubElement(div, \"div\")\n        title_div = markdown.util.etree.SubElement(summary_div, \"div\")\n        title_div.set(\"class\", \"message_inline_image_title\")\n        title_div.text = title\n        desc_div = markdown.util.etree.SubElement(summary_div, \"desc\")\n        desc_div.set(\"class\", \"message_inline_image_desc\")\n\ndef add_embed(root: Element, link: str, extracted_data: Dict[str, Any]) -> None:\n    container = markdown.util.etree.SubElement(root, \"div\")\n    container.set(\"class\", \"message_embed\")\n\n    img_link = extracted_data.get('image')\n    if img_link:\n        parsed_img_link = urllib.parse.urlparse(img_link)\n        # Append domain where relative img_link url is given\n        if not parsed_img_link.netloc:\n            parsed_url = urllib.parse.urlparse(link)\n            domain = '{url.scheme}://{url.netloc}/'.format(url=parsed_url)\n            img_link = urllib.parse.urljoin(domain, img_link)\n        img = markdown.util.etree.SubElement(container, \"a\")\n        img.set(\"style\", \"background-image: url(\" + img_link + \")\")\n        img.set(\"href\", link)\n        img.set(\"target\", \"_blank\")\n        img.set(\"class\", \"message_embed_image\")\n\n    data_container = markdown.util.etree.SubElement(container, \"div\")\n    data_container.set(\"class\", \"data-container\")\n\n    title = extracted_data.get('title')\n    if title:\n        title_elm = markdown.util.etree.SubElement(data_container, \"div\")\n        title_elm.set(\"class\", \"message_embed_title\")\n        a = markdown.util.etree.SubElement(title_elm, \"a\")\n        a.set(\"href\", link)\n        a.set(\"target\", \"_blank\")\n        a.set(\"title\", title)\n        a.text = title\n    description = extracted_data.get('description')\n    if description:\n        description_elm = markdown.util.etree.SubElement(data_container, \"div\")\n        description_elm.set(\"class\", \"message_embed_description\")\n        description_elm.text = description\n\n@cache_with_key(lambda tweet_id: tweet_id, cache_name=\"database\", with_statsd_key=\"tweet_data\")\ndef fetch_tweet_data(tweet_id: str) -> Optional[Dict[str, Any]]:\n    if settings.TEST_SUITE:\n        from . import testing_mocks\n        res = testing_mocks.twitter(tweet_id)\n    else:\n        creds = {\n            'consumer_key': settings.TWITTER_CONSUMER_KEY,\n            'consumer_secret': settings.TWITTER_CONSUMER_SECRET,\n            'access_token_key': settings.TWITTER_ACCESS_TOKEN_KEY,\n            'access_token_secret': settings.TWITTER_ACCESS_TOKEN_SECRET,\n        }\n        if not all(creds.values()):\n            return None\n\n        # We lazily import twitter here because its import process is\n        # surprisingly slow, and doing so has a significant impact on\n        # the startup performance of `manage.py` commands.\n        import twitter\n\n        try:\n            api = twitter.Api(tweet_mode='extended', **creds)\n            # Sometimes Twitter hangs on responses.  Timing out here\n            # will cause the Tweet to go through as-is with no inline\n            # preview, rather than having the message be rejected\n            # entirely. This timeout needs to be less than our overall\n            # formatting timeout.\n            tweet = timeout(3, api.GetStatus, tweet_id)\n            res = tweet.AsDict()\n        except AttributeError:\n            bugdown_logger.error('Unable to load twitter api, you may have the wrong '\n                                 'library installed, see https://github.com/zulip/zulip/issues/86')\n            return None\n        except TimeoutExpired:\n            # We'd like to try again later and not cache the bad result,\n            # so we need to re-raise the exception (just as though\n            # we were being rate-limited)\n            raise\n        except twitter.TwitterError as e:\n            t = e.args[0]\n            if len(t) == 1 and ('code' in t[0]) and (t[0]['code'] == 34):\n                # Code 34 means that the message doesn't exist; return\n                # None so that we will cache the error\n                return None\n            elif len(t) == 1 and ('code' in t[0]) and (t[0]['code'] == 88 or\n                                                       t[0]['code'] == 130):\n                # Code 88 means that we were rate-limited and 130\n                # means Twitter is having capacity issues; either way\n                # just raise the error so we don't cache None and will\n                # try again later.\n                raise\n            else:\n                # It's not clear what to do in cases of other errors,\n                # but for now it seems reasonable to log at error\n                # level (so that we get notified), but then cache the\n                # failure to proceed with our usual work\n                bugdown_logger.error(traceback.format_exc())\n                return None\n    return res\n\nHEAD_START_RE = re.compile('^head[ >]')\nHEAD_END_RE = re.compile('^/head[ >]')\nMETA_START_RE = re.compile('^meta[ >]')\nMETA_END_RE = re.compile('^/meta[ >]')\n\ndef fetch_open_graph_image(url: str) -> Optional[Dict[str, Any]]:\n    in_head = False\n    # HTML will auto close meta tags, when we start the next tag add\n    # a closing tag if it has not been closed yet.\n    last_closed = True\n    head = []\n    # TODO: What if response content is huge? Should we get headers first?\n    try:\n        content = requests.get(url, timeout=1).text\n    except Exception:\n        return None\n    # Extract the head and meta tags\n    # All meta tags are self closing, have no children or are closed\n    # automatically.\n    for part in content.split('<'):\n        if not in_head and HEAD_START_RE.match(part):\n            # Started the head node output it to have a document root\n            in_head = True\n            head.append('<head>')\n        elif in_head and HEAD_END_RE.match(part):\n            # Found the end of the head close any remaining tag then stop\n            # processing\n            in_head = False\n            if not last_closed:\n                last_closed = True\n                head.append('</meta>')\n            head.append('</head>')\n            break\n\n        elif in_head and META_START_RE.match(part):\n            # Found a meta node copy it\n            if not last_closed:\n                head.append('</meta>')\n                last_closed = True\n            head.append('<')\n            head.append(part)\n            if '/>' not in part:\n                last_closed = False\n\n        elif in_head and META_END_RE.match(part):\n            # End of a meta node just copy it to close the tag\n            head.append('<')\n            head.append(part)\n            last_closed = True\n\n    try:\n        doc = etree.fromstring(''.join(head))\n    except etree.ParseError:\n        return None\n    og_image = doc.find('meta[@property=\"og:image\"]')\n    og_title = doc.find('meta[@property=\"og:title\"]')\n    og_desc = doc.find('meta[@property=\"og:description\"]')\n    title = None\n    desc = None\n    if og_image is not None:\n        image = og_image.get('content')\n    else:\n        return None\n    if og_title is not None:\n        title = og_title.get('content')\n    if og_desc is not None:\n        desc = og_desc.get('content')\n    return {'image': image, 'title': title, 'desc': desc}\n\ndef get_tweet_id(url: str) -> Optional[str]:\n    parsed_url = urllib.parse.urlparse(url)\n    if not (parsed_url.netloc == 'twitter.com' or parsed_url.netloc.endswith('.twitter.com')):\n        return None\n    to_match = parsed_url.path\n    # In old-style twitter.com/#!/wdaher/status/1231241234-style URLs,\n    # we need to look at the fragment instead\n    if parsed_url.path == '/' and len(parsed_url.fragment) > 5:\n        to_match = parsed_url.fragment\n\n    tweet_id_match = re.match(r'^!?/.*?/status(es)?/(?P<tweetid>\\d{10,30})(/photo/[0-9])?/?$', to_match)\n    if not tweet_id_match:\n        return None\n    return tweet_id_match.group(\"tweetid\")\n\nclass InlineHttpsProcessor(markdown.treeprocessors.Treeprocessor):\n    def run(self, root: Element) -> None:\n        # Get all URLs from the blob\n        found_imgs = walk_tree(root, lambda e: e if e.tag == \"img\" else None)\n        for img in found_imgs:\n            url = img.get(\"src\")\n            if urllib.parse.urlsplit(url).scheme != \"http\":\n                # Don't rewrite images on our own site (e.g. emoji).\n                continue\n            img.set(\"src\", get_camo_url(url))\n\nclass BacktickPattern(markdown.inlinepatterns.Pattern):\n    \"\"\" Return a `<code>` element containing the matching text. \"\"\"\n    def __init__(self, pattern: str) -> None:\n        markdown.inlinepatterns.Pattern.__init__(self, pattern)\n        self.ESCAPED_BSLASH = '%s%s%s' % (markdown.util.STX, ord('\\\\'), markdown.util.ETX)\n        self.tag = 'code'\n\n    def handleMatch(self, m: Match[str]) -> Union[str, Element]:\n        if m.group(4):\n            el = markdown.util.etree.Element(self.tag)\n            # Modified to not strip whitespace\n            el.text = markdown.util.AtomicString(m.group(4))\n            return el\n        else:\n            return m.group(2).replace('\\\\\\\\', self.ESCAPED_BSLASH)\n\nclass InlineInterestingLinkProcessor(markdown.treeprocessors.Treeprocessor):\n    TWITTER_MAX_IMAGE_HEIGHT = 400\n    TWITTER_MAX_TO_PREVIEW = 3\n    INLINE_PREVIEW_LIMIT_PER_MESSAGE = 5\n\n    def __init__(self, md: markdown.Markdown) -> None:\n        markdown.treeprocessors.Treeprocessor.__init__(self, md)\n\n    def get_actual_image_url(self, url: str) -> str:\n        # Add specific per-site cases to convert image-preview urls to image urls.\n        # See https://github.com/zulip/zulip/issues/4658 for more information\n        parsed_url = urllib.parse.urlparse(url)\n        if (parsed_url.netloc == 'github.com' or parsed_url.netloc.endswith('.github.com')):\n            # https://github.com/zulip/zulip/blob/master/static/images/logo/zulip-icon-128x128.png ->\n            # https://raw.githubusercontent.com/zulip/zulip/master/static/images/logo/zulip-icon-128x128.png\n            split_path = parsed_url.path.split('/')\n            if len(split_path) > 3 and split_path[3] == \"blob\":\n                return urllib.parse.urljoin('https://raw.githubusercontent.com',\n                                            '/'.join(split_path[0:3] + split_path[4:]))\n\n        return url\n\n    def is_image(self, url: str) -> bool:\n        if not self.markdown.image_preview_enabled:\n            return False\n        parsed_url = urllib.parse.urlparse(url)\n        # List from http://support.google.com/chromeos/bin/answer.py?hl=en&answer=183093\n        for ext in [\".bmp\", \".gif\", \".jpg\", \"jpeg\", \".png\", \".webp\"]:\n            if parsed_url.path.lower().endswith(ext):\n                return True\n        return False\n\n    def dropbox_image(self, url: str) -> Optional[Dict[str, Any]]:\n        # TODO: The returned Dict could possibly be a TypedDict in future.\n        parsed_url = urllib.parse.urlparse(url)\n        if (parsed_url.netloc == 'dropbox.com' or parsed_url.netloc.endswith('.dropbox.com')):\n            is_album = parsed_url.path.startswith('/sc/') or parsed_url.path.startswith('/photos/')\n            # Only allow preview Dropbox shared links\n            if not (parsed_url.path.startswith('/s/') or\n                    parsed_url.path.startswith('/sh/') or\n                    is_album):\n                return None\n\n            # Try to retrieve open graph protocol info for a preview\n            # This might be redundant right now for shared links for images.\n            # However, we might want to make use of title and description\n            # in the future. If the actual image is too big, we might also\n            # want to use the open graph image.\n            image_info = fetch_open_graph_image(url)\n\n            is_image = is_album or self.is_image(url)\n\n            # If it is from an album or not an actual image file,\n            # just use open graph image.\n            if is_album or not is_image:\n                # Failed to follow link to find an image preview so\n                # use placeholder image and guess filename\n                if image_info is None:\n                    return None\n\n                image_info[\"is_image\"] = is_image\n                return image_info\n\n            # Otherwise, try to retrieve the actual image.\n            # This is because open graph image from Dropbox may have padding\n            # and gifs do not work.\n            # TODO: What if image is huge? Should we get headers first?\n            if image_info is None:\n                image_info = dict()\n            image_info['is_image'] = True\n            parsed_url_list = list(parsed_url)\n            parsed_url_list[4] = \"dl=1\"  # Replaces query\n            image_info[\"image\"] = urllib.parse.urlunparse(parsed_url_list)\n\n            return image_info\n        return None\n\n    def youtube_id(self, url: str) -> Optional[str]:\n        if not self.markdown.image_preview_enabled:\n            return None\n        # Youtube video id extraction regular expression from http://pastebin.com/KyKAFv1s\n        # Slightly modified to support URLs of the form youtu.be/<id>\n        # If it matches, match.group(2) is the video id.\n        schema_re = r'(?:https?://)'\n        host_re = r'(?:youtu\\.be/|(?:\\w+\\.)?youtube(?:-nocookie)?\\.com/)'\n        param_re = r'(?:(?:(?:v|embed)/)|(?:(?:watch(?:_popup)?(?:\\.php)?)?(?:\\?|#!?)(?:.+&)?v=))'\n        id_re = r'([0-9A-Za-z_-]+)'\n        youtube_re = r'^({schema_re}?{host_re}{param_re}?)?{id_re}(?(1).+)?$'\n        youtube_re = youtube_re.format(schema_re=schema_re, host_re=host_re, id_re=id_re, param_re=param_re)\n        match = re.match(youtube_re, url)\n        if match is None:\n            return None\n        return match.group(2)\n\n    def youtube_image(self, url: str) -> Optional[str]:\n        yt_id = self.youtube_id(url)\n\n        if yt_id is not None:\n            return \"https://i.ytimg.com/vi/%s/default.jpg\" % (yt_id,)\n        return None\n\n    def vimeo_id(self, url: str) -> Optional[str]:\n        if not self.markdown.image_preview_enabled:\n            return None\n        #(http|https)?:\\/\\/(www\\.)?vimeo.com\\/(?:channels\\/(?:\\w+\\/)?|groups\\/([^\\/]*)\\/videos\\/|)(\\d+)(?:|\\/\\?)\n        # If it matches, match.group('id') is the video id.\n\n        vimeo_re = r'^((http|https)?:\\/\\/(www\\.)?vimeo.com\\/' + \\\n                   r'(?:channels\\/(?:\\w+\\/)?|groups\\/' + \\\n                   r'([^\\/]*)\\/videos\\/|)(\\d+)(?:|\\/\\?))$'\n        match = re.match(vimeo_re, url)\n        if match is None:\n            return None\n        return match.group(5)\n\n    def vimeo_title(self, extracted_data: Dict[str, Any]) -> Optional[str]:\n        title = extracted_data.get(\"title\")\n        if title is not None:\n            return \"Vimeo - {}\".format(title)\n        return None\n\n    def twitter_text(self, text: str,\n                     urls: List[Dict[str, str]],\n                     user_mentions: List[Dict[str, Any]],\n                     media: List[Dict[str, Any]]) -> Element:\n        \"\"\"\n        Use data from the twitter API to turn links, mentions and media into A\n        tags. Also convert unicode emojis to images.\n\n        This works by using the urls, user_mentions and media data from\n        the twitter API and searching for unicode emojis in the text using\n        `unicode_emoji_regex`.\n\n        The first step is finding the locations of the URLs, mentions, media and\n        emoji in the text. For each match we build a dictionary with type, the start\n        location, end location, the URL to link to, and the text(codepoint and title\n        in case of emojis) to be used in the link(image in case of emojis).\n\n        Next we sort the matches by start location. And for each we add the\n        text from the end of the last link to the start of the current link to\n        the output. The text needs to added to the text attribute of the first\n        node (the P tag) or the tail the last link created.\n\n        Finally we add any remaining text to the last node.\n        \"\"\"\n\n        to_process = []  # type: List[Dict[str, Any]]\n        # Build dicts for URLs\n        for url_data in urls:\n            short_url = url_data[\"url\"]\n            full_url = url_data[\"expanded_url\"]\n            for match in re.finditer(re.escape(short_url), text, re.IGNORECASE):\n                to_process.append({\n                    'type': 'url',\n                    'start': match.start(),\n                    'end': match.end(),\n                    'url': short_url,\n                    'text': full_url,\n                })\n        # Build dicts for mentions\n        for user_mention in user_mentions:\n            screen_name = user_mention['screen_name']\n            mention_string = '@' + screen_name\n            for match in re.finditer(re.escape(mention_string), text, re.IGNORECASE):\n                to_process.append({\n                    'type': 'mention',\n                    'start': match.start(),\n                    'end': match.end(),\n                    'url': 'https://twitter.com/' + urllib.parse.quote(screen_name),\n                    'text': mention_string,\n                })\n        # Build dicts for media\n        for media_item in media:\n            short_url = media_item['url']\n            expanded_url = media_item['expanded_url']\n            for match in re.finditer(re.escape(short_url), text, re.IGNORECASE):\n                to_process.append({\n                    'type': 'media',\n                    'start': match.start(),\n                    'end': match.end(),\n                    'url': short_url,\n                    'text': expanded_url,\n                })\n        # Build dicts for emojis\n        for match in re.finditer(unicode_emoji_regex, text, re.IGNORECASE):\n            orig_syntax = match.group('syntax')\n            codepoint = unicode_emoji_to_codepoint(orig_syntax)\n            if codepoint in codepoint_to_name:\n                display_string = ':' + codepoint_to_name[codepoint] + ':'\n                to_process.append({\n                    'type': 'emoji',\n                    'start': match.start(),\n                    'end': match.end(),\n                    'codepoint': codepoint,\n                    'title': display_string,\n                })\n\n        to_process.sort(key=lambda x: x['start'])\n        p = current_node = markdown.util.etree.Element('p')\n\n        def set_text(text: str) -> None:\n            \"\"\"\n            Helper to set the text or the tail of the current_node\n            \"\"\"\n            if current_node == p:\n                current_node.text = text\n            else:\n                current_node.tail = text\n\n        db_data = self.markdown.zulip_db_data\n        current_index = 0\n        for item in to_process:\n            # The text we want to link starts in already linked text skip it\n            if item['start'] < current_index:\n                continue\n            # Add text from the end of last link to the start of the current\n            # link\n            set_text(text[current_index:item['start']])\n            current_index = item['end']\n            if item['type'] != 'emoji':\n                current_node = elem = url_to_a(db_data, item['url'], item['text'])\n            else:\n                current_node = elem = make_emoji(item['codepoint'], item['title'])\n            p.append(elem)\n\n        # Add any unused text\n        set_text(text[current_index:])\n        return p\n\n    def twitter_link(self, url: str) -> Optional[Element]:\n        tweet_id = get_tweet_id(url)\n\n        if tweet_id is None:\n            return None\n\n        try:\n            res = fetch_tweet_data(tweet_id)\n            if res is None:\n                return None\n            user = res['user']  # type: Dict[str, Any]\n            tweet = markdown.util.etree.Element(\"div\")\n            tweet.set(\"class\", \"twitter-tweet\")\n            img_a = markdown.util.etree.SubElement(tweet, 'a')\n            img_a.set(\"href\", url)\n            img_a.set(\"target\", \"_blank\")\n            profile_img = markdown.util.etree.SubElement(img_a, 'img')\n            profile_img.set('class', 'twitter-avatar')\n            # For some reason, for, e.g. tweet 285072525413724161,\n            # python-twitter does not give us a\n            # profile_image_url_https, but instead puts that URL in\n            # profile_image_url. So use _https if available, but fall\n            # back gracefully.\n            image_url = user.get('profile_image_url_https', user['profile_image_url'])\n            profile_img.set('src', image_url)\n\n            text = html.unescape(res['full_text'])\n            urls = res.get('urls', [])\n            user_mentions = res.get('user_mentions', [])\n            media = res.get('media', [])  # type: List[Dict[str, Any]]\n            p = self.twitter_text(text, urls, user_mentions, media)\n            tweet.append(p)\n\n            span = markdown.util.etree.SubElement(tweet, 'span')\n            span.text = \"- %s (@%s)\" % (user['name'], user['screen_name'])\n\n            # Add image previews\n            for media_item in media:\n                # Only photos have a preview image\n                if media_item['type'] != 'photo':\n                    continue\n\n                # Find the image size that is smaller than\n                # TWITTER_MAX_IMAGE_HEIGHT px tall or the smallest\n                size_name_tuples = list(media_item['sizes'].items())\n                size_name_tuples.sort(reverse=True,\n                                      key=lambda x: x[1]['h'])\n                for size_name, size in size_name_tuples:\n                    if size['h'] < self.TWITTER_MAX_IMAGE_HEIGHT:\n                        break\n\n                media_url = '%s:%s' % (media_item['media_url_https'], size_name)\n                img_div = markdown.util.etree.SubElement(tweet, 'div')\n                img_div.set('class', 'twitter-image')\n                img_a = markdown.util.etree.SubElement(img_div, 'a')\n                img_a.set('href', media_item['url'])\n                img_a.set('target', '_blank')\n                img_a.set('title', media_item['url'])\n                img = markdown.util.etree.SubElement(img_a, 'img')\n                img.set('src', media_url)\n\n            return tweet\n        except Exception:\n            # We put this in its own try-except because it requires external\n            # connectivity. If Twitter flakes out, we don't want to not-render\n            # the entire message; we just want to not show the Twitter preview.\n            bugdown_logger.warning(traceback.format_exc())\n            return None\n\n    def get_url_data(self, e: Element) -> Optional[Tuple[str, str]]:\n        if e.tag == \"a\":\n            if e.text is not None:\n                return (e.get(\"href\"), e.text)\n            return (e.get(\"href\"), e.get(\"href\"))\n        return None\n\n    def handle_image_inlining(self, root: Element, found_url: ResultWithFamily) -> None:\n        grandparent = found_url.family.grandparent\n        parent = found_url.family.parent\n        ahref_element = found_url.family.child\n        (url, text) = found_url.result\n        actual_url = self.get_actual_image_url(url)\n\n        # url != text usually implies a named link, which we opt not to remove\n        url_eq_text = (url == text)\n\n        if parent.tag == 'li':\n            add_a(parent, self.get_actual_image_url(url), url, title=text)\n            if not parent.text and not ahref_element.tail and url_eq_text:\n                parent.remove(ahref_element)\n\n        elif parent.tag == 'p':\n            parent_index = None\n            for index, uncle in enumerate(grandparent.getchildren()):\n                if uncle is parent:\n                    parent_index = index\n                    break\n\n            if parent_index is not None:\n                ins_index = self.find_proper_insertion_index(grandparent, parent, parent_index)\n                add_a(grandparent, actual_url, url, title=text, insertion_index=ins_index)\n\n            else:\n                # We're not inserting after parent, since parent not found.\n                # Append to end of list of grandparent's children as normal\n                add_a(grandparent, actual_url, url, title=text)\n\n            # If link is alone in a paragraph, delete paragraph containing it\n            if (len(parent.getchildren()) == 1 and\n                    (not parent.text or parent.text == \"\\n\") and\n                    not ahref_element.tail and\n                    url_eq_text):\n                grandparent.remove(parent)\n\n        else:\n            # If none of the above criteria match, fall back to old behavior\n            add_a(root, actual_url, url, title=text)\n\n    def find_proper_insertion_index(self, grandparent: Element, parent: Element,\n                                    parent_index_in_grandparent: int) -> int:\n        # If there are several inline images from same paragraph, ensure that\n        # they are in correct (and not opposite) order by inserting after last\n        # inline image from paragraph 'parent'\n\n        uncles = grandparent.getchildren()\n        parent_links = [ele.attrib['href'] for ele in parent.iter(tag=\"a\")]\n        insertion_index = parent_index_in_grandparent\n\n        while True:\n            insertion_index += 1\n            if insertion_index >= len(uncles):\n                return insertion_index\n\n            uncle = uncles[insertion_index]\n            inline_image_classes = ['message_inline_image', 'message_inline_ref']\n            if (\n                uncle.tag != 'div' or\n                'class' not in uncle.keys() or\n                uncle.attrib['class'] not in inline_image_classes\n            ):\n                return insertion_index\n\n            uncle_link = list(uncle.iter(tag=\"a\"))[0].attrib['href']\n            if uncle_link not in parent_links:\n                return insertion_index\n\n    def is_absolute_url(self, url: str) -> bool:\n        return bool(urllib.parse.urlparse(url).netloc)\n\n    def run(self, root: Element) -> None:\n        # Get all URLs from the blob\n        found_urls = walk_tree_with_family(root, self.get_url_data)\n        if len(found_urls) == 0 or len(found_urls) > self.INLINE_PREVIEW_LIMIT_PER_MESSAGE:\n            return\n\n        rendered_tweet_count = 0\n\n        for found_url in found_urls:\n            (url, text) = found_url.result\n            if not self.is_absolute_url(url):\n                if self.is_image(url):\n                    self.handle_image_inlining(root, found_url)\n                # We don't have a strong use case for doing url preview for relative links.\n                continue\n\n            dropbox_image = self.dropbox_image(url)\n            if dropbox_image is not None:\n                class_attr = \"message_inline_ref\"\n                is_image = dropbox_image[\"is_image\"]\n                if is_image:\n                    class_attr = \"message_inline_image\"\n                    # Not making use of title and description of images\n                add_a(root, dropbox_image['image'], url,\n                      title=dropbox_image.get('title', \"\"),\n                      desc=dropbox_image.get('desc', \"\"),\n                      class_attr=class_attr,\n                      already_thumbnailed=True)\n                continue\n            if self.is_image(url):\n                self.handle_image_inlining(root, found_url)\n                continue\n            if get_tweet_id(url) is not None:\n                if rendered_tweet_count >= self.TWITTER_MAX_TO_PREVIEW:\n                    # Only render at most one tweet per message\n                    continue\n                twitter_data = self.twitter_link(url)\n                if twitter_data is None:\n                    # This link is not actually a tweet known to twitter\n                    continue\n                rendered_tweet_count += 1\n                div = markdown.util.etree.SubElement(root, \"div\")\n                div.set(\"class\", \"inline-preview-twitter\")\n                div.insert(0, twitter_data)\n                continue\n            youtube = self.youtube_image(url)\n            if youtube is not None:\n                yt_id = self.youtube_id(url)\n                add_a(root, youtube, url, None, None,\n                      \"youtube-video message_inline_image\",\n                      yt_id, already_thumbnailed=True)\n                continue\n\n            db_data = self.markdown.zulip_db_data\n            if db_data and db_data['sent_by_bot']:\n                continue\n\n            if not self.markdown.url_embed_preview_enabled:\n                continue\n\n            try:\n                extracted_data = link_preview.link_embed_data_from_cache(url)\n            except NotFoundInCache:\n                self.markdown.zulip_message.links_for_preview.add(url)\n                continue\n            if extracted_data:\n                vm_id = self.vimeo_id(url)\n                if vm_id is not None:\n                    vimeo_image = extracted_data.get('image')\n                    vimeo_title = self.vimeo_title(extracted_data)\n                    if vimeo_image is not None:\n                        add_a(root, vimeo_image, url, vimeo_title,\n                              None, \"vimeo-video message_inline_image\", vm_id,\n                              already_thumbnailed=True)\n                    if vimeo_title is not None:\n                        found_url.family.child.text = vimeo_title\n                else:\n                    add_embed(root, url, extracted_data)\n\nclass Avatar(markdown.inlinepatterns.Pattern):\n    def handleMatch(self, match: Match[str]) -> Optional[Element]:\n        img = markdown.util.etree.Element('img')\n        email_address = match.group('email')\n        email = email_address.strip().lower()\n        profile_id = None\n\n        db_data = self.markdown.zulip_db_data\n        if db_data is not None:\n            user_dict = db_data['email_info'].get(email)\n            if user_dict is not None:\n                profile_id = user_dict['id']\n\n        img.set('class', 'message_body_gravatar')\n        img.set('src', '/avatar/{0}?s=30'.format(profile_id or email))\n        img.set('title', email)\n        img.set('alt', email)\n        return img\n\ndef possible_avatar_emails(content: str) -> Set[str]:\n    emails = set()\n    for REGEX in [AVATAR_REGEX, GRAVATAR_REGEX]:\n        matches = re.findall(REGEX, content)\n        for email in matches:\n            if email:\n                emails.add(email)\n\n    return emails\n\npath_to_name_to_codepoint = os.path.join(settings.STATIC_ROOT,\n                                         \"generated\", \"emoji\", \"name_to_codepoint.json\")\nwith open(path_to_name_to_codepoint) as name_to_codepoint_file:\n    name_to_codepoint = ujson.load(name_to_codepoint_file)\n\npath_to_codepoint_to_name = os.path.join(settings.STATIC_ROOT,\n                                         \"generated\", \"emoji\", \"codepoint_to_name.json\")\nwith open(path_to_codepoint_to_name) as codepoint_to_name_file:\n    codepoint_to_name = ujson.load(codepoint_to_name_file)\n\n# All of our emojis(non ZWJ sequences) belong to one of these unicode blocks:\n# \\U0001f100-\\U0001f1ff - Enclosed Alphanumeric Supplement\n# \\U0001f200-\\U0001f2ff - Enclosed Ideographic Supplement\n# \\U0001f300-\\U0001f5ff - Miscellaneous Symbols and Pictographs\n# \\U0001f600-\\U0001f64f - Emoticons (Emoji)\n# \\U0001f680-\\U0001f6ff - Transport and Map Symbols\n# \\U0001f900-\\U0001f9ff - Supplemental Symbols and Pictographs\n# \\u2000-\\u206f         - General Punctuation\n# \\u2300-\\u23ff         - Miscellaneous Technical\n# \\u2400-\\u243f         - Control Pictures\n# \\u2440-\\u245f         - Optical Character Recognition\n# \\u2460-\\u24ff         - Enclosed Alphanumerics\n# \\u2500-\\u257f         - Box Drawing\n# \\u2580-\\u259f         - Block Elements\n# \\u25a0-\\u25ff         - Geometric Shapes\n# \\u2600-\\u26ff         - Miscellaneous Symbols\n# \\u2700-\\u27bf         - Dingbats\n# \\u2900-\\u297f         - Supplemental Arrows-B\n# \\u2b00-\\u2bff         - Miscellaneous Symbols and Arrows\n# \\u3000-\\u303f         - CJK Symbols and Punctuation\n# \\u3200-\\u32ff         - Enclosed CJK Letters and Months\nunicode_emoji_regex = '(?P<syntax>['\\\n    '\\U0001F100-\\U0001F64F'    \\\n    '\\U0001F680-\\U0001F6FF'    \\\n    '\\U0001F900-\\U0001F9FF'    \\\n    '\\u2000-\\u206F'            \\\n    '\\u2300-\\u27BF'            \\\n    '\\u2900-\\u297F'            \\\n    '\\u2B00-\\u2BFF'            \\\n    '\\u3000-\\u303F'            \\\n    '\\u3200-\\u32FF'            \\\n    '])'\n# The equivalent JS regex is \\ud83c[\\udd00-\\udfff]|\\ud83d[\\udc00-\\ude4f]|\\ud83d[\\ude80-\\udeff]|\n# \\ud83e[\\udd00-\\uddff]|[\\u2000-\\u206f]|[\\u2300-\\u27bf]|[\\u2b00-\\u2bff]|[\\u3000-\\u303f]|\n# [\\u3200-\\u32ff]. See below comments for explanation. The JS regex is used by marked.js for\n# frontend unicode emoji processing.\n# The JS regex \\ud83c[\\udd00-\\udfff]|\\ud83d[\\udc00-\\ude4f] represents U0001f100-\\U0001f64f\n# The JS regex \\ud83d[\\ude80-\\udeff] represents \\U0001f680-\\U0001f6ff\n# The JS regex \\ud83e[\\udd00-\\uddff] represents \\U0001f900-\\U0001f9ff\n# The JS regex [\\u2000-\\u206f] represents \\u2000-\\u206f\n# The JS regex [\\u2300-\\u27bf] represents \\u2300-\\u27bf\n# Similarly other JS regexes can be mapped to the respective unicode blocks.\n# For more information, please refer to the following article:\n# http://crocodillon.com/blog/parsing-emoji-unicode-in-javascript\n\ndef make_emoji(codepoint: str, display_string: str) -> Element:\n    # Replace underscore in emoji's title with space\n    title = display_string[1:-1].replace(\"_\", \" \")\n    span = markdown.util.etree.Element('span')\n    span.set('class', 'emoji emoji-%s' % (codepoint,))\n    span.set('title', title)\n    span.set('role', 'img')\n    span.set('aria-label', title)\n    span.text = display_string\n    return span\n\ndef make_realm_emoji(src: str, display_string: str) -> Element:\n    elt = markdown.util.etree.Element('img')\n    elt.set('src', src)\n    elt.set('class', 'emoji')\n    elt.set(\"alt\", display_string)\n    elt.set(\"title\", display_string[1:-1].replace(\"_\", \" \"))\n    return elt\n\ndef unicode_emoji_to_codepoint(unicode_emoji: str) -> str:\n    codepoint = hex(ord(unicode_emoji))[2:]\n    # Unicode codepoints are minimum of length 4, padded\n    # with zeroes if the length is less than zero.\n    while len(codepoint) < 4:\n        codepoint = '0' + codepoint\n    return codepoint\n\nclass EmoticonTranslation(markdown.inlinepatterns.Pattern):\n    \"\"\" Translates emoticons like `:)` into emoji like `:smile:`. \"\"\"\n    def handleMatch(self, match: Match[str]) -> Optional[Element]:\n        db_data = self.markdown.zulip_db_data\n        if db_data is None or not db_data['translate_emoticons']:\n            return None\n\n        emoticon = match.group('emoticon')\n        translated = translate_emoticons(emoticon)\n        name = translated[1:-1]\n        return make_emoji(name_to_codepoint[name], translated)\n\nclass UnicodeEmoji(markdown.inlinepatterns.Pattern):\n    def handleMatch(self, match: Match[str]) -> Optional[Element]:\n        orig_syntax = match.group('syntax')\n        codepoint = unicode_emoji_to_codepoint(orig_syntax)\n        if codepoint in codepoint_to_name:\n            display_string = ':' + codepoint_to_name[codepoint] + ':'\n            return make_emoji(codepoint, display_string)\n        else:\n            return None\n\nclass Emoji(markdown.inlinepatterns.Pattern):\n    def handleMatch(self, match: Match[str]) -> Optional[Element]:\n        orig_syntax = match.group(\"syntax\")\n        name = orig_syntax[1:-1]\n\n        active_realm_emoji = {}  # type: Dict[str, Dict[str, str]]\n        db_data = self.markdown.zulip_db_data\n        if db_data is not None:\n            active_realm_emoji = db_data['active_realm_emoji']\n\n        if self.markdown.zulip_message and name in active_realm_emoji:\n            return make_realm_emoji(active_realm_emoji[name]['source_url'], orig_syntax)\n        elif name == 'zulip':\n            return make_realm_emoji('/static/generated/emoji/images/emoji/unicode/zulip.png', orig_syntax)\n        elif name in name_to_codepoint:\n            return make_emoji(name_to_codepoint[name], orig_syntax)\n        else:\n            return None\n\ndef content_has_emoji_syntax(content: str) -> bool:\n    return re.search(EMOJI_REGEX, content) is not None\n\nclass ModalLink(markdown.inlinepatterns.Pattern):\n    \"\"\"\n    A pattern that allows including in-app modal links in messages.\n    \"\"\"\n\n    def handleMatch(self, match: Match[str]) -> Element:\n        relative_url = match.group('relative_url')\n        text = match.group('text')\n\n        a_tag = markdown.util.etree.Element(\"a\")\n        a_tag.set(\"href\", relative_url)\n        a_tag.set(\"title\", relative_url)\n        a_tag.text = text\n\n        return a_tag\n\nclass Tex(markdown.inlinepatterns.Pattern):\n    def handleMatch(self, match: Match[str]) -> Element:\n        rendered = render_tex(match.group('body'), is_inline=True)\n        if rendered is not None:\n            return etree.fromstring(rendered.encode('utf-8'))\n        else:  # Something went wrong while rendering\n            span = markdown.util.etree.Element('span')\n            span.set('class', 'tex-error')\n            span.text = '$$' + match.group('body') + '$$'\n            return span\n\nupload_title_re = re.compile(\"^(https?://[^/]*)?(/user_uploads/\\\\d+)(/[^/]*)?/[^/]*/(?P<filename>[^/]*)$\")\ndef url_filename(url: str) -> str:\n    \"\"\"Extract the filename if a URL is an uploaded file, or return the original URL\"\"\"\n    match = upload_title_re.match(url)\n    if match:\n        return match.group('filename')\n    else:\n        return url\n\ndef fixup_link(link: markdown.util.etree.Element, target_blank: bool=True) -> None:\n    \"\"\"Set certain attributes we want on every link.\"\"\"\n    if target_blank:\n        link.set('target', '_blank')\n    link.set('title', url_filename(link.get('href')))\n\n\ndef sanitize_url(url: str) -> Optional[str]:\n    \"\"\"\n    Sanitize a url against xss attacks.\n    See the docstring on markdown.inlinepatterns.LinkPattern.sanitize_url.\n    \"\"\"\n    try:\n        parts = urllib.parse.urlparse(url.replace(' ', '%20'))\n        scheme, netloc, path, params, query, fragment = parts\n    except ValueError:\n        # Bad url - so bad it couldn't be parsed.\n        return ''\n\n    # If there is no scheme or netloc and there is a '@' in the path,\n    # treat it as a mailto: and set the appropriate scheme\n    if scheme == '' and netloc == '' and '@' in path:\n        scheme = 'mailto'\n    elif scheme == '' and netloc == '' and len(path) > 0 and path[0] == '/':\n        # Allow domain-relative links\n        return urllib.parse.urlunparse(('', '', path, params, query, fragment))\n    elif (scheme, netloc, path, params, query) == ('', '', '', '', '') and len(fragment) > 0:\n        # Allow fragment links\n        return urllib.parse.urlunparse(('', '', '', '', '', fragment))\n\n    # Zulip modification: If scheme is not specified, assume http://\n    # We re-enter sanitize_url because netloc etc. need to be re-parsed.\n    if not scheme:\n        return sanitize_url('http://' + url)\n\n    locless_schemes = ['mailto', 'news', 'file', 'bitcoin']\n    if netloc == '' and scheme not in locless_schemes:\n        # This fails regardless of anything else.\n        # Return immediately to save additional processing\n        return None\n\n    # Upstream code will accept a URL like javascript://foo because it\n    # appears to have a netloc.  Additionally there are plenty of other\n    # schemes that do weird things like launch external programs.  To be\n    # on the safe side, we whitelist the scheme.\n    if scheme not in ('http', 'https', 'ftp', 'mailto', 'file', 'bitcoin'):\n        return None\n\n    # Upstream code scans path, parameters, and query for colon characters\n    # because\n    #\n    #    some aliases [for javascript:] will appear to urllib.parse to have\n    #    no scheme. On top of that relative links (i.e.: \"foo/bar.html\")\n    #    have no scheme.\n    #\n    # We already converted an empty scheme to http:// above, so we skip\n    # the colon check, which would also forbid a lot of legitimate URLs.\n\n    # Url passes all tests. Return url as-is.\n    return urllib.parse.urlunparse((scheme, netloc, path, params, query, fragment))\n\ndef url_to_a(db_data: Optional[DbData], url: str, text: Optional[str]=None) -> Union[Element, str]:\n    a = markdown.util.etree.Element('a')\n\n    href = sanitize_url(url)\n    target_blank = True\n    if href is None:\n        # Rejected by sanitize_url; render it as plain text.\n        return url\n    if text is None:\n        text = markdown.util.AtomicString(url)\n\n    href = rewrite_local_links_to_relative(db_data, href)\n    target_blank = not href.startswith(\"#narrow\") and not href.startswith('mailto:')\n\n    a.set('href', href)\n    a.text = text\n    fixup_link(a, target_blank)\n    return a\n\nclass CompiledPattern(markdown.inlinepatterns.Pattern):\n    def __init__(self, compiled_re: Pattern, md: markdown.Markdown) -> None:\n        # This is similar to the superclass's small __init__ function,\n        # but we skip the compilation step and let the caller give us\n        # a compiled regex.\n        self.compiled_re = compiled_re\n        self.md = md\n\nclass AutoLink(CompiledPattern):\n    def handleMatch(self, match: Match[str]) -> ElementStringNone:\n        url = match.group('url')\n        db_data = self.markdown.zulip_db_data\n        return url_to_a(db_data, url)\n\nclass UListProcessor(markdown.blockprocessors.UListProcessor):\n    \"\"\" Process unordered list blocks.\n\n        Based on markdown.blockprocessors.UListProcessor, but does not accept\n        '+' or '-' as a bullet character.\"\"\"\n\n    TAG = 'ul'\n    RE = re.compile('^[ ]{0,3}[*][ ]+(.*)')\n\n    def __init__(self, parser: Any) -> None:\n\n        # HACK: Set the tab length to 2 just for the initialization of\n        # this class, so that bulleted lists (and only bulleted lists)\n        # work off 2-space indentation.\n        parser.markdown.tab_length = 2\n        super().__init__(parser)\n        parser.markdown.tab_length = 4\n\nclass ListIndentProcessor(markdown.blockprocessors.ListIndentProcessor):\n    \"\"\" Process unordered list blocks.\n\n        Based on markdown.blockprocessors.ListIndentProcessor, but with 2-space indent\n    \"\"\"\n\n    def __init__(self, parser: Any) -> None:\n\n        # HACK: Set the tab length to 2 just for the initialization of\n        # this class, so that bulleted lists (and only bulleted lists)\n        # work off 2-space indentation.\n        parser.markdown.tab_length = 2\n        super().__init__(parser)\n        parser.markdown.tab_length = 4\n\nclass BlockQuoteProcessor(markdown.blockprocessors.BlockQuoteProcessor):\n    \"\"\" Process BlockQuotes.\n\n        Based on markdown.blockprocessors.BlockQuoteProcessor, but with 2-space indent\n    \"\"\"\n\n    # Original regex for blockquote is RE = re.compile(r'(^|\\n)[ ]{0,3}>[ ]?(.*)')\n    RE = re.compile(r'(^|\\n)(?!(?:[ ]{0,3}>\\s*(?:$|\\n))*(?:$|\\n))'\n                    r'[ ]{0,3}>[ ]?(.*)')\n    mention_re = re.compile(mention.find_mentions)\n\n    def clean(self, line: str) -> str:\n        # Silence all the mentions inside blockquotes\n        line = re.sub(self.mention_re, lambda m: \"@_{}\".format(m.group('match')), line)\n\n        # And then run the upstream processor's code for removing the '>'\n        return super().clean(line)\n\nclass BugdownUListPreprocessor(markdown.preprocessors.Preprocessor):\n    \"\"\" Allows unordered list blocks that come directly after a\n        paragraph to be rendered as an unordered list\n\n        Detects paragraphs that have a matching list item that comes\n        directly after a line of text, and inserts a newline between\n        to satisfy Markdown\"\"\"\n\n    LI_RE = re.compile('^[ ]{0,3}[*][ ]+(.*)', re.MULTILINE)\n    HANGING_ULIST_RE = re.compile('^.+\\\\n([ ]{0,3}[*][ ]+.*)', re.MULTILINE)\n\n    def run(self, lines: List[str]) -> List[str]:\n        \"\"\" Insert a newline between a paragraph and ulist if missing \"\"\"\n        inserts = 0\n        fence = None\n        copy = lines[:]\n        for i in range(len(lines) - 1):\n            # Ignore anything that is inside a fenced code block\n            m = FENCE_RE.match(lines[i])\n            if not fence and m:\n                fence = m.group('fence')\n            elif fence and m and fence == m.group('fence'):\n                fence = None\n\n            # If we're not in a fenced block and we detect an upcoming list\n            #  hanging off a paragraph, add a newline\n            if (not fence and lines[i] and\n                self.LI_RE.match(lines[i+1]) and\n                    not self.LI_RE.match(lines[i])):\n\n                copy.insert(i+inserts+1, '')\n                inserts += 1\n        return copy\n\nclass AutoNumberOListPreprocessor(markdown.preprocessors.Preprocessor):\n    \"\"\" Finds a sequence of lines numbered by the same number\"\"\"\n    RE = re.compile(r'^([ ]*)(\\d+)\\.[ ]+(.*)')\n    TAB_LENGTH = 2\n\n    def run(self, lines: List[str]) -> List[str]:\n        new_lines = []  # type: List[str]\n        current_list = []  # type: List[Match[str]]\n        current_indent = 0\n\n        for line in lines:\n            m = self.RE.match(line)\n\n            # Remember if this line is a continuation of already started list\n            is_next_item = (m and current_list\n                            and current_indent == len(m.group(1)) // self.TAB_LENGTH)\n\n            if not is_next_item:\n                # There is no more items in the list we were processing\n                new_lines.extend(self.renumber(current_list))\n                current_list = []\n\n            if not m:\n                # Ordinary line\n                new_lines.append(line)\n            elif is_next_item:\n                # Another list item\n                current_list.append(m)\n            else:\n                # First list item\n                current_list = [m]\n                current_indent = len(m.group(1)) // self.TAB_LENGTH\n\n        new_lines.extend(self.renumber(current_list))\n\n        return new_lines\n\n    def renumber(self, mlist: List[Match[str]]) -> List[str]:\n        if not mlist:\n            return []\n\n        start_number = int(mlist[0].group(2))\n\n        # Change numbers only if every one is the same\n        change_numbers = True\n        for m in mlist:\n            if int(m.group(2)) != start_number:\n                change_numbers = False\n                break\n\n        lines = []  # type: List[str]\n        counter = start_number\n\n        for m in mlist:\n            number = str(counter) if change_numbers else m.group(2)\n            lines.append('%s%s. %s' % (m.group(1), number, m.group(3)))\n            counter += 1\n\n        return lines\n\n# We need the following since upgrade from py-markdown 2.6.11 to 3.0.1\n# modifies the link handling significantly. The following is taken from\n# py-markdown 2.6.11 markdown/inlinepatterns.py.\n@one_time\ndef get_link_re() -> str:\n    '''\n    Very important--if you need to change this code to depend on\n    any arguments, you must eliminate the \"one_time\" decorator\n    and consider performance implications.  We only want to compute\n    this value once.\n    '''\n\n    NOBRACKET = r'[^\\]\\[]*'\n    BRK = (\n        r'\\[(' +\n        (NOBRACKET + r'(\\[')*6 +\n        (NOBRACKET + r'\\])*')*6 +\n        NOBRACKET + r')\\]'\n    )\n    NOIMG = r'(?<!\\!)'\n\n    # [text](url) or [text](<url>) or [text](url \"title\")\n    LINK_RE = NOIMG + BRK + \\\n        r'''\\(\\s*(<(?:[^<>\\\\]|\\\\.)*>|(\\([^()]*\\)|[^()])*?)\\s*(('(?:[^'\\\\]|\\\\.)*'|\"(?:[^\"\\\\]|\\\\.)*\")\\s*)?\\)'''\n    return normal_compile(LINK_RE)\n\ndef prepare_realm_pattern(source: str) -> str:\n    \"\"\" Augment a realm filter so it only matches after start-of-string,\n    whitespace, or opening delimiters, won't match if there are word\n    characters directly after, and saves what was matched as \"name\". \"\"\"\n    return r\"\"\"(?<![^\\s'\"\\(,:<])(?P<name>\"\"\" + source + r')(?!\\w)'\n\n# Given a regular expression pattern, linkifies groups that match it\n# using the provided format string to construct the URL.\nclass RealmFilterPattern(markdown.inlinepatterns.Pattern):\n    \"\"\" Applied a given realm filter to the input \"\"\"\n\n    def __init__(self, source_pattern: str,\n                 format_string: str,\n                 markdown_instance: Optional[markdown.Markdown]=None) -> None:\n        self.pattern = prepare_realm_pattern(source_pattern)\n        self.format_string = format_string\n        markdown.inlinepatterns.Pattern.__init__(self, self.pattern, markdown_instance)\n\n    def handleMatch(self, m: Match[str]) -> Union[Element, str]:\n        db_data = self.markdown.zulip_db_data\n        return url_to_a(db_data,\n                        self.format_string % m.groupdict(),\n                        m.group(\"name\"))\n\nclass UserMentionPattern(markdown.inlinepatterns.Pattern):\n    def handleMatch(self, m: Match[str]) -> Optional[Element]:\n        match = m.group('match')\n        silent = m.group('silent') == '_'\n\n        db_data = self.markdown.zulip_db_data\n        if self.markdown.zulip_message and db_data is not None:\n            if match.startswith(\"**\") and match.endswith(\"**\"):\n                name = match[2:-2]\n            else:\n                return None\n\n            wildcard = mention.user_mention_matches_wildcard(name)\n\n            id_syntax_match = re.match(r'.+\\|(?P<user_id>\\d+)$', name)\n            if id_syntax_match:\n                id = id_syntax_match.group(\"user_id\")\n                user = db_data['mention_data'].get_user_by_id(id)\n            else:\n                user = db_data['mention_data'].get_user_by_name(name)\n\n            if wildcard:\n                self.markdown.zulip_message.mentions_wildcard = True\n                user_id = \"*\"\n            elif user:\n                if not silent:\n                    self.markdown.zulip_message.mentions_user_ids.add(user['id'])\n                name = user['full_name']\n                user_id = str(user['id'])\n            else:\n                # Don't highlight @mentions that don't refer to a valid user\n                return None\n\n            el = markdown.util.etree.Element(\"span\")\n            el.set('data-user-id', user_id)\n            if silent:\n                el.set('class', 'user-mention silent')\n                el.text = \"%s\" % (name,)\n            else:\n                el.set('class', 'user-mention')\n                el.text = \"@%s\" % (name,)\n            return el\n        return None\n\nclass UserGroupMentionPattern(markdown.inlinepatterns.Pattern):\n    def handleMatch(self, m: Match[str]) -> Optional[Element]:\n        match = m.group(2)\n\n        db_data = self.markdown.zulip_db_data\n        if self.markdown.zulip_message and db_data is not None:\n            name = extract_user_group(match)\n            user_group = db_data['mention_data'].get_user_group(name)\n            if user_group:\n                self.markdown.zulip_message.mentions_user_group_ids.add(user_group.id)\n                name = user_group.name\n                user_group_id = str(user_group.id)\n            else:\n                # Don't highlight @-mentions that don't refer to a valid user\n                # group.\n                return None\n\n            el = markdown.util.etree.Element(\"span\")\n            el.set('class', 'user-group-mention')\n            el.set('data-user-group-id', user_group_id)\n            el.text = \"@%s\" % (name,)\n            return el\n        return None\n\nclass StreamPattern(CompiledPattern):\n    def find_stream_by_name(self, name: Match[str]) -> Optional[Dict[str, Any]]:\n        db_data = self.markdown.zulip_db_data\n        if db_data is None:\n            return None\n        stream = db_data['stream_names'].get(name)\n        return stream\n\n    def handleMatch(self, m: Match[str]) -> Optional[Element]:\n        name = m.group('stream_name')\n\n        if self.markdown.zulip_message:\n            stream = self.find_stream_by_name(name)\n            if stream is None:\n                return None\n            el = markdown.util.etree.Element('a')\n            el.set('class', 'stream')\n            el.set('data-stream-id', str(stream['id']))\n            # TODO: We should quite possibly not be specifying the\n            # href here and instead having the browser auto-add the\n            # href when it processes a message with one of these, to\n            # provide more clarity to API clients.\n            stream_url = encode_stream(stream['id'], name)\n            el.set('href', '/#narrow/stream/{stream_url}'.format(stream_url=stream_url))\n            el.text = '#{stream_name}'.format(stream_name=name)\n            return el\n        return None\n\ndef possible_linked_stream_names(content: str) -> Set[str]:\n    matches = re.findall(STREAM_LINK_REGEX, content, re.VERBOSE)\n    return set(matches)\n\nclass AlertWordsNotificationProcessor(markdown.preprocessors.Preprocessor):\n    def run(self, lines: Iterable[str]) -> Iterable[str]:\n        db_data = self.markdown.zulip_db_data\n        if self.markdown.zulip_message and db_data is not None:\n            # We check for alert words here, the set of which are\n            # dependent on which users may see this message.\n            #\n            # Our caller passes in the list of possible_words.  We\n            # don't do any special rendering; we just append the alert words\n            # we find to the set self.markdown.zulip_message.alert_words.\n\n            realm_words = db_data['possible_words']\n\n            content = '\\n'.join(lines).lower()\n\n            allowed_before_punctuation = \"|\".join([r'\\s', '^', r'[\\(\\\".,\\';\\[\\*`>]'])\n            allowed_after_punctuation = \"|\".join([r'\\s', '$', r'[\\)\\\"\\?:.,\\';\\]!\\*`]'])\n\n            for word in realm_words:\n                escaped = re.escape(word.lower())\n                match_re = re.compile('(?:%s)%s(?:%s)' %\n                                      (allowed_before_punctuation,\n                                       escaped,\n                                       allowed_after_punctuation))\n                if re.search(match_re, content):\n                    self.markdown.zulip_message.alert_words.add(word)\n\n        return lines\n\n# This prevents realm_filters from running on the content of a\n# Markdown link, breaking up the link.  This is a monkey-patch, but it\n# might be worth sending a version of this change upstream.\nclass AtomicLinkPattern(CompiledPattern):\n    def get_element(self, m: Match[str]) -> Optional[Element]:\n        href = m.group(9)\n        if not href:\n            return None\n\n        if href[0] == \"<\":\n            href = href[1:-1]\n        href = sanitize_url(self.unescape(href.strip()))\n        if href is None:\n            return None\n\n        db_data = self.markdown.zulip_db_data\n        href = rewrite_local_links_to_relative(db_data, href)\n\n        el = markdown.util.etree.Element('a')\n        el.text = m.group(2)\n        el.set('href', href)\n        fixup_link(el, target_blank=(href[:1] != '#'))\n        return el\n\n    def handleMatch(self, m: Match[str]) -> Optional[Element]:\n        ret = self.get_element(m)\n        if ret is None:\n            return None\n        if not isinstance(ret, str):\n            ret.text = markdown.util.AtomicString(ret.text)\n        return ret\n\ndef get_sub_registry(r: markdown.util.Registry, keys: List[str]) -> markdown.util.Registry:\n    # Registry is a new class added by py-markdown to replace Ordered List.\n    # Since Registry doesn't support .keys(), it is easier to make a new\n    # object instead of removing keys from the existing object.\n    new_r = markdown.util.Registry()\n    for k in keys:\n        new_r.register(r[k], k, r.get_index_for_name(k))\n    return new_r\n\n# These are used as keys (\"realm_filters_keys\") to md_engines and the respective\n# realm filter caches\nDEFAULT_BUGDOWN_KEY = -1\nZEPHYR_MIRROR_BUGDOWN_KEY = -2\n\nclass Bugdown(markdown.Markdown):\n    def __init__(self, *args: Any, **kwargs: Union[bool, int, List[Any]]) -> None:\n        # define default configs\n        self.config = {\n            \"realm_filters\": [kwargs['realm_filters'],\n                              \"Realm-specific filters for realm_filters_key %s\" % (kwargs['realm'],)],\n            \"realm\": [kwargs['realm'], \"Realm id\"],\n            \"code_block_processor_disabled\": [kwargs['code_block_processor_disabled'],\n                                              \"Disabled for email gateway\"]\n        }\n\n        super().__init__(*args, **kwargs)\n        self.set_output_format('html')\n\n    def build_parser(self) -> markdown.Markdown:\n        # Build the parser using selected default features from py-markdown.\n        # The complete list of all available processors can be found in the\n        # super().build_parser() function.\n        #\n        # Note: for any py-markdown updates, manually check if we want any\n        # of the new features added upstream or not; they wouldn't get\n        # included by default.\n        self.preprocessors = self.build_preprocessors()\n        self.parser = self.build_block_parser()\n        self.inlinePatterns = self.build_inlinepatterns()\n        self.treeprocessors = self.build_treeprocessors()\n        self.postprocessors = self.build_postprocessors()\n        self.handle_zephyr_mirror()\n        return self\n\n    def build_preprocessors(self) -> markdown.util.Registry:\n        # We disable the following preprocessors from upstream:\n        #\n        # html_block - insecure\n        # reference - references don't make sense in a chat context.\n        preprocessors = markdown.util.Registry()\n        preprocessors.register(AutoNumberOListPreprocessor(self), 'auto_number_olist', 40)\n        preprocessors.register(BugdownUListPreprocessor(self), 'hanging_ulists', 35)\n        preprocessors.register(markdown.preprocessors.NormalizeWhitespace(self), 'normalize_whitespace', 30)\n        preprocessors.register(fenced_code.FencedBlockPreprocessor(self), 'fenced_code_block', 25)\n        preprocessors.register(AlertWordsNotificationProcessor(self), 'custom_text_notifications', 20)\n        return preprocessors\n\n    def build_block_parser(self) -> markdown.util.Registry:\n        # We disable the following blockparsers from upstream:\n        #\n        # indent - replaced by ours\n        # hashheader - disabled, since headers look bad and don't make sense in a chat context.\n        # setextheader - disabled, since headers look bad and don't make sense in a chat context.\n        # olist - replaced by ours\n        # ulist - replaced by ours\n        # quote - replaced by ours\n        parser = markdown.blockprocessors.BlockParser(self)\n        parser.blockprocessors.register(markdown.blockprocessors.EmptyBlockProcessor(parser), 'empty', 85)\n        if not self.getConfig('code_block_processor_disabled'):\n            parser.blockprocessors.register(markdown.blockprocessors.CodeBlockProcessor(parser), 'code', 80)\n        # We get priority 75 from 'table' extension\n        parser.blockprocessors.register(markdown.blockprocessors.HRProcessor(parser), 'hr', 70)\n        parser.blockprocessors.register(UListProcessor(parser), 'ulist', 65)\n        parser.blockprocessors.register(ListIndentProcessor(parser), 'indent', 60)\n        parser.blockprocessors.register(BlockQuoteProcessor(parser), 'quote', 55)\n        parser.blockprocessors.register(markdown.blockprocessors.ParagraphProcessor(parser), 'paragraph', 50)\n        return parser\n\n    def build_inlinepatterns(self) -> markdown.util.Registry:\n        # We disable the following upstream inline patterns:\n        #\n        # backtick -        replaced by ours\n        # escape -          probably will re-add at some point.\n        # link -            replaced by ours\n        # image_link -      replaced by ours\n        # autolink -        replaced by ours\n        # automail -        replaced by ours\n        # linebreak -       we use nl2br and consider that good enough\n        # html -            insecure\n        # reference -       references not useful\n        # image_reference - references not useful\n        # short_reference - references not useful\n        # ---------------------------------------------------\n        # strong_em -       for these three patterns,\n        # strong2 -         we have our own versions where\n        # emphasis2 -       we disable _ for bold and emphasis\n\n        # Declare regexes for clean single line calls to .register().\n        NOT_STRONG_RE = markdown.inlinepatterns.NOT_STRONG_RE\n        # Custom strikethrough syntax: ~~foo~~\n        DEL_RE = r'(?<!~)(\\~\\~)([^~\\n]+?)(\\~\\~)(?!~)'\n        # Custom bold syntax: **foo** but not __foo__\n        # str inside ** must start and end with a word character\n        # it need for things like \"const char *x = (char *)y\"\n        EMPHASIS_RE = r'(\\*)(?!\\s+)([^\\*^\\n]+)(?<!\\s)\\*'\n        ENTITY_RE = markdown.inlinepatterns.ENTITY_RE\n        STRONG_EM_RE = r'(\\*\\*\\*)(?!\\s+)([^\\*^\\n]+)(?<!\\s)\\*\\*\\*'\n        # Inline code block without whitespace stripping\n        BACKTICK_RE = r'(?:(?<!\\\\)((?:\\\\{2})+)(?=`+)|(?<!\\\\)(`+)(.+?)(?<!`)\\3(?!`))'\n\n        # Add Inline Patterns.  We use a custom numbering of the\n        # rules, that preserves the order from upstream but leaves\n        # space for us to add our own.\n        reg = markdown.util.Registry()\n        reg.register(BacktickPattern(BACKTICK_RE), 'backtick', 105)\n        reg.register(markdown.inlinepatterns.DoubleTagPattern(STRONG_EM_RE, 'strong,em'), 'strong_em', 100)\n        reg.register(UserMentionPattern(mention.find_mentions, self), 'usermention', 95)\n        reg.register(Tex(r'\\B(?<!\\$)\\$\\$(?P<body>[^\\n_$](\\\\\\$|[^$\\n])*)\\$\\$(?!\\$)\\B'), 'tex', 90)\n        reg.register(StreamPattern(get_compiled_stream_link_regex(), self), 'stream', 85)\n        reg.register(Avatar(AVATAR_REGEX, self), 'avatar', 80)\n        reg.register(ModalLink(r'!modal_link\\((?P<relative_url>[^)]*), (?P<text>[^)]*)\\)'), 'modal_link', 75)\n        # Note that !gravatar syntax should be deprecated long term.\n        reg.register(Avatar(GRAVATAR_REGEX, self), 'gravatar', 70)\n        reg.register(UserGroupMentionPattern(mention.user_group_mentions, self), 'usergroupmention', 65)\n        reg.register(AtomicLinkPattern(get_link_re(), self), 'link', 60)\n        reg.register(AutoLink(get_web_link_regex(), self), 'autolink', 55)\n        # Reserve priority 45-54 for Realm Filters\n        reg = self.register_realm_filters(reg)\n        reg.register(markdown.inlinepatterns.HtmlInlineProcessor(ENTITY_RE, self), 'entity', 40)\n        reg.register(markdown.inlinepatterns.SimpleTagPattern(r'(\\*\\*)([^\\n]+?)\\2', 'strong'), 'strong', 35)\n        reg.register(markdown.inlinepatterns.SimpleTagPattern(EMPHASIS_RE, 'em'), 'emphasis', 30)\n        reg.register(markdown.inlinepatterns.SimpleTagPattern(DEL_RE, 'del'), 'del', 25)\n        reg.register(markdown.inlinepatterns.SimpleTextInlineProcessor(NOT_STRONG_RE), 'not_strong', 20)\n        reg.register(Emoji(EMOJI_REGEX, self), 'emoji', 15)\n        reg.register(EmoticonTranslation(emoticon_regex, self), 'translate_emoticons', 10)\n        # We get priority 5 from 'nl2br' extension\n        reg.register(UnicodeEmoji(unicode_emoji_regex), 'unicodeemoji', 0)\n        return reg\n\n    def register_realm_filters(self, inlinePatterns: markdown.util.Registry) -> markdown.util.Registry:\n        for (pattern, format_string, id) in self.getConfig(\"realm_filters\"):\n            inlinePatterns.register(RealmFilterPattern(pattern, format_string, self),\n                                    'realm_filters/%s' % (pattern), 45)\n        return inlinePatterns\n\n    def build_treeprocessors(self) -> markdown.util.Registry:\n        # Here we build all the processors from upstream, plus a few of our own.\n        treeprocessors = markdown.util.Registry()\n        # We get priority 30 from 'hilite' extension\n        treeprocessors.register(markdown.treeprocessors.InlineProcessor(self), 'inline', 25)\n        treeprocessors.register(markdown.treeprocessors.PrettifyTreeprocessor(self), 'prettify', 20)\n        treeprocessors.register(InlineInterestingLinkProcessor(self), 'inline_interesting_links', 15)\n        if settings.CAMO_URI:\n            treeprocessors.register(InlineHttpsProcessor(self), 'rewrite_to_https', 10)\n        return treeprocessors\n\n    def build_postprocessors(self) -> markdown.util.Registry:\n        # These are the default python-markdown processors, unmodified.\n        postprocessors = markdown.util.Registry()\n        postprocessors.register(markdown.postprocessors.RawHtmlPostprocessor(self), 'raw_html', 20)\n        postprocessors.register(markdown.postprocessors.AndSubstitutePostprocessor(), 'amp_substitute', 15)\n        postprocessors.register(markdown.postprocessors.UnescapePostprocessor(), 'unescape', 10)\n        return postprocessors\n\n    def getConfig(self, key: str, default: str='') -> Any:\n        \"\"\" Return a setting for the given key or an empty string. \"\"\"\n        if key in self.config:\n            return self.config[key][0]\n        else:\n            return default\n\n    def handle_zephyr_mirror(self) -> None:\n        if self.getConfig(\"realm\") == ZEPHYR_MIRROR_BUGDOWN_KEY:\n            # Disable almost all inline patterns for zephyr mirror\n            # users' traffic that is mirrored.  Note that\n            # inline_interesting_links is a treeprocessor and thus is\n            # not removed\n            self.inlinePatterns = get_sub_registry(self.inlinePatterns, ['autolink'])\n            self.treeprocessors = get_sub_registry(self.treeprocessors, ['inline_interesting_links',\n                                                                         'rewrite_to_https'])\n            # insert new 'inline' processor because we have changed self.inlinePatterns\n            # but InlineProcessor copies md as self.md in __init__.\n            self.treeprocessors.register(markdown.treeprocessors.InlineProcessor(self), 'inline', 25)\n            self.preprocessors = get_sub_registry(self.preprocessors, ['custom_text_notifications'])\n            self.parser.blockprocessors = get_sub_registry(self.parser.blockprocessors, ['paragraph'])\n\nmd_engines = {}  # type: Dict[Tuple[int, bool], markdown.Markdown]\nrealm_filter_data = {}  # type: Dict[int, List[Tuple[str, str, int]]]\n\ndef make_md_engine(realm_filters_key: int, email_gateway: bool) -> None:\n    md_engine_key = (realm_filters_key, email_gateway)\n    if md_engine_key in md_engines:\n        del md_engines[md_engine_key]\n\n    realm_filters = realm_filter_data[realm_filters_key]\n    md_engines[md_engine_key] = build_engine(\n        realm_filters=realm_filters,\n        realm_filters_key=realm_filters_key,\n        email_gateway=email_gateway,\n    )\n\ndef build_engine(realm_filters: List[Tuple[str, str, int]],\n                 realm_filters_key: int,\n                 email_gateway: bool) -> markdown.Markdown:\n    engine = Bugdown(\n        realm_filters=realm_filters,\n        realm=realm_filters_key,\n        code_block_processor_disabled=email_gateway,\n        extensions = [\n            nl2br.makeExtension(),\n            tables.makeExtension(),\n            codehilite.makeExtension(\n                linenums=False,\n                guess_lang=False\n            ),\n        ])\n    return engine\n\ndef topic_links(realm_filters_key: int, topic_name: str) -> List[str]:\n    matches = []  # type: List[str]\n\n    realm_filters = realm_filters_for_realm(realm_filters_key)\n\n    for realm_filter in realm_filters:\n        pattern = prepare_realm_pattern(realm_filter[0])\n        for m in re.finditer(pattern, topic_name):\n            matches += [realm_filter[1] % m.groupdict()]\n    return matches\n\ndef maybe_update_markdown_engines(realm_filters_key: Optional[int], email_gateway: bool) -> None:\n    # If realm_filters_key is None, load all filters\n    global realm_filter_data\n    if realm_filters_key is None:\n        all_filters = all_realm_filters()\n        all_filters[DEFAULT_BUGDOWN_KEY] = []\n        for realm_filters_key, filters in all_filters.items():\n            realm_filter_data[realm_filters_key] = filters\n            make_md_engine(realm_filters_key, email_gateway)\n        # Hack to ensure that getConfig(\"realm\") is right for mirrored Zephyrs\n        realm_filter_data[ZEPHYR_MIRROR_BUGDOWN_KEY] = []\n        make_md_engine(ZEPHYR_MIRROR_BUGDOWN_KEY, False)\n    else:\n        realm_filters = realm_filters_for_realm(realm_filters_key)\n        if realm_filters_key not in realm_filter_data or    \\\n                realm_filter_data[realm_filters_key] != realm_filters:\n            # Realm filters data has changed, update `realm_filter_data` and any\n            # of the existing markdown engines using this set of realm filters.\n            realm_filter_data[realm_filters_key] = realm_filters\n            for email_gateway_flag in [True, False]:\n                if (realm_filters_key, email_gateway_flag) in md_engines:\n                    # Update only existing engines(if any), don't create new one.\n                    make_md_engine(realm_filters_key, email_gateway_flag)\n\n        if (realm_filters_key, email_gateway) not in md_engines:\n            # Markdown engine corresponding to this key doesn't exists so create one.\n            make_md_engine(realm_filters_key, email_gateway)\n\n# We want to log Markdown parser failures, but shouldn't log the actual input\n# message for privacy reasons.  The compromise is to replace all alphanumeric\n# characters with 'x'.\n#\n# We also use repr() to improve reproducibility, and to escape terminal control\n# codes, which can do surprisingly nasty things.\n_privacy_re = re.compile('\\\\w', flags=re.UNICODE)\ndef privacy_clean_markdown(content: str) -> str:\n    return repr(_privacy_re.sub('x', content))\n\ndef log_bugdown_error(msg: str) -> None:\n    \"\"\"We use this unusual logging approach to log the bugdown error, in\n    order to prevent AdminNotifyHandler from sending the santized\n    original markdown formatting into another Zulip message, which\n    could cause an infinite exception loop.\"\"\"\n    bugdown_logger.error(msg)\n\ndef get_email_info(realm_id: int, emails: Set[str]) -> Dict[str, FullNameInfo]:\n    if not emails:\n        return dict()\n\n    q_list = {\n        Q(email__iexact=email.strip().lower())\n        for email in emails\n    }\n\n    rows = UserProfile.objects.filter(\n        realm_id=realm_id\n    ).filter(\n        functools.reduce(lambda a, b: a | b, q_list),\n    ).values(\n        'id',\n        'email',\n    )\n\n    dct = {\n        row['email'].strip().lower(): row\n        for row in rows\n    }\n    return dct\n\ndef get_possible_mentions_info(realm_id: int, mention_texts: Set[str]) -> List[FullNameInfo]:\n    if not mention_texts:\n        return list()\n\n    # Remove the trailing part of the `name|id` mention syntax,\n    # thus storing only full names in full_names.\n    full_names = set()\n    name_re = r'(?P<full_name>.+)\\|\\d+$'\n    for mention_text in mention_texts:\n        name_syntax_match = re.match(name_re, mention_text)\n        if name_syntax_match:\n            full_names.add(name_syntax_match.group(\"full_name\"))\n        else:\n            full_names.add(mention_text)\n\n    q_list = {\n        Q(full_name__iexact=full_name)\n        for full_name in full_names\n    }\n\n    rows = UserProfile.objects.filter(\n        realm_id=realm_id,\n        is_active=True,\n    ).filter(\n        functools.reduce(lambda a, b: a | b, q_list),\n    ).values(\n        'id',\n        'full_name',\n        'email',\n    )\n    return list(rows)\n\nclass MentionData:\n    def __init__(self, realm_id: int, content: str) -> None:\n        mention_texts = possible_mentions(content)\n        possible_mentions_info = get_possible_mentions_info(realm_id, mention_texts)\n        self.full_name_info = {\n            row['full_name'].lower(): row\n            for row in possible_mentions_info\n        }\n        self.user_id_info = {\n            row['id']: row\n            for row in possible_mentions_info\n        }\n        self.init_user_group_data(realm_id=realm_id, content=content)\n\n    def init_user_group_data(self,\n                             realm_id: int,\n                             content: str) -> None:\n        user_group_names = possible_user_group_mentions(content)\n        self.user_group_name_info = get_user_group_name_info(realm_id, user_group_names)\n        self.user_group_members = defaultdict(list)  # type: Dict[int, List[int]]\n        group_ids = [group.id for group in self.user_group_name_info.values()]\n\n        if not group_ids:\n            # Early-return to avoid the cost of hitting the ORM,\n            # which shows up in profiles.\n            return\n\n        membership = UserGroupMembership.objects.filter(user_group_id__in=group_ids)\n        for info in membership.values('user_group_id', 'user_profile_id'):\n            group_id = info['user_group_id']\n            user_profile_id = info['user_profile_id']\n            self.user_group_members[group_id].append(user_profile_id)\n\n    def get_user_by_name(self, name: str) -> Optional[FullNameInfo]:\n        # warning: get_user_by_name is not dependable if two\n        # users of the same full name are mentioned. Use\n        # get_user_by_id where possible.\n        return self.full_name_info.get(name.lower(), None)\n\n    def get_user_by_id(self, id: str) -> Optional[FullNameInfo]:\n        return self.user_id_info.get(int(id), None)\n\n    def get_user_ids(self) -> Set[int]:\n        \"\"\"\n        Returns the user IDs that might have been mentioned by this\n        content.  Note that because this data structure has not parsed\n        the message and does not know about escaping/code blocks, this\n        will overestimate the list of user ids.\n        \"\"\"\n        return set(self.user_id_info.keys())\n\n    def get_user_group(self, name: str) -> Optional[UserGroup]:\n        return self.user_group_name_info.get(name.lower(), None)\n\n    def get_group_members(self, user_group_id: int) -> List[int]:\n        return self.user_group_members.get(user_group_id, [])\n\ndef get_user_group_name_info(realm_id: int, user_group_names: Set[str]) -> Dict[str, UserGroup]:\n    if not user_group_names:\n        return dict()\n\n    rows = UserGroup.objects.filter(realm_id=realm_id,\n                                    name__in=user_group_names)\n    dct = {row.name.lower(): row for row in rows}\n    return dct\n\ndef get_stream_name_info(realm: Realm, stream_names: Set[str]) -> Dict[str, FullNameInfo]:\n    if not stream_names:\n        return dict()\n\n    q_list = {\n        Q(name=name)\n        for name in stream_names\n    }\n\n    rows = get_active_streams(\n        realm=realm,\n    ).filter(\n        functools.reduce(lambda a, b: a | b, q_list),\n    ).values(\n        'id',\n        'name',\n    )\n\n    dct = {\n        row['name']: row\n        for row in rows\n    }\n    return dct\n\n\ndef do_convert(content: str,\n               message: Optional[Message]=None,\n               message_realm: Optional[Realm]=None,\n               possible_words: Optional[Set[str]]=None,\n               sent_by_bot: Optional[bool]=False,\n               translate_emoticons: Optional[bool]=False,\n               mention_data: Optional[MentionData]=None,\n               email_gateway: Optional[bool]=False,\n               no_previews: Optional[bool]=False) -> str:\n    \"\"\"Convert Markdown to HTML, with Zulip-specific settings and hacks.\"\"\"\n    # This logic is a bit convoluted, but the overall goal is to support a range of use cases:\n    # * Nothing is passed in other than content -> just run default options (e.g. for docs)\n    # * message is passed, but no realm is -> look up realm from message\n    # * message_realm is passed -> use that realm for bugdown purposes\n    if message is not None:\n        if message_realm is None:\n            message_realm = message.get_realm()\n    if message_realm is None:\n        realm_filters_key = DEFAULT_BUGDOWN_KEY\n    else:\n        realm_filters_key = message_realm.id\n\n    if message and hasattr(message, 'id') and message.id:\n        logging_message_id = 'id# ' + str(message.id)\n    else:\n        logging_message_id = 'unknown'\n\n    if message is not None and message_realm is not None:\n        if message_realm.is_zephyr_mirror_realm:\n            if message.sending_client.name == \"zephyr_mirror\":\n                # Use slightly customized Markdown processor for content\n                # delivered via zephyr_mirror\n                realm_filters_key = ZEPHYR_MIRROR_BUGDOWN_KEY\n\n    maybe_update_markdown_engines(realm_filters_key, email_gateway)\n    md_engine_key = (realm_filters_key, email_gateway)\n\n    if md_engine_key in md_engines:\n        _md_engine = md_engines[md_engine_key]\n    else:\n        if DEFAULT_BUGDOWN_KEY not in md_engines:\n            maybe_update_markdown_engines(realm_filters_key=None, email_gateway=False)\n\n        _md_engine = md_engines[(DEFAULT_BUGDOWN_KEY, email_gateway)]\n    # Reset the parser; otherwise it will get slower over time.\n    _md_engine.reset()\n\n    # Filters such as UserMentionPattern need a message.\n    _md_engine.zulip_message = message\n    _md_engine.zulip_realm = message_realm\n    _md_engine.zulip_db_data = None  # for now\n    _md_engine.image_preview_enabled = image_preview_enabled(\n        message, message_realm, no_previews)\n    _md_engine.url_embed_preview_enabled = url_embed_preview_enabled(\n        message, message_realm, no_previews)\n\n    # Pre-fetch data from the DB that is used in the bugdown thread\n    if message is not None:\n        assert message_realm is not None  # ensured above if message is not None\n        if possible_words is None:\n            possible_words = set()  # Set[str]\n\n        # Here we fetch the data structures needed to render\n        # mentions/avatars/stream mentions from the database, but only\n        # if there is syntax in the message that might use them, since\n        # the fetches are somewhat expensive and these types of syntax\n        # are uncommon enough that it's a useful optimization.\n\n        if mention_data is None:\n            mention_data = MentionData(message_realm.id, content)\n\n        emails = possible_avatar_emails(content)\n        email_info = get_email_info(message_realm.id, emails)\n\n        stream_names = possible_linked_stream_names(content)\n        stream_name_info = get_stream_name_info(message_realm, stream_names)\n\n        if content_has_emoji_syntax(content):\n            active_realm_emoji = message_realm.get_active_emoji()\n        else:\n            active_realm_emoji = dict()\n\n        _md_engine.zulip_db_data = {\n            'possible_words': possible_words,\n            'email_info': email_info,\n            'mention_data': mention_data,\n            'active_realm_emoji': active_realm_emoji,\n            'realm_uri': message_realm.uri,\n            'sent_by_bot': sent_by_bot,\n            'stream_names': stream_name_info,\n            'translate_emoticons': translate_emoticons,\n        }\n\n    try:\n        # Spend at most 5 seconds rendering; this protects the backend\n        # from being overloaded by bugs (e.g. markdown logic that is\n        # extremely inefficient in corner cases) as well as user\n        # errors (e.g. a realm filter that makes some syntax\n        # infinite-loop).\n        rendered_content = timeout(5, _md_engine.convert, content)\n\n        # Throw an exception if the content is huge; this protects the\n        # rest of the codebase from any bugs where we end up rendering\n        # something huge.\n        if len(rendered_content) > MAX_MESSAGE_LENGTH * 10:\n            raise BugdownRenderingException('Rendered content exceeds %s characters (message %s)' %\n                                            (MAX_MESSAGE_LENGTH * 10, logging_message_id))\n        return rendered_content\n    except Exception:\n        cleaned = privacy_clean_markdown(content)\n        # NOTE: Don't change this message without also changing the\n        # logic in logging_handlers.py or we can create recursive\n        # exceptions.\n        exception_message = ('Exception in Markdown parser: %sInput (sanitized) was: %s\\n (message %s)'\n                             % (traceback.format_exc(), cleaned, logging_message_id))\n        bugdown_logger.exception(exception_message)\n\n        raise BugdownRenderingException()\n    finally:\n        # These next three lines are slightly paranoid, since\n        # we always set these right before actually using the\n        # engine, but better safe then sorry.\n        _md_engine.zulip_message = None\n        _md_engine.zulip_realm = None\n        _md_engine.zulip_db_data = None\n\nbugdown_time_start = 0.0\nbugdown_total_time = 0.0\nbugdown_total_requests = 0\n\ndef get_bugdown_time() -> float:\n    return bugdown_total_time\n\ndef get_bugdown_requests() -> int:\n    return bugdown_total_requests\n\ndef bugdown_stats_start() -> None:\n    global bugdown_time_start\n    bugdown_time_start = time.time()\n\ndef bugdown_stats_finish() -> None:\n    global bugdown_total_time\n    global bugdown_total_requests\n    global bugdown_time_start\n    bugdown_total_requests += 1\n    bugdown_total_time += (time.time() - bugdown_time_start)\n\ndef convert(content: str,\n            message: Optional[Message]=None,\n            message_realm: Optional[Realm]=None,\n            possible_words: Optional[Set[str]]=None,\n            sent_by_bot: Optional[bool]=False,\n            translate_emoticons: Optional[bool]=False,\n            mention_data: Optional[MentionData]=None,\n            email_gateway: Optional[bool]=False,\n            no_previews: Optional[bool]=False) -> str:\n    bugdown_stats_start()\n    ret = do_convert(content, message, message_realm,\n                     possible_words, sent_by_bot, translate_emoticons,\n                     mention_data, email_gateway, no_previews=no_previews)\n    bugdown_stats_finish()\n    return ret\n", "target": 0}
{"idx": 893, "func": "#!/usr/bin/env python\n#\n# Copyright 2009 Facebook\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"); you may\n# not use this file except in compliance with the License. You may obtain\n# a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n# License for the specific language governing permissions and limitations\n# under the License.\n\n\"\"\"``tornado.web`` provides a simple web framework with asynchronous\nfeatures that allow it to scale to large numbers of open connections,\nmaking it ideal for `long polling\n<http://en.wikipedia.org/wiki/Push_technology#Long_polling>`_.\n\nHere is a simple \"Hello, world\" example app::\n\n    import tornado.ioloop\n    import tornado.web\n\n    class MainHandler(tornado.web.RequestHandler):\n        def get(self):\n            self.write(\"Hello, world\")\n\n    if __name__ == \"__main__\":\n        application = tornado.web.Application([\n            (r\"/\", MainHandler),\n        ])\n        application.listen(8888)\n        tornado.ioloop.IOLoop.instance().start()\n\nSee the :doc:`Tornado overview <overview>` for more details and a good getting\nstarted guide.\n\nThread-safety notes\n-------------------\n\nIn general, methods on `RequestHandler` and elsewhere in Tornado are\nnot thread-safe.  In particular, methods such as\n`~RequestHandler.write()`, `~RequestHandler.finish()`, and\n`~RequestHandler.flush()` must only be called from the main thread.  If\nyou use multiple threads it is important to use `.IOLoop.add_callback`\nto transfer control back to the main thread before finishing the\nrequest.\n\"\"\"\n\nfrom __future__ import absolute_import, division, print_function, with_statement\n\n\nimport base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport mimetypes\nimport numbers\nimport os.path\nimport re\nimport stat\nimport sys\nimport threading\nimport time\nimport tornado\nimport traceback\nimport types\nimport uuid\n\nfrom tornado.concurrent import Future\nfrom tornado import escape\nfrom tornado import httputil\nfrom tornado import locale\nfrom tornado.log import access_log, app_log, gen_log\nfrom tornado import stack_context\nfrom tornado import template\nfrom tornado.escape import utf8, _unicode\nfrom tornado.util import bytes_type, import_object, ObjectDict, raise_exc_info, unicode_type\n\ntry:\n    from io import BytesIO  # python 3\nexcept ImportError:\n    from cStringIO import StringIO as BytesIO  # python 2\n\ntry:\n    import Cookie  # py2\nexcept ImportError:\n    import http.cookies as Cookie  # py3\n\ntry:\n    import urlparse  # py2\nexcept ImportError:\n    import urllib.parse as urlparse  # py3\n\ntry:\n    from urllib import urlencode  # py2\nexcept ImportError:\n    from urllib.parse import urlencode  # py3\n\n\nMIN_SUPPORTED_SIGNED_VALUE_VERSION = 1\n\"\"\"The oldest signed value version supported by this version of Tornado.\n\nSigned values older than this version cannot be decoded.\n\n.. versionadded:: 3.2.1\n\"\"\"\n\nMAX_SUPPORTED_SIGNED_VALUE_VERSION = 2\n\"\"\"The newest signed value version supported by this version of Tornado.\n\nSigned values newer than this version cannot be decoded.\n\n.. versionadded:: 3.2.1\n\"\"\"\n\nDEFAULT_SIGNED_VALUE_VERSION = 2\n\"\"\"The signed value version produced by `.RequestHandler.create_signed_value`.\n\nMay be overridden by passing a ``version`` keyword argument.\n\n.. versionadded:: 3.2.1\n\"\"\"\n\nDEFAULT_SIGNED_VALUE_MIN_VERSION = 1\n\"\"\"The oldest signed value accepted by `.RequestHandler.get_secure_cookie`.\n\nMay be overrided by passing a ``min_version`` keyword argument.\n\n.. versionadded:: 3.2.1\n\"\"\"\n\n\nclass RequestHandler(object):\n    \"\"\"Subclass this class and define `get()` or `post()` to make a handler.\n\n    If you want to support more methods than the standard GET/HEAD/POST, you\n    should override the class variable ``SUPPORTED_METHODS`` in your\n    `RequestHandler` subclass.\n    \"\"\"\n    SUPPORTED_METHODS = (\"GET\", \"HEAD\", \"POST\", \"DELETE\", \"PATCH\", \"PUT\",\n                         \"OPTIONS\")\n\n    _template_loaders = {}  # {path: template.BaseLoader}\n    _template_loader_lock = threading.Lock()\n    _remove_control_chars_regex = re.compile(r\"[\\x00-\\x08\\x0e-\\x1f]\")\n\n    def __init__(self, application, request, **kwargs):\n        super(RequestHandler, self).__init__()\n\n        self.application = application\n        self.request = request\n        self._headers_written = False\n        self._finished = False\n        self._auto_finish = True\n        self._transforms = None  # will be set in _execute\n        self.path_args = None\n        self.path_kwargs = None\n        self.ui = ObjectDict((n, self._ui_method(m)) for n, m in\n                             application.ui_methods.items())\n        # UIModules are available as both `modules` and `_tt_modules` in the\n        # template namespace.  Historically only `modules` was available\n        # but could be clobbered by user additions to the namespace.\n        # The template {% module %} directive looks in `_tt_modules` to avoid\n        # possible conflicts.\n        self.ui[\"_tt_modules\"] = _UIModuleNamespace(self,\n                                                    application.ui_modules)\n        self.ui[\"modules\"] = self.ui[\"_tt_modules\"]\n        self.clear()\n        # Check since connection is not available in WSGI\n        if getattr(self.request, \"connection\", None):\n            self.request.connection.set_close_callback(\n                self.on_connection_close)\n        self.initialize(**kwargs)\n\n    def initialize(self):\n        \"\"\"Hook for subclass initialization.\n\n        A dictionary passed as the third argument of a url spec will be\n        supplied as keyword arguments to initialize().\n\n        Example::\n\n            class ProfileHandler(RequestHandler):\n                def initialize(self, database):\n                    self.database = database\n\n                def get(self, username):\n                    ...\n\n            app = Application([\n                (r'/user/(.*)', ProfileHandler, dict(database=database)),\n                ])\n        \"\"\"\n        pass\n\n    @property\n    def settings(self):\n        \"\"\"An alias for `self.application.settings <Application.settings>`.\"\"\"\n        return self.application.settings\n\n    def head(self, *args, **kwargs):\n        raise HTTPError(405)\n\n    def get(self, *args, **kwargs):\n        raise HTTPError(405)\n\n    def post(self, *args, **kwargs):\n        raise HTTPError(405)\n\n    def delete(self, *args, **kwargs):\n        raise HTTPError(405)\n\n    def patch(self, *args, **kwargs):\n        raise HTTPError(405)\n\n    def put(self, *args, **kwargs):\n        raise HTTPError(405)\n\n    def options(self, *args, **kwargs):\n        raise HTTPError(405)\n\n    def prepare(self):\n        \"\"\"Called at the beginning of a request before  `get`/`post`/etc.\n\n        Override this method to perform common initialization regardless\n        of the request method.\n\n        Asynchronous support: Decorate this method with `.gen.coroutine`\n        or `.return_future` to make it asynchronous (the\n        `asynchronous` decorator cannot be used on `prepare`).\n        If this method returns a `.Future` execution will not proceed\n        until the `.Future` is done.\n\n        .. versionadded:: 3.1\n           Asynchronous support.\n        \"\"\"\n        pass\n\n    def on_finish(self):\n        \"\"\"Called after the end of a request.\n\n        Override this method to perform cleanup, logging, etc.\n        This method is a counterpart to `prepare`.  ``on_finish`` may\n        not produce any output, as it is called after the response\n        has been sent to the client.\n        \"\"\"\n        pass\n\n    def on_connection_close(self):\n        \"\"\"Called in async handlers if the client closed the connection.\n\n        Override this to clean up resources associated with\n        long-lived connections.  Note that this method is called only if\n        the connection was closed during asynchronous processing; if you\n        need to do cleanup after every request override `on_finish`\n        instead.\n\n        Proxies may keep a connection open for a time (perhaps\n        indefinitely) after the client has gone away, so this method\n        may not be called promptly after the end user closes their\n        connection.\n        \"\"\"\n        pass\n\n    def clear(self):\n        \"\"\"Resets all headers and content for this response.\"\"\"\n        self._headers = httputil.HTTPHeaders({\n            \"Server\": \"TornadoServer/%s\" % tornado.version,\n            \"Content-Type\": \"text/html; charset=UTF-8\",\n            \"Date\": httputil.format_timestamp(time.time()),\n        })\n        self.set_default_headers()\n        if (not self.request.supports_http_1_1() and\n            getattr(self.request, 'connection', None) and\n                not self.request.connection.no_keep_alive):\n            conn_header = self.request.headers.get(\"Connection\")\n            if conn_header and (conn_header.lower() == \"keep-alive\"):\n                self._headers[\"Connection\"] = \"Keep-Alive\"\n        self._write_buffer = []\n        self._status_code = 200\n        self._reason = httputil.responses[200]\n\n    def set_default_headers(self):\n        \"\"\"Override this to set HTTP headers at the beginning of the request.\n\n        For example, this is the place to set a custom ``Server`` header.\n        Note that setting such headers in the normal flow of request\n        processing may not do what you want, since headers may be reset\n        during error handling.\n        \"\"\"\n        pass\n\n    def set_status(self, status_code, reason=None):\n        \"\"\"Sets the status code for our response.\n\n        :arg int status_code: Response status code. If ``reason`` is ``None``,\n            it must be present in `httplib.responses <http.client.responses>`.\n        :arg string reason: Human-readable reason phrase describing the status\n            code. If ``None``, it will be filled in from\n            `httplib.responses <http.client.responses>`.\n        \"\"\"\n        self._status_code = status_code\n        if reason is not None:\n            self._reason = escape.native_str(reason)\n        else:\n            try:\n                self._reason = httputil.responses[status_code]\n            except KeyError:\n                raise ValueError(\"unknown status code %d\", status_code)\n\n    def get_status(self):\n        \"\"\"Returns the status code for our response.\"\"\"\n        return self._status_code\n\n    def set_header(self, name, value):\n        \"\"\"Sets the given response header name and value.\n\n        If a datetime is given, we automatically format it according to the\n        HTTP specification. If the value is not a string, we convert it to\n        a string. All header values are then encoded as UTF-8.\n        \"\"\"\n        self._headers[name] = self._convert_header_value(value)\n\n    def add_header(self, name, value):\n        \"\"\"Adds the given response header and value.\n\n        Unlike `set_header`, `add_header` may be called multiple times\n        to return multiple values for the same header.\n        \"\"\"\n        self._headers.add(name, self._convert_header_value(value))\n\n    def clear_header(self, name):\n        \"\"\"Clears an outgoing header, undoing a previous `set_header` call.\n\n        Note that this method does not apply to multi-valued headers\n        set by `add_header`.\n        \"\"\"\n        if name in self._headers:\n            del self._headers[name]\n\n    _INVALID_HEADER_CHAR_RE = re.compile(br\"[\\x00-\\x1f]\")\n\n    def _convert_header_value(self, value):\n        if isinstance(value, bytes_type):\n            pass\n        elif isinstance(value, unicode_type):\n            value = value.encode('utf-8')\n        elif isinstance(value, numbers.Integral):\n            # return immediately since we know the converted value will be safe\n            return str(value)\n        elif isinstance(value, datetime.datetime):\n            return httputil.format_timestamp(value)\n        else:\n            raise TypeError(\"Unsupported header value %r\" % value)\n        # If \\n is allowed into the header, it is possible to inject\n        # additional headers or split the request. Also cap length to\n        # prevent obviously erroneous values.\n        if (len(value) > 4000 or\n                RequestHandler._INVALID_HEADER_CHAR_RE.search(value)):\n            raise ValueError(\"Unsafe header value %r\", value)\n        return value\n\n    _ARG_DEFAULT = []\n\n    def get_argument(self, name, default=_ARG_DEFAULT, strip=True):\n        \"\"\"Returns the value of the argument with the given name.\n\n        If default is not provided, the argument is considered to be\n        required, and we raise a `MissingArgumentError` if it is missing.\n\n        If the argument appears in the url more than once, we return the\n        last value.\n\n        The returned value is always unicode.\n        \"\"\"\n        return self._get_argument(name, default, self.request.arguments, strip)\n\n    def get_arguments(self, name, strip=True):\n        \"\"\"Returns a list of the arguments with the given name.\n\n        If the argument is not present, returns an empty list.\n\n        The returned values are always unicode.\n        \"\"\"\n        return self._get_arguments(name, self.request.arguments, strip)\n\n    def get_body_argument(self, name, default=_ARG_DEFAULT, strip=True):\n        \"\"\"Returns the value of the argument with the given name\n        from the request body.\n\n        If default is not provided, the argument is considered to be\n        required, and we raise a `MissingArgumentError` if it is missing.\n\n        If the argument appears in the url more than once, we return the\n        last value.\n\n        The returned value is always unicode.\n\n        .. versionadded:: 3.2\n        \"\"\"\n        return self._get_argument(name, default, self.request.body_arguments, strip)\n\n    def get_body_arguments(self, name, strip=True):\n        \"\"\"Returns a list of the body arguments with the given name.\n\n        If the argument is not present, returns an empty list.\n\n        The returned values are always unicode.\n\n        .. versionadded:: 3.2\n        \"\"\"\n        return self._get_arguments(name, self.request.body_arguments, strip)\n\n    def get_query_argument(self, name, default=_ARG_DEFAULT, strip=True):\n        \"\"\"Returns the value of the argument with the given name\n        from the request query string.\n\n        If default is not provided, the argument is considered to be\n        required, and we raise a `MissingArgumentError` if it is missing.\n\n        If the argument appears in the url more than once, we return the\n        last value.\n\n        The returned value is always unicode.\n\n        .. versionadded:: 3.2\n        \"\"\"\n        return self._get_argument(name, default, self.request.query_arguments, strip)\n\n    def get_query_arguments(self, name, strip=True):\n        \"\"\"Returns a list of the query arguments with the given name.\n\n        If the argument is not present, returns an empty list.\n\n        The returned values are always unicode.\n\n        .. versionadded:: 3.2\n        \"\"\"\n        return self._get_arguments(name, self.request.query_arguments, strip)\n\n    def _get_argument(self, name, default, source, strip=True):\n        args = self._get_arguments(name, source, strip=strip)\n        if not args:\n            if default is self._ARG_DEFAULT:\n                raise MissingArgumentError(name)\n            return default\n        return args[-1]\n\n    def _get_arguments(self, name, source, strip=True):\n        values = []\n        for v in source.get(name, []):\n            v = self.decode_argument(v, name=name)\n            if isinstance(v, unicode_type):\n                # Get rid of any weird control chars (unless decoding gave\n                # us bytes, in which case leave it alone)\n                v = RequestHandler._remove_control_chars_regex.sub(\" \", v)\n            if strip:\n                v = v.strip()\n            values.append(v)\n        return values\n\n    def decode_argument(self, value, name=None):\n        \"\"\"Decodes an argument from the request.\n\n        The argument has been percent-decoded and is now a byte string.\n        By default, this method decodes the argument as utf-8 and returns\n        a unicode string, but this may be overridden in subclasses.\n\n        This method is used as a filter for both `get_argument()` and for\n        values extracted from the url and passed to `get()`/`post()`/etc.\n\n        The name of the argument is provided if known, but may be None\n        (e.g. for unnamed groups in the url regex).\n        \"\"\"\n        try:\n            return _unicode(value)\n        except UnicodeDecodeError:\n            raise HTTPError(400, \"Invalid unicode in %s: %r\" %\n                            (name or \"url\", value[:40]))\n\n    @property\n    def cookies(self):\n        \"\"\"An alias for `self.request.cookies <.httpserver.HTTPRequest.cookies>`.\"\"\"\n        return self.request.cookies\n\n    def get_cookie(self, name, default=None):\n        \"\"\"Gets the value of the cookie with the given name, else default.\"\"\"\n        if self.request.cookies is not None and name in self.request.cookies:\n            return self.request.cookies[name].value\n        return default\n\n    def set_cookie(self, name, value, domain=None, expires=None, path=\"/\",\n                   expires_days=None, **kwargs):\n        \"\"\"Sets the given cookie name/value with the given options.\n\n        Additional keyword arguments are set on the Cookie.Morsel\n        directly.\n        See http://docs.python.org/library/cookie.html#morsel-objects\n        for available attributes.\n        \"\"\"\n        # The cookie library only accepts type str, in both python 2 and 3\n        name = escape.native_str(name)\n        value = escape.native_str(value)\n        if re.search(r\"[\\x00-\\x20]\", name + value):\n            # Don't let us accidentally inject bad stuff\n            raise ValueError(\"Invalid cookie %r: %r\" % (name, value))\n        if not hasattr(self, \"_new_cookie\"):\n            self._new_cookie = Cookie.SimpleCookie()\n        if name in self._new_cookie:\n            del self._new_cookie[name]\n        self._new_cookie[name] = value\n        morsel = self._new_cookie[name]\n        if domain:\n            morsel[\"domain\"] = domain\n        if expires_days is not None and not expires:\n            expires = datetime.datetime.utcnow() + datetime.timedelta(\n                days=expires_days)\n        if expires:\n            morsel[\"expires\"] = httputil.format_timestamp(expires)\n        if path:\n            morsel[\"path\"] = path\n        for k, v in kwargs.items():\n            if k == 'max_age':\n                k = 'max-age'\n            morsel[k] = v\n\n    def clear_cookie(self, name, path=\"/\", domain=None):\n        \"\"\"Deletes the cookie with the given name.\n\n        Due to limitations of the cookie protocol, you must pass the same\n        path and domain to clear a cookie as were used when that cookie\n        was set (but there is no way to find out on the server side\n        which values were used for a given cookie).\n        \"\"\"\n        expires = datetime.datetime.utcnow() - datetime.timedelta(days=365)\n        self.set_cookie(name, value=\"\", path=path, expires=expires,\n                        domain=domain)\n\n    def clear_all_cookies(self, path=\"/\", domain=None):\n        \"\"\"Deletes all the cookies the user sent with this request.\n\n        See `clear_cookie` for more information on the path and domain\n        parameters.\n\n        .. versionchanged:: 3.2\n\n           Added the ``path`` and ``domain`` parameters.\n        \"\"\"\n        for name in self.request.cookies:\n            self.clear_cookie(name, path=path, domain=domain)\n\n    def set_secure_cookie(self, name, value, expires_days=30, version=None,\n                          **kwargs):\n        \"\"\"Signs and timestamps a cookie so it cannot be forged.\n\n        You must specify the ``cookie_secret`` setting in your Application\n        to use this method. It should be a long, random sequence of bytes\n        to be used as the HMAC secret for the signature.\n\n        To read a cookie set with this method, use `get_secure_cookie()`.\n\n        Note that the ``expires_days`` parameter sets the lifetime of the\n        cookie in the browser, but is independent of the ``max_age_days``\n        parameter to `get_secure_cookie`.\n\n        Secure cookies may contain arbitrary byte values, not just unicode\n        strings (unlike regular cookies)\n\n        .. versionchanged:: 3.2.1\n\n           Added the ``version`` argument.  Introduced cookie version 2\n           and made it the default.\n        \"\"\"\n        self.set_cookie(name, self.create_signed_value(name, value,\n                                                       version=version),\n                        expires_days=expires_days, **kwargs)\n\n    def create_signed_value(self, name, value, version=None):\n        \"\"\"Signs and timestamps a string so it cannot be forged.\n\n        Normally used via set_secure_cookie, but provided as a separate\n        method for non-cookie uses.  To decode a value not stored\n        as a cookie use the optional value argument to get_secure_cookie.\n\n        .. versionchanged:: 3.2.1\n\n           Added the ``version`` argument.  Introduced cookie version 2\n           and made it the default.\n        \"\"\"\n        self.require_setting(\"cookie_secret\", \"secure cookies\")\n        return create_signed_value(self.application.settings[\"cookie_secret\"],\n                                   name, value, version=version)\n\n    def get_secure_cookie(self, name, value=None, max_age_days=31,\n                          min_version=None):\n        \"\"\"Returns the given signed cookie if it validates, or None.\n\n        The decoded cookie value is returned as a byte string (unlike\n        `get_cookie`).\n\n        .. versionchanged:: 3.2.1\n\n           Added the ``min_version`` argument.  Introduced cookie version 2;\n           both versions 1 and 2 are accepted by default.\n        \"\"\"\n        self.require_setting(\"cookie_secret\", \"secure cookies\")\n        if value is None:\n            value = self.get_cookie(name)\n        return decode_signed_value(self.application.settings[\"cookie_secret\"],\n                                   name, value, max_age_days=max_age_days,\n                                   min_version=min_version)\n\n    def redirect(self, url, permanent=False, status=None):\n        \"\"\"Sends a redirect to the given (optionally relative) URL.\n\n        If the ``status`` argument is specified, that value is used as the\n        HTTP status code; otherwise either 301 (permanent) or 302\n        (temporary) is chosen based on the ``permanent`` argument.\n        The default is 302 (temporary).\n        \"\"\"\n        if self._headers_written:\n            raise Exception(\"Cannot redirect after headers have been written\")\n        if status is None:\n            status = 301 if permanent else 302\n        else:\n            assert isinstance(status, int) and 300 <= status <= 399\n        self.set_status(status)\n        self.set_header(\"Location\", urlparse.urljoin(utf8(self.request.uri),\n                                                     utf8(url)))\n        self.finish()\n\n    def write(self, chunk):\n        \"\"\"Writes the given chunk to the output buffer.\n\n        To write the output to the network, use the flush() method below.\n\n        If the given chunk is a dictionary, we write it as JSON and set\n        the Content-Type of the response to be ``application/json``.\n        (if you want to send JSON as a different ``Content-Type``, call\n        set_header *after* calling write()).\n\n        Note that lists are not converted to JSON because of a potential\n        cross-site security vulnerability.  All JSON output should be\n        wrapped in a dictionary.  More details at\n        http://haacked.com/archive/2008/11/20/anatomy-of-a-subtle-json-vulnerability.aspx\n        \"\"\"\n        if self._finished:\n            raise RuntimeError(\"Cannot write() after finish().  May be caused \"\n                               \"by using async operations without the \"\n                               \"@asynchronous decorator.\")\n        if isinstance(chunk, dict):\n            chunk = escape.json_encode(chunk)\n            self.set_header(\"Content-Type\", \"application/json; charset=UTF-8\")\n        chunk = utf8(chunk)\n        self._write_buffer.append(chunk)\n\n    def render(self, template_name, **kwargs):\n        \"\"\"Renders the template with the given arguments as the response.\"\"\"\n        html = self.render_string(template_name, **kwargs)\n\n        # Insert the additional JS and CSS added by the modules on the page\n        js_embed = []\n        js_files = []\n        css_embed = []\n        css_files = []\n        html_heads = []\n        html_bodies = []\n        for module in getattr(self, \"_active_modules\", {}).values():\n            embed_part = module.embedded_javascript()\n            if embed_part:\n                js_embed.append(utf8(embed_part))\n            file_part = module.javascript_files()\n            if file_part:\n                if isinstance(file_part, (unicode_type, bytes_type)):\n                    js_files.append(file_part)\n                else:\n                    js_files.extend(file_part)\n            embed_part = module.embedded_css()\n            if embed_part:\n                css_embed.append(utf8(embed_part))\n            file_part = module.css_files()\n            if file_part:\n                if isinstance(file_part, (unicode_type, bytes_type)):\n                    css_files.append(file_part)\n                else:\n                    css_files.extend(file_part)\n            head_part = module.html_head()\n            if head_part:\n                html_heads.append(utf8(head_part))\n            body_part = module.html_body()\n            if body_part:\n                html_bodies.append(utf8(body_part))\n\n        def is_absolute(path):\n            return any(path.startswith(x) for x in [\"/\", \"http:\", \"https:\"])\n        if js_files:\n            # Maintain order of JavaScript files given by modules\n            paths = []\n            unique_paths = set()\n            for path in js_files:\n                if not is_absolute(path):\n                    path = self.static_url(path)\n                if path not in unique_paths:\n                    paths.append(path)\n                    unique_paths.add(path)\n            js = ''.join('<script src=\"' + escape.xhtml_escape(p) +\n                         '\" type=\"text/javascript\"></script>'\n                         for p in paths)\n            sloc = html.rindex(b'</body>')\n            html = html[:sloc] + utf8(js) + b'\\n' + html[sloc:]\n        if js_embed:\n            js = b'<script type=\"text/javascript\">\\n//<![CDATA[\\n' + \\\n                b'\\n'.join(js_embed) + b'\\n//]]>\\n</script>'\n            sloc = html.rindex(b'</body>')\n            html = html[:sloc] + js + b'\\n' + html[sloc:]\n        if css_files:\n            paths = []\n            unique_paths = set()\n            for path in css_files:\n                if not is_absolute(path):\n                    path = self.static_url(path)\n                if path not in unique_paths:\n                    paths.append(path)\n                    unique_paths.add(path)\n            css = ''.join('<link href=\"' + escape.xhtml_escape(p) + '\" '\n                          'type=\"text/css\" rel=\"stylesheet\"/>'\n                          for p in paths)\n            hloc = html.index(b'</head>')\n            html = html[:hloc] + utf8(css) + b'\\n' + html[hloc:]\n        if css_embed:\n            css = b'<style type=\"text/css\">\\n' + b'\\n'.join(css_embed) + \\\n                b'\\n</style>'\n            hloc = html.index(b'</head>')\n            html = html[:hloc] + css + b'\\n' + html[hloc:]\n        if html_heads:\n            hloc = html.index(b'</head>')\n            html = html[:hloc] + b''.join(html_heads) + b'\\n' + html[hloc:]\n        if html_bodies:\n            hloc = html.index(b'</body>')\n            html = html[:hloc] + b''.join(html_bodies) + b'\\n' + html[hloc:]\n        self.finish(html)\n\n    def render_string(self, template_name, **kwargs):\n        \"\"\"Generate the given template with the given arguments.\n\n        We return the generated byte string (in utf8). To generate and\n        write a template as a response, use render() above.\n        \"\"\"\n        # If no template_path is specified, use the path of the calling file\n        template_path = self.get_template_path()\n        if not template_path:\n            frame = sys._getframe(0)\n            web_file = frame.f_code.co_filename\n            while frame.f_code.co_filename == web_file:\n                frame = frame.f_back\n            template_path = os.path.dirname(frame.f_code.co_filename)\n        with RequestHandler._template_loader_lock:\n            if template_path not in RequestHandler._template_loaders:\n                loader = self.create_template_loader(template_path)\n                RequestHandler._template_loaders[template_path] = loader\n            else:\n                loader = RequestHandler._template_loaders[template_path]\n        t = loader.load(template_name)\n        namespace = self.get_template_namespace()\n        namespace.update(kwargs)\n        return t.generate(**namespace)\n\n    def get_template_namespace(self):\n        \"\"\"Returns a dictionary to be used as the default template namespace.\n\n        May be overridden by subclasses to add or modify values.\n\n        The results of this method will be combined with additional\n        defaults in the `tornado.template` module and keyword arguments\n        to `render` or `render_string`.\n        \"\"\"\n        namespace = dict(\n            handler=self,\n            request=self.request,\n            current_user=self.current_user,\n            locale=self.locale,\n            _=self.locale.translate,\n            static_url=self.static_url,\n            xsrf_form_html=self.xsrf_form_html,\n            reverse_url=self.reverse_url\n        )\n        namespace.update(self.ui)\n        return namespace\n\n    def create_template_loader(self, template_path):\n        \"\"\"Returns a new template loader for the given path.\n\n        May be overridden by subclasses.  By default returns a\n        directory-based loader on the given path, using the\n        ``autoescape`` application setting.  If a ``template_loader``\n        application setting is supplied, uses that instead.\n        \"\"\"\n        settings = self.application.settings\n        if \"template_loader\" in settings:\n            return settings[\"template_loader\"]\n        kwargs = {}\n        if \"autoescape\" in settings:\n            # autoescape=None means \"no escaping\", so we have to be sure\n            # to only pass this kwarg if the user asked for it.\n            kwargs[\"autoescape\"] = settings[\"autoescape\"]\n        return template.Loader(template_path, **kwargs)\n\n    def flush(self, include_footers=False, callback=None):\n        \"\"\"Flushes the current output buffer to the network.\n\n        The ``callback`` argument, if given, can be used for flow control:\n        it will be run when all flushed data has been written to the socket.\n        Note that only one flush callback can be outstanding at a time;\n        if another flush occurs before the previous flush's callback\n        has been run, the previous callback will be discarded.\n        \"\"\"\n        if self.application._wsgi:\n            # WSGI applications cannot usefully support flush, so just make\n            # it a no-op (and run the callback immediately).\n            if callback is not None:\n                callback()\n            return\n\n        chunk = b\"\".join(self._write_buffer)\n        self._write_buffer = []\n        if not self._headers_written:\n            self._headers_written = True\n            for transform in self._transforms:\n                self._status_code, self._headers, chunk = \\\n                    transform.transform_first_chunk(\n                        self._status_code, self._headers, chunk, include_footers)\n            headers = self._generate_headers()\n        else:\n            for transform in self._transforms:\n                chunk = transform.transform_chunk(chunk, include_footers)\n            headers = b\"\"\n\n        # Ignore the chunk and only write the headers for HEAD requests\n        if self.request.method == \"HEAD\":\n            if headers:\n                self.request.write(headers, callback=callback)\n            return\n\n        self.request.write(headers + chunk, callback=callback)\n\n    def finish(self, chunk=None):\n        \"\"\"Finishes this response, ending the HTTP request.\"\"\"\n        if self._finished:\n            raise RuntimeError(\"finish() called twice.  May be caused \"\n                               \"by using async operations without the \"\n                               \"@asynchronous decorator.\")\n\n        if chunk is not None:\n            self.write(chunk)\n\n        # Automatically support ETags and add the Content-Length header if\n        # we have not flushed any content yet.\n        if not self._headers_written:\n            if (self._status_code == 200 and\n                self.request.method in (\"GET\", \"HEAD\") and\n                    \"Etag\" not in self._headers):\n                self.set_etag_header()\n                if self.check_etag_header():\n                    self._write_buffer = []\n                    self.set_status(304)\n            if self._status_code == 304:\n                assert not self._write_buffer, \"Cannot send body with 304\"\n                self._clear_headers_for_304()\n            elif \"Content-Length\" not in self._headers:\n                content_length = sum(len(part) for part in self._write_buffer)\n                self.set_header(\"Content-Length\", content_length)\n\n        if hasattr(self.request, \"connection\"):\n            # Now that the request is finished, clear the callback we\n            # set on the HTTPConnection (which would otherwise prevent the\n            # garbage collection of the RequestHandler when there\n            # are keepalive connections)\n            self.request.connection.set_close_callback(None)\n\n        if not self.application._wsgi:\n            self.flush(include_footers=True)\n            self.request.finish()\n            self._log()\n        self._finished = True\n        self.on_finish()\n        # Break up a reference cycle between this handler and the\n        # _ui_module closures to allow for faster GC on CPython.\n        self.ui = None\n\n    def send_error(self, status_code=500, **kwargs):\n        \"\"\"Sends the given HTTP error code to the browser.\n\n        If `flush()` has already been called, it is not possible to send\n        an error, so this method will simply terminate the response.\n        If output has been written but not yet flushed, it will be discarded\n        and replaced with the error page.\n\n        Override `write_error()` to customize the error page that is returned.\n        Additional keyword arguments are passed through to `write_error`.\n        \"\"\"\n        if self._headers_written:\n            gen_log.error(\"Cannot send error response after headers written\")\n            if not self._finished:\n                self.finish()\n            return\n        self.clear()\n\n        reason = None\n        if 'exc_info' in kwargs:\n            exception = kwargs['exc_info'][1]\n            if isinstance(exception, HTTPError) and exception.reason:\n                reason = exception.reason\n        self.set_status(status_code, reason=reason)\n        try:\n            self.write_error(status_code, **kwargs)\n        except Exception:\n            app_log.error(\"Uncaught exception in write_error\", exc_info=True)\n        if not self._finished:\n            self.finish()\n\n    def write_error(self, status_code, **kwargs):\n        \"\"\"Override to implement custom error pages.\n\n        ``write_error`` may call `write`, `render`, `set_header`, etc\n        to produce output as usual.\n\n        If this error was caused by an uncaught exception (including\n        HTTPError), an ``exc_info`` triple will be available as\n        ``kwargs[\"exc_info\"]``.  Note that this exception may not be\n        the \"current\" exception for purposes of methods like\n        ``sys.exc_info()`` or ``traceback.format_exc``.\n\n        For historical reasons, if a method ``get_error_html`` exists,\n        it will be used instead of the default ``write_error`` implementation.\n        ``get_error_html`` returned a string instead of producing output\n        normally, and had different semantics for exception handling.\n        Users of ``get_error_html`` are encouraged to convert their code\n        to override ``write_error`` instead.\n        \"\"\"\n        if hasattr(self, 'get_error_html'):\n            if 'exc_info' in kwargs:\n                exc_info = kwargs.pop('exc_info')\n                kwargs['exception'] = exc_info[1]\n                try:\n                    # Put the traceback into sys.exc_info()\n                    raise_exc_info(exc_info)\n                except Exception:\n                    self.finish(self.get_error_html(status_code, **kwargs))\n            else:\n                self.finish(self.get_error_html(status_code, **kwargs))\n            return\n        if self.settings.get(\"serve_traceback\") and \"exc_info\" in kwargs:\n            # in debug mode, try to send a traceback\n            self.set_header('Content-Type', 'text/plain')\n            for line in traceback.format_exception(*kwargs[\"exc_info\"]):\n                self.write(line)\n            self.finish()\n        else:\n            self.finish(\"<html><title>%(code)d: %(message)s</title>\"\n                        \"<body>%(code)d: %(message)s</body></html>\" % {\n                            \"code\": status_code,\n                            \"message\": self._reason,\n                        })\n\n    @property\n    def locale(self):\n        \"\"\"The local for the current session.\n\n        Determined by either `get_user_locale`, which you can override to\n        set the locale based on, e.g., a user preference stored in a\n        database, or `get_browser_locale`, which uses the ``Accept-Language``\n        header.\n        \"\"\"\n        if not hasattr(self, \"_locale\"):\n            self._locale = self.get_user_locale()\n            if not self._locale:\n                self._locale = self.get_browser_locale()\n                assert self._locale\n        return self._locale\n\n    def get_user_locale(self):\n        \"\"\"Override to determine the locale from the authenticated user.\n\n        If None is returned, we fall back to `get_browser_locale()`.\n\n        This method should return a `tornado.locale.Locale` object,\n        most likely obtained via a call like ``tornado.locale.get(\"en\")``\n        \"\"\"\n        return None\n\n    def get_browser_locale(self, default=\"en_US\"):\n        \"\"\"Determines the user's locale from ``Accept-Language`` header.\n\n        See http://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html#sec14.4\n        \"\"\"\n        if \"Accept-Language\" in self.request.headers:\n            languages = self.request.headers[\"Accept-Language\"].split(\",\")\n            locales = []\n            for language in languages:\n                parts = language.strip().split(\";\")\n                if len(parts) > 1 and parts[1].startswith(\"q=\"):\n                    try:\n                        score = float(parts[1][2:])\n                    except (ValueError, TypeError):\n                        score = 0.0\n                else:\n                    score = 1.0\n                locales.append((parts[0], score))\n            if locales:\n                locales.sort(key=lambda pair: pair[1], reverse=True)\n                codes = [l[0] for l in locales]\n                return locale.get(*codes)\n        return locale.get(default)\n\n    @property\n    def current_user(self):\n        \"\"\"The authenticated user for this request.\n\n        This is a cached version of `get_current_user`, which you can\n        override to set the user based on, e.g., a cookie. If that\n        method is not overridden, this method always returns None.\n\n        We lazy-load the current user the first time this method is called\n        and cache the result after that.\n        \"\"\"\n        if not hasattr(self, \"_current_user\"):\n            self._current_user = self.get_current_user()\n        return self._current_user\n\n    @current_user.setter\n    def current_user(self, value):\n        self._current_user = value\n\n    def get_current_user(self):\n        \"\"\"Override to determine the current user from, e.g., a cookie.\"\"\"\n        return None\n\n    def get_login_url(self):\n        \"\"\"Override to customize the login URL based on the request.\n\n        By default, we use the ``login_url`` application setting.\n        \"\"\"\n        self.require_setting(\"login_url\", \"@tornado.web.authenticated\")\n        return self.application.settings[\"login_url\"]\n\n    def get_template_path(self):\n        \"\"\"Override to customize template path for each handler.\n\n        By default, we use the ``template_path`` application setting.\n        Return None to load templates relative to the calling file.\n        \"\"\"\n        return self.application.settings.get(\"template_path\")\n\n    @property\n    def xsrf_token(self):\n        \"\"\"The XSRF-prevention token for the current user/session.\n\n        To prevent cross-site request forgery, we set an '_xsrf' cookie\n        and include the same '_xsrf' value as an argument with all POST\n        requests. If the two do not match, we reject the form submission\n        as a potential forgery.\n\n        See http://en.wikipedia.org/wiki/Cross-site_request_forgery\n        \"\"\"\n        if not hasattr(self, \"_xsrf_token\"):\n            token = self.get_cookie(\"_xsrf\")\n            if not token:\n                token = binascii.b2a_hex(os.urandom(16))\n                expires_days = 30 if self.current_user else None\n                self.set_cookie(\"_xsrf\", token, expires_days=expires_days)\n            self._xsrf_token = token\n        return self._xsrf_token\n\n    def check_xsrf_cookie(self):\n        \"\"\"Verifies that the ``_xsrf`` cookie matches the ``_xsrf`` argument.\n\n        To prevent cross-site request forgery, we set an ``_xsrf``\n        cookie and include the same value as a non-cookie\n        field with all ``POST`` requests. If the two do not match, we\n        reject the form submission as a potential forgery.\n\n        The ``_xsrf`` value may be set as either a form field named ``_xsrf``\n        or in a custom HTTP header named ``X-XSRFToken`` or ``X-CSRFToken``\n        (the latter is accepted for compatibility with Django).\n\n        See http://en.wikipedia.org/wiki/Cross-site_request_forgery\n\n        Prior to release 1.1.1, this check was ignored if the HTTP header\n        ``X-Requested-With: XMLHTTPRequest`` was present.  This exception\n        has been shown to be insecure and has been removed.  For more\n        information please see\n        http://www.djangoproject.com/weblog/2011/feb/08/security/\n        http://weblog.rubyonrails.org/2011/2/8/csrf-protection-bypass-in-ruby-on-rails\n        \"\"\"\n        token = (self.get_argument(\"_xsrf\", None) or\n                 self.request.headers.get(\"X-Xsrftoken\") or\n                 self.request.headers.get(\"X-Csrftoken\"))\n        if not token:\n            raise HTTPError(403, \"'_xsrf' argument missing from POST\")\n        if not _time_independent_equals(utf8(self.xsrf_token), utf8(token)):\n            raise HTTPError(403, \"XSRF cookie does not match POST argument\")\n\n    def xsrf_form_html(self):\n        \"\"\"An HTML ``<input/>`` element to be included with all POST forms.\n\n        It defines the ``_xsrf`` input value, which we check on all POST\n        requests to prevent cross-site request forgery. If you have set\n        the ``xsrf_cookies`` application setting, you must include this\n        HTML within all of your HTML forms.\n\n        In a template, this method should be called with ``{% module\n        xsrf_form_html() %}``\n\n        See `check_xsrf_cookie()` above for more information.\n        \"\"\"\n        return '<input type=\"hidden\" name=\"_xsrf\" value=\"' + \\\n            escape.xhtml_escape(self.xsrf_token) + '\"/>'\n\n    def static_url(self, path, include_host=None, **kwargs):\n        \"\"\"Returns a static URL for the given relative static file path.\n\n        This method requires you set the ``static_path`` setting in your\n        application (which specifies the root directory of your static\n        files).\n\n        This method returns a versioned url (by default appending\n        ``?v=<signature>``), which allows the static files to be\n        cached indefinitely.  This can be disabled by passing\n        ``include_version=False`` (in the default implementation;\n        other static file implementations are not required to support\n        this, but they may support other options).\n\n        By default this method returns URLs relative to the current\n        host, but if ``include_host`` is true the URL returned will be\n        absolute.  If this handler has an ``include_host`` attribute,\n        that value will be used as the default for all `static_url`\n        calls that do not pass ``include_host`` as a keyword argument.\n\n        \"\"\"\n        self.require_setting(\"static_path\", \"static_url\")\n        get_url = self.settings.get(\"static_handler_class\",\n                                    StaticFileHandler).make_static_url\n\n        if include_host is None:\n            include_host = getattr(self, \"include_host\", False)\n\n        if include_host:\n            base = self.request.protocol + \"://\" + self.request.host\n        else:\n            base = \"\"\n\n        return base + get_url(self.settings, path, **kwargs)\n\n    def async_callback(self, callback, *args, **kwargs):\n        \"\"\"Obsolete - catches exceptions from the wrapped function.\n\n        This function is unnecessary since Tornado 1.1.\n        \"\"\"\n        if callback is None:\n            return None\n        if args or kwargs:\n            callback = functools.partial(callback, *args, **kwargs)\n\n        def wrapper(*args, **kwargs):\n            try:\n                return callback(*args, **kwargs)\n            except Exception as e:\n                if self._headers_written:\n                    app_log.error(\"Exception after headers written\",\n                                  exc_info=True)\n                else:\n                    self._handle_request_exception(e)\n        return wrapper\n\n    def require_setting(self, name, feature=\"this feature\"):\n        \"\"\"Raises an exception if the given app setting is not defined.\"\"\"\n        if not self.application.settings.get(name):\n            raise Exception(\"You must define the '%s' setting in your \"\n                            \"application to use %s\" % (name, feature))\n\n    def reverse_url(self, name, *args):\n        \"\"\"Alias for `Application.reverse_url`.\"\"\"\n        return self.application.reverse_url(name, *args)\n\n    def compute_etag(self):\n        \"\"\"Computes the etag header to be used for this request.\n\n        By default uses a hash of the content written so far.\n\n        May be overridden to provide custom etag implementations,\n        or may return None to disable tornado's default etag support.\n        \"\"\"\n        hasher = hashlib.sha1()\n        for part in self._write_buffer:\n            hasher.update(part)\n        return '\"%s\"' % hasher.hexdigest()\n\n    def set_etag_header(self):\n        \"\"\"Sets the response's Etag header using ``self.compute_etag()``.\n\n        Note: no header will be set if ``compute_etag()`` returns ``None``.\n\n        This method is called automatically when the request is finished.\n        \"\"\"\n        etag = self.compute_etag()\n        if etag is not None:\n            self.set_header(\"Etag\", etag)\n\n    def check_etag_header(self):\n        \"\"\"Checks the ``Etag`` header against requests's ``If-None-Match``.\n\n        Returns ``True`` if the request's Etag matches and a 304 should be\n        returned. For example::\n\n            self.set_etag_header()\n            if self.check_etag_header():\n                self.set_status(304)\n                return\n\n        This method is called automatically when the request is finished,\n        but may be called earlier for applications that override\n        `compute_etag` and want to do an early check for ``If-None-Match``\n        before completing the request.  The ``Etag`` header should be set\n        (perhaps with `set_etag_header`) before calling this method.\n        \"\"\"\n        etag = self._headers.get(\"Etag\")\n        inm = utf8(self.request.headers.get(\"If-None-Match\", \"\"))\n        return bool(etag and inm and inm.find(etag) >= 0)\n\n    def _stack_context_handle_exception(self, type, value, traceback):\n        try:\n            # For historical reasons _handle_request_exception only takes\n            # the exception value instead of the full triple,\n            # so re-raise the exception to ensure that it's in\n            # sys.exc_info()\n            raise_exc_info((type, value, traceback))\n        except Exception:\n            self._handle_request_exception(value)\n        return True\n\n    def _execute(self, transforms, *args, **kwargs):\n        \"\"\"Executes this request with the given output transforms.\"\"\"\n        self._transforms = transforms\n        try:\n            if self.request.method not in self.SUPPORTED_METHODS:\n                raise HTTPError(405)\n            self.path_args = [self.decode_argument(arg) for arg in args]\n            self.path_kwargs = dict((k, self.decode_argument(v, name=k))\n                                    for (k, v) in kwargs.items())\n            # If XSRF cookies are turned on, reject form submissions without\n            # the proper cookie\n            if self.request.method not in (\"GET\", \"HEAD\", \"OPTIONS\") and \\\n                    self.application.settings.get(\"xsrf_cookies\"):\n                self.check_xsrf_cookie()\n            self._when_complete(self.prepare(), self._execute_method)\n        except Exception as e:\n            self._handle_request_exception(e)\n\n    def _when_complete(self, result, callback):\n        try:\n            if result is None:\n                callback()\n            elif isinstance(result, Future):\n                if result.done():\n                    if result.result() is not None:\n                        raise ValueError('Expected None, got %r' % result.result())\n                    callback()\n                else:\n                    # Delayed import of IOLoop because it's not available\n                    # on app engine\n                    from tornado.ioloop import IOLoop\n                    IOLoop.current().add_future(\n                        result, functools.partial(self._when_complete,\n                                                  callback=callback))\n            else:\n                raise ValueError(\"Expected Future or None, got %r\" % result)\n        except Exception as e:\n            self._handle_request_exception(e)\n\n    def _execute_method(self):\n        if not self._finished:\n            method = getattr(self, self.request.method.lower())\n            self._when_complete(method(*self.path_args, **self.path_kwargs),\n                                self._execute_finish)\n\n    def _execute_finish(self):\n        if self._auto_finish and not self._finished:\n            self.finish()\n\n    def _generate_headers(self):\n        reason = self._reason\n        lines = [utf8(self.request.version + \" \" +\n                      str(self._status_code) +\n                      \" \" + reason)]\n        lines.extend([utf8(n) + b\": \" + utf8(v) for n, v in self._headers.get_all()])\n\n        if hasattr(self, \"_new_cookie\"):\n            for cookie in self._new_cookie.values():\n                lines.append(utf8(\"Set-Cookie: \" + cookie.OutputString(None)))\n        return b\"\\r\\n\".join(lines) + b\"\\r\\n\\r\\n\"\n\n    def _log(self):\n        \"\"\"Logs the current request.\n\n        Sort of deprecated since this functionality was moved to the\n        Application, but left in place for the benefit of existing apps\n        that have overridden this method.\n        \"\"\"\n        self.application.log_request(self)\n\n    def _request_summary(self):\n        return self.request.method + \" \" + self.request.uri + \\\n            \" (\" + self.request.remote_ip + \")\"\n\n    def _handle_request_exception(self, e):\n        self.log_exception(*sys.exc_info())\n        if self._finished:\n            # Extra errors after the request has been finished should\n            # be logged, but there is no reason to continue to try and\n            # send a response.\n            return\n        if isinstance(e, HTTPError):\n            if e.status_code not in httputil.responses and not e.reason:\n                gen_log.error(\"Bad HTTP status code: %d\", e.status_code)\n                self.send_error(500, exc_info=sys.exc_info())\n            else:\n                self.send_error(e.status_code, exc_info=sys.exc_info())\n        else:\n            self.send_error(500, exc_info=sys.exc_info())\n\n    def log_exception(self, typ, value, tb):\n        \"\"\"Override to customize logging of uncaught exceptions.\n\n        By default logs instances of `HTTPError` as warnings without\n        stack traces (on the ``tornado.general`` logger), and all\n        other exceptions as errors with stack traces (on the\n        ``tornado.application`` logger).\n\n        .. versionadded:: 3.1\n        \"\"\"\n        if isinstance(value, HTTPError):\n            if value.log_message:\n                format = \"%d %s: \" + value.log_message\n                args = ([value.status_code, self._request_summary()] +\n                        list(value.args))\n                gen_log.warning(format, *args)\n        else:\n            app_log.error(\"Uncaught exception %s\\n%r\", self._request_summary(),\n                          self.request, exc_info=(typ, value, tb))\n\n    def _ui_module(self, name, module):\n        def render(*args, **kwargs):\n            if not hasattr(self, \"_active_modules\"):\n                self._active_modules = {}\n            if name not in self._active_modules:\n                self._active_modules[name] = module(self)\n            rendered = self._active_modules[name].render(*args, **kwargs)\n            return rendered\n        return render\n\n    def _ui_method(self, method):\n        return lambda *args, **kwargs: method(self, *args, **kwargs)\n\n    def _clear_headers_for_304(self):\n        # 304 responses should not contain entity headers (defined in\n        # http://www.w3.org/Protocols/rfc2616/rfc2616-sec7.html#sec7.1)\n        # not explicitly allowed by\n        # http://www.w3.org/Protocols/rfc2616/rfc2616-sec10.html#sec10.3.5\n        headers = [\"Allow\", \"Content-Encoding\", \"Content-Language\",\n                   \"Content-Length\", \"Content-MD5\", \"Content-Range\",\n                   \"Content-Type\", \"Last-Modified\"]\n        for h in headers:\n            self.clear_header(h)\n\n\ndef asynchronous(method):\n    \"\"\"Wrap request handler methods with this if they are asynchronous.\n\n    This decorator is unnecessary if the method is also decorated with\n    ``@gen.coroutine`` (it is legal but unnecessary to use the two\n    decorators together, in which case ``@asynchronous`` must be\n    first).\n\n    This decorator should only be applied to the :ref:`HTTP verb\n    methods <verbs>`; its behavior is undefined for any other method.\n    This decorator does not *make* a method asynchronous; it tells\n    the framework that the method *is* asynchronous.  For this decorator\n    to be useful the method must (at least sometimes) do something\n    asynchronous.\n\n    If this decorator is given, the response is not finished when the\n    method returns. It is up to the request handler to call\n    `self.finish() <RequestHandler.finish>` to finish the HTTP\n    request. Without this decorator, the request is automatically\n    finished when the ``get()`` or ``post()`` method returns. Example::\n\n       class MyRequestHandler(web.RequestHandler):\n           @web.asynchronous\n           def get(self):\n              http = httpclient.AsyncHTTPClient()\n              http.fetch(\"http://friendfeed.com/\", self._on_download)\n\n           def _on_download(self, response):\n              self.write(\"Downloaded!\")\n              self.finish()\n\n    .. versionadded:: 3.1\n       The ability to use ``@gen.coroutine`` without ``@asynchronous``.\n    \"\"\"\n    # Delay the IOLoop import because it's not available on app engine.\n    from tornado.ioloop import IOLoop\n    @functools.wraps(method)\n    def wrapper(self, *args, **kwargs):\n        if self.application._wsgi:\n            raise Exception(\"@asynchronous is not supported for WSGI apps\")\n        self._auto_finish = False\n        with stack_context.ExceptionStackContext(\n                self._stack_context_handle_exception):\n            result = method(self, *args, **kwargs)\n            if isinstance(result, Future):\n                # If @asynchronous is used with @gen.coroutine, (but\n                # not @gen.engine), we can automatically finish the\n                # request when the future resolves.  Additionally,\n                # the Future will swallow any exceptions so we need\n                # to throw them back out to the stack context to finish\n                # the request.\n                def future_complete(f):\n                    f.result()\n                    if not self._finished:\n                        self.finish()\n                IOLoop.current().add_future(result, future_complete)\n                # Once we have done this, hide the Future from our\n                # caller (i.e. RequestHandler._when_complete), which\n                # would otherwise set up its own callback and\n                # exception handler (resulting in exceptions being\n                # logged twice).\n                return None\n            return result\n    return wrapper\n\n\ndef removeslash(method):\n    \"\"\"Use this decorator to remove trailing slashes from the request path.\n\n    For example, a request to ``/foo/`` would redirect to ``/foo`` with this\n    decorator. Your request handler mapping should use a regular expression\n    like ``r'/foo/*'`` in conjunction with using the decorator.\n    \"\"\"\n    @functools.wraps(method)\n    def wrapper(self, *args, **kwargs):\n        if self.request.path.endswith(\"/\"):\n            if self.request.method in (\"GET\", \"HEAD\"):\n                uri = self.request.path.rstrip(\"/\")\n                if uri:  # don't try to redirect '/' to ''\n                    if self.request.query:\n                        uri += \"?\" + self.request.query\n                    self.redirect(uri, permanent=True)\n                    return\n            else:\n                raise HTTPError(404)\n        return method(self, *args, **kwargs)\n    return wrapper\n\n\ndef addslash(method):\n    \"\"\"Use this decorator to add a missing trailing slash to the request path.\n\n    For example, a request to ``/foo`` would redirect to ``/foo/`` with this\n    decorator. Your request handler mapping should use a regular expression\n    like ``r'/foo/?'`` in conjunction with using the decorator.\n    \"\"\"\n    @functools.wraps(method)\n    def wrapper(self, *args, **kwargs):\n        if not self.request.path.endswith(\"/\"):\n            if self.request.method in (\"GET\", \"HEAD\"):\n                uri = self.request.path + \"/\"\n                if self.request.query:\n                    uri += \"?\" + self.request.query\n                self.redirect(uri, permanent=True)\n                return\n            raise HTTPError(404)\n        return method(self, *args, **kwargs)\n    return wrapper\n\n\nclass Application(object):\n    \"\"\"A collection of request handlers that make up a web application.\n\n    Instances of this class are callable and can be passed directly to\n    HTTPServer to serve the application::\n\n        application = web.Application([\n            (r\"/\", MainPageHandler),\n        ])\n        http_server = httpserver.HTTPServer(application)\n        http_server.listen(8080)\n        ioloop.IOLoop.instance().start()\n\n    The constructor for this class takes in a list of `URLSpec` objects\n    or (regexp, request_class) tuples. When we receive requests, we\n    iterate over the list in order and instantiate an instance of the\n    first request class whose regexp matches the request path.\n    The request class can be specified as either a class object or a\n    (fully-qualified) name.\n\n    Each tuple can contain additional elements, which correspond to the\n    arguments to the `URLSpec` constructor.  (Prior to Tornado 3.2, this\n    only tuples of two or three elements were allowed).\n\n    A dictionary may be passed as the third element of the tuple,\n    which will be used as keyword arguments to the handler's\n    constructor and `~RequestHandler.initialize` method.  This pattern\n    is used for the `StaticFileHandler` in this example (note that a\n    `StaticFileHandler` can be installed automatically with the\n    static_path setting described below)::\n\n        application = web.Application([\n            (r\"/static/(.*)\", web.StaticFileHandler, {\"path\": \"/var/www\"}),\n        ])\n\n    We support virtual hosts with the `add_handlers` method, which takes in\n    a host regular expression as the first argument::\n\n        application.add_handlers(r\"www\\.myhost\\.com\", [\n            (r\"/article/([0-9]+)\", ArticleHandler),\n        ])\n\n    You can serve static files by sending the ``static_path`` setting\n    as a keyword argument. We will serve those files from the\n    ``/static/`` URI (this is configurable with the\n    ``static_url_prefix`` setting), and we will serve ``/favicon.ico``\n    and ``/robots.txt`` from the same directory.  A custom subclass of\n    `StaticFileHandler` can be specified with the\n    ``static_handler_class`` setting.\n\n    \"\"\"\n    def __init__(self, handlers=None, default_host=\"\", transforms=None,\n                 wsgi=False, **settings):\n        if transforms is None:\n            self.transforms = []\n            if settings.get(\"gzip\"):\n                self.transforms.append(GZipContentEncoding)\n            self.transforms.append(ChunkedTransferEncoding)\n        else:\n            self.transforms = transforms\n        self.handlers = []\n        self.named_handlers = {}\n        self.default_host = default_host\n        self.settings = settings\n        self.ui_modules = {'linkify': _linkify,\n                           'xsrf_form_html': _xsrf_form_html,\n                           'Template': TemplateModule,\n                           }\n        self.ui_methods = {}\n        self._wsgi = wsgi\n        self._load_ui_modules(settings.get(\"ui_modules\", {}))\n        self._load_ui_methods(settings.get(\"ui_methods\", {}))\n        if self.settings.get(\"static_path\"):\n            path = self.settings[\"static_path\"]\n            handlers = list(handlers or [])\n            static_url_prefix = settings.get(\"static_url_prefix\",\n                                             \"/static/\")\n            static_handler_class = settings.get(\"static_handler_class\",\n                                                StaticFileHandler)\n            static_handler_args = settings.get(\"static_handler_args\", {})\n            static_handler_args['path'] = path\n            for pattern in [re.escape(static_url_prefix) + r\"(.*)\",\n                            r\"/(favicon\\.ico)\", r\"/(robots\\.txt)\"]:\n                handlers.insert(0, (pattern, static_handler_class,\n                                    static_handler_args))\n        if handlers:\n            self.add_handlers(\".*$\", handlers)\n\n        if self.settings.get('debug'):\n            self.settings.setdefault('autoreload', True)\n            self.settings.setdefault('compiled_template_cache', False)\n            self.settings.setdefault('static_hash_cache', False)\n            self.settings.setdefault('serve_traceback', True)\n\n        # Automatically reload modified modules\n        if self.settings.get('autoreload') and not wsgi:\n            from tornado import autoreload\n            autoreload.start()\n\n    def listen(self, port, address=\"\", **kwargs):\n        \"\"\"Starts an HTTP server for this application on the given port.\n\n        This is a convenience alias for creating an `.HTTPServer`\n        object and calling its listen method.  Keyword arguments not\n        supported by `HTTPServer.listen <.TCPServer.listen>` are passed to the\n        `.HTTPServer` constructor.  For advanced uses\n        (e.g. multi-process mode), do not use this method; create an\n        `.HTTPServer` and call its\n        `.TCPServer.bind`/`.TCPServer.start` methods directly.\n\n        Note that after calling this method you still need to call\n        ``IOLoop.instance().start()`` to start the server.\n        \"\"\"\n        # import is here rather than top level because HTTPServer\n        # is not importable on appengine\n        from tornado.httpserver import HTTPServer\n        server = HTTPServer(self, **kwargs)\n        server.listen(port, address)\n\n    def add_handlers(self, host_pattern, host_handlers):\n        \"\"\"Appends the given handlers to our handler list.\n\n        Host patterns are processed sequentially in the order they were\n        added. All matching patterns will be considered.\n        \"\"\"\n        if not host_pattern.endswith(\"$\"):\n            host_pattern += \"$\"\n        handlers = []\n        # The handlers with the wildcard host_pattern are a special\n        # case - they're added in the constructor but should have lower\n        # precedence than the more-precise handlers added later.\n        # If a wildcard handler group exists, it should always be last\n        # in the list, so insert new groups just before it.\n        if self.handlers and self.handlers[-1][0].pattern == '.*$':\n            self.handlers.insert(-1, (re.compile(host_pattern), handlers))\n        else:\n            self.handlers.append((re.compile(host_pattern), handlers))\n\n        for spec in host_handlers:\n            if isinstance(spec, (tuple, list)):\n                assert len(spec) in (2, 3, 4)\n                spec = URLSpec(*spec)\n            handlers.append(spec)\n            if spec.name:\n                if spec.name in self.named_handlers:\n                    app_log.warning(\n                        \"Multiple handlers named %s; replacing previous value\",\n                        spec.name)\n                self.named_handlers[spec.name] = spec\n\n    def add_transform(self, transform_class):\n        self.transforms.append(transform_class)\n\n    def _get_host_handlers(self, request):\n        host = request.host.lower().split(':')[0]\n        matches = []\n        for pattern, handlers in self.handlers:\n            if pattern.match(host):\n                matches.extend(handlers)\n        # Look for default host if not behind load balancer (for debugging)\n        if not matches and \"X-Real-Ip\" not in request.headers:\n            for pattern, handlers in self.handlers:\n                if pattern.match(self.default_host):\n                    matches.extend(handlers)\n        return matches or None\n\n    def _load_ui_methods(self, methods):\n        if isinstance(methods, types.ModuleType):\n            self._load_ui_methods(dict((n, getattr(methods, n))\n                                       for n in dir(methods)))\n        elif isinstance(methods, list):\n            for m in methods:\n                self._load_ui_methods(m)\n        else:\n            for name, fn in methods.items():\n                if not name.startswith(\"_\") and hasattr(fn, \"__call__\") \\\n                        and name[0].lower() == name[0]:\n                    self.ui_methods[name] = fn\n\n    def _load_ui_modules(self, modules):\n        if isinstance(modules, types.ModuleType):\n            self._load_ui_modules(dict((n, getattr(modules, n))\n                                       for n in dir(modules)))\n        elif isinstance(modules, list):\n            for m in modules:\n                self._load_ui_modules(m)\n        else:\n            assert isinstance(modules, dict)\n            for name, cls in modules.items():\n                try:\n                    if issubclass(cls, UIModule):\n                        self.ui_modules[name] = cls\n                except TypeError:\n                    pass\n\n    def __call__(self, request):\n        \"\"\"Called by HTTPServer to execute the request.\"\"\"\n        transforms = [t(request) for t in self.transforms]\n        handler = None\n        args = []\n        kwargs = {}\n        handlers = self._get_host_handlers(request)\n        if not handlers:\n            handler = RedirectHandler(\n                self, request, url=\"http://\" + self.default_host + \"/\")\n        else:\n            for spec in handlers:\n                match = spec.regex.match(request.path)\n                if match:\n                    handler = spec.handler_class(self, request, **spec.kwargs)\n                    if spec.regex.groups:\n                        # None-safe wrapper around url_unescape to handle\n                        # unmatched optional groups correctly\n                        def unquote(s):\n                            if s is None:\n                                return s\n                            return escape.url_unescape(s, encoding=None,\n                                                       plus=False)\n                        # Pass matched groups to the handler.  Since\n                        # match.groups() includes both named and unnamed groups,\n                        # we want to use either groups or groupdict but not both.\n                        # Note that args are passed as bytes so the handler can\n                        # decide what encoding to use.\n\n                        if spec.regex.groupindex:\n                            kwargs = dict(\n                                (str(k), unquote(v))\n                                for (k, v) in match.groupdict().items())\n                        else:\n                            args = [unquote(s) for s in match.groups()]\n                    break\n            if not handler:\n                if self.settings.get('default_handler_class'):\n                    handler_class = self.settings['default_handler_class']\n                    handler_args = self.settings.get(\n                        'default_handler_args', {})\n                else:\n                    handler_class = ErrorHandler\n                    handler_args = dict(status_code=404)\n                handler = handler_class(self, request, **handler_args)\n\n        # If template cache is disabled (usually in the debug mode),\n        # re-compile templates and reload static files on every\n        # request so you don't need to restart to see changes\n        if not self.settings.get(\"compiled_template_cache\", True):\n            with RequestHandler._template_loader_lock:\n                for loader in RequestHandler._template_loaders.values():\n                    loader.reset()\n        if not self.settings.get('static_hash_cache', True):\n            StaticFileHandler.reset()\n\n        handler._execute(transforms, *args, **kwargs)\n        return handler\n\n    def reverse_url(self, name, *args):\n        \"\"\"Returns a URL path for handler named ``name``\n\n        The handler must be added to the application as a named `URLSpec`.\n\n        Args will be substituted for capturing groups in the `URLSpec` regex.\n        They will be converted to strings if necessary, encoded as utf8,\n        and url-escaped.\n        \"\"\"\n        if name in self.named_handlers:\n            return self.named_handlers[name].reverse(*args)\n        raise KeyError(\"%s not found in named urls\" % name)\n\n    def log_request(self, handler):\n        \"\"\"Writes a completed HTTP request to the logs.\n\n        By default writes to the python root logger.  To change\n        this behavior either subclass Application and override this method,\n        or pass a function in the application settings dictionary as\n        ``log_function``.\n        \"\"\"\n        if \"log_function\" in self.settings:\n            self.settings[\"log_function\"](handler)\n            return\n        if handler.get_status() < 400:\n            log_method = access_log.info\n        elif handler.get_status() < 500:\n            log_method = access_log.warning\n        else:\n            log_method = access_log.error\n        request_time = 1000.0 * handler.request.request_time()\n        log_method(\"%d %s %.2fms\", handler.get_status(),\n                   handler._request_summary(), request_time)\n\n\nclass HTTPError(Exception):\n    \"\"\"An exception that will turn into an HTTP error response.\n\n    Raising an `HTTPError` is a convenient alternative to calling\n    `RequestHandler.send_error` since it automatically ends the\n    current function.\n\n    :arg int status_code: HTTP status code.  Must be listed in\n        `httplib.responses <http.client.responses>` unless the ``reason``\n        keyword argument is given.\n    :arg string log_message: Message to be written to the log for this error\n        (will not be shown to the user unless the `Application` is in debug\n        mode).  May contain ``%s``-style placeholders, which will be filled\n        in with remaining positional parameters.\n    :arg string reason: Keyword-only argument.  The HTTP \"reason\" phrase\n        to pass in the status line along with ``status_code``.  Normally\n        determined automatically from ``status_code``, but can be used\n        to use a non-standard numeric code.\n    \"\"\"\n    def __init__(self, status_code, log_message=None, *args, **kwargs):\n        self.status_code = status_code\n        self.log_message = log_message\n        self.args = args\n        self.reason = kwargs.get('reason', None)\n\n    def __str__(self):\n        message = \"HTTP %d: %s\" % (\n            self.status_code,\n            self.reason or httputil.responses.get(self.status_code, 'Unknown'))\n        if self.log_message:\n            return message + \" (\" + (self.log_message % self.args) + \")\"\n        else:\n            return message\n\n\nclass MissingArgumentError(HTTPError):\n    \"\"\"Exception raised by `RequestHandler.get_argument`.\n\n    This is a subclass of `HTTPError`, so if it is uncaught a 400 response\n    code will be used instead of 500 (and a stack trace will not be logged).\n\n    .. versionadded:: 3.1\n    \"\"\"\n    def __init__(self, arg_name):\n        super(MissingArgumentError, self).__init__(\n            400, 'Missing argument %s' % arg_name)\n        self.arg_name = arg_name\n\n\nclass ErrorHandler(RequestHandler):\n    \"\"\"Generates an error response with ``status_code`` for all requests.\"\"\"\n    def initialize(self, status_code):\n        self.set_status(status_code)\n\n    def prepare(self):\n        raise HTTPError(self._status_code)\n\n    def check_xsrf_cookie(self):\n        # POSTs to an ErrorHandler don't actually have side effects,\n        # so we don't need to check the xsrf token.  This allows POSTs\n        # to the wrong url to return a 404 instead of 403.\n        pass\n\n\nclass RedirectHandler(RequestHandler):\n    \"\"\"Redirects the client to the given URL for all GET requests.\n\n    You should provide the keyword argument ``url`` to the handler, e.g.::\n\n        application = web.Application([\n            (r\"/oldpath\", web.RedirectHandler, {\"url\": \"/newpath\"}),\n        ])\n    \"\"\"\n    def initialize(self, url, permanent=True):\n        self._url = url\n        self._permanent = permanent\n\n    def get(self):\n        self.redirect(self._url, permanent=self._permanent)\n\n\nclass StaticFileHandler(RequestHandler):\n    \"\"\"A simple handler that can serve static content from a directory.\n\n    A `StaticFileHandler` is configured automatically if you pass the\n    ``static_path`` keyword argument to `Application`.  This handler\n    can be customized with the ``static_url_prefix``, ``static_handler_class``,\n    and ``static_handler_args`` settings.\n\n    To map an additional path to this handler for a static data directory\n    you would add a line to your application like::\n\n        application = web.Application([\n            (r\"/content/(.*)\", web.StaticFileHandler, {\"path\": \"/var/www\"}),\n        ])\n\n    The handler constructor requires a ``path`` argument, which specifies the\n    local root directory of the content to be served.\n\n    Note that a capture group in the regex is required to parse the value for\n    the ``path`` argument to the get() method (different than the constructor\n    argument above); see `URLSpec` for details.\n\n    To maximize the effectiveness of browser caching, this class supports\n    versioned urls (by default using the argument ``?v=``).  If a version\n    is given, we instruct the browser to cache this file indefinitely.\n    `make_static_url` (also available as `RequestHandler.static_url`) can\n    be used to construct a versioned url.\n\n    This handler is intended primarily for use in development and light-duty\n    file serving; for heavy traffic it will be more efficient to use\n    a dedicated static file server (such as nginx or Apache).  We support\n    the HTTP ``Accept-Ranges`` mechanism to return partial content (because\n    some browsers require this functionality to be present to seek in\n    HTML5 audio or video), but this handler should not be used with\n    files that are too large to fit comfortably in memory.\n\n    **Subclassing notes**\n\n    This class is designed to be extensible by subclassing, but because\n    of the way static urls are generated with class methods rather than\n    instance methods, the inheritance patterns are somewhat unusual.\n    Be sure to use the ``@classmethod`` decorator when overriding a\n    class method.  Instance methods may use the attributes ``self.path``\n    ``self.absolute_path``, and ``self.modified``.\n\n    Subclasses should only override methods discussed in this section;\n    overriding other methods is error-prone.  Overriding\n    ``StaticFileHandler.get`` is particularly problematic due to the\n    tight coupling with ``compute_etag`` and other methods.\n\n    To change the way static urls are generated (e.g. to match the behavior\n    of another server or CDN), override `make_static_url`, `parse_url_path`,\n    `get_cache_time`, and/or `get_version`.\n\n    To replace all interaction with the filesystem (e.g. to serve\n    static content from a database), override `get_content`,\n    `get_content_size`, `get_modified_time`, `get_absolute_path`, and\n    `validate_absolute_path`.\n\n    .. versionchanged:: 3.1\n       Many of the methods for subclasses were added in Tornado 3.1.\n    \"\"\"\n    CACHE_MAX_AGE = 86400 * 365 * 10  # 10 years\n\n    _static_hashes = {}\n    _lock = threading.Lock()  # protects _static_hashes\n\n    def initialize(self, path, default_filename=None):\n        self.root = path\n        self.default_filename = default_filename\n\n    @classmethod\n    def reset(cls):\n        with cls._lock:\n            cls._static_hashes = {}\n\n    def head(self, path):\n        self.get(path, include_body=False)\n\n    def get(self, path, include_body=True):\n        # Set up our path instance variables.\n        self.path = self.parse_url_path(path)\n        del path  # make sure we don't refer to path instead of self.path again\n        absolute_path = self.get_absolute_path(self.root, self.path)\n        self.absolute_path = self.validate_absolute_path(\n            self.root, absolute_path)\n        if self.absolute_path is None:\n            return\n\n        self.modified = self.get_modified_time()\n        self.set_headers()\n\n        if self.should_return_304():\n            self.set_status(304)\n            return\n\n        request_range = None\n        range_header = self.request.headers.get(\"Range\")\n        if range_header:\n            # As per RFC 2616 14.16, if an invalid Range header is specified,\n            # the request will be treated as if the header didn't exist.\n            request_range = httputil._parse_request_range(range_header)\n\n        if request_range:\n            start, end = request_range\n            size = self.get_content_size()\n            if (start is not None and start >= size) or end == 0:\n                # As per RFC 2616 14.35.1, a range is not satisfiable only: if\n                # the first requested byte is equal to or greater than the\n                # content, or when a suffix with length 0 is specified\n                self.set_status(416)  # Range Not Satisfiable\n                self.set_header(\"Content-Type\", \"text/plain\")\n                self.set_header(\"Content-Range\", \"bytes */%s\" % (size, ))\n                return\n            if start is not None and start < 0:\n                start += size\n            if end is not None and end > size:\n                # Clients sometimes blindly use a large range to limit their\n                # download size; cap the endpoint at the actual file size.\n                end = size\n            # Note: only return HTTP 206 if less than the entire range has been\n            # requested. Not only is this semantically correct, but Chrome\n            # refuses to play audio if it gets an HTTP 206 in response to\n            # ``Range: bytes=0-``.\n            if size != (end or size) - (start or 0):\n                self.set_status(206)  # Partial Content\n                self.set_header(\"Content-Range\",\n                                httputil._get_content_range(start, end, size))\n        else:\n            start = end = None\n        content = self.get_content(self.absolute_path, start, end)\n        if isinstance(content, bytes_type):\n            content = [content]\n        content_length = 0\n        for chunk in content:\n            if include_body:\n                self.write(chunk)\n            else:\n                content_length += len(chunk)\n        if not include_body:\n            assert self.request.method == \"HEAD\"\n            self.set_header(\"Content-Length\", content_length)\n\n    def compute_etag(self):\n        \"\"\"Sets the ``Etag`` header based on static url version.\n\n        This allows efficient ``If-None-Match`` checks against cached\n        versions, and sends the correct ``Etag`` for a partial response\n        (i.e. the same ``Etag`` as the full file).\n\n        .. versionadded:: 3.1\n        \"\"\"\n        version_hash = self._get_cached_version(self.absolute_path)\n        if not version_hash:\n            return None\n        return '\"%s\"' % (version_hash, )\n\n    def set_headers(self):\n        \"\"\"Sets the content and caching headers on the response.\n\n        .. versionadded:: 3.1\n        \"\"\"\n        self.set_header(\"Accept-Ranges\", \"bytes\")\n        self.set_etag_header()\n\n        if self.modified is not None:\n            self.set_header(\"Last-Modified\", self.modified)\n\n        content_type = self.get_content_type()\n        if content_type:\n            self.set_header(\"Content-Type\", content_type)\n\n        cache_time = self.get_cache_time(self.path, self.modified, content_type)\n        if cache_time > 0:\n            self.set_header(\"Expires\", datetime.datetime.utcnow() +\n                            datetime.timedelta(seconds=cache_time))\n            self.set_header(\"Cache-Control\", \"max-age=\" + str(cache_time))\n\n        self.set_extra_headers(self.path)\n\n    def should_return_304(self):\n        \"\"\"Returns True if the headers indicate that we should return 304.\n\n        .. versionadded:: 3.1\n        \"\"\"\n        if self.check_etag_header():\n            return True\n\n        # Check the If-Modified-Since, and don't send the result if the\n        # content has not been modified\n        ims_value = self.request.headers.get(\"If-Modified-Since\")\n        if ims_value is not None:\n            date_tuple = email.utils.parsedate(ims_value)\n            if date_tuple is not None:\n                if_since = datetime.datetime(*date_tuple[:6])\n                if if_since >= self.modified:\n                    return True\n\n        return False\n\n    @classmethod\n    def get_absolute_path(cls, root, path):\n        \"\"\"Returns the absolute location of ``path`` relative to ``root``.\n\n        ``root`` is the path configured for this `StaticFileHandler`\n        (in most cases the ``static_path`` `Application` setting).\n\n        This class method may be overridden in subclasses.  By default\n        it returns a filesystem path, but other strings may be used\n        as long as they are unique and understood by the subclass's\n        overridden `get_content`.\n\n        .. versionadded:: 3.1\n        \"\"\"\n        abspath = os.path.abspath(os.path.join(root, path))\n        return abspath\n\n    def validate_absolute_path(self, root, absolute_path):\n        \"\"\"Validate and return the absolute path.\n\n        ``root`` is the configured path for the `StaticFileHandler`,\n        and ``path`` is the result of `get_absolute_path`\n\n        This is an instance method called during request processing,\n        so it may raise `HTTPError` or use methods like\n        `RequestHandler.redirect` (return None after redirecting to\n        halt further processing).  This is where 404 errors for missing files\n        are generated.\n\n        This method may modify the path before returning it, but note that\n        any such modifications will not be understood by `make_static_url`.\n\n        In instance methods, this method's result is available as\n        ``self.absolute_path``.\n\n        .. versionadded:: 3.1\n        \"\"\"\n        root = os.path.abspath(root)\n        # os.path.abspath strips a trailing /\n        # it needs to be temporarily added back for requests to root/\n        if not (absolute_path + os.path.sep).startswith(root):\n            raise HTTPError(403, \"%s is not in root static directory\",\n                            self.path)\n        if (os.path.isdir(absolute_path) and\n                self.default_filename is not None):\n            # need to look at the request.path here for when path is empty\n            # but there is some prefix to the path that was already\n            # trimmed by the routing\n            if not self.request.path.endswith(\"/\"):\n                self.redirect(self.request.path + \"/\", permanent=True)\n                return\n            absolute_path = os.path.join(absolute_path, self.default_filename)\n        if not os.path.exists(absolute_path):\n            raise HTTPError(404)\n        if not os.path.isfile(absolute_path):\n            raise HTTPError(403, \"%s is not a file\", self.path)\n        return absolute_path\n\n    @classmethod\n    def get_content(cls, abspath, start=None, end=None):\n        \"\"\"Retrieve the content of the requested resource which is located\n        at the given absolute path.\n\n        This class method may be overridden by subclasses.  Note that its\n        signature is different from other overridable class methods\n        (no ``settings`` argument); this is deliberate to ensure that\n        ``abspath`` is able to stand on its own as a cache key.\n\n        This method should either return a byte string or an iterator\n        of byte strings.  The latter is preferred for large files\n        as it helps reduce memory fragmentation.\n\n        .. versionadded:: 3.1\n        \"\"\"\n        with open(abspath, \"rb\") as file:\n            if start is not None:\n                file.seek(start)\n            if end is not None:\n                remaining = end - (start or 0)\n            else:\n                remaining = None\n            while True:\n                chunk_size = 64 * 1024\n                if remaining is not None and remaining < chunk_size:\n                    chunk_size = remaining\n                chunk = file.read(chunk_size)\n                if chunk:\n                    if remaining is not None:\n                        remaining -= len(chunk)\n                    yield chunk\n                else:\n                    if remaining is not None:\n                        assert remaining == 0\n                    return\n\n    @classmethod\n    def get_content_version(cls, abspath):\n        \"\"\"Returns a version string for the resource at the given path.\n\n        This class method may be overridden by subclasses.  The\n        default implementation is a hash of the file's contents.\n\n        .. versionadded:: 3.1\n        \"\"\"\n        data = cls.get_content(abspath)\n        hasher = hashlib.md5()\n        if isinstance(data, bytes_type):\n            hasher.update(data)\n        else:\n            for chunk in data:\n                hasher.update(chunk)\n        return hasher.hexdigest()\n\n    def _stat(self):\n        if not hasattr(self, '_stat_result'):\n            self._stat_result = os.stat(self.absolute_path)\n        return self._stat_result\n\n    def get_content_size(self):\n        \"\"\"Retrieve the total size of the resource at the given path.\n\n        This method may be overridden by subclasses. It will only\n        be called if a partial result is requested from `get_content`\n\n        .. versionadded:: 3.1\n        \"\"\"\n        stat_result = self._stat()\n        return stat_result[stat.ST_SIZE]\n\n    def get_modified_time(self):\n        \"\"\"Returns the time that ``self.absolute_path`` was last modified.\n\n        May be overridden in subclasses.  Should return a `~datetime.datetime`\n        object or None.\n\n        .. versionadded:: 3.1\n        \"\"\"\n        stat_result = self._stat()\n        modified = datetime.datetime.utcfromtimestamp(stat_result[stat.ST_MTIME])\n        return modified\n\n    def get_content_type(self):\n        \"\"\"Returns the ``Content-Type`` header to be used for this request.\n\n        .. versionadded:: 3.1\n        \"\"\"\n        mime_type, encoding = mimetypes.guess_type(self.absolute_path)\n        return mime_type\n\n    def set_extra_headers(self, path):\n        \"\"\"For subclass to add extra headers to the response\"\"\"\n        pass\n\n    def get_cache_time(self, path, modified, mime_type):\n        \"\"\"Override to customize cache control behavior.\n\n        Return a positive number of seconds to make the result\n        cacheable for that amount of time or 0 to mark resource as\n        cacheable for an unspecified amount of time (subject to\n        browser heuristics).\n\n        By default returns cache expiry of 10 years for resources requested\n        with ``v`` argument.\n        \"\"\"\n        return self.CACHE_MAX_AGE if \"v\" in self.request.arguments else 0\n\n    @classmethod\n    def make_static_url(cls, settings, path, include_version=True):\n        \"\"\"Constructs a versioned url for the given path.\n\n        This method may be overridden in subclasses (but note that it\n        is a class method rather than an instance method).  Subclasses\n        are only required to implement the signature\n        ``make_static_url(cls, settings, path)``; other keyword\n        arguments may be passed through `~RequestHandler.static_url`\n        but are not standard.\n\n        ``settings`` is the `Application.settings` dictionary.  ``path``\n        is the static path being requested.  The url returned should be\n        relative to the current host.\n\n        ``include_version`` determines whether the generated URL should\n        include the query string containing the version hash of the\n        file corresponding to the given ``path``.\n\n        \"\"\"\n        url = settings.get('static_url_prefix', '/static/') + path\n        if not include_version:\n            return url\n\n        version_hash = cls.get_version(settings, path)\n        if not version_hash:\n            return url\n\n        return '%s?v=%s' % (url, version_hash)\n\n    def parse_url_path(self, url_path):\n        \"\"\"Converts a static URL path into a filesystem path.\n\n        ``url_path`` is the path component of the URL with\n        ``static_url_prefix`` removed.  The return value should be\n        filesystem path relative to ``static_path``.\n\n        This is the inverse of `make_static_url`.\n        \"\"\"\n        if os.path.sep != \"/\":\n            url_path = url_path.replace(\"/\", os.path.sep)\n        return url_path\n\n    @classmethod\n    def get_version(cls, settings, path):\n        \"\"\"Generate the version string to be used in static URLs.\n\n        ``settings`` is the `Application.settings` dictionary and ``path``\n        is the relative location of the requested asset on the filesystem.\n        The returned value should be a string, or ``None`` if no version\n        could be determined.\n\n        .. versionchanged:: 3.1\n           This method was previously recommended for subclasses to override;\n           `get_content_version` is now preferred as it allows the base\n           class to handle caching of the result.\n        \"\"\"\n        abs_path = cls.get_absolute_path(settings['static_path'], path)\n        return cls._get_cached_version(abs_path)\n\n    @classmethod\n    def _get_cached_version(cls, abs_path):\n        with cls._lock:\n            hashes = cls._static_hashes\n            if abs_path not in hashes:\n                try:\n                    hashes[abs_path] = cls.get_content_version(abs_path)\n                except Exception:\n                    gen_log.error(\"Could not open static file %r\", abs_path)\n                    hashes[abs_path] = None\n            hsh = hashes.get(abs_path)\n            if hsh:\n                return hsh\n        return None\n\n\nclass FallbackHandler(RequestHandler):\n    \"\"\"A `RequestHandler` that wraps another HTTP server callback.\n\n    The fallback is a callable object that accepts an\n    `~.httpserver.HTTPRequest`, such as an `Application` or\n    `tornado.wsgi.WSGIContainer`.  This is most useful to use both\n    Tornado ``RequestHandlers`` and WSGI in the same server.  Typical\n    usage::\n\n        wsgi_app = tornado.wsgi.WSGIContainer(\n            django.core.handlers.wsgi.WSGIHandler())\n        application = tornado.web.Application([\n            (r\"/foo\", FooHandler),\n            (r\".*\", FallbackHandler, dict(fallback=wsgi_app),\n        ])\n    \"\"\"\n    def initialize(self, fallback):\n        self.fallback = fallback\n\n    def prepare(self):\n        self.fallback(self.request)\n        self._finished = True\n\n\nclass OutputTransform(object):\n    \"\"\"A transform modifies the result of an HTTP request (e.g., GZip encoding)\n\n    A new transform instance is created for every request. See the\n    ChunkedTransferEncoding example below if you want to implement a\n    new Transform.\n    \"\"\"\n    def __init__(self, request):\n        pass\n\n    def transform_first_chunk(self, status_code, headers, chunk, finishing):\n        return status_code, headers, chunk\n\n    def transform_chunk(self, chunk, finishing):\n        return chunk\n\n\nclass GZipContentEncoding(OutputTransform):\n    \"\"\"Applies the gzip content encoding to the response.\n\n    See http://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html#sec14.11\n    \"\"\"\n    CONTENT_TYPES = set([\n        \"text/plain\", \"text/html\", \"text/css\", \"text/xml\", \"application/javascript\",\n        \"application/x-javascript\", \"application/xml\", \"application/atom+xml\",\n        \"text/javascript\", \"application/json\", \"application/xhtml+xml\"])\n    MIN_LENGTH = 5\n\n    def __init__(self, request):\n        self._gzipping = request.supports_http_1_1() and \\\n            \"gzip\" in request.headers.get(\"Accept-Encoding\", \"\")\n\n    def transform_first_chunk(self, status_code, headers, chunk, finishing):\n        if 'Vary' in headers:\n            headers['Vary'] += b', Accept-Encoding'\n        else:\n            headers['Vary'] = b'Accept-Encoding'\n        if self._gzipping:\n            ctype = _unicode(headers.get(\"Content-Type\", \"\")).split(\";\")[0]\n            self._gzipping = (ctype in self.CONTENT_TYPES) and \\\n                (not finishing or len(chunk) >= self.MIN_LENGTH) and \\\n                (finishing or \"Content-Length\" not in headers) and \\\n                (\"Content-Encoding\" not in headers)\n        if self._gzipping:\n            headers[\"Content-Encoding\"] = \"gzip\"\n            self._gzip_value = BytesIO()\n            self._gzip_file = gzip.GzipFile(mode=\"w\", fileobj=self._gzip_value)\n            chunk = self.transform_chunk(chunk, finishing)\n            if \"Content-Length\" in headers:\n                headers[\"Content-Length\"] = str(len(chunk))\n        return status_code, headers, chunk\n\n    def transform_chunk(self, chunk, finishing):\n        if self._gzipping:\n            self._gzip_file.write(chunk)\n            if finishing:\n                self._gzip_file.close()\n            else:\n                self._gzip_file.flush()\n            chunk = self._gzip_value.getvalue()\n            self._gzip_value.truncate(0)\n            self._gzip_value.seek(0)\n        return chunk\n\n\nclass ChunkedTransferEncoding(OutputTransform):\n    \"\"\"Applies the chunked transfer encoding to the response.\n\n    See http://www.w3.org/Protocols/rfc2616/rfc2616-sec3.html#sec3.6.1\n    \"\"\"\n    def __init__(self, request):\n        self._chunking = request.supports_http_1_1()\n\n    def transform_first_chunk(self, status_code, headers, chunk, finishing):\n        # 304 responses have no body (not even a zero-length body), and so\n        # should not have either Content-Length or Transfer-Encoding headers.\n        if self._chunking and status_code != 304:\n            # No need to chunk the output if a Content-Length is specified\n            if \"Content-Length\" in headers or \"Transfer-Encoding\" in headers:\n                self._chunking = False\n            else:\n                headers[\"Transfer-Encoding\"] = \"chunked\"\n                chunk = self.transform_chunk(chunk, finishing)\n        return status_code, headers, chunk\n\n    def transform_chunk(self, block, finishing):\n        if self._chunking:\n            # Don't write out empty chunks because that means END-OF-STREAM\n            # with chunked encoding\n            if block:\n                block = utf8(\"%x\" % len(block)) + b\"\\r\\n\" + block + b\"\\r\\n\"\n            if finishing:\n                block += b\"0\\r\\n\\r\\n\"\n        return block\n\n\ndef authenticated(method):\n    \"\"\"Decorate methods with this to require that the user be logged in.\n\n    If the user is not logged in, they will be redirected to the configured\n    `login url <RequestHandler.get_login_url>`.\n    \"\"\"\n    @functools.wraps(method)\n    def wrapper(self, *args, **kwargs):\n        if not self.current_user:\n            if self.request.method in (\"GET\", \"HEAD\"):\n                url = self.get_login_url()\n                if \"?\" not in url:\n                    if urlparse.urlsplit(url).scheme:\n                        # if login url is absolute, make next absolute too\n                        next_url = self.request.full_url()\n                    else:\n                        next_url = self.request.uri\n                    url += \"?\" + urlencode(dict(next=next_url))\n                self.redirect(url)\n                return\n            raise HTTPError(403)\n        return method(self, *args, **kwargs)\n    return wrapper\n\n\nclass UIModule(object):\n    \"\"\"A re-usable, modular UI unit on a page.\n\n    UI modules often execute additional queries, and they can include\n    additional CSS and JavaScript that will be included in the output\n    page, which is automatically inserted on page render.\n    \"\"\"\n    def __init__(self, handler):\n        self.handler = handler\n        self.request = handler.request\n        self.ui = handler.ui\n        self.locale = handler.locale\n\n    @property\n    def current_user(self):\n        return self.handler.current_user\n\n    def render(self, *args, **kwargs):\n        \"\"\"Overridden in subclasses to return this module's output.\"\"\"\n        raise NotImplementedError()\n\n    def embedded_javascript(self):\n        \"\"\"Returns a JavaScript string that will be embedded in the page.\"\"\"\n        return None\n\n    def javascript_files(self):\n        \"\"\"Returns a list of JavaScript files required by this module.\"\"\"\n        return None\n\n    def embedded_css(self):\n        \"\"\"Returns a CSS string that will be embedded in the page.\"\"\"\n        return None\n\n    def css_files(self):\n        \"\"\"Returns a list of CSS files required by this module.\"\"\"\n        return None\n\n    def html_head(self):\n        \"\"\"Returns a CSS string that will be put in the <head/> element\"\"\"\n        return None\n\n    def html_body(self):\n        \"\"\"Returns an HTML string that will be put in the <body/> element\"\"\"\n        return None\n\n    def render_string(self, path, **kwargs):\n        \"\"\"Renders a template and returns it as a string.\"\"\"\n        return self.handler.render_string(path, **kwargs)\n\n\nclass _linkify(UIModule):\n    def render(self, text, **kwargs):\n        return escape.linkify(text, **kwargs)\n\n\nclass _xsrf_form_html(UIModule):\n    def render(self):\n        return self.handler.xsrf_form_html()\n\n\nclass TemplateModule(UIModule):\n    \"\"\"UIModule that simply renders the given template.\n\n    {% module Template(\"foo.html\") %} is similar to {% include \"foo.html\" %},\n    but the module version gets its own namespace (with kwargs passed to\n    Template()) instead of inheriting the outer template's namespace.\n\n    Templates rendered through this module also get access to UIModule's\n    automatic javascript/css features.  Simply call set_resources\n    inside the template and give it keyword arguments corresponding to\n    the methods on UIModule: {{ set_resources(js_files=static_url(\"my.js\")) }}\n    Note that these resources are output once per template file, not once\n    per instantiation of the template, so they must not depend on\n    any arguments to the template.\n    \"\"\"\n    def __init__(self, handler):\n        super(TemplateModule, self).__init__(handler)\n        # keep resources in both a list and a dict to preserve order\n        self._resource_list = []\n        self._resource_dict = {}\n\n    def render(self, path, **kwargs):\n        def set_resources(**kwargs):\n            if path not in self._resource_dict:\n                self._resource_list.append(kwargs)\n                self._resource_dict[path] = kwargs\n            else:\n                if self._resource_dict[path] != kwargs:\n                    raise ValueError(\"set_resources called with different \"\n                                     \"resources for the same template\")\n            return \"\"\n        return self.render_string(path, set_resources=set_resources,\n                                  **kwargs)\n\n    def _get_resources(self, key):\n        return (r[key] for r in self._resource_list if key in r)\n\n    def embedded_javascript(self):\n        return \"\\n\".join(self._get_resources(\"embedded_javascript\"))\n\n    def javascript_files(self):\n        result = []\n        for f in self._get_resources(\"javascript_files\"):\n            if isinstance(f, (unicode_type, bytes_type)):\n                result.append(f)\n            else:\n                result.extend(f)\n        return result\n\n    def embedded_css(self):\n        return \"\\n\".join(self._get_resources(\"embedded_css\"))\n\n    def css_files(self):\n        result = []\n        for f in self._get_resources(\"css_files\"):\n            if isinstance(f, (unicode_type, bytes_type)):\n                result.append(f)\n            else:\n                result.extend(f)\n        return result\n\n    def html_head(self):\n        return \"\".join(self._get_resources(\"html_head\"))\n\n    def html_body(self):\n        return \"\".join(self._get_resources(\"html_body\"))\n\n\nclass _UIModuleNamespace(object):\n    \"\"\"Lazy namespace which creates UIModule proxies bound to a handler.\"\"\"\n    def __init__(self, handler, ui_modules):\n        self.handler = handler\n        self.ui_modules = ui_modules\n\n    def __getitem__(self, key):\n        return self.handler._ui_module(key, self.ui_modules[key])\n\n    def __getattr__(self, key):\n        try:\n            return self[key]\n        except KeyError as e:\n            raise AttributeError(str(e))\n\n\nclass URLSpec(object):\n    \"\"\"Specifies mappings between URLs and handlers.\"\"\"\n    def __init__(self, pattern, handler, kwargs=None, name=None):\n        \"\"\"Parameters:\n\n        * ``pattern``: Regular expression to be matched.  Any groups\n          in the regex will be passed in to the handler's get/post/etc\n          methods as arguments.\n\n        * ``handler_class``: `RequestHandler` subclass to be invoked.\n\n        * ``kwargs`` (optional): A dictionary of additional arguments\n          to be passed to the handler's constructor.\n\n        * ``name`` (optional): A name for this handler.  Used by\n          `Application.reverse_url`.\n        \"\"\"\n        if not pattern.endswith('$'):\n            pattern += '$'\n        self.regex = re.compile(pattern)\n        assert len(self.regex.groupindex) in (0, self.regex.groups), \\\n            (\"groups in url regexes must either be all named or all \"\n             \"positional: %r\" % self.regex.pattern)\n\n        if isinstance(handler, str):\n            # import the Module and instantiate the class\n            # Must be a fully qualified name (module.ClassName)\n            handler = import_object(handler)\n\n        self.handler_class = handler\n        self.kwargs = kwargs or {}\n        self.name = name\n        self._path, self._group_count = self._find_groups()\n\n    def __repr__(self):\n        return '%s(%r, %s, kwargs=%r, name=%r)' % \\\n            (self.__class__.__name__, self.regex.pattern,\n             self.handler_class, self.kwargs, self.name)\n\n    def _find_groups(self):\n        \"\"\"Returns a tuple (reverse string, group count) for a url.\n\n        For example: Given the url pattern /([0-9]{4})/([a-z-]+)/, this method\n        would return ('/%s/%s/', 2).\n        \"\"\"\n        pattern = self.regex.pattern\n        if pattern.startswith('^'):\n            pattern = pattern[1:]\n        if pattern.endswith('$'):\n            pattern = pattern[:-1]\n\n        if self.regex.groups != pattern.count('('):\n            # The pattern is too complicated for our simplistic matching,\n            # so we can't support reversing it.\n            return (None, None)\n\n        pieces = []\n        for fragment in pattern.split('('):\n            if ')' in fragment:\n                paren_loc = fragment.index(')')\n                if paren_loc >= 0:\n                    pieces.append('%s' + fragment[paren_loc + 1:])\n            else:\n                pieces.append(fragment)\n\n        return (''.join(pieces), self.regex.groups)\n\n    def reverse(self, *args):\n        assert self._path is not None, \\\n            \"Cannot reverse url regex \" + self.regex.pattern\n        assert len(args) == self._group_count, \"required number of arguments \"\\\n            \"not found\"\n        if not len(args):\n            return self._path\n        converted_args = []\n        for a in args:\n            if not isinstance(a, (unicode_type, bytes_type)):\n                a = str(a)\n            converted_args.append(escape.url_escape(utf8(a), plus=False))\n        return self._path % tuple(converted_args)\n\nurl = URLSpec\n\n\nif hasattr(hmac, 'compare_digest'):  # python 3.3\n    _time_independent_equals = hmac.compare_digest\nelse:\n    def _time_independent_equals(a, b):\n        if len(a) != len(b):\n            return False\n        result = 0\n        if isinstance(a[0], int):  # python3 byte strings\n            for x, y in zip(a, b):\n                result |= x ^ y\n        else:  # python2\n            for x, y in zip(a, b):\n                result |= ord(x) ^ ord(y)\n        return result == 0\n\n\ndef create_signed_value(secret, name, value, version=None, clock=None):\n    if version is None:\n        version = DEFAULT_SIGNED_VALUE_VERSION\n    if clock is None:\n        clock = time.time\n    timestamp = utf8(str(int(clock())))\n    value = base64.b64encode(utf8(value))\n    if version == 1:\n        signature = _create_signature_v1(secret, name, value, timestamp)\n        value = b\"|\".join([value, timestamp, signature])\n        return value\n    elif version == 2:\n        # The v2 format consists of a version number and a series of\n        # length-prefixed fields \"%d:%s\", the last of which is a\n        # signature, all separated by pipes.  All numbers are in\n        # decimal format with no leading zeros.  The signature is an\n        # HMAC-SHA256 of the whole string up to that point, including\n        # the final pipe.\n        #\n        # The fields are:\n        # - format version (i.e. 2; no length prefix)\n        # - key version (currently 0; reserved for future key rotation features)\n        # - timestamp (integer seconds since epoch)\n        # - name (not encoded; assumed to be ~alphanumeric)\n        # - value (base64-encoded)\n        # - signature (hex-encoded; no length prefix)\n        def format_field(s):\n            return utf8(\"%d:\" % len(s)) + utf8(s)\n        to_sign = b\"|\".join([\n            b\"2|1:0\",\n            format_field(timestamp),\n            format_field(name),\n            format_field(value),\n            b''])\n        signature = _create_signature_v2(secret, to_sign)\n        return to_sign + signature\n    else:\n        raise ValueError(\"Unsupported version %d\" % version)\n\n# A leading version number in decimal with no leading zeros, followed by a pipe.\n_signed_value_version_re = re.compile(br\"^([1-9][0-9]*)\\|(.*)$\")\n\ndef decode_signed_value(secret, name, value, max_age_days=31, clock=None,min_version=None):\n    if clock is None:\n        clock = time.time\n    if min_version is None:\n        min_version = DEFAULT_SIGNED_VALUE_MIN_VERSION\n    if min_version > 2:\n        raise ValueError(\"Unsupported min_version %d\" % min_version)\n    if not value:\n        return None\n\n    # Figure out what version this is.  Version 1 did not include an\n    # explicit version field and started with arbitrary base64 data,\n    # which makes this tricky.\n    value = utf8(value)\n    m = _signed_value_version_re.match(value)\n    if m is None:\n        version = 1\n    else:\n        try:\n            version = int(m.group(1))\n            if version > 999:\n                # Certain payloads from the version-less v1 format may\n                # be parsed as valid integers.  Due to base64 padding\n                # restrictions, this can only happen for numbers whose\n                # length is a multiple of 4, so we can treat all\n                # numbers up to 999 as versions, and for the rest we\n                # fall back to v1 format.\n                version = 1\n        except ValueError:\n            version = 1\n\n    if version < min_version:\n        return None\n    if version == 1:\n        return _decode_signed_value_v1(secret, name, value, max_age_days, clock)\n    elif version == 2:\n        return _decode_signed_value_v2(secret, name, value, max_age_days, clock)\n    else:\n        return None\n\ndef _decode_signed_value_v1(secret, name, value, max_age_days, clock):\n    parts = utf8(value).split(b\"|\")\n    if len(parts) != 3:\n        return None\n    signature = _create_signature_v1(secret, name, parts[0], parts[1])\n    if not _time_independent_equals(parts[2], signature):\n        gen_log.warning(\"Invalid cookie signature %r\", value)\n        return None\n    timestamp = int(parts[1])\n    if timestamp < clock() - max_age_days * 86400:\n        gen_log.warning(\"Expired cookie %r\", value)\n        return None\n    if timestamp > clock() + 31 * 86400:\n        # _cookie_signature does not hash a delimiter between the\n        # parts of the cookie, so an attacker could transfer trailing\n        # digits from the payload to the timestamp without altering the\n        # signature.  For backwards compatibility, sanity-check timestamp\n        # here instead of modifying _cookie_signature.\n        gen_log.warning(\"Cookie timestamp in future; possible tampering %r\", value)\n        return None\n    if parts[1].startswith(b\"0\"):\n        gen_log.warning(\"Tampered cookie %r\", value)\n        return None\n    try:\n        return base64.b64decode(parts[0])\n    except Exception:\n        return None\n\n\ndef _decode_signed_value_v2(secret, name, value, max_age_days, clock):\n    def _consume_field(s):\n        length, _, rest = s.partition(b':')\n        n = int(length)\n        field_value = rest[:n]\n        # In python 3, indexing bytes returns small integers; we must\n        # use a slice to get a byte string as in python 2.\n        if rest[n:n+1] != b'|':\n            raise ValueError(\"malformed v2 signed value field\")\n        rest = rest[n+1:]\n        return field_value, rest\n    rest = value[2:]  # remove version number\n    try:\n        key_version, rest = _consume_field(rest)\n        timestamp, rest = _consume_field(rest)\n        name_field, rest = _consume_field(rest)\n        value_field, rest = _consume_field(rest)\n    except ValueError:\n        return None\n    passed_sig = rest\n    signed_string = value[:-len(passed_sig)]\n    expected_sig = _create_signature_v2(secret, signed_string)\n    if not _time_independent_equals(passed_sig, expected_sig):\n        return None\n    if name_field != utf8(name):\n        return None\n    timestamp = int(timestamp)\n    if timestamp < clock() - max_age_days * 86400:\n        # The signature has expired.\n        return None\n    try:\n        return base64.b64decode(value_field)\n    except Exception:\n        return None\n\n\ndef _create_signature_v1(secret, *parts):\n    hash = hmac.new(utf8(secret), digestmod=hashlib.sha1)\n    for part in parts:\n        hash.update(utf8(part))\n    return utf8(hash.hexdigest())\n\ndef _create_signature_v2(secret, s):\n    hash = hmac.new(utf8(secret), digestmod=hashlib.sha256)\n    hash.update(utf8(s))\n    return utf8(hash.hexdigest())\n", "target": 1}
{"idx": 894, "func": "\"\"\"Serve files directly from the ContentsManager.\"\"\"\n\n# Copyright (c) IPython Development Team.\n# Distributed under the terms of the Modified BSD License.\n\nimport os\nimport mimetypes\nimport json\nimport base64\n\nfrom tornado import web\n\nfrom IPython.html.base.handlers import IPythonHandler\n\nclass FilesHandler(IPythonHandler):\n    \"\"\"serve files via ContentsManager\"\"\"\n\n    @web.authenticated\n    def get(self, path):\n        cm = self.contents_manager\n        if cm.is_hidden(path):\n            self.log.info(\"Refusing to serve hidden file, via 404 Error\")\n            raise web.HTTPError(404)\n        \n        path = path.strip('/')\n        if '/' in path:\n            _, name = path.rsplit('/', 1)\n        else:\n            name = path\n        \n        model = cm.get(path, type='file')\n        \n        if self.get_argument(\"download\", False):\n            self.set_header('Content-Disposition','attachment; filename=\"%s\"' % name)\n        \n        # get mimetype from filename\n        if name.endswith('.ipynb'):\n            self.set_header('Content-Type', 'application/json')\n        else:\n            cur_mime = mimetypes.guess_type(name)[0]\n            if cur_mime is not None:\n                self.set_header('Content-Type', cur_mime)\n        \n        if model['format'] == 'base64':\n            b64_bytes = model['content'].encode('ascii')\n            self.write(base64.decodestring(b64_bytes))\n        elif model['format'] == 'json':\n            self.write(json.dumps(model['content']))\n        else:\n            self.write(model['content'])\n        self.flush()\n\ndefault_handlers = [\n    (r\"/files/(.*)\", FilesHandler),\n]", "target": 1}
{"idx": 895, "func": "# vim: tabstop=4 shiftwidth=4 softtabstop=4\n\n# Copyright 2012 OpenStack LLC\n# Copyright 2012 Canonical Ltd.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"); you may\n# not use this file except in compliance with the License. You may obtain\n# a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n# License for the specific language governing permissions and limitations\n# under the License.\n\n\"\"\"Main entry point into the Catalog service.\"\"\"\n\nimport uuid\n\nfrom keystone import config\nfrom keystone import exception\nfrom keystone import identity\nfrom keystone import policy\nfrom keystone import token\nfrom keystone.common import manager\nfrom keystone.common import wsgi\n\n\nCONF = config.CONF\n\n\nclass Manager(manager.Manager):\n    \"\"\"Default pivot point for the Catalog backend.\n\n    See :mod:`keystone.common.manager.Manager` for more details on how this\n    dynamically calls the backend.\n\n    \"\"\"\n\n    def __init__(self):\n        super(Manager, self).__init__(CONF.catalog.driver)\n\n\nclass Driver(object):\n    \"\"\"Interface description for an Catalog driver.\"\"\"\n    def list_services(self):\n        \"\"\"List all service ids in catalog.\n\n        Returns: list of service_ids or an empty list.\n\n        \"\"\"\n        raise exception.NotImplemented()\n\n    def get_service(self, service_id):\n        \"\"\"Get service by id.\n\n        Returns: service_ref dict or None.\n\n        \"\"\"\n        raise exception.NotImplemented()\n\n    def delete_service(self, service_id):\n        raise exception.NotImplemented()\n\n    def create_service(self, service_id, service_ref):\n        raise exception.NotImplemented()\n\n    def create_endpoint(self, endpoint_id, endpoint_ref):\n        raise exception.NotImplemented()\n\n    def delete_endpoint(self, endpoint_id):\n        raise exception.NotImplemented()\n\n    def get_endpoint(self, endpoint_id):\n        \"\"\"Get endpoint by id.\n\n        Returns: endpoint_ref dict or None.\n\n        \"\"\"\n        raise exception.NotImplemented()\n\n    def list_endpoints(self):\n        \"\"\"List all endpoint ids in catalog.\n\n        Returns: list of endpoint_ids or an empty list.\n\n        \"\"\"\n        raise exception.NotImplemented()\n\n    def get_catalog(self, user_id, tenant_id, metadata=None):\n        \"\"\"Retreive and format the current service catalog.\n\n        Returns: A nested dict representing the service catalog or an\n                 empty dict.\n\n        Example:\n\n            { 'RegionOne':\n                {'compute': {\n                    'adminURL': u'http://host:8774/v1.1/tenantid',\n                    'internalURL': u'http://host:8774/v1.1/tenant_id',\n                    'name': 'Compute Service',\n                    'publicURL': u'http://host:8774/v1.1/tenantid'},\n                 'ec2': {\n                    'adminURL': 'http://host:8773/services/Admin',\n                    'internalURL': 'http://host:8773/services/Cloud',\n                    'name': 'EC2 Service',\n                    'publicURL': 'http://host:8773/services/Cloud'}}\n\n        \"\"\"\n        raise exception.NotImplemented()\n\n\nclass ServiceController(wsgi.Application):\n    def __init__(self):\n        self.catalog_api = Manager()\n        super(ServiceController, self).__init__()\n\n    # CRUD extensions\n    # NOTE(termie): this OS-KSADM stuff is not very consistent\n    def get_services(self, context):\n        service_list = self.catalog_api.list_services(context)\n        service_refs = [self.catalog_api.get_service(context, x)\n                        for x in service_list]\n        return {'OS-KSADM:services': service_refs}\n\n    def get_service(self, context, service_id):\n        service_ref = self.catalog_api.get_service(context, service_id)\n        if not service_ref:\n            raise exception.ServiceNotFound(service_id=service_id)\n        return {'OS-KSADM:service': service_ref}\n\n    def delete_service(self, context, service_id):\n        service_ref = self.catalog_api.get_service(context, service_id)\n        if not service_ref:\n            raise exception.ServiceNotFound(service_id=service_id)\n        self.catalog_api.delete_service(context, service_id)\n\n    def create_service(self, context, OS_KSADM_service):\n        service_id = uuid.uuid4().hex\n        service_ref = OS_KSADM_service.copy()\n        service_ref['id'] = service_id\n        new_service_ref = self.catalog_api.create_service(\n                context, service_id, service_ref)\n        return {'OS-KSADM:service': new_service_ref}\n\n\nclass EndpointController(wsgi.Application):\n    def __init__(self):\n        self.catalog_api = Manager()\n        self.identity_api = identity.Manager()\n        self.policy_api = policy.Manager()\n        self.token_api = token.Manager()\n        super(EndpointController, self).__init__()\n\n    def get_endpoints(self, context):\n        self.assert_admin(context)\n        endpoint_list = self.catalog_api.list_endpoints(context)\n        endpoint_refs = [self.catalog_api.get_endpoint(context, e)\n                         for e in endpoint_list]\n        return {'endpoints': endpoint_refs}\n\n    def create_endpoint(self, context, endpoint):\n        self.assert_admin(context)\n        endpoint_id = uuid.uuid4().hex\n        endpoint_ref = endpoint.copy()\n        endpoint_ref['id'] = endpoint_id\n\n        service_id = endpoint_ref['service_id']\n        if not self.catalog_api.get_service(context, service_id):\n            raise exception.ServiceNotFound(service_id=service_id)\n\n        new_endpoint_ref = self.catalog_api.create_endpoint(\n                                context, endpoint_id, endpoint_ref)\n        return {'endpoint': new_endpoint_ref}\n\n    def delete_endpoint(self, context, endpoint_id):\n        self.assert_admin(context)\n        self.catalog_api.delete_endpoint(context, endpoint_id)\n", "target": 1}
{"idx": 896, "func": "# vim: ft=python fileencoding=utf-8 sts=4 sw=4 et:\n\n# Copyright 2016-2019 Florian Bruhin (The Compiler) <mail@qutebrowser.org>\n#\n# This file is part of qutebrowser.\n#\n# qutebrowser is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# qutebrowser is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with qutebrowser.  If not, see <http://www.gnu.org/licenses/>.\n\n\"\"\"Base class for a wrapper over QWebView/QWebEngineView.\"\"\"\n\nimport enum\nimport itertools\nimport typing\n\nimport attr\nfrom PyQt5.QtCore import (pyqtSignal, pyqtSlot, QUrl, QObject, QSizeF, Qt,\n                          QEvent, QPoint)\nfrom PyQt5.QtGui import QKeyEvent, QIcon\nfrom PyQt5.QtWidgets import QWidget, QApplication, QDialog\nfrom PyQt5.QtPrintSupport import QPrintDialog, QPrinter\nfrom PyQt5.QtNetwork import QNetworkAccessManager\n\nimport pygments\nimport pygments.lexers\nimport pygments.formatters\n\nfrom qutebrowser.keyinput import modeman\nfrom qutebrowser.config import config\nfrom qutebrowser.utils import (utils, objreg, usertypes, log, qtutils,\n                               urlutils, message)\nfrom qutebrowser.misc import miscwidgets, objects\nfrom qutebrowser.browser import eventfilter, hints\nfrom qutebrowser.qt import sip\n\nif typing.TYPE_CHECKING:\n    # pylint: disable=unused-import,useless-suppression\n    from qutebrowser.browser import webelem\n    from qutebrowser.browser.inspector import AbstractWebInspector\n\n\ntab_id_gen = itertools.count(0)\n\n\ndef create(win_id: int,\n           private: bool,\n           parent: QWidget = None) -> 'AbstractTab':\n    \"\"\"Get a QtWebKit/QtWebEngine tab object.\n\n    Args:\n        win_id: The window ID where the tab will be shown.\n        private: Whether the tab is a private/off the record tab.\n        parent: The Qt parent to set.\n    \"\"\"\n    # Importing modules here so we don't depend on QtWebEngine without the\n    # argument and to avoid circular imports.\n    mode_manager = modeman.instance(win_id)\n    if objects.backend == usertypes.Backend.QtWebEngine:\n        from qutebrowser.browser.webengine import webenginetab\n        tab_class = webenginetab.WebEngineTab\n    else:\n        from qutebrowser.browser.webkit import webkittab\n        tab_class = webkittab.WebKitTab\n    return tab_class(win_id=win_id, mode_manager=mode_manager, private=private,\n                     parent=parent)\n\n\ndef init() -> None:\n    \"\"\"Initialize backend-specific modules.\"\"\"\n    if objects.backend == usertypes.Backend.QtWebEngine:\n        from qutebrowser.browser.webengine import webenginetab\n        webenginetab.init()\n\n\nclass WebTabError(Exception):\n\n    \"\"\"Base class for various errors.\"\"\"\n\n\nclass UnsupportedOperationError(WebTabError):\n\n    \"\"\"Raised when an operation is not supported with the given backend.\"\"\"\n\n\nTerminationStatus = enum.Enum('TerminationStatus', [\n    'normal',\n    'abnormal',  # non-zero exit status\n    'crashed',   # e.g. segfault\n    'killed',\n    'unknown',\n])\n\n\n@attr.s\nclass TabData:\n\n    \"\"\"A simple namespace with a fixed set of attributes.\n\n    Attributes:\n        keep_icon: Whether the (e.g. cloned) icon should not be cleared on page\n                   load.\n        inspector: The QWebInspector used for this webview.\n        viewing_source: Set if we're currently showing a source view.\n                        Only used when sources are shown via pygments.\n        open_target: Where to open the next link.\n                     Only used for QtWebKit.\n        override_target: Override for open_target for fake clicks (like hints).\n                         Only used for QtWebKit.\n        pinned: Flag to pin the tab.\n        fullscreen: Whether the tab has a video shown fullscreen currently.\n        netrc_used: Whether netrc authentication was performed.\n        input_mode: current input mode for the tab.\n    \"\"\"\n\n    keep_icon = attr.ib(False)  # type: bool\n    viewing_source = attr.ib(False)  # type: bool\n    inspector = attr.ib(None)  # type: typing.Optional[AbstractWebInspector]\n    open_target = attr.ib(\n        usertypes.ClickTarget.normal)  # type: usertypes.ClickTarget\n    override_target = attr.ib(None)  # type: usertypes.ClickTarget\n    pinned = attr.ib(False)  # type: bool\n    fullscreen = attr.ib(False)  # type: bool\n    netrc_used = attr.ib(False)  # type: bool\n    input_mode = attr.ib(usertypes.KeyMode.normal)  # type: usertypes.KeyMode\n\n    def should_show_icon(self) -> bool:\n        return (config.val.tabs.favicons.show == 'always' or\n                config.val.tabs.favicons.show == 'pinned' and self.pinned)\n\n\nclass AbstractAction:\n\n    \"\"\"Attribute ``action`` of AbstractTab for Qt WebActions.\"\"\"\n\n    # The class actions are defined on (QWeb{Engine,}Page)\n    action_class = None  # type: type\n    # The type of the actions (QWeb{Engine,}Page.WebAction)\n    action_base = None  # type: type\n\n    def __init__(self, tab: 'AbstractTab') -> None:\n        self._widget = typing.cast(QWidget, None)\n        self._tab = tab\n\n    def exit_fullscreen(self) -> None:\n        \"\"\"Exit the fullscreen mode.\"\"\"\n        raise NotImplementedError\n\n    def save_page(self) -> None:\n        \"\"\"Save the current page.\"\"\"\n        raise NotImplementedError\n\n    def run_string(self, name: str) -> None:\n        \"\"\"Run a webaction based on its name.\"\"\"\n        member = getattr(self.action_class, name, None)\n        if not isinstance(member, self.action_base):\n            raise WebTabError(\"{} is not a valid web action!\".format(name))\n        self._widget.triggerPageAction(member)\n\n    def show_source(\n            self,\n            pygments: bool = False  # pylint: disable=redefined-outer-name\n    ) -> None:\n        \"\"\"Show the source of the current page in a new tab.\"\"\"\n        raise NotImplementedError\n\n    def _show_source_pygments(self) -> None:\n\n        def show_source_cb(source: str) -> None:\n            \"\"\"Show source as soon as it's ready.\"\"\"\n            # WORKAROUND for https://github.com/PyCQA/pylint/issues/491\n            # pylint: disable=no-member\n            lexer = pygments.lexers.HtmlLexer()\n            formatter = pygments.formatters.HtmlFormatter(\n                full=True, linenos='table')\n            # pylint: enable=no-member\n            highlighted = pygments.highlight(source, lexer, formatter)\n\n            tb = objreg.get('tabbed-browser', scope='window',\n                            window=self._tab.win_id)\n            new_tab = tb.tabopen(background=False, related=True)\n            new_tab.set_html(highlighted, self._tab.url())\n            new_tab.data.viewing_source = True\n\n        self._tab.dump_async(show_source_cb)\n\n\nclass AbstractPrinting:\n\n    \"\"\"Attribute ``printing`` of AbstractTab for printing the page.\"\"\"\n\n    def __init__(self, tab: 'AbstractTab') -> None:\n        self._widget = None\n        self._tab = tab\n\n    def check_pdf_support(self) -> None:\n        \"\"\"Check whether writing to PDFs is supported.\n\n        If it's not supported (by the current Qt version), a WebTabError is\n        raised.\n        \"\"\"\n        raise NotImplementedError\n\n    def check_printer_support(self) -> None:\n        \"\"\"Check whether writing to a printer is supported.\n\n        If it's not supported (by the current Qt version), a WebTabError is\n        raised.\n        \"\"\"\n        raise NotImplementedError\n\n    def check_preview_support(self) -> None:\n        \"\"\"Check whether showing a print preview is supported.\n\n        If it's not supported (by the current Qt version), a WebTabError is\n        raised.\n        \"\"\"\n        raise NotImplementedError\n\n    def to_pdf(self, filename: str) -> bool:\n        \"\"\"Print the tab to a PDF with the given filename.\"\"\"\n        raise NotImplementedError\n\n    def to_printer(self, printer: QPrinter,\n                   callback: typing.Callable[[bool], None] = None) -> None:\n        \"\"\"Print the tab.\n\n        Args:\n            printer: The QPrinter to print to.\n            callback: Called with a boolean\n                      (True if printing succeeded, False otherwise)\n        \"\"\"\n        raise NotImplementedError\n\n    def show_dialog(self) -> None:\n        \"\"\"Print with a QPrintDialog.\"\"\"\n        self.check_printer_support()\n\n        def print_callback(ok: bool) -> None:\n            \"\"\"Called when printing finished.\"\"\"\n            if not ok:\n                message.error(\"Printing failed!\")\n            diag.deleteLater()\n\n        def do_print() -> None:\n            \"\"\"Called when the dialog was closed.\"\"\"\n            self.to_printer(diag.printer(), print_callback)\n\n        diag = QPrintDialog(self._tab)\n        if utils.is_mac:\n            # For some reason we get a segfault when using open() on macOS\n            ret = diag.exec_()\n            if ret == QDialog.Accepted:\n                do_print()\n        else:\n            diag.open(do_print)\n\n\nclass AbstractSearch(QObject):\n\n    \"\"\"Attribute ``search`` of AbstractTab for doing searches.\n\n    Attributes:\n        text: The last thing this view was searched for.\n        search_displayed: Whether we're currently displaying search results in\n                          this view.\n        _flags: The flags of the last search (needs to be set by subclasses).\n        _widget: The underlying WebView widget.\n    \"\"\"\n\n    #: Signal emitted when a search was finished\n    #: (True if the text was found, False otherwise)\n    finished = pyqtSignal(bool)\n    #: Signal emitted when an existing search was cleared.\n    cleared = pyqtSignal()\n\n    _Callback = typing.Callable[[bool], None]\n\n    def __init__(self, tab: 'AbstractTab', parent: QWidget = None):\n        super().__init__(parent)\n        self._tab = tab\n        self._widget = None\n        self.text = None  # type: typing.Optional[str]\n        self.search_displayed = False\n\n    def _is_case_sensitive(self, ignore_case: usertypes.IgnoreCase) -> bool:\n        \"\"\"Check if case-sensitivity should be used.\n\n        This assumes self.text is already set properly.\n\n        Arguments:\n            ignore_case: The ignore_case value from the config.\n        \"\"\"\n        assert self.text is not None\n        mapping = {\n            usertypes.IgnoreCase.smart: not self.text.islower(),\n            usertypes.IgnoreCase.never: True,\n            usertypes.IgnoreCase.always: False,\n        }\n        return mapping[ignore_case]\n\n    def search(self, text: str, *,\n               ignore_case: usertypes.IgnoreCase = usertypes.IgnoreCase.never,\n               reverse: bool = False,\n               result_cb: _Callback = None) -> None:\n        \"\"\"Find the given text on the page.\n\n        Args:\n            text: The text to search for.\n            ignore_case: Search case-insensitively.\n            reverse: Reverse search direction.\n            result_cb: Called with a bool indicating whether a match was found.\n        \"\"\"\n        raise NotImplementedError\n\n    def clear(self) -> None:\n        \"\"\"Clear the current search.\"\"\"\n        raise NotImplementedError\n\n    def prev_result(self, *, result_cb: _Callback = None) -> None:\n        \"\"\"Go to the previous result of the current search.\n\n        Args:\n            result_cb: Called with a bool indicating whether a match was found.\n        \"\"\"\n        raise NotImplementedError\n\n    def next_result(self, *, result_cb: _Callback = None) -> None:\n        \"\"\"Go to the next result of the current search.\n\n        Args:\n            result_cb: Called with a bool indicating whether a match was found.\n        \"\"\"\n        raise NotImplementedError\n\n\nclass AbstractZoom(QObject):\n\n    \"\"\"Attribute ``zoom`` of AbstractTab for controlling zoom.\"\"\"\n\n    def __init__(self, tab: 'AbstractTab', parent: QWidget = None) -> None:\n        super().__init__(parent)\n        self._tab = tab\n        self._widget = None\n        # Whether zoom was changed from the default.\n        self._default_zoom_changed = False\n        self._init_neighborlist()\n        config.instance.changed.connect(self._on_config_changed)\n        self._zoom_factor = float(config.val.zoom.default) / 100\n\n    @pyqtSlot(str)\n    def _on_config_changed(self, option: str) -> None:\n        if option in ['zoom.levels', 'zoom.default']:\n            if not self._default_zoom_changed:\n                factor = float(config.val.zoom.default) / 100\n                self.set_factor(factor)\n            self._init_neighborlist()\n\n    def _init_neighborlist(self) -> None:\n        \"\"\"Initialize self._neighborlist.\n\n        It is a NeighborList with the zoom levels.\"\"\"\n        levels = config.val.zoom.levels\n        self._neighborlist = usertypes.NeighborList(\n            levels, mode=usertypes.NeighborList.Modes.edge)\n        self._neighborlist.fuzzyval = config.val.zoom.default\n\n    def apply_offset(self, offset: int) -> None:\n        \"\"\"Increase/Decrease the zoom level by the given offset.\n\n        Args:\n            offset: The offset in the zoom level list.\n\n        Return:\n            The new zoom percentage.\n        \"\"\"\n        level = self._neighborlist.getitem(offset)\n        self.set_factor(float(level) / 100, fuzzyval=False)\n        return level\n\n    def _set_factor_internal(self, factor: float) -> None:\n        raise NotImplementedError\n\n    def set_factor(self, factor: float, *, fuzzyval: bool = True) -> None:\n        \"\"\"Zoom to a given zoom factor.\n\n        Args:\n            factor: The zoom factor as float.\n            fuzzyval: Whether to set the NeighborLists fuzzyval.\n        \"\"\"\n        if fuzzyval:\n            self._neighborlist.fuzzyval = int(factor * 100)\n        if factor < 0:\n            raise ValueError(\"Can't zoom to factor {}!\".format(factor))\n\n        default_zoom_factor = float(config.val.zoom.default) / 100\n        self._default_zoom_changed = (factor != default_zoom_factor)\n\n        self._zoom_factor = factor\n        self._set_factor_internal(factor)\n\n    def factor(self) -> float:\n        return self._zoom_factor\n\n    def apply_default(self) -> None:\n        self._set_factor_internal(float(config.val.zoom.default) / 100)\n\n    def reapply(self) -> None:\n        self._set_factor_internal(self._zoom_factor)\n\n\nclass AbstractCaret(QObject):\n\n    \"\"\"Attribute ``caret`` of AbstractTab for caret browsing.\"\"\"\n\n    #: Signal emitted when the selection was toggled.\n    #: (argument - whether the selection is now active)\n    selection_toggled = pyqtSignal(bool)\n    #: Emitted when a ``follow_selection`` action is done.\n    follow_selected_done = pyqtSignal()\n\n    def __init__(self,\n                 tab: 'AbstractTab',\n                 mode_manager: modeman.ModeManager,\n                 parent: QWidget = None) -> None:\n        super().__init__(parent)\n        self._tab = tab\n        self._widget = None\n        self.selection_enabled = False\n        self._mode_manager = mode_manager\n        mode_manager.entered.connect(self._on_mode_entered)\n        mode_manager.left.connect(self._on_mode_left)\n\n    def _on_mode_entered(self, mode: usertypes.KeyMode) -> None:\n        raise NotImplementedError\n\n    def _on_mode_left(self, mode: usertypes.KeyMode) -> None:\n        raise NotImplementedError\n\n    def move_to_next_line(self, count: int = 1) -> None:\n        raise NotImplementedError\n\n    def move_to_prev_line(self, count: int = 1) -> None:\n        raise NotImplementedError\n\n    def move_to_next_char(self, count: int = 1) -> None:\n        raise NotImplementedError\n\n    def move_to_prev_char(self, count: int = 1) -> None:\n        raise NotImplementedError\n\n    def move_to_end_of_word(self, count: int = 1) -> None:\n        raise NotImplementedError\n\n    def move_to_next_word(self, count: int = 1) -> None:\n        raise NotImplementedError\n\n    def move_to_prev_word(self, count: int = 1) -> None:\n        raise NotImplementedError\n\n    def move_to_start_of_line(self) -> None:\n        raise NotImplementedError\n\n    def move_to_end_of_line(self) -> None:\n        raise NotImplementedError\n\n    def move_to_start_of_next_block(self, count: int = 1) -> None:\n        raise NotImplementedError\n\n    def move_to_start_of_prev_block(self, count: int = 1) -> None:\n        raise NotImplementedError\n\n    def move_to_end_of_next_block(self, count: int = 1) -> None:\n        raise NotImplementedError\n\n    def move_to_end_of_prev_block(self, count: int = 1) -> None:\n        raise NotImplementedError\n\n    def move_to_start_of_document(self) -> None:\n        raise NotImplementedError\n\n    def move_to_end_of_document(self) -> None:\n        raise NotImplementedError\n\n    def toggle_selection(self) -> None:\n        raise NotImplementedError\n\n    def drop_selection(self) -> None:\n        raise NotImplementedError\n\n    def selection(self, callback: typing.Callable[[str], None]) -> None:\n        raise NotImplementedError\n\n    def reverse_selection(self) -> None:\n        raise NotImplementedError\n\n    def _follow_enter(self, tab: bool) -> None:\n        \"\"\"Follow a link by faking an enter press.\"\"\"\n        if tab:\n            self._tab.fake_key_press(Qt.Key_Enter, modifier=Qt.ControlModifier)\n        else:\n            self._tab.fake_key_press(Qt.Key_Enter)\n\n    def follow_selected(self, *, tab: bool = False) -> None:\n        raise NotImplementedError\n\n\nclass AbstractScroller(QObject):\n\n    \"\"\"Attribute ``scroller`` of AbstractTab to manage scroll position.\"\"\"\n\n    #: Signal emitted when the scroll position changed (int, int)\n    perc_changed = pyqtSignal(int, int)\n    #: Signal emitted before the user requested a jump.\n    #: Used to set the special ' mark so the user can return.\n    before_jump_requested = pyqtSignal()\n\n    def __init__(self, tab: 'AbstractTab', parent: QWidget = None):\n        super().__init__(parent)\n        self._tab = tab\n        self._widget = None  # type: typing.Optional[QWidget]\n        if 'log-scroll-pos' in objects.debug_flags:\n            self.perc_changed.connect(self._log_scroll_pos_change)\n\n    @pyqtSlot()\n    def _log_scroll_pos_change(self) -> None:\n        log.webview.vdebug(  # type: ignore\n            \"Scroll position changed to {}\".format(self.pos_px()))\n\n    def _init_widget(self, widget: QWidget) -> None:\n        self._widget = widget\n\n    def pos_px(self) -> int:\n        raise NotImplementedError\n\n    def pos_perc(self) -> int:\n        raise NotImplementedError\n\n    def to_perc(self, x: int = None, y: int = None) -> None:\n        raise NotImplementedError\n\n    def to_point(self, point: QPoint) -> None:\n        raise NotImplementedError\n\n    def to_anchor(self, name: str) -> None:\n        raise NotImplementedError\n\n    def delta(self, x: int = 0, y: int = 0) -> None:\n        raise NotImplementedError\n\n    def delta_page(self, x: float = 0, y: float = 0) -> None:\n        raise NotImplementedError\n\n    def up(self, count: int = 1) -> None:\n        raise NotImplementedError\n\n    def down(self, count: int = 1) -> None:\n        raise NotImplementedError\n\n    def left(self, count: int = 1) -> None:\n        raise NotImplementedError\n\n    def right(self, count: int = 1) -> None:\n        raise NotImplementedError\n\n    def top(self) -> None:\n        raise NotImplementedError\n\n    def bottom(self) -> None:\n        raise NotImplementedError\n\n    def page_up(self, count: int = 1) -> None:\n        raise NotImplementedError\n\n    def page_down(self, count: int = 1) -> None:\n        raise NotImplementedError\n\n    def at_top(self) -> bool:\n        raise NotImplementedError\n\n    def at_bottom(self) -> bool:\n        raise NotImplementedError\n\n\nclass AbstractHistoryPrivate:\n\n    \"\"\"Private API related to the history.\"\"\"\n\n    def __init__(self, tab: 'AbstractTab'):\n        self._tab = tab\n        self._history = None\n\n    def serialize(self) -> bytes:\n        \"\"\"Serialize into an opaque format understood by self.deserialize.\"\"\"\n        raise NotImplementedError\n\n    def deserialize(self, data: bytes) -> None:\n        \"\"\"Deserialize from a format produced by self.serialize.\"\"\"\n        raise NotImplementedError\n\n    def load_items(self, items: typing.Sequence) -> None:\n        \"\"\"Deserialize from a list of WebHistoryItems.\"\"\"\n        raise NotImplementedError\n\n\nclass AbstractHistory:\n\n    \"\"\"The history attribute of a AbstractTab.\"\"\"\n\n    def __init__(self, tab: 'AbstractTab') -> None:\n        self._tab = tab\n        self._history = None\n        self.private_api = AbstractHistoryPrivate(tab)\n\n    def __len__(self) -> int:\n        raise NotImplementedError\n\n    def __iter__(self) -> typing.Iterable:\n        raise NotImplementedError\n\n    def _check_count(self, count: int) -> None:\n        \"\"\"Check whether the count is positive.\"\"\"\n        if count < 0:\n            raise WebTabError(\"count needs to be positive!\")\n\n    def current_idx(self) -> int:\n        raise NotImplementedError\n\n    def back(self, count: int = 1) -> None:\n        \"\"\"Go back in the tab's history.\"\"\"\n        self._check_count(count)\n        idx = self.current_idx() - count\n        if idx >= 0:\n            self._go_to_item(self._item_at(idx))\n        else:\n            self._go_to_item(self._item_at(0))\n            raise WebTabError(\"At beginning of history.\")\n\n    def forward(self, count: int = 1) -> None:\n        \"\"\"Go forward in the tab's history.\"\"\"\n        self._check_count(count)\n        idx = self.current_idx() + count\n        if idx < len(self):\n            self._go_to_item(self._item_at(idx))\n        else:\n            self._go_to_item(self._item_at(len(self) - 1))\n            raise WebTabError(\"At end of history.\")\n\n    def can_go_back(self) -> bool:\n        raise NotImplementedError\n\n    def can_go_forward(self) -> bool:\n        raise NotImplementedError\n\n    def _item_at(self, i: int) -> typing.Any:\n        raise NotImplementedError\n\n    def _go_to_item(self, item: typing.Any) -> None:\n        raise NotImplementedError\n\n\nclass AbstractElements:\n\n    \"\"\"Finding and handling of elements on the page.\"\"\"\n\n    _MultiCallback = typing.Callable[\n        [typing.Sequence['webelem.AbstractWebElement']], None]\n    _SingleCallback = typing.Callable[\n        [typing.Optional['webelem.AbstractWebElement']], None]\n    _ErrorCallback = typing.Callable[[Exception], None]\n\n    def __init__(self, tab: 'AbstractTab') -> None:\n        self._widget = None\n        self._tab = tab\n\n    def find_css(self, selector: str,\n                 callback: _MultiCallback,\n                 error_cb: _ErrorCallback, *,\n                 only_visible: bool = False) -> None:\n        \"\"\"Find all HTML elements matching a given selector async.\n\n        If there's an error, the callback is called with a webelem.Error\n        instance.\n\n        Args:\n            callback: The callback to be called when the search finished.\n            error_cb: The callback to be called when an error occurred.\n            selector: The CSS selector to search for.\n            only_visible: Only show elements which are visible on screen.\n        \"\"\"\n        raise NotImplementedError\n\n    def find_id(self, elem_id: str, callback: _SingleCallback) -> None:\n        \"\"\"Find the HTML element with the given ID async.\n\n        Args:\n            callback: The callback to be called when the search finished.\n                      Called with a WebEngineElement or None.\n            elem_id: The ID to search for.\n        \"\"\"\n        raise NotImplementedError\n\n    def find_focused(self, callback: _SingleCallback) -> None:\n        \"\"\"Find the focused element on the page async.\n\n        Args:\n            callback: The callback to be called when the search finished.\n                      Called with a WebEngineElement or None.\n        \"\"\"\n        raise NotImplementedError\n\n    def find_at_pos(self, pos: QPoint, callback: _SingleCallback) -> None:\n        \"\"\"Find the element at the given position async.\n\n        This is also called \"hit test\" elsewhere.\n\n        Args:\n            pos: The QPoint to get the element for.\n            callback: The callback to be called when the search finished.\n                      Called with a WebEngineElement or None.\n        \"\"\"\n        raise NotImplementedError\n\n\nclass AbstractAudio(QObject):\n\n    \"\"\"Handling of audio/muting for this tab.\"\"\"\n\n    muted_changed = pyqtSignal(bool)\n    recently_audible_changed = pyqtSignal(bool)\n\n    def __init__(self, tab: 'AbstractTab', parent: QWidget = None) -> None:\n        super().__init__(parent)\n        self._widget = None  # type: typing.Optional[QWidget]\n        self._tab = tab\n\n    def set_muted(self, muted: bool, override: bool = False) -> None:\n        \"\"\"Set this tab as muted or not.\n\n        Arguments:\n            override: If set to True, muting/unmuting was done manually and\n                      overrides future automatic mute/unmute changes based on\n                      the URL.\n        \"\"\"\n        raise NotImplementedError\n\n    def is_muted(self) -> bool:\n        raise NotImplementedError\n\n    def is_recently_audible(self) -> bool:\n        \"\"\"Whether this tab has had audio playing recently.\"\"\"\n        raise NotImplementedError\n\n\nclass AbstractTabPrivate:\n\n    \"\"\"Tab-related methods which are only needed in the core.\n\n    Those methods are not part of the API which is exposed to extensions, and\n    should ideally be removed at some point in the future.\n    \"\"\"\n\n    def __init__(self, mode_manager: modeman.ModeManager,\n                 tab: 'AbstractTab') -> None:\n        self._widget = None  # type: typing.Optional[QWidget]\n        self._tab = tab\n        self._mode_manager = mode_manager\n\n    def event_target(self) -> QWidget:\n        \"\"\"Return the widget events should be sent to.\"\"\"\n        raise NotImplementedError\n\n    def handle_auto_insert_mode(self, ok: bool) -> None:\n        \"\"\"Handle `input.insert_mode.auto_load` after loading finished.\"\"\"\n        if not ok or not config.cache['input.insert_mode.auto_load']:\n            return\n\n        cur_mode = self._mode_manager.mode\n        if cur_mode == usertypes.KeyMode.insert:\n            return\n\n        def _auto_insert_mode_cb(\n                elem: typing.Optional['webelem.AbstractWebElement']\n        ) -> None:\n            \"\"\"Called from JS after finding the focused element.\"\"\"\n            if elem is None:\n                log.webview.debug(\"No focused element!\")\n                return\n            if elem.is_editable():\n                modeman.enter(self._tab.win_id, usertypes.KeyMode.insert,\n                              'load finished', only_if_normal=True)\n\n        self._tab.elements.find_focused(_auto_insert_mode_cb)\n\n    def clear_ssl_errors(self) -> None:\n        raise NotImplementedError\n\n    def networkaccessmanager(self) -> typing.Optional[QNetworkAccessManager]:\n        \"\"\"Get the QNetworkAccessManager for this tab.\n\n        This is only implemented for QtWebKit.\n        For QtWebEngine, always returns None.\n        \"\"\"\n        raise NotImplementedError\n\n    def user_agent(self) -> typing.Optional[str]:\n        \"\"\"Get the user agent for this tab.\n\n        This is only implemented for QtWebKit.\n        For QtWebEngine, always returns None.\n        \"\"\"\n        raise NotImplementedError\n\n    def shutdown(self) -> None:\n        raise NotImplementedError\n\n\nclass AbstractTab(QWidget):\n\n    \"\"\"An adapter for QWebView/QWebEngineView representing a single tab.\"\"\"\n\n    #: Signal emitted when a website requests to close this tab.\n    window_close_requested = pyqtSignal()\n    #: Signal emitted when a link is hovered (the hover text)\n    link_hovered = pyqtSignal(str)\n    #: Signal emitted when a page started loading\n    load_started = pyqtSignal()\n    #: Signal emitted when a page is loading (progress percentage)\n    load_progress = pyqtSignal(int)\n    #: Signal emitted when a page finished loading (success as bool)\n    load_finished = pyqtSignal(bool)\n    #: Signal emitted when a page's favicon changed (icon as QIcon)\n    icon_changed = pyqtSignal(QIcon)\n    #: Signal emitted when a page's title changed (new title as str)\n    title_changed = pyqtSignal(str)\n    #: Signal emitted when a new tab should be opened (url as QUrl)\n    new_tab_requested = pyqtSignal(QUrl)\n    #: Signal emitted when a page's URL changed (url as QUrl)\n    url_changed = pyqtSignal(QUrl)\n    #: Signal emitted when a tab's content size changed\n    #: (new size as QSizeF)\n    contents_size_changed = pyqtSignal(QSizeF)\n    #: Signal emitted when a page requested full-screen (bool)\n    fullscreen_requested = pyqtSignal(bool)\n    #: Signal emitted before load starts (URL as QUrl)\n    before_load_started = pyqtSignal(QUrl)\n\n    # Signal emitted when a page's load status changed\n    # (argument: usertypes.LoadStatus)\n    load_status_changed = pyqtSignal(usertypes.LoadStatus)\n    # Signal emitted before shutting down\n    shutting_down = pyqtSignal()\n    # Signal emitted when a history item should be added\n    history_item_triggered = pyqtSignal(QUrl, QUrl, str)\n    # Signal emitted when the underlying renderer process terminated.\n    # arg 0: A TerminationStatus member.\n    # arg 1: The exit code.\n    renderer_process_terminated = pyqtSignal(TerminationStatus, int)\n\n    def __init__(self, *, win_id: int, private: bool,\n                 parent: QWidget = None) -> None:\n        self.is_private = private\n        self.win_id = win_id\n        self.tab_id = next(tab_id_gen)\n        super().__init__(parent)\n\n        self.registry = objreg.ObjectRegistry()\n        tab_registry = objreg.get('tab-registry', scope='window',\n                                  window=win_id)\n        tab_registry[self.tab_id] = self\n        objreg.register('tab', self, registry=self.registry)\n\n        self.data = TabData()\n        self._layout = miscwidgets.WrapperLayout(self)\n        self._widget = None  # type: typing.Optional[QWidget]\n        self._progress = 0\n        self._has_ssl_errors = False\n        self._load_status = usertypes.LoadStatus.none\n        self._tab_event_filter = eventfilter.TabEventFilter(\n            self, parent=self)\n        self.backend = None\n\n        # FIXME:qtwebengine  Should this be public api via self.hints?\n        #                    Also, should we get it out of objreg?\n        hintmanager = hints.HintManager(win_id, self.tab_id, parent=self)\n        objreg.register('hintmanager', hintmanager, scope='tab',\n                        window=self.win_id, tab=self.tab_id)\n\n        self.before_load_started.connect(self._on_before_load_started)\n\n    def _set_widget(self, widget: QWidget) -> None:\n        # pylint: disable=protected-access\n        self._widget = widget\n        self._layout.wrap(self, widget)\n        self.history._history = widget.history()\n        self.history.private_api._history = widget.history()\n        self.scroller._init_widget(widget)\n        self.caret._widget = widget\n        self.zoom._widget = widget\n        self.search._widget = widget\n        self.printing._widget = widget\n        self.action._widget = widget\n        self.elements._widget = widget\n        self.audio._widget = widget\n        self.private_api._widget = widget\n        self.settings._settings = widget.settings()\n\n        self._install_event_filter()\n        self.zoom.apply_default()\n\n    def _install_event_filter(self) -> None:\n        raise NotImplementedError\n\n    def _set_load_status(self, val: usertypes.LoadStatus) -> None:\n        \"\"\"Setter for load_status.\"\"\"\n        if not isinstance(val, usertypes.LoadStatus):\n            raise TypeError(\"Type {} is no LoadStatus member!\".format(val))\n        log.webview.debug(\"load status for {}: {}\".format(repr(self), val))\n        self._load_status = val\n        self.load_status_changed.emit(val)\n\n    def send_event(self, evt: QEvent) -> None:\n        \"\"\"Send the given event to the underlying widget.\n\n        The event will be sent via QApplication.postEvent.\n        Note that a posted event must not be re-used in any way!\n        \"\"\"\n        # This only gives us some mild protection against re-using events, but\n        # it's certainly better than a segfault.\n        if getattr(evt, 'posted', False):\n            raise utils.Unreachable(\"Can't re-use an event which was already \"\n                                    \"posted!\")\n\n        recipient = self.private_api.event_target()\n        if recipient is None:\n            # https://github.com/qutebrowser/qutebrowser/issues/3888\n            log.webview.warning(\"Unable to find event target!\")\n            return\n\n        evt.posted = True\n        QApplication.postEvent(recipient, evt)\n\n    def navigation_blocked(self) -> bool:\n        \"\"\"Test if navigation is allowed on the current tab.\"\"\"\n        return self.data.pinned and config.val.tabs.pinned.frozen\n\n    @pyqtSlot(QUrl)\n    def _on_before_load_started(self, url: QUrl) -> None:\n        \"\"\"Adjust the title if we are going to visit a URL soon.\"\"\"\n        qtutils.ensure_valid(url)\n        url_string = url.toDisplayString()\n        log.webview.debug(\"Going to start loading: {}\".format(url_string))\n        self.title_changed.emit(url_string)\n\n    @pyqtSlot(QUrl)\n    def _on_url_changed(self, url: QUrl) -> None:\n        \"\"\"Update title when URL has changed and no title is available.\"\"\"\n        if url.isValid() and not self.title():\n            self.title_changed.emit(url.toDisplayString())\n        self.url_changed.emit(url)\n\n    @pyqtSlot()\n    def _on_load_started(self) -> None:\n        self._progress = 0\n        self._has_ssl_errors = False\n        self.data.viewing_source = False\n        self._set_load_status(usertypes.LoadStatus.loading)\n        self.load_started.emit()\n\n    @pyqtSlot(usertypes.NavigationRequest)\n    def _on_navigation_request(\n            self,\n            navigation: usertypes.NavigationRequest\n    ) -> None:\n        \"\"\"Handle common acceptNavigationRequest code.\"\"\"\n        url = utils.elide(navigation.url.toDisplayString(), 100)\n        log.webview.debug(\"navigation request: url {}, type {}, is_main_frame \"\n                          \"{}\".format(url,\n                                      navigation.navigation_type,\n                                      navigation.is_main_frame))\n\n        if not navigation.url.isValid():\n            # Also a WORKAROUND for missing IDNA 2008 support in QUrl, see\n            # https://bugreports.qt.io/browse/QTBUG-60364\n\n            if navigation.navigation_type == navigation.Type.link_clicked:\n                msg = urlutils.get_errstring(navigation.url,\n                                             \"Invalid link clicked\")\n                message.error(msg)\n                self.data.open_target = usertypes.ClickTarget.normal\n\n            log.webview.debug(\"Ignoring invalid URL {} in \"\n                              \"acceptNavigationRequest: {}\".format(\n                                  navigation.url.toDisplayString(),\n                                  navigation.url.errorString()))\n            navigation.accepted = False\n\n    @pyqtSlot(bool)\n    def _on_load_finished(self, ok: bool) -> None:\n        assert self._widget is not None\n        if sip.isdeleted(self._widget):\n            # https://github.com/qutebrowser/qutebrowser/issues/3498\n            return\n\n        try:\n            sess_manager = objreg.get('session-manager')\n        except KeyError:\n            # https://github.com/qutebrowser/qutebrowser/issues/4311\n            return\n\n        sess_manager.save_autosave()\n        self.load_finished.emit(ok)\n\n        if not self.title():\n            self.title_changed.emit(self.url().toDisplayString())\n\n        self.zoom.reapply()\n\n    def _update_load_status(self, ok: bool) -> None:\n        \"\"\"Update the load status after a page finished loading.\n\n        Needs to be called by subclasses to trigger a load status update, e.g.\n        as a response to a loadFinished signal.\n        \"\"\"\n        if ok and not self._has_ssl_errors:\n            if self.url().scheme() == 'https':\n                self._set_load_status(usertypes.LoadStatus.success_https)\n            else:\n                self._set_load_status(usertypes.LoadStatus.success)\n        elif ok:\n            self._set_load_status(usertypes.LoadStatus.warn)\n        else:\n            self._set_load_status(usertypes.LoadStatus.error)\n\n    @pyqtSlot()\n    def _on_history_trigger(self) -> None:\n        \"\"\"Emit history_item_triggered based on backend-specific signal.\"\"\"\n        raise NotImplementedError\n\n    @pyqtSlot(int)\n    def _on_load_progress(self, perc: int) -> None:\n        self._progress = perc\n        self.load_progress.emit(perc)\n\n    def url(self, *, requested: bool = False) -> QUrl:\n        raise NotImplementedError\n\n    def progress(self) -> int:\n        return self._progress\n\n    def load_status(self) -> usertypes.LoadStatus:\n        return self._load_status\n\n    def _load_url_prepare(self, url: QUrl, *,\n                          emit_before_load_started: bool = True) -> None:\n        qtutils.ensure_valid(url)\n        if emit_before_load_started:\n            self.before_load_started.emit(url)\n\n    def load_url(self, url: QUrl, *,\n                 emit_before_load_started: bool = True) -> None:\n        raise NotImplementedError\n\n    def reload(self, *, force: bool = False) -> None:\n        raise NotImplementedError\n\n    def stop(self) -> None:\n        raise NotImplementedError\n\n    def fake_key_press(self,\n                       key: Qt.Key,\n                       modifier: Qt.KeyboardModifier = Qt.NoModifier) -> None:\n        \"\"\"Send a fake key event to this tab.\"\"\"\n        press_evt = QKeyEvent(QEvent.KeyPress, key, modifier, 0, 0, 0)\n        release_evt = QKeyEvent(QEvent.KeyRelease, key, modifier,\n                                0, 0, 0)\n        self.send_event(press_evt)\n        self.send_event(release_evt)\n\n    def dump_async(self,\n                   callback: typing.Callable[[str], None], *,\n                   plain: bool = False) -> None:\n        \"\"\"Dump the current page's html asynchronously.\n\n        The given callback will be called with the result when dumping is\n        complete.\n        \"\"\"\n        raise NotImplementedError\n\n    def run_js_async(\n            self,\n            code: str,\n            callback: typing.Callable[[typing.Any], None] = None, *,\n            world: typing.Union[usertypes.JsWorld, int] = None\n    ) -> None:\n        \"\"\"Run javascript async.\n\n        The given callback will be called with the result when running JS is\n        complete.\n\n        Args:\n            code: The javascript code to run.\n            callback: The callback to call with the result, or None.\n            world: A world ID (int or usertypes.JsWorld member) to run the JS\n                   in the main world or in another isolated world.\n        \"\"\"\n        raise NotImplementedError\n\n    def title(self) -> str:\n        raise NotImplementedError\n\n    def icon(self) -> None:\n        raise NotImplementedError\n\n    def set_html(self, html: str, base_url: QUrl = QUrl()) -> None:\n        raise NotImplementedError\n\n    def __repr__(self) -> str:\n        try:\n            qurl = self.url()\n            url = qurl.toDisplayString(QUrl.EncodeUnicode)  # type: ignore\n        except (AttributeError, RuntimeError) as exc:\n            url = '<{}>'.format(exc.__class__.__name__)\n        else:\n            url = utils.elide(url, 100)\n        return utils.get_repr(self, tab_id=self.tab_id, url=url)\n\n    def is_deleted(self) -> bool:\n        assert self._widget is not None\n        return sip.isdeleted(self._widget)\n", "target": 1}
{"idx": 897, "func": "# (c) 2012, Michael DeHaan <michael.dehaan@gmail.com>\n#\n# This file is part of Ansible\n#\n# Ansible is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# Ansible is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.\n\nimport sys\nimport re\nimport os\nimport shlex\nimport yaml\nimport copy\nimport optparse\nimport operator\nfrom ansible import errors\nfrom ansible import __version__\nfrom ansible.utils import template\nfrom ansible.utils.display_functions import *\nfrom ansible.utils.plugins import *\nfrom ansible.callbacks import display\nimport ansible.constants as C\nimport ast\nimport time\nimport StringIO\nimport stat\nimport termios\nimport tty\nimport pipes\nimport random\nimport difflib\nimport warnings\nimport traceback\nimport getpass\nimport sys\nimport json\n\n#import vault\nfrom vault import VaultLib\n\nVERBOSITY=0\n\nMAX_FILE_SIZE_FOR_DIFF=1*1024*1024\n\ntry:\n    import json\nexcept ImportError:\n    import simplejson as json\n\ntry:\n    from hashlib import md5 as _md5\nexcept ImportError:\n    from md5 import md5 as _md5\n\nPASSLIB_AVAILABLE = False\ntry:\n    import passlib.hash\n    PASSLIB_AVAILABLE = True\nexcept:\n    pass\n\nKEYCZAR_AVAILABLE=False\ntry:\n    try:\n        # some versions of pycrypto may not have this?\n        from Crypto.pct_warnings import PowmInsecureWarning\n    except ImportError:\n        PowmInsecureWarning = RuntimeWarning\n\n    with warnings.catch_warnings(record=True) as warning_handler:\n        warnings.simplefilter(\"error\", PowmInsecureWarning)\n        try:\n            import keyczar.errors as key_errors\n            from keyczar.keys import AesKey\n        except PowmInsecureWarning:\n            system_warning(\n                \"The version of gmp you have installed has a known issue regarding \" + \\\n                \"timing vulnerabilities when used with pycrypto. \" + \\\n                \"If possible, you should update it (ie. yum update gmp).\"\n            )\n            warnings.resetwarnings()\n            warnings.simplefilter(\"ignore\")\n            import keyczar.errors as key_errors\n            from keyczar.keys import AesKey\n        KEYCZAR_AVAILABLE=True\nexcept ImportError:\n    pass\n\n###############################################################\n# Abstractions around keyczar\n###############################################################\n\ndef key_for_hostname(hostname):\n    # fireball mode is an implementation of ansible firing up zeromq via SSH\n    # to use no persistent daemons or key management\n\n    if not KEYCZAR_AVAILABLE:\n        raise errors.AnsibleError(\"python-keyczar must be installed on the control machine to use accelerated modes\")\n\n    key_path = os.path.expanduser(C.ACCELERATE_KEYS_DIR)\n    if not os.path.exists(key_path):\n        os.makedirs(key_path, mode=0700)\n        os.chmod(key_path, int(C.ACCELERATE_KEYS_DIR_PERMS, 8))\n    elif not os.path.isdir(key_path):\n        raise errors.AnsibleError('ACCELERATE_KEYS_DIR is not a directory.')\n\n    if stat.S_IMODE(os.stat(key_path).st_mode) != int(C.ACCELERATE_KEYS_DIR_PERMS, 8):\n        raise errors.AnsibleError('Incorrect permissions on the private key directory. Use `chmod 0%o %s` to correct this issue, and make sure any of the keys files contained within that directory are set to 0%o' % (int(C.ACCELERATE_KEYS_DIR_PERMS, 8), C.ACCELERATE_KEYS_DIR, int(C.ACCELERATE_KEYS_FILE_PERMS, 8)))\n\n    key_path = os.path.join(key_path, hostname)\n\n    # use new AES keys every 2 hours, which means fireball must not allow running for longer either\n    if not os.path.exists(key_path) or (time.time() - os.path.getmtime(key_path) > 60*60*2):\n        key = AesKey.Generate()\n        fd = os.open(key_path, os.O_WRONLY | os.O_CREAT, int(C.ACCELERATE_KEYS_FILE_PERMS, 8))\n        fh = os.fdopen(fd, 'w')\n        fh.write(str(key))\n        fh.close()\n        return key\n    else:\n        if stat.S_IMODE(os.stat(key_path).st_mode) != int(C.ACCELERATE_KEYS_FILE_PERMS, 8):\n            raise errors.AnsibleError('Incorrect permissions on the key file for this host. Use `chmod 0%o %s` to correct this issue.' % (int(C.ACCELERATE_KEYS_FILE_PERMS, 8), key_path))\n        fh = open(key_path)\n        key = AesKey.Read(fh.read())\n        fh.close()\n        return key\n\ndef encrypt(key, msg):\n    return key.Encrypt(msg)\n\ndef decrypt(key, msg):\n    try:\n        return key.Decrypt(msg)\n    except key_errors.InvalidSignatureError:\n        raise errors.AnsibleError(\"decryption failed\")\n\n###############################################################\n# UTILITY FUNCTIONS FOR COMMAND LINE TOOLS\n###############################################################\n\ndef err(msg):\n    ''' print an error message to stderr '''\n\n    print >> sys.stderr, msg\n\ndef exit(msg, rc=1):\n    ''' quit with an error to stdout and a failure code '''\n\n    err(msg)\n    sys.exit(rc)\n\ndef jsonify(result, format=False):\n    ''' format JSON output (uncompressed or uncompressed) '''\n\n    if result is None:\n        return \"{}\"\n    result2 = result.copy()\n    for key, value in result2.items():\n        if type(value) is str:\n            result2[key] = value.decode('utf-8', 'ignore')\n    if format:\n        return json.dumps(result2, sort_keys=True, indent=4)\n    else:\n        return json.dumps(result2, sort_keys=True)\n\ndef write_tree_file(tree, hostname, buf):\n    ''' write something into treedir/hostname '''\n\n    # TODO: might be nice to append playbook runs per host in a similar way\n    # in which case, we'd want append mode.\n    path = os.path.join(tree, hostname)\n    fd = open(path, \"w+\")\n    fd.write(buf)\n    fd.close()\n\ndef is_failed(result):\n    ''' is a given JSON result a failed result? '''\n\n    return ((result.get('rc', 0) != 0) or (result.get('failed', False) in [ True, 'True', 'true']))\n\ndef is_changed(result):\n    ''' is a given JSON result a changed result? '''\n\n    return (result.get('changed', False) in [ True, 'True', 'true'])\n\ndef check_conditional(conditional, basedir, inject, fail_on_undefined=False):\n\n    if conditional is None or conditional == '':\n        return True\n\n    if isinstance(conditional, list):\n        for x in conditional:\n            if not check_conditional(x, basedir, inject, fail_on_undefined=fail_on_undefined):\n                return False\n        return True\n\n    if not isinstance(conditional, basestring):\n        return conditional\n\n    conditional = conditional.replace(\"jinja2_compare \",\"\")\n    # allow variable names\n    if conditional in inject and '-' not in str(inject[conditional]):\n        conditional = inject[conditional]\n    conditional = template.template(basedir, conditional, inject, fail_on_undefined=fail_on_undefined)\n    original = str(conditional).replace(\"jinja2_compare \",\"\")\n    # a Jinja2 evaluation that results in something Python can eval!\n    presented = \"{%% if %s %%} True {%% else %%} False {%% endif %%}\" % conditional\n    conditional = template.template(basedir, presented, inject)\n    val = conditional.strip()\n    if val == presented:\n        # the templating failed, meaning most likely a \n        # variable was undefined. If we happened to be \n        # looking for an undefined variable, return True,\n        # otherwise fail\n        if \"is undefined\" in conditional:\n            return True\n        elif \"is defined\" in conditional:\n            return False\n        else:\n            raise errors.AnsibleError(\"error while evaluating conditional: %s\" % original)\n    elif val == \"True\":\n        return True\n    elif val == \"False\":\n        return False\n    else:\n        raise errors.AnsibleError(\"unable to evaluate conditional: %s\" % original)\n\ndef is_executable(path):\n    '''is the given path executable?'''\n    return (stat.S_IXUSR & os.stat(path)[stat.ST_MODE]\n            or stat.S_IXGRP & os.stat(path)[stat.ST_MODE]\n            or stat.S_IXOTH & os.stat(path)[stat.ST_MODE])\n\ndef unfrackpath(path):\n    ''' \n    returns a path that is free of symlinks, environment\n    variables, relative path traversals and symbols (~)\n    example:\n    '$HOME/../../var/mail' becomes '/var/spool/mail'\n    '''\n    return os.path.normpath(os.path.realpath(os.path.expandvars(os.path.expanduser(path))))\n\ndef prepare_writeable_dir(tree,mode=0777):\n    ''' make sure a directory exists and is writeable '''\n\n    # modify the mode to ensure the owner at least\n    # has read/write access to this directory\n    mode |= 0700\n\n    # make sure the tree path is always expanded\n    # and normalized and free of symlinks\n    tree = unfrackpath(tree)\n\n    if not os.path.exists(tree):\n        try:\n            os.makedirs(tree, mode)\n        except (IOError, OSError), e:\n            raise errors.AnsibleError(\"Could not make dir %s: %s\" % (tree, e))\n    if not os.access(tree, os.W_OK):\n        raise errors.AnsibleError(\"Cannot write to path %s\" % tree)\n    return tree\n\ndef path_dwim(basedir, given):\n    '''\n    make relative paths work like folks expect.\n    '''\n\n    if given.startswith(\"/\"):\n        return os.path.abspath(given)\n    elif given.startswith(\"~\"):\n        return os.path.abspath(os.path.expanduser(given))\n    else:\n        if basedir is None:\n            basedir = \".\"\n        return os.path.abspath(os.path.join(basedir, given))\n\ndef path_dwim_relative(original, dirname, source, playbook_base, check=True):\n    ''' find one file in a directory one level up in a dir named dirname relative to current '''\n    # (used by roles code)\n\n    basedir = os.path.dirname(original)\n    if os.path.islink(basedir):\n        basedir = unfrackpath(basedir)\n        template2 = os.path.join(basedir, dirname, source)\n    else:\n        template2 = os.path.join(basedir, '..', dirname, source)\n    source2 = path_dwim(basedir, template2)\n    if os.path.exists(source2):\n        return source2\n    obvious_local_path = path_dwim(playbook_base, source)\n    if os.path.exists(obvious_local_path):\n        return obvious_local_path\n    if check:\n        raise errors.AnsibleError(\"input file not found at %s or %s\" % (source2, obvious_local_path))\n    return source2 # which does not exist\n\ndef json_loads(data):\n    ''' parse a JSON string and return a data structure '''\n\n    return json.loads(data)\n\ndef parse_json(raw_data):\n    ''' this version for module return data only '''\n\n    orig_data = raw_data\n\n    # ignore stuff like tcgetattr spewage or other warnings\n    data = filter_leading_non_json_lines(raw_data)\n\n    try:\n        return json.loads(data)\n    except:\n        # not JSON, but try \"Baby JSON\" which allows many of our modules to not\n        # require JSON and makes writing modules in bash much simpler\n        results = {}\n        try:\n            tokens = shlex.split(data)\n        except:\n            print \"failed to parse json: \"+ data\n            raise\n\n        for t in tokens:\n            if \"=\" not in t:\n                raise errors.AnsibleError(\"failed to parse: %s\" % orig_data)\n            (key,value) = t.split(\"=\", 1)\n            if key == 'changed' or 'failed':\n                if value.lower() in [ 'true', '1' ]:\n                    value = True\n                elif value.lower() in [ 'false', '0' ]:\n                    value = False\n            if key == 'rc':\n                value = int(value)\n            results[key] = value\n        if len(results.keys()) == 0:\n            return { \"failed\" : True, \"parsed\" : False, \"msg\" : orig_data }\n        return results\n\ndef smush_braces(data):\n    ''' smush Jinaj2 braces so unresolved templates like {{ foo }} don't get parsed weird by key=value code '''\n    while '{{ ' in data:\n        data = data.replace('{{ ', '{{')\n    while ' }}' in data:\n        data = data.replace(' }}', '}}')\n    return data\n\ndef smush_ds(data):\n    # things like key={{ foo }} are not handled by shlex.split well, so preprocess any YAML we load\n    # so we do not have to call smush elsewhere\n    if type(data) == list:\n        return [ smush_ds(x) for x in data ]\n    elif type(data) == dict:\n        for (k,v) in data.items():\n            data[k] = smush_ds(v)\n        return data\n    elif isinstance(data, basestring):\n        return smush_braces(data)\n    else:\n        return data\n\ndef parse_yaml(data, path_hint=None):\n    ''' convert a yaml string to a data structure.  Also supports JSON, ssssssh!!!'''\n\n    stripped_data = data.lstrip()\n    loaded = None\n    if stripped_data.startswith(\"{\") or stripped_data.startswith(\"[\"):\n        # since the line starts with { or [ we can infer this is a JSON document.\n        try:\n            loaded = json.loads(data)\n        except ValueError, ve:\n            if path_hint:\n                raise errors.AnsibleError(path_hint + \": \" + str(ve))\n            else:\n                raise errors.AnsibleError(str(ve))\n    else:\n        # else this is pretty sure to be a YAML document\n        loaded = yaml.safe_load(data)\n\n    return smush_ds(loaded)\n\ndef process_common_errors(msg, probline, column):\n    replaced = probline.replace(\" \",\"\")\n\n    if \":{{\" in replaced and \"}}\" in replaced:\n        msg = msg + \"\"\"\nThis one looks easy to fix.  YAML thought it was looking for the start of a \nhash/dictionary and was confused to see a second \"{\".  Most likely this was\nmeant to be an ansible template evaluation instead, so we have to give the \nparser a small hint that we wanted a string instead. The solution here is to \njust quote the entire value.\n\nFor instance, if the original line was:\n\n    app_path: {{ base_path }}/foo\n\nIt should be written as:\n\n    app_path: \"{{ base_path }}/foo\"\n\"\"\"\n        return msg\n\n    elif len(probline) and len(probline) > 1 and len(probline) > column and probline[column] == \":\" and probline.count(':') > 1:\n        msg = msg + \"\"\"\nThis one looks easy to fix.  There seems to be an extra unquoted colon in the line \nand this is confusing the parser. It was only expecting to find one free \ncolon. The solution is just add some quotes around the colon, or quote the \nentire line after the first colon.\n\nFor instance, if the original line was:\n\n    copy: src=file.txt dest=/path/filename:with_colon.txt\n\nIt can be written as:\n\n    copy: src=file.txt dest='/path/filename:with_colon.txt'\n\nOr:\n    \n    copy: 'src=file.txt dest=/path/filename:with_colon.txt'\n\n\n\"\"\"\n        return msg\n    else:\n        parts = probline.split(\":\")\n        if len(parts) > 1:\n            middle = parts[1].strip()\n            match = False\n            unbalanced = False\n            if middle.startswith(\"'\") and not middle.endswith(\"'\"):\n                match = True\n            elif middle.startswith('\"') and not middle.endswith('\"'):\n                match = True\n            if len(middle) > 0 and middle[0] in [ '\"', \"'\" ] and middle[-1] in [ '\"', \"'\" ] and probline.count(\"'\") > 2 or probline.count('\"') > 2:\n                unbalanced = True\n            if match:\n                msg = msg + \"\"\"\nThis one looks easy to fix.  It seems that there is a value started \nwith a quote, and the YAML parser is expecting to see the line ended \nwith the same kind of quote.  For instance:\n\n    when: \"ok\" in result.stdout\n\nCould be written as:\n\n   when: '\"ok\" in result.stdout'\n\nor equivalently:\n\n   when: \"'ok' in result.stdout\"\n\n\"\"\"\n                return msg\n\n            if unbalanced:\n                msg = msg + \"\"\"\nWe could be wrong, but this one looks like it might be an issue with \nunbalanced quotes.  If starting a value with a quote, make sure the \nline ends with the same set of quotes.  For instance this arbitrary \nexample:\n\n    foo: \"bad\" \"wolf\"\n\nCould be written as:\n\n    foo: '\"bad\" \"wolf\"'\n\n\"\"\"\n                return msg\n\n    return msg\n\ndef process_yaml_error(exc, data, path=None, show_content=True):\n    if hasattr(exc, 'problem_mark'):\n        mark = exc.problem_mark\n        if show_content:\n            if mark.line -1 >= 0:\n                before_probline = data.split(\"\\n\")[mark.line-1]\n            else:\n                before_probline = ''\n            probline = data.split(\"\\n\")[mark.line]\n            arrow = \" \" * mark.column + \"^\"\n            msg = \"\"\"Syntax Error while loading YAML script, %s\nNote: The error may actually appear before this position: line %s, column %s\n\n%s\n%s\n%s\"\"\" % (path, mark.line + 1, mark.column + 1, before_probline, probline, arrow)\n\n            unquoted_var = None\n            if '{{' in probline and '}}' in probline:\n                if '\"{{' not in probline or \"'{{\" not in probline:\n                    unquoted_var = True\n\n            if not unquoted_var:\n                msg = process_common_errors(msg, probline, mark.column)\n            else:\n                msg = msg + \"\"\"\nWe could be wrong, but this one looks like it might be an issue with\nmissing quotes.  Always quote template expression brackets when they \nstart a value. For instance:            \n\n    with_items:\n      - {{ foo }}\n\nShould be written as:\n\n    with_items:\n      - \"{{ foo }}\"      \n\n\"\"\"\n        else:\n            # most likely displaying a file with sensitive content,\n            # so don't show any of the actual lines of yaml just the\n            # line number itself\n            msg = \"\"\"Syntax error while loading YAML script, %s\nThe error appears to have been on line %s, column %s, but may actually\nbe before there depending on the exact syntax problem.\n\"\"\" % (path, mark.line + 1, mark.column + 1)\n\n    else:\n        # No problem markers means we have to throw a generic\n        # \"stuff messed up\" type message. Sry bud.\n        if path:\n            msg = \"Could not parse YAML. Check over %s again.\" % path\n        else:\n            msg = \"Could not parse YAML.\"\n    raise errors.AnsibleYAMLValidationFailed(msg)\n\n\ndef parse_yaml_from_file(path, vault_password=None):\n    ''' convert a yaml file to a data structure '''\n\n    data = None\n    show_content = True\n\n    try:\n        data = open(path).read()\n    except IOError:\n        raise errors.AnsibleError(\"file could not read: %s\" % path)\n\n    vault = VaultLib(password=vault_password)\n    if vault.is_encrypted(data):\n        data = vault.decrypt(data)\n        show_content = False\n\n    try:\n        return parse_yaml(data, path_hint=path)\n    except yaml.YAMLError, exc:\n        process_yaml_error(exc, data, path, show_content)\n\ndef parse_kv(args):\n    ''' convert a string of key/value items to a dict '''\n    options = {}\n    if args is not None:\n        # attempting to split a unicode here does bad things\n        args = args.encode('utf-8')\n        try:\n            vargs = shlex.split(args, posix=True)\n        except ValueError, ve:\n            if 'no closing quotation' in str(ve).lower():\n                raise errors.AnsibleError(\"error parsing argument string, try quoting the entire line.\")\n            else:\n                raise\n        vargs = [x.decode('utf-8') for x in vargs]\n        for x in vargs:\n            if \"=\" in x:\n                k, v = x.split(\"=\",1)\n                options[k]=v\n    return options\n\ndef merge_hash(a, b):\n    ''' recursively merges hash b into a\n    keys from b take precedence over keys from a '''\n\n    result = copy.deepcopy(a)\n\n    # next, iterate over b keys and values\n    for k, v in b.iteritems():\n        # if there's already such key in a\n        # and that key contains dict\n        if k in result and isinstance(result[k], dict):\n            # merge those dicts recursively\n            result[k] = merge_hash(a[k], v)\n        else:\n            # otherwise, just copy a value from b to a\n            result[k] = v\n\n    return result\n\ndef md5s(data):\n    ''' Return MD5 hex digest of data. '''\n\n    digest = _md5()\n    try:\n        digest.update(data)\n    except UnicodeEncodeError:\n        digest.update(data.encode('utf-8'))\n    return digest.hexdigest()\n\ndef md5(filename):\n    ''' Return MD5 hex digest of local file, None if file is not present or a directory. '''\n\n    if not os.path.exists(filename) or os.path.isdir(filename):\n        return None\n    digest = _md5()\n    blocksize = 64 * 1024\n    try:\n        infile = open(filename, 'rb')\n        block = infile.read(blocksize)\n        while block:\n            digest.update(block)\n            block = infile.read(blocksize)\n        infile.close()\n    except IOError, e:\n        raise errors.AnsibleError(\"error while accessing the file %s, error was: %s\" % (filename, e))\n    return digest.hexdigest()\n\ndef default(value, function):\n    ''' syntactic sugar around lazy evaluation of defaults '''\n    if value is None:\n        return function()\n    return value\n\ndef _gitinfo():\n    ''' returns a string containing git branch, commit id and commit date '''\n    result = None\n    repo_path = os.path.join(os.path.dirname(__file__), '..', '..', '..', '.git')\n\n    if os.path.exists(repo_path):\n        # Check if the .git is a file. If it is a file, it means that we are in a submodule structure.\n        if os.path.isfile(repo_path):\n            try:\n                gitdir = yaml.safe_load(open(repo_path)).get('gitdir')\n                # There is a posibility the .git file to have an absolute path.\n                if os.path.isabs(gitdir):\n                    repo_path = gitdir\n                else:\n                    repo_path = os.path.join(repo_path.split('.git')[0], gitdir)\n            except (IOError, AttributeError):\n                return ''\n        f = open(os.path.join(repo_path, \"HEAD\"))\n        branch = f.readline().split('/')[-1].rstrip(\"\\n\")\n        f.close()\n        branch_path = os.path.join(repo_path, \"refs\", \"heads\", branch)\n        if os.path.exists(branch_path):\n            f = open(branch_path)\n            commit = f.readline()[:10]\n            f.close()\n            date = time.localtime(os.stat(branch_path).st_mtime)\n            if time.daylight == 0:\n                offset = time.timezone\n            else:\n                offset = time.altzone\n            result = \"({0} {1}) last updated {2} (GMT {3:+04d})\".format(branch, commit,\n                time.strftime(\"%Y/%m/%d %H:%M:%S\", date), offset / -36)\n    else:\n        result = ''\n    return result\n\ndef version(prog):\n    result = \"{0} {1}\".format(prog, __version__)\n    gitinfo = _gitinfo()\n    if gitinfo:\n        result = result + \" {0}\".format(gitinfo)\n    return result\n\ndef getch():\n    ''' read in a single character '''\n    fd = sys.stdin.fileno()\n    old_settings = termios.tcgetattr(fd)\n    try:\n        tty.setraw(sys.stdin.fileno())\n        ch = sys.stdin.read(1)\n    finally:\n        termios.tcsetattr(fd, termios.TCSADRAIN, old_settings)\n    return ch\n\ndef sanitize_output(str):\n    ''' strips private info out of a string '''\n\n    private_keys = ['password', 'login_password']\n\n    filter_re = [\n        # filter out things like user:pass@foo/whatever\n        # and http://username:pass@wherever/foo\n        re.compile('^(?P<before>.*:)(?P<password>.*)(?P<after>\\@.*)$'),\n    ]\n\n    parts = str.split()\n    output = ''\n    for part in parts:\n        try:\n            (k,v) = part.split('=', 1)\n            if k in private_keys:\n                output += \" %s=VALUE_HIDDEN\" % k\n            else:\n                found = False\n                for filter in filter_re:\n                    m = filter.match(v)\n                    if m:\n                        d = m.groupdict()\n                        output += \" %s=%s\" % (k, d['before'] + \"********\" + d['after'])\n                        found = True\n                        break\n                if not found:\n                    output += \" %s\" % part\n        except:\n            output += \" %s\" % part\n\n    return output.strip()\n\n####################################################################\n# option handling code for /usr/bin/ansible and ansible-playbook\n# below this line\n\nclass SortedOptParser(optparse.OptionParser):\n    '''Optparser which sorts the options by opt before outputting --help'''\n\n    def format_help(self, formatter=None):\n        self.option_list.sort(key=operator.methodcaller('get_opt_string'))\n        return optparse.OptionParser.format_help(self, formatter=None)\n\ndef increment_debug(option, opt, value, parser):\n    global VERBOSITY\n    VERBOSITY += 1\n\ndef base_parser(constants=C, usage=\"\", output_opts=False, runas_opts=False,\n    async_opts=False, connect_opts=False, subset_opts=False, check_opts=False, diff_opts=False):\n    ''' create an options parser for any ansible script '''\n\n    parser = SortedOptParser(usage, version=version(\"%prog\"))\n    parser.add_option('-v','--verbose', default=False, action=\"callback\",\n        callback=increment_debug, help=\"verbose mode (-vvv for more, -vvvv to enable connection debugging)\")\n\n    parser.add_option('-f','--forks', dest='forks', default=constants.DEFAULT_FORKS, type='int',\n        help=\"specify number of parallel processes to use (default=%s)\" % constants.DEFAULT_FORKS)\n    parser.add_option('-i', '--inventory-file', dest='inventory',\n        help=\"specify inventory host file (default=%s)\" % constants.DEFAULT_HOST_LIST,\n        default=constants.DEFAULT_HOST_LIST)\n    parser.add_option('-k', '--ask-pass', default=False, dest='ask_pass', action='store_true',\n        help='ask for SSH password')\n    parser.add_option('--private-key', default=C.DEFAULT_PRIVATE_KEY_FILE, dest='private_key_file',\n        help='use this file to authenticate the connection')\n    parser.add_option('-K', '--ask-sudo-pass', default=False, dest='ask_sudo_pass', action='store_true',\n        help='ask for sudo password')\n    parser.add_option('--ask-su-pass', default=False, dest='ask_su_pass', action='store_true', \n        help='ask for su password')\n    parser.add_option('--ask-vault-pass', default=False, dest='ask_vault_pass', action='store_true', \n        help='ask for vault password')\n    parser.add_option('--vault-password-file', default=None, dest='vault_password_file',\n        help=\"vault password file\")\n    parser.add_option('--list-hosts', dest='listhosts', action='store_true',\n        help='outputs a list of matching hosts; does not execute anything else')\n    parser.add_option('-M', '--module-path', dest='module_path',\n        help=\"specify path(s) to module library (default=%s)\" % constants.DEFAULT_MODULE_PATH,\n        default=None)\n\n    if subset_opts:\n        parser.add_option('-l', '--limit', default=constants.DEFAULT_SUBSET, dest='subset',\n            help='further limit selected hosts to an additional pattern')\n\n    parser.add_option('-T', '--timeout', default=constants.DEFAULT_TIMEOUT, type='int',\n        dest='timeout',\n        help=\"override the SSH timeout in seconds (default=%s)\" % constants.DEFAULT_TIMEOUT)\n\n    if output_opts:\n        parser.add_option('-o', '--one-line', dest='one_line', action='store_true',\n            help='condense output')\n        parser.add_option('-t', '--tree', dest='tree', default=None,\n            help='log output to this directory')\n\n    if runas_opts:\n        parser.add_option(\"-s\", \"--sudo\", default=constants.DEFAULT_SUDO, action=\"store_true\",\n            dest='sudo', help=\"run operations with sudo (nopasswd)\")\n        parser.add_option('-U', '--sudo-user', dest='sudo_user', default=None,\n                          help='desired sudo user (default=root)')  # Can't default to root because we need to detect when this option was given\n        parser.add_option('-u', '--user', default=constants.DEFAULT_REMOTE_USER,\n            dest='remote_user', help='connect as this user (default=%s)' % constants.DEFAULT_REMOTE_USER)\n\n        parser.add_option('-S', '--su', default=constants.DEFAULT_SU,\n                          action='store_true', help='run operations with su')\n        parser.add_option('-R', '--su-user', help='run operations with su as this '\n                                                  'user (default=%s)' % constants.DEFAULT_SU_USER)\n\n    if connect_opts:\n        parser.add_option('-c', '--connection', dest='connection',\n                          default=C.DEFAULT_TRANSPORT,\n                          help=\"connection type to use (default=%s)\" % C.DEFAULT_TRANSPORT)\n\n    if async_opts:\n        parser.add_option('-P', '--poll', default=constants.DEFAULT_POLL_INTERVAL, type='int',\n            dest='poll_interval',\n            help=\"set the poll interval if using -B (default=%s)\" % constants.DEFAULT_POLL_INTERVAL)\n        parser.add_option('-B', '--background', dest='seconds', type='int', default=0,\n            help='run asynchronously, failing after X seconds (default=N/A)')\n\n    if check_opts:\n        parser.add_option(\"-C\", \"--check\", default=False, dest='check', action='store_true',\n            help=\"don't make any changes; instead, try to predict some of the changes that may occur\"\n        )\n\n    if diff_opts:\n        parser.add_option(\"-D\", \"--diff\", default=False, dest='diff', action='store_true',\n            help=\"when changing (small) files and templates, show the differences in those files; works great with --check\"\n        )\n\n\n    return parser\n\ndef ask_vault_passwords(ask_vault_pass=False, ask_new_vault_pass=False, confirm_vault=False, confirm_new=False):\n\n    vault_pass = None\n    new_vault_pass = None\n\n    if ask_vault_pass:\n        vault_pass = getpass.getpass(prompt=\"Vault password: \")\n\n    if ask_vault_pass and confirm_vault:\n        vault_pass2 = getpass.getpass(prompt=\"Confirm Vault password: \")\n        if vault_pass != vault_pass2:\n            raise errors.AnsibleError(\"Passwords do not match\")\n\n    if ask_new_vault_pass:\n        new_vault_pass = getpass.getpass(prompt=\"New Vault password: \")\n\n    if ask_new_vault_pass and confirm_new:\n        new_vault_pass2 = getpass.getpass(prompt=\"Confirm New Vault password: \")\n        if new_vault_pass != new_vault_pass2:\n            raise errors.AnsibleError(\"Passwords do not match\")\n\n    # enforce no newline chars at the end of passwords\n    if vault_pass:\n        vault_pass = vault_pass.strip()\n    if new_vault_pass:\n        new_vault_pass = new_vault_pass.strip()\n\n    return vault_pass, new_vault_pass\n\ndef ask_passwords(ask_pass=False, ask_sudo_pass=False, ask_su_pass=False, ask_vault_pass=False):\n    sshpass = None\n    sudopass = None\n    su_pass = None\n    vault_pass = None\n    sudo_prompt = \"sudo password: \"\n    su_prompt = \"su password: \"\n\n    if ask_pass:\n        sshpass = getpass.getpass(prompt=\"SSH password: \")\n        sudo_prompt = \"sudo password [defaults to SSH password]: \"\n\n    if ask_sudo_pass:\n        sudopass = getpass.getpass(prompt=sudo_prompt)\n        if ask_pass and sudopass == '':\n            sudopass = sshpass\n\n    if ask_su_pass:\n        su_pass = getpass.getpass(prompt=su_prompt)\n\n    if ask_vault_pass:\n        vault_pass = getpass.getpass(prompt=\"Vault password: \")\n\n    return (sshpass, sudopass, su_pass, vault_pass)\n\ndef do_encrypt(result, encrypt, salt_size=None, salt=None):\n    if PASSLIB_AVAILABLE:\n        try:\n            crypt = getattr(passlib.hash, encrypt)\n        except:\n            raise errors.AnsibleError(\"passlib does not support '%s' algorithm\" % encrypt)\n\n        if salt_size:\n            result = crypt.encrypt(result, salt_size=salt_size)\n        elif salt:\n            result = crypt.encrypt(result, salt=salt)\n        else:\n            result = crypt.encrypt(result)\n    else:\n        raise errors.AnsibleError(\"passlib must be installed to encrypt vars_prompt values\")\n\n    return result\n\ndef last_non_blank_line(buf):\n\n    all_lines = buf.splitlines()\n    all_lines.reverse()\n    for line in all_lines:\n        if (len(line) > 0):\n            return line\n    # shouldn't occur unless there's no output\n    return \"\"\n\ndef filter_leading_non_json_lines(buf):\n    '''\n    used to avoid random output from SSH at the top of JSON output, like messages from\n    tcagetattr, or where dropbear spews MOTD on every single command (which is nuts).\n\n    need to filter anything which starts not with '{', '[', ', '=' or is an empty line.\n    filter only leading lines since multiline JSON is valid.\n    '''\n\n    kv_regex = re.compile(r'.*\\w+=\\w+.*')\n    filtered_lines = StringIO.StringIO()\n    stop_filtering = False\n    for line in buf.splitlines():\n        if stop_filtering or kv_regex.match(line) or line.startswith('{') or line.startswith('['):\n            stop_filtering = True\n            filtered_lines.write(line + '\\n')\n    return filtered_lines.getvalue()\n\ndef boolean(value):\n    val = str(value)\n    if val.lower() in [ \"true\", \"t\", \"y\", \"1\", \"yes\" ]:\n        return True\n    else:\n        return False\n\ndef make_sudo_cmd(sudo_user, executable, cmd):\n    \"\"\"\n    helper function for connection plugins to create sudo commands\n    \"\"\"\n    # Rather than detect if sudo wants a password this time, -k makes\n    # sudo always ask for a password if one is required.\n    # Passing a quoted compound command to sudo (or sudo -s)\n    # directly doesn't work, so we shellquote it with pipes.quote()\n    # and pass the quoted string to the user's shell.  We loop reading\n    # output until we see the randomly-generated sudo prompt set with\n    # the -p option.\n    randbits = ''.join(chr(random.randint(ord('a'), ord('z'))) for x in xrange(32))\n    prompt = '[sudo via ansible, key=%s] password: ' % randbits\n    success_key = 'SUDO-SUCCESS-%s' % randbits\n    sudocmd = '%s -k && %s %s -S -p \"%s\" -u %s %s -c %s' % (\n        C.DEFAULT_SUDO_EXE, C.DEFAULT_SUDO_EXE, C.DEFAULT_SUDO_FLAGS,\n        prompt, sudo_user, executable or '$SHELL', pipes.quote('echo %s; %s' % (success_key, cmd)))\n    return ('/bin/sh -c ' + pipes.quote(sudocmd), prompt, success_key)\n\n\ndef make_su_cmd(su_user, executable, cmd):\n    \"\"\"\n    Helper function for connection plugins to create direct su commands\n    \"\"\"\n    # TODO: work on this function\n    randbits = ''.join(chr(random.randint(ord('a'), ord('z'))) for x in xrange(32))\n    prompt = '[Pp]assword: ?$'\n    success_key = 'SUDO-SUCCESS-%s' % randbits\n    sudocmd = '%s %s %s -c \"%s -c %s\"' % (\n        C.DEFAULT_SU_EXE, C.DEFAULT_SU_FLAGS, su_user, executable or '$SHELL',\n        pipes.quote('echo %s; %s' % (success_key, cmd))\n    )\n    return ('/bin/sh -c ' + pipes.quote(sudocmd), prompt, success_key)\n\n_TO_UNICODE_TYPES = (unicode, type(None))\n\ndef to_unicode(value):\n    if isinstance(value, _TO_UNICODE_TYPES):\n        return value\n    return value.decode(\"utf-8\")\n\ndef get_diff(diff):\n    # called by --diff usage in playbook and runner via callbacks\n    # include names in diffs 'before' and 'after' and do diff -U 10\n\n    try:\n        with warnings.catch_warnings():\n            warnings.simplefilter('ignore')\n            ret = []\n            if 'dst_binary' in diff:\n                ret.append(\"diff skipped: destination file appears to be binary\\n\")\n            if 'src_binary' in diff:\n                ret.append(\"diff skipped: source file appears to be binary\\n\")\n            if 'dst_larger' in diff:\n                ret.append(\"diff skipped: destination file size is greater than %d\\n\" % diff['dst_larger'])\n            if 'src_larger' in diff:\n                ret.append(\"diff skipped: source file size is greater than %d\\n\" % diff['src_larger'])\n            if 'before' in diff and 'after' in diff:\n                if 'before_header' in diff:\n                    before_header = \"before: %s\" % diff['before_header']\n                else:\n                    before_header = 'before'\n                if 'after_header' in diff:\n                    after_header = \"after: %s\" % diff['after_header']\n                else:\n                    after_header = 'after'\n                differ = difflib.unified_diff(to_unicode(diff['before']).splitlines(True), to_unicode(diff['after']).splitlines(True), before_header, after_header, '', '', 10)\n                for line in list(differ):\n                    ret.append(line)\n            return u\"\".join(ret)\n    except UnicodeDecodeError:\n        return \">> the files are different, but the diff library cannot compare unicode strings\"\n\ndef is_list_of_strings(items):\n    for x in items:\n        if not isinstance(x, basestring):\n            return False\n    return True\n\ndef list_union(a, b):\n    result = []\n    for x in a:\n        if x not in result:\n            result.append(x)\n    for x in b:\n        if x not in result:\n            result.append(x)\n    return result\n\ndef list_intersection(a, b):\n    result = []\n    for x in a:\n        if x in b and x not in result:\n            result.append(x)\n    return result\n\ndef safe_eval(expr, locals={}, include_exceptions=False):\n    '''\n    this is intended for allowing things like:\n    with_items: a_list_variable\n    where Jinja2 would return a string\n    but we do not want to allow it to call functions (outside of Jinja2, where\n    the env is constrained)\n\n    Based on:\n    http://stackoverflow.com/questions/12523516/using-ast-and-whitelists-to-make-pythons-eval-safe\n    '''\n\n    # this is the whitelist of AST nodes we are going to \n    # allow in the evaluation. Any node type other than \n    # those listed here will raise an exception in our custom\n    # visitor class defined below.\n    SAFE_NODES = set(\n        (\n            ast.Expression,\n            ast.Compare,\n            ast.Str,\n            ast.List,\n            ast.Tuple,\n            ast.Dict,\n            ast.Call,\n            ast.Load,\n            ast.BinOp,\n            ast.UnaryOp,\n            ast.Num,\n            ast.Name,\n            ast.Add,\n            ast.Sub,\n            ast.Mult,\n            ast.Div,\n        )\n    )\n\n    # AST node types were expanded after 2.6\n    if not sys.version.startswith('2.6'):\n        SAFE_NODES.union(\n            set(\n                (ast.Set,)\n            )\n        )\n\n    # builtin functions that are not safe to call\n    INVALID_CALLS = (\n       'classmethod', 'compile', 'delattr', 'eval', 'execfile', 'file',\n       'filter', 'help', 'input', 'object', 'open', 'raw_input', 'reduce',\n       'reload', 'repr', 'setattr', 'staticmethod', 'super', 'type',\n    )\n\n    class CleansingNodeVisitor(ast.NodeVisitor):\n        def generic_visit(self, node):\n            if type(node) not in SAFE_NODES:\n                #raise Exception(\"invalid expression (%s) type=%s\" % (expr, type(node)))\n                raise Exception(\"invalid expression (%s)\" % expr)\n            super(CleansingNodeVisitor, self).generic_visit(node)\n        def visit_Call(self, call):\n            if call.func.id in INVALID_CALLS:\n                raise Exception(\"invalid function: %s\" % call.func.id)\n\n    if not isinstance(expr, basestring):\n        # already templated to a datastructure, perhaps?\n        if include_exceptions:\n            return (expr, None)\n        return expr\n\n    try:\n        parsed_tree = ast.parse(expr, mode='eval')\n        cnv = CleansingNodeVisitor()\n        cnv.visit(parsed_tree)\n        compiled = compile(parsed_tree, expr, 'eval')\n        result = eval(compiled, {}, locals)\n\n        if include_exceptions:\n            return (result, None)\n        else:\n            return result\n    except SyntaxError, e:\n        # special handling for syntax errors, we just return\n        # the expression string back as-is\n        if include_exceptions:\n            return (expr, None)\n        return expr\n    except Exception, e:\n        if include_exceptions:\n            return (expr, e)\n        return expr\n\n\ndef listify_lookup_plugin_terms(terms, basedir, inject):\n\n    if isinstance(terms, basestring):\n        # someone did:\n        #    with_items: alist\n        # OR\n        #    with_items: {{ alist }}\n\n        stripped = terms.strip()\n        if not (stripped.startswith('{') or stripped.startswith('[')) and not stripped.startswith(\"/\") and not stripped.startswith('set(['):\n            # if not already a list, get ready to evaluate with Jinja2\n            # not sure why the \"/\" is in above code :)\n            try:\n                new_terms = template.template(basedir, \"{{ %s }}\" % terms, inject)\n                if isinstance(new_terms, basestring) and \"{{\" in new_terms:\n                    pass\n                else:\n                    terms = new_terms\n            except:\n                pass\n\n        if '{' in terms or '[' in terms:\n            # Jinja2 already evaluated a variable to a list.\n            # Jinja2-ified list needs to be converted back to a real type\n            # TODO: something a bit less heavy than eval\n            return safe_eval(terms)\n\n        if isinstance(terms, basestring):\n            terms = [ terms ]\n\n    return terms\n\ndef combine_vars(a, b):\n\n    if C.DEFAULT_HASH_BEHAVIOUR == \"merge\":\n        return merge_hash(a, b)\n    else:\n        return dict(a.items() + b.items())\n\ndef random_password(length=20, chars=C.DEFAULT_PASSWORD_CHARS):\n    '''Return a random password string of length containing only chars.'''\n\n    password = []\n    while len(password) < length:\n        new_char = os.urandom(1)\n        if new_char in chars:\n            password.append(new_char)\n\n    return ''.join(password)\n\ndef before_comment(msg):\n    ''' what's the part of a string before a comment? '''\n    msg = msg.replace(\"\\#\",\"**NOT_A_COMMENT**\")\n    msg = msg.split(\"#\")[0]\n    msg = msg.replace(\"**NOT_A_COMMENT**\",\"#\")\n    return msg\n\n\n\n", "target": 1}
{"idx": 898, "func": "# -*- coding: utf-8 -*-\n#\n# This file is part of Radicale Server - Calendar Server\n# Copyright \u00a9 2014 Jean-Marc Martins\n# Copyright \u00a9 2014-2015 Guillaume Ayoub\n#\n# This library is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# This library is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with Radicale.  If not, see <http://www.gnu.org/licenses/>.\n\n\"\"\"\nMulti files per calendar filesystem storage backend.\n\n\"\"\"\n\nimport os\nimport shutil\nimport time\nimport sys\n\nfrom . import filesystem\nfrom .. import ical\nfrom .. import log\nfrom .. import pathutils\n\n\nclass Collection(filesystem.Collection):\n    \"\"\"Collection stored in several files per calendar.\"\"\"\n    def _create_dirs(self):\n        if not os.path.exists(self._filesystem_path):\n            os.makedirs(self._filesystem_path)\n\n    @property\n    def headers(self):\n        return (\n            ical.Header(\"PRODID:-//Radicale//NONSGML Radicale Server//EN\"),\n            ical.Header(\"VERSION:%s\" % self.version))\n\n    def write(self):\n        self._create_dirs()\n        for component in self.components:\n            text = ical.serialize(\n                self.tag, self.headers, [component] + self.timezones)\n            name = (\n                component.name if sys.version_info[0] >= 3 else\n                component.name.encode(filesystem.FILESYSTEM_ENCODING))\n            filesystem_path = os.path.join(self._filesystem_path, name)\n            with filesystem.open(filesystem_path, \"w\") as fd:\n                fd.write(text)\n\n    def delete(self):\n        shutil.rmtree(self._filesystem_path)\n        os.remove(self._props_path)\n\n    def remove(self, name):\n        filesystem_path = os.path.join(self._filesystem_path, name)\n        if os.path.exists(filesystem_path):\n            os.remove(filesystem_path)\n\n    @property\n    def text(self):\n        components = (\n            ical.Timezone, ical.Event, ical.Todo, ical.Journal, ical.Card)\n        items = set()\n        try:\n            filenames = os.listdir(self._filesystem_path)\n        except (OSError, IOError) as e:\n            log.LOGGER.info('Error while reading collection %r: %r'\n                            % (self._filesystem_path, e))\n            return \"\"\n\n        for filename in filenames:\n            path = os.path.join(self._filesystem_path, filename)\n            try:\n                with filesystem.open(path) as fd:\n                    items.update(self._parse(fd.read(), components))\n            except (OSError, IOError) as e:\n                log.LOGGER.warning('Error while reading item %r: %r'\n                                   % (path, e))\n\n        return ical.serialize(\n            self.tag, self.headers, sorted(items, key=lambda x: x.name))\n\n    @classmethod\n    def is_node(cls, path):\n        filesystem_path = pathutils.path_to_filesystem(path,\n                                                       filesystem.FOLDER)\n        return (os.path.isdir(filesystem_path) and\n                not os.path.exists(filesystem_path + \".props\"))\n\n    @classmethod\n    def is_leaf(cls, path):\n        filesystem_path = pathutils.path_to_filesystem(path,\n                                                       filesystem.FOLDER)\n        return (os.path.isdir(filesystem_path) and\n                os.path.exists(path + \".props\"))\n\n    @property\n    def last_modified(self):\n        last = max([\n            os.path.getmtime(os.path.join(self._filesystem_path, filename))\n            for filename in os.listdir(self._filesystem_path)] or [0])\n        return time.strftime(\"%a, %d %b %Y %H:%M:%S +0000\", time.gmtime(last))\n", "target": 0}
{"idx": 899, "func": "# -*- coding: utf-8 -*-\n#\n# This file is part of Radicale Server - Calendar Server\n# Copyright \u00a9 2008 Nicolas Kandel\n# Copyright \u00a9 2008 Pascal Halter\n# Copyright \u00a9 2008-2013 Guillaume Ayoub\n#\n# This library is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# This library is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with Radicale.  If not, see <http://www.gnu.org/licenses/>.\n\n\"\"\"\nImplement htpasswd authentication.\n\nApache's htpasswd command (httpd.apache.org/docs/programs/htpasswd.html) manages\na file for storing user credentials. It can encrypt passwords using different\nmethods, e.g. BCRYPT, MD5-APR1 (a version of MD5 modified for Apache), SHA1, or\nby using the system's CRYPT routine. The CRYPT and SHA1 encryption methods\nimplemented by htpasswd are considered as insecure. MD5-APR1 provides medium\nsecurity as of 2015. Only BCRYPT can be considered secure by current standards.\n\nMD5-APR1-encrypted credentials can be written by all versions of htpasswd (its\nthe default, in fact), whereas BCRYPT requires htpasswd 2.4.x or newer.\n\nThe `is_authenticated(user, password)` function provided by this module\nverifies the user-given credentials by parsing the htpasswd credential file\npointed to by the ``htpasswd_filename`` configuration value while assuming\nthe password encryption method specified via the ``htpasswd_encryption``\nconfiguration value.\n\nThe following htpasswd password encrpytion methods are supported by Radicale\nout-of-the-box:\n\n    - plain-text (created by htpasswd -p...) -- INSECURE\n    - CRYPT      (created by htpasswd -d...) -- INSECURE\n    - SHA1       (created by htpasswd -s...) -- INSECURE\n\nWhen passlib (https://pypi.python.org/pypi/passlib) is importable, the\nfollowing significantly more secure schemes are parsable by Radicale:\n\n    - MD5-APR1   (htpasswd -m...) -- htpasswd's default method\n    - BCRYPT     (htpasswd -B...) -- Requires htpasswd 2.4.x\n\n\"\"\"\n\n\nimport base64\nimport hashlib\nimport os\nimport random\nimport time\n\nfrom .. import config\n\n\nFILENAME = os.path.expanduser(config.get(\"auth\", \"htpasswd_filename\"))\nENCRYPTION = config.get(\"auth\", \"htpasswd_encryption\")\n\n\ndef _plain(hash_value, password):\n    \"\"\"Check if ``hash_value`` and ``password`` match, using plain method.\"\"\"\n    return hash_value == password\n\n\ndef _crypt(hash_value, password):\n    \"\"\"Check if ``hash_value`` and ``password`` match, using crypt method.\"\"\"\n    return crypt.crypt(password, hash_value) == hash_value\n\n\ndef _sha1(hash_value, password):\n    \"\"\"Check if ``hash_value`` and ``password`` match, using sha1 method.\"\"\"\n    hash_value = hash_value.replace(\"{SHA}\", \"\").encode(\"ascii\")\n    password = password.encode(config.get(\"encoding\", \"stock\"))\n    sha1 = hashlib.sha1()  # pylint: disable=E1101\n    sha1.update(password)\n    return sha1.digest() == base64.b64decode(hash_value)\n\n\ndef _ssha(hash_salt_value, password):\n    \"\"\"Check if ``hash_salt_value`` and ``password`` match, using salted sha1\n    method. This method is not directly supported by htpasswd, but it can be\n    written with e.g. openssl, and nginx can parse it.\"\"\"\n    hash_salt_value = base64.b64decode(hash_salt_value.replace(\"{SSHA}\", \"\"))\n    password = password.encode(config.get(\"encoding\", \"stock\"))\n    hash_value = hash_salt_value[:20]\n    salt_value = hash_salt_value[20:]\n    sha1 = hashlib.sha1()  # pylint: disable=E1101\n    sha1.update(password)\n    sha1.update(salt_value)\n    return sha1.digest() == hash_value\n\n\ndef _bcrypt(hash_value, password):\n    return _passlib_bcrypt.verify(password, hash_value)\n\n\ndef _md5apr1(hash_value, password):\n    return _passlib_md5apr1.verify(password, hash_value)\n\n\n# Prepare mapping between encryption names and verification functions.\n# Pre-fill with methods that do not have external dependencies.\n_verifuncs = {\n    \"ssha\": _ssha,\n    \"sha1\": _sha1,\n    \"plain\": _plain}\n\n\n# Conditionally attempt to import external dependencies.\nif ENCRYPTION == \"md5\":\n    try:\n        from passlib.hash import apr_md5_crypt as _passlib_md5apr1\n    except ImportError:\n        raise RuntimeError((\"The htpasswd_encryption method 'md5' requires \"\n            \"availability of the passlib module.\"))\n    _verifuncs[\"md5\"] = _md5apr1\nelif ENCRYPTION == \"bcrypt\":\n    try:\n        from passlib.hash import bcrypt as _passlib_bcrypt\n    except ImportError:\n        raise RuntimeError((\"The htpasswd_encryption method 'bcrypt' requires \"\n            \"availability of the passlib module with bcrypt support.\"))\n    # A call to `encrypt` raises passlib.exc.MissingBackendError with a good\n    # error message if bcrypt backend is not available. Trigger this here.\n    _passlib_bcrypt.encrypt(\"test-bcrypt-backend\")\n    _verifuncs[\"bcrypt\"] = _bcrypt\nelif ENCRYPTION == \"crypt\":\n    try:\n        import crypt\n    except ImportError:\n        raise RuntimeError((\"The htpasswd_encryption method 'crypt' requires \"\n            \"crypt() system support.\"))\n    _verifuncs[\"crypt\"] = _crypt\n\n\n# Validate initial configuration.\nif ENCRYPTION not in _verifuncs:\n    raise RuntimeError((\"The htpasswd encryption method '%s' is not \"\n        \"supported.\" % ENCRYPTION))\n \n\ndef is_authenticated(user, password):\n    \"\"\"Validate credentials.\n\n    Iterate through htpasswd credential file until user matches, extract hash\n    (encrypted password) and check hash against user-given password, using the\n    method specified in the Radicale config.\n\n    \"\"\"\n    with open(FILENAME) as f:\n        for line in f:\n            strippedline = line.strip()\n            if strippedline:\n                login, hash_value = strippedline.split(\":\")\n                if login == user:\n                    if _verifuncs[ENCRYPTION](hash_value, password):\n                        # Allow encryption method to be overridden at runtime.\n                        return True\n    # Random timer to avoid timing oracles and simple bruteforce attacks\n    time.sleep(1 + random.random())\n    return False\n\n", "target": 0}
{"idx": 900, "func": "from __future__ import print_function\n\nimport argparse\nimport json\nfrom oauthlib.oauth2 import LegacyApplicationClient\nimport logging\nimport logging.handlers\nfrom requests_oauthlib import OAuth2Session\nimport os\nimport requests\nimport six\nimport sys\nimport traceback\n\nfrom six.moves.urllib.parse import quote as urlquote\nfrom six.moves.urllib.parse import urlparse\n\n\n# ------------------------------------------------------------------------------\n\nlogger = None\nprog_name = os.path.basename(sys.argv[0])\nAUTH_ROLES = ['root-admin', 'realm-admin', 'anonymous']\n\nLOG_FILE_ROTATION_COUNT = 3\n\nTOKEN_URL_TEMPLATE = (\n    '{server}/auth/realms/{realm}/protocol/openid-connect/token')\nGET_SERVER_INFO_TEMPLATE = (\n    '{server}/auth/admin/serverinfo/')\nGET_REALMS_URL_TEMPLATE = (\n    '{server}/auth/admin/realms')\nCREATE_REALM_URL_TEMPLATE = (\n    '{server}/auth/admin/realms')\nDELETE_REALM_URL_TEMPLATE = (\n    '{server}/auth/admin/realms/{realm}')\nGET_REALM_METADATA_TEMPLATE = (\n    '{server}/auth/realms/{realm}/protocol/saml/descriptor')\n\nCLIENT_REPRESENTATION_TEMPLATE = (\n    '{server}/auth/admin/realms/{realm}/clients/{id}')\nGET_CLIENTS_URL_TEMPLATE = (\n    '{server}/auth/admin/realms/{realm}/clients')\nCLIENT_DESCRIPTOR_URL_TEMPLATE = (\n    '{server}/auth/admin/realms/{realm}/client-description-converter')\nCREATE_CLIENT_URL_TEMPLATE = (\n    '{server}/auth/admin/realms/{realm}/clients')\n\nGET_INITIAL_ACCESS_TOKEN_TEMPLATE = (\n    '{server}/auth/admin/realms/{realm}/clients-initial-access')\nSAML2_CLIENT_REGISTRATION_TEMPLATE = (\n  '{server}/auth/realms/{realm}/clients-registrations/saml2-entity-descriptor')\n\nGET_CLIENT_PROTOCOL_MAPPERS_TEMPLATE = (\n    '{server}/auth/admin/realms/{realm}/clients/{id}/protocol-mappers/models')\nGET_CLIENT_PROTOCOL_MAPPERS_BY_PROTOCOL_TEMPLATE = (\n    '{server}/auth/admin/realms/{realm}/clients/{id}/protocol-mappers/protocol/{protocol}')\n\nPOST_CLIENT_PROTOCOL_MAPPER_TEMPLATE = (\n    '{server}/auth/admin/realms/{realm}/clients/{id}/protocol-mappers/models')\n\n\nADMIN_CLIENT_ID = 'admin-cli'\n\n# ------------------------------------------------------------------------------\n\n\nclass RESTError(Exception):\n    def __init__(self, status_code, status_reason,\n                 response_json, response_text, cmd):\n        self.status_code = status_code\n        self.status_reason = status_reason\n        self.error_description = None\n        self.error = None\n        self.response_json = response_json\n        self.response_text = response_text\n        self.cmd = cmd\n\n        self.message = '{status_reason}({status_code}): '.format(\n            status_reason=self.status_reason,\n            status_code=self.status_code)\n\n        if response_json:\n            self.error_description = response_json.get('error_description')\n            if self.error_description is None:\n                self.error_description = response_json.get('errorMessage')\n            self.error = response_json.get('error')\n            self.message += '\"{error_description}\" [{error}]'.format(\n                error_description=self.error_description,\n                error=self.error)\n        else:\n            self.message += '\"{response_text}\"'.format(\n                response_text=self.response_text)\n\n        self.args = (self.message,)\n\n    def __str__(self):\n        return self.message\n\n# ------------------------------------------------------------------------------\n\n\ndef configure_logging(options):\n    global logger  # pylint: disable=W0603\n\n    log_dir = os.path.dirname(options.log_file)\n    if os.path.exists(log_dir):\n        if not os.path.isdir(log_dir):\n            raise ValueError('logging directory \"{log_dir}\" exists but is not '\n                             'directory'.format(log_dir=log_dir))\n    else:\n        os.makedirs(log_dir)\n\n    log_level = logging.ERROR\n    if options.verbose:\n        log_level = logging.INFO\n    if options.debug:\n        log_level = logging.DEBUG\n\n        # These two lines enable debugging at httplib level\n        # (requests->urllib3->http.client) You will see the REQUEST,\n        # including HEADERS and DATA, and RESPONSE with HEADERS but\n        # without DATA.  The only thing missing will be the\n        # response.body which is not logged.\n        try:\n            import http.client as http_client  # Python 3\n        except ImportError:\n            import httplib as http_client      # Python 2\n\n        http_client.HTTPConnection.debuglevel = 1\n\n        # Turn on cookielib debugging\n        if False:\n            try:\n                import http.cookiejar as cookiejar\n            except ImportError:\n                import cookielib as cookiejar  # Python 2\n            cookiejar.debug = True\n\n    logger = logging.getLogger(prog_name)\n\n    try:\n        file_handler = logging.handlers.RotatingFileHandler(\n            options.log_file, backupCount=LOG_FILE_ROTATION_COUNT)\n    except IOError as e:\n        print('Unable to open log file %s (%s)' % (options.log_file, e),\n              file=sys.stderr)\n\n    else:\n        formatter = logging.Formatter(\n            '%(asctime)s %(name)s %(levelname)s: %(message)s')\n        file_handler.setFormatter(formatter)\n        file_handler.setLevel(logging.DEBUG)\n        logger.addHandler(file_handler)\n\n    console_handler = logging.StreamHandler(sys.stdout)\n    formatter = logging.Formatter('%(message)s')\n    console_handler.setFormatter(formatter)\n    console_handler.setLevel(log_level)\n    logger.addHandler(console_handler)\n\n    # Set the log level on the logger to the lowest level\n    # possible. This allows the message to be emitted from the logger\n    # to it's handlers where the level will be filtered on a per\n    # handler basis.\n    logger.setLevel(1)\n\n# ------------------------------------------------------------------------------\n\n\ndef json_pretty(text):\n    return json.dumps(json.loads(text),\n                      indent=4, sort_keys=True)\n\n\ndef py_json_pretty(py_json):\n    return json_pretty(json.dumps(py_json))\n\n\ndef server_name_from_url(url):\n    return urlparse(url).netloc\n\n\ndef get_realm_names_from_realms(realms):\n    return [x['realm'] for x in realms]\n\n\ndef get_client_client_ids_from_clients(clients):\n    return [x['clientId'] for x in clients]\n\n\ndef find_client_by_name(clients, client_id):\n    for client in clients:\n        if client.get('clientId') == client_id:\n            return client\n    raise KeyError('{item} not found'.format(item=client_id))\n\n\n# ------------------------------------------------------------------------------\n\nclass KeycloakREST(object):\n\n    def __init__(self, server, auth_role=None, session=None):\n        self.server = server\n        self.auth_role = auth_role\n        self.session = session\n\n    def get_initial_access_token(self, realm_name):\n        cmd_name = \"get initial access token for realm '{realm}'\".format(\n            realm=realm_name)\n        url = GET_INITIAL_ACCESS_TOKEN_TEMPLATE.format(\n            server=self.server, realm=urlquote(realm_name))\n\n        logger.debug(\"%s on server %s\", cmd_name, self.server)\n\n        params = {\"expiration\": 60,  # seconds\n                  \"count\": 1}\n\n        response = self.session.post(url, json=params)\n        logger.debug(\"%s response code: %s %s\",\n                     cmd_name, response.status_code, response.reason)\n\n        try:\n            response_json = response.json()\n        except ValueError as e:\n            response_json = None\n\n        if (not response_json or\n            response.status_code != requests.codes.ok):\n            logger.error(\"%s error: status=%s (%s) text=%s\",\n                         cmd_name, response.status_code, response.reason,\n                         response.text)\n            raise RESTError(response.status_code, response.reason,\n                            response_json, response.text, cmd_name)\n\n        logger.debug(\"%s response = %s\", cmd_name, json_pretty(response.text))\n\n        return response_json    # ClientInitialAccessPresentation\n\n    def get_server_info(self):\n        cmd_name = \"get server info\"\n        url = GET_SERVER_INFO_TEMPLATE.format(server=self.server)\n\n        logger.debug(\"%s on server %s\", cmd_name, self.server)\n        response = self.session.get(url)\n        logger.debug(\"%s response code: %s %s\",\n                     cmd_name, response.status_code, response.reason)\n\n        try:\n            response_json = response.json()\n        except ValueError as e:\n            response_json = None\n\n        if (not response_json or\n            response.status_code != requests.codes.ok):\n            logger.error(\"%s error: status=%s (%s) text=%s\",\n                         cmd_name, response.status_code, response.reason,\n                         response.text)\n            raise RESTError(response.status_code, response.reason,\n                            response_json, response.text, cmd_name)\n\n        logger.debug(\"%s response = %s\", cmd_name, json_pretty(response.text))\n\n        return response_json\n\n    def get_realms(self):\n        cmd_name = \"get realms\"\n        url = GET_REALMS_URL_TEMPLATE.format(server=self.server)\n\n        logger.debug(\"%s on server %s\", cmd_name, self.server)\n        response = self.session.get(url)\n        logger.debug(\"%s response code: %s %s\",\n                     cmd_name, response.status_code, response.reason)\n\n        try:\n            response_json = response.json()\n        except ValueError as e:\n            response_json = None\n\n        if (not response_json or\n            response.status_code != requests.codes.ok):\n            logger.error(\"%s error: status=%s (%s) text=%s\",\n                         cmd_name, response.status_code, response.reason,\n                         response.text)\n            raise RESTError(response.status_code, response.reason,\n                            response_json, response.text, cmd_name)\n\n        logger.debug(\"%s response = %s\", cmd_name, json_pretty(response.text))\n\n        return response_json\n\n    def create_realm(self, realm_name):\n        cmd_name = \"create realm '{realm}'\".format(realm=realm_name)\n        url = CREATE_REALM_URL_TEMPLATE.format(server=self.server)\n\n        logger.debug(\"%s on server %s\", cmd_name, self.server)\n\n        params = {\"enabled\": True,\n                  \"id\": realm_name,\n                  \"realm\": realm_name,\n                  }\n\n        response = self.session.post(url, json=params)\n        logger.debug(\"%s response code: %s %s\",\n                     cmd_name, response.status_code, response.reason)\n\n        try:\n            response_json = response.json()\n        except ValueError as e:\n            response_json = None\n\n        if response.status_code != requests.codes.created:\n            logger.error(\"%s error: status=%s (%s) text=%s\",\n                         cmd_name, response.status_code, response.reason,\n                         response.text)\n            raise RESTError(response.status_code, response.reason,\n                            response_json, response.text, cmd_name)\n\n        logger.debug(\"%s response = %s\", cmd_name, response.text)\n\n    def delete_realm(self, realm_name):\n        cmd_name = \"delete realm '{realm}'\".format(realm=realm_name)\n        url = DELETE_REALM_URL_TEMPLATE.format(\n            server=self.server, realm=urlquote(realm_name))\n\n        logger.debug(\"%s on server %s\", cmd_name, self.server)\n        response = self.session.delete(url)\n        logger.debug(\"%s response code: %s %s\",\n                     cmd_name, response.status_code, response.reason)\n\n        try:\n            response_json = response.json()\n        except ValueError as e:\n            response_json = None\n\n        if response.status_code != requests.codes.no_content:\n            logger.error(\"%s error: status=%s (%s) text=%s\",\n                         cmd_name, response.status_code, response.reason,\n                         response.text)\n            raise RESTError(response.status_code, response.reason,\n                            response_json, response.text, cmd_name)\n\n        logger.debug(\"%s response = %s\", cmd_name, response.text)\n\n    def get_realm_metadata(self, realm_name):\n        cmd_name = \"get metadata for realm '{realm}'\".format(realm=realm_name)\n        url = GET_REALM_METADATA_TEMPLATE.format(\n            server=self.server, realm=urlquote(realm_name))\n\n        logger.debug(\"%s on server %s\", cmd_name, self.server)\n        response = self.session.get(url)\n        logger.debug(\"%s response code: %s %s\",\n                     cmd_name, response.status_code, response.reason)\n\n        try:\n            response_json = response.json()\n        except ValueError as e:\n            response_json = None\n\n        if response.status_code != requests.codes.ok:\n            logger.error(\"%s error: status=%s (%s) text=%s\",\n                         cmd_name, response.status_code, response.reason,\n                         response.text)\n            raise RESTError(response.status_code, response.reason,\n                            response_json, response.text, cmd_name)\n\n        logger.debug(\"%s response = %s\", cmd_name, response.text)\n        return response.text\n\n    def get_clients(self, realm_name):\n        cmd_name = \"get clients in realm '{realm}'\".format(realm=realm_name)\n        url = GET_CLIENTS_URL_TEMPLATE.format(\n            server=self.server, realm=urlquote(realm_name))\n\n        logger.debug(\"%s on server %s\", cmd_name, self.server)\n        response = self.session.get(url)\n        logger.debug(\"%s response code: %s %s\",\n                     cmd_name, response.status_code, response.reason)\n\n        try:\n            response_json = response.json()\n        except ValueError as e:\n            response_json = None\n\n        if (not response_json or\n            response.status_code != requests.codes.ok):\n            logger.error(\"%s error: status=%s (%s) text=%s\",\n                         cmd_name, response.status_code, response.reason,\n                         response.text)\n            raise RESTError(response.status_code, response.reason,\n                            response_json, response.text, cmd_name)\n\n        logger.debug(\"%s response = %s\", cmd_name, json_pretty(response.text))\n\n        return response_json\n\n\n    def get_client_by_id(self, realm_name, id):\n        cmd_name = \"get client id {id} in realm '{realm}'\".format(\n            id=id, realm=realm_name)\n        url = GET_CLIENTS_URL_TEMPLATE.format(\n            server=self.server, realm=urlquote(realm_name))\n\n        params = {'clientID': id}\n\n        logger.debug(\"%s on server %s\", cmd_name, self.server)\n        response = self.session.get(url, params=params)\n        logger.debug(\"%s response code: %s %s\",\n                     cmd_name, response.status_code, response.reason)\n\n        try:\n            response_json = response.json()\n        except ValueError as e:\n            response_json = None\n\n        if (not response_json or\n            response.status_code != requests.codes.ok):\n            logger.error(\"%s error: status=%s (%s) text=%s\",\n                         cmd_name, response.status_code, response.reason,\n                         response.text)\n            raise RESTError(response.status_code, response.reason,\n                            response_json, response.text, cmd_name)\n\n        logger.debug(\"%s response = %s\", cmd_name, json_pretty(response.text))\n\n        return response_json\n\n\n    def get_client_by_name(self, realm_name, client_name):\n        clients = self.get_clients(realm_name)\n        client = find_client_by_name(clients, client_name)\n        id = client.get('id')\n        logger.debug(\"client name '%s' mapped to id '%s'\",\n                     client_name, id)\n        logger.debug(\"client %s\\n%s\", client_name, py_json_pretty(client))\n        return client\n\n    def get_client_id_by_name(self, realm_name, client_name):\n        client = self.get_client_by_name(realm_name, client_name)\n        id = client.get('id')\n        return id\n\n    def get_client_descriptor(self, realm_name, metadata):\n        cmd_name = \"get client descriptor realm '{realm}'\".format(\n            realm=realm_name)\n        url = CLIENT_DESCRIPTOR_URL_TEMPLATE.format(\n            server=self.server, realm=urlquote(realm_name))\n\n        logger.debug(\"%s on server %s\", cmd_name, self.server)\n\n        headers = {'Content-Type': 'application/xml;charset=utf-8'}\n\n        response = self.session.post(url, headers=headers, data=metadata)\n        logger.debug(\"%s response code: %s %s\",\n                     cmd_name, response.status_code, response.reason)\n\n        try:\n            response_json = response.json()\n        except ValueError as e:\n            response_json = None\n\n        if (not response_json or\n            response.status_code != requests.codes.ok):\n            logger.error(\"%s error: status=%s (%s) text=%s\",\n                         cmd_name, response.status_code, response.reason,\n                         response.text)\n            raise RESTError(response.status_code, response.reason,\n                            response_json, response.text, cmd_name)\n\n        logger.debug(\"%s response = %s\", cmd_name, json_pretty(response.text))\n\n        return response_json\n\n    def create_client_from_descriptor(self, realm_name, descriptor):\n        cmd_name = \"create client from descriptor \"\n        \"'{client_id}'in realm '{realm}'\".format(\n            client_id=descriptor['clientId'], realm=realm_name)\n        url = CREATE_CLIENT_URL_TEMPLATE.format(\n            server=self.server, realm=urlquote(realm_name))\n\n        logger.debug(\"%s on server %s\", cmd_name, self.server)\n\n        response = self.session.post(url, json=descriptor)\n        logger.debug(\"%s response code: %s %s\",\n                     cmd_name, response.status_code, response.reason)\n\n        try:\n            response_json = response.json()\n        except ValueError as e:\n            response_json = None\n\n        if response.status_code != requests.codes.created:\n            logger.error(\"%s error: status=%s (%s) text=%s\",\n                         cmd_name, response.status_code, response.reason,\n                         response.text)\n            raise RESTError(response.status_code, response.reason,\n                            response_json, response.text, cmd_name)\n\n        logger.debug(\"%s response = %s\", cmd_name, response.text)\n\n    def create_client(self, realm_name, metadata):\n        logger.debug(\"create client in realm %s on server %s\",\n                     realm_name, self.server)\n        descriptor = self.get_client_descriptor(realm_name, metadata)\n        self.create_client_from_descriptor(realm_name, descriptor)\n        return descriptor\n\n    def register_client(self, initial_access_token, realm_name, metadata):\n        cmd_name = \"register_client realm '{realm}'\".format(\n            realm=realm_name)\n        url = SAML2_CLIENT_REGISTRATION_TEMPLATE.format(\n            server=self.server, realm=urlquote(realm_name))\n\n        logger.debug(\"%s on server %s\", cmd_name, self.server)\n\n        headers = {'Content-Type': 'application/xml;charset=utf-8'}\n\n        if initial_access_token:\n            headers['Authorization'] = 'Bearer {token}'.format(\n                token=initial_access_token)\n\n        response = self.session.post(url, headers=headers, data=metadata)\n        logger.debug(\"%s response code: %s %s\",\n                     cmd_name, response.status_code, response.reason)\n\n        try:\n            response_json = response.json()\n        except ValueError as e:\n            response_json = None\n\n        if (not response_json or\n            response.status_code != requests.codes.created):\n            logger.error(\"%s error: status=%s (%s) text=%s\",\n                         cmd_name, response.status_code, response.reason,\n                         response.text)\n            raise RESTError(response.status_code, response.reason,\n                            response_json, response.text, cmd_name)\n\n        logger.debug(\"%s response = %s\", cmd_name, json_pretty(response.text))\n\n        return response_json    # ClientRepresentation\n\n    def delete_client_by_name(self, realm_name, client_name):\n        id = self.get_client_id_by_name(realm_name, client_name)\n        self.delete_client_by_id(realm_name, id)\n\n\n    def delete_client_by_id(self, realm_name, id):\n        cmd_name = \"delete client id '{id}'in realm '{realm}'\".format(\n            id=id, realm=realm_name)\n        url = CLIENT_REPRESENTATION_TEMPLATE.format(\n            server=self.server, realm=urlquote(realm_name),\n            id=urlquote(id))\n\n        logger.debug(\"%s on server %s\", cmd_name, self.server)\n        response = self.session.delete(url)\n        logger.debug(\"%s response code: %s %s\",\n                     cmd_name, response.status_code, response.reason)\n\n        try:\n            response_json = response.json()\n        except ValueError as e:\n            response_json = None\n\n        if response.status_code != requests.codes.no_content:\n            logger.error(\"%s error: status=%s (%s) text=%s\",\n                         cmd_name, response.status_code, response.reason,\n                         response.text)\n            raise RESTError(response.status_code, response.reason,\n                            response_json, response.text, cmd_name)\n\n        logger.debug(\"%s response = %s\", cmd_name, response.text)\n\n    def update_client(self, realm_name, client):\n        id = client['id']\n        cmd_name = \"update client {id} in realm '{realm}'\".format(\n            id=client['clientId'], realm=realm_name)\n        url = CLIENT_REPRESENTATION_TEMPLATE.format(\n            server=self.server, realm=urlquote(realm_name),\n            id=urlquote(id))\n\n        logger.debug(\"%s on server %s\", cmd_name, self.server)\n\n        response = self.session.put(url, json=client)\n        logger.debug(\"%s response code: %s %s\",\n                     cmd_name, response.status_code, response.reason)\n\n        try:\n            response_json = response.json()\n        except ValueError as e:\n            response_json = None\n\n        if response.status_code != requests.codes.no_content:\n            logger.error(\"%s error: status=%s (%s) text=%s\",\n                         cmd_name, response.status_code, response.reason,\n                         response.text)\n            raise RESTError(response.status_code, response.reason,\n                            response_json, response.text, cmd_name)\n\n        logger.debug(\"%s response = %s\", cmd_name, response.text)\n\n\n    def update_client_attributes(self, realm_name, client, update_attrs):\n        client_id = client['clientId']\n        logger.debug(\"update client attrs: client_id=%s \"\n        \"current attrs=%s update=%s\" % (client_id, client['attributes'],\n                                update_attrs))\n        client['attributes'].update(update_attrs)\n        logger.debug(\"update client attrs: client_id=%s \"\n        \"new attrs=%s\" % (client_id, client['attributes']))\n        self.update_client(realm_name, client);\n\n\n    def update_client_by_name_attributes(self, realm_name, client_name,\n                                         update_attrs):\n        client = self.get_client_by_name(realm_name, client_name)\n        self.update_client_attributes(realm_name, client, update_attrs)\n\n    def new_saml_group_protocol_mapper(self, mapper_name, attribute_name,\n                                       friendly_name=None,\n                                       single_attribute=True):\n        mapper = {\n            'protocol': 'saml',\n            'name': mapper_name,\n            'protocolMapper': 'saml-group-membership-mapper',\n            'config': {\n                'attribute.name': attribute_name,\n                'attribute.nameformat': 'Basic',\n                'single': single_attribute,\n                'full.path': False,\n            },\n        }\n\n        if friendly_name:\n            mapper['config']['friendly.name'] = friendly_name\n\n        return mapper\n\n    def create_client_protocol_mapper(self, realm_name, client, mapper):\n        id = client['id']\n        cmd_name = (\"create protocol-mapper '{mapper_name}' for client {id} \"\n                    \"in realm '{realm}'\".format(\n                        mapper_name=mapper['name'],id=client['clientId'], realm=realm_name))\n        url = POST_CLIENT_PROTOCOL_MAPPER_TEMPLATE.format(\n            server=self.server,\n            realm=urlquote(realm_name),\n            id=urlquote(id))\n\n        logger.debug(\"%s on server %s\", cmd_name, self.server)\n\n        response = self.session.post(url, json=mapper)\n        logger.debug(\"%s response code: %s %s\",\n                     cmd_name, response.status_code, response.reason)\n\n        try:\n            response_json = response.json()\n        except ValueError as e:\n            response_json = None\n\n        if response.status_code != requests.codes.created:\n            logger.error(\"%s error: status=%s (%s) text=%s\",\n                         cmd_name, response.status_code, response.reason,\n                         response.text)\n            raise RESTError(response.status_code, response.reason,\n                            response_json, response.text, cmd_name)\n\n        logger.debug(\"%s response = %s\", cmd_name, response.text)\n\n\n    def create_client_by_name_protocol_mapper(self, realm_name, client_name,\n                                              mapper):\n        client = self.get_client_by_name(realm_name, client_name)\n        self.create_client_protocol_mapper(realm_name, client, mapper)\n\n\n\n    def add_client_by_name_redirect_uris(self, realm_name, client_name, uris):\n        client = self.get_client_by_name(realm_name, client_name)\n\n        uris = set(uris)\n        redirect_uris = set(client['redirectUris'])\n        redirect_uris |= uris\n        client['redirectUris'] = list(redirect_uris)\n        self.update_client(realm_name, client);\n\n    def remove_client_by_name_redirect_uris(self, realm_name, client_name, uris):\n        client = self.get_client_by_name(realm_name, client_name)\n\n        uris = set(uris)\n        redirect_uris = set(client['redirectUris'])\n        redirect_uris -= uris\n        client['redirectUris'] = list(redirect_uris)\n\n        self.update_client(realm_name, client);\n\n\n# ------------------------------------------------------------------------------\n\n\nclass KeycloakAdminConnection(KeycloakREST):\n\n    def __init__(self, server, auth_role, realm, client_id,\n                 username, password, tls_verify):\n        super(KeycloakAdminConnection, self).__init__(server, auth_role)\n\n        self.realm = realm\n        self.client_id = client_id\n        self.username = username\n        self.password = password\n\n        self.session = self._create_session(tls_verify)\n\n    def _create_session(self, tls_verify):\n        token_url = TOKEN_URL_TEMPLATE.format(\n            server=self.server, realm=urlquote(self.realm))\n        refresh_url = token_url\n\n        client = LegacyApplicationClient(client_id=self.client_id)\n        session = OAuth2Session(client=client,\n                                auto_refresh_url=refresh_url,\n                                auto_refresh_kwargs={\n                                    'client_id': self.client_id})\n\n        session.verify = tls_verify\n        token = session.fetch_token(token_url=token_url,\n                                    username=self.username,\n                                    password=self.password,\n                                    client_id=self.client_id,\n                                    verify=session.verify)\n\n        return session\n\n\nclass KeycloakAnonymousConnection(KeycloakREST):\n\n    def __init__(self, server, tls_verify):\n        super(KeycloakAnonymousConnection, self).__init__(server, 'anonymous')\n        self.session = self._create_session(tls_verify)\n\n\n    def _create_session(self, tls_verify):\n        session = requests.Session()\n        session.verify = tls_verify\n\n        return session\n\n# ------------------------------------------------------------------------------\n\n\ndef do_server_info(options, conn):\n    server_info = conn.get_server_info()\n    print(json_pretty(server_info))\n\n\ndef do_list_realms(options, conn):\n    realms = conn.get_realms()\n    realm_names = get_realm_names_from_realms(realms)\n    print('\\n'.join(sorted(realm_names)))\n\n\ndef do_create_realm(options, conn):\n    conn.create_realm(options.realm_name)\n\n\ndef do_delete_realm(options, conn):\n    conn.delete_realm(options.realm_name)\n\n\ndef do_get_realm_metadata(options, conn):\n    metadata = conn.get_realm_metadata(options.realm_name)\n    print(metadata)\n\n\ndef do_list_clients(options, conn):\n    clients = conn.get_clients(options.realm_name)\n    client_ids = get_client_client_ids_from_clients(clients)\n    print('\\n'.join(sorted(client_ids)))\n\n\ndef do_create_client(options, conn):\n    metadata = options.metadata.read()\n    descriptor = conn.create_client(options.realm_name, metadata)\n\n\ndef do_register_client(options, conn):\n    metadata = options.metadata.read()\n    client_representation = conn.register_client(\n        options.initial_access_token,\n        options.realm_name, metadata)\n\n\ndef do_delete_client(options, conn):\n    conn.delete_client_by_name(options.realm_name, options.client_name)\n\ndef do_client_test(options, conn):\n    'experimental test code used during development'\n\n    uri = 'https://openstack.jdennis.oslab.test:5000/v3/mellon/fooResponse'\n\n    conn.remove_client_by_name_redirect_uri(options.realm_name,\n                                            options.client_name,\n                                            uri)\n\n# ------------------------------------------------------------------------------\n\nverbose_help = '''\n\nThe structure of the command line arguments is \"noun verb\" where noun\nis one of Keycloak's data items (e.g. realm, client, etc.) and the\nverb is an action to perform on the item. Each of the nouns and verbs\nmay have their own set of arguments which must follow the noun or\nverb.\n\nFor example to delete the client XYZ in the realm ABC:\n\necho password | {prog_name} -s http://example.com:8080 -P - client delete -r ABC -c XYZ\n\nwhere 'client' is the noun, 'delete' is the verb and -r ABC -c XYZ are\narguments to the delete action.\n\nIf the command completes successfully the exit status is 0. The exit\nstatus is 1 if an authenticated connection with the server cannont be\nsuccessfully established. The exit status is 2 if the REST operation\nfails.\n\nThe server should be a scheme://hostname:port URL.\n'''\n\n\nclass TlsVerifyAction(argparse.Action):\n    def __init__(self, option_strings, dest, nargs=None, **kwargs):\n        if nargs is not None:\n            raise ValueError(\"nargs not allowed\")\n        super(TlsVerifyAction, self).__init__(option_strings, dest, **kwargs)\n\n    def __call__(self, parser, namespace, values, option_string=None):\n        if values.lower() in ['true', 'yes', 'on']:\n            verify = True\n        elif values.lower() in ['false', 'no', 'off']:\n            verify = False\n        else:\n            verify = values\n            \n        setattr(namespace, self.dest, verify)\n\ndef main():\n    global logger\n    result = 0\n\n    parser = argparse.ArgumentParser(description='Keycloak REST client',\n                    prog=prog_name,\n                    epilog=verbose_help.format(prog_name=prog_name),\n                    formatter_class=argparse.RawDescriptionHelpFormatter)\n\n    parser.add_argument('-v', '--verbose', action='store_true',\n                        help='be chatty')\n\n    parser.add_argument('-d', '--debug', action='store_true',\n                        help='turn on debug info')\n\n    parser.add_argument('--show-traceback', action='store_true',\n                        help='exceptions print traceback in addition to '\n                             'error message')\n\n    parser.add_argument('--log-file',\n                        default='/tmp/{prog_name}.log'.format(\n                            prog_name=prog_name),\n                        help='log file pathname')\n\n    parser.add_argument('--permit-insecure-transport',  action='store_true',\n                        help='Normally secure transport such as TLS '\n                        'is required, defeat this check')\n\n    parser.add_argument('--tls-verify', action=TlsVerifyAction,\n                        default=True,\n                        help='TLS certificate verification for requests to'\n                        ' the server. May be one of case insenstive '\n                        '[true, yes, on] to enable,'\n                        '[false, no, off] to disable.'\n                        'Or the pathname to a OpenSSL CA bundle to use.'\n                        ' Default is True.')\n\n    group = parser.add_argument_group('Server')\n\n    group.add_argument('-s', '--server',\n                       required=True,\n                       help='DNS name or IP address of Keycloak server')\n\n    group.add_argument('-a', '--auth-role',\n                       choices=AUTH_ROLES,\n                       default='root-admin',\n                       help='authenticating as what type of user (default: root-admin)')\n\n    group.add_argument('-u', '--admin-username',\n                       default='admin',\n                       help='admin user name (default: admin)')\n\n    group.add_argument('-P', '--admin-password-file',\n                       type=argparse.FileType('rb'),\n                       help=('file containing admin password '\n                             '(or use a hyphen \"-\" to read the password '\n                             'from stdin)'))\n\n    group.add_argument('--admin-realm',\n                       default='master',\n                       help='realm admin belongs to')\n\n    cmd_parsers = parser.add_subparsers(help='available commands')\n\n    # --- realm commands ---\n    realm_parser = cmd_parsers.add_parser('realm',\n                                          help='realm operations')\n\n    sub_parser = realm_parser.add_subparsers(help='realm commands')\n\n    cmd_parser = sub_parser.add_parser('server_info',\n                                       help='dump server info')\n    cmd_parser.set_defaults(func=do_server_info)\n\n    cmd_parser = sub_parser.add_parser('list',\n                                       help='list realm names')\n    cmd_parser.set_defaults(func=do_list_realms)\n\n    cmd_parser = sub_parser.add_parser('create',\n                                       help='create new realm')\n    cmd_parser.add_argument('-r', '--realm-name', required=True,\n                            help='realm name')\n    cmd_parser.set_defaults(func=do_create_realm)\n\n    cmd_parser = sub_parser.add_parser('delete',\n                                       help='delete existing realm')\n    cmd_parser.add_argument('-r', '--realm-name', required=True,\n                            help='realm name')\n    cmd_parser.set_defaults(func=do_delete_realm)\n\n    cmd_parser = sub_parser.add_parser('metadata',\n                                       help='retrieve realm metadata')\n    cmd_parser.add_argument('-r', '--realm-name', required=True,\n                            help='realm name')\n    cmd_parser.set_defaults(func=do_get_realm_metadata)\n\n    # --- client commands ---\n    client_parser = cmd_parsers.add_parser('client',\n                                           help='client operations')\n\n    sub_parser = client_parser.add_subparsers(help='client commands')\n\n    cmd_parser = sub_parser.add_parser('list',\n                                       help='list client names')\n    cmd_parser.add_argument('-r', '--realm-name', required=True,\n                            help='realm name')\n\n    cmd_parser.set_defaults(func=do_list_clients)\n\n    cmd_parser = sub_parser.add_parser('create',\n                                       help='create new client')\n    cmd_parser.add_argument('-r', '--realm-name', required=True,\n                            help='realm name')\n    cmd_parser.add_argument('-m', '--metadata', type=argparse.FileType('rb'),\n                            required=True,\n                            help='SP metadata file or stdin')\n    cmd_parser.set_defaults(func=do_create_client)\n\n    cmd_parser = sub_parser.add_parser('register',\n                                       help='register new client')\n    cmd_parser.add_argument('-r', '--realm-name', required=True,\n                            help='realm name')\n    cmd_parser.add_argument('-m', '--metadata', type=argparse.FileType('rb'),\n                            required=True,\n                            help='SP metadata file or stdin')\n    cmd_parser.add_argument('--initial-access-token', required=True,\n                            help='realm initial access token for '\n                            'client registeration')\n    cmd_parser.set_defaults(func=do_register_client)\n\n    cmd_parser = sub_parser.add_parser('delete',\n                                       help='delete existing client')\n    cmd_parser.add_argument('-r', '--realm-name', required=True,\n                            help='realm name')\n    cmd_parser.add_argument('-c', '--client-name', required=True,\n                            help='client name')\n    cmd_parser.set_defaults(func=do_delete_client)\n\n    cmd_parser = sub_parser.add_parser('test',\n                                       help='experimental test used during '\n                                       'development')\n    cmd_parser.add_argument('-r', '--realm-name', required=True,\n                            help='realm name')\n    cmd_parser.add_argument('-c', '--client-name', required=True,\n                            help='client name')\n    cmd_parser.set_defaults(func=do_client_test)\n\n    # Process command line arguments\n    options = parser.parse_args()\n    configure_logging(options)\n\n    if options.permit_insecure_transport:\n        os.environ['OAUTHLIB_INSECURE_TRANSPORT'] = '1'\n\n    # Get admin password\n    options.admin_password = None\n\n    # 1. Try password file\n    if options.admin_password_file is not None:\n        options.admin_password = options.keycloak_admin_password_file.readline().strip()\n        options.keycloak_admin_password_file.close()\n\n    # 2. Try KEYCLOAK_ADMIN_PASSWORD environment variable\n    if options.admin_password is None:\n        if (('KEYCLOAK_ADMIN_PASSWORD' in os.environ) and\n            (os.environ['KEYCLOAK_ADMIN_PASSWORD'])):\n            options.admin_password = os.environ['KEYCLOAK_ADMIN_PASSWORD']\n\n    try:\n        anonymous_conn = KeycloakAnonymousConnection(options.server,\n                                                     options.tls_verify)\n\n        admin_conn = KeycloakAdminConnection(options.server,\n                                             options.auth_role,\n                                             options.admin_realm,\n                                             ADMIN_CLIENT_ID,\n                                             options.admin_username,\n                                             options.admin_password,\n                                             options.tls_verify)\n    except Exception as e:\n        if options.show_traceback:\n            traceback.print_exc()\n        print(six.text_type(e), file=sys.stderr)\n        result = 1\n        return result\n\n    try:\n        if options.func == do_register_client:\n            conn = admin_conn\n        else:\n            conn = admin_conn\n        result = options.func(options, conn)\n    except Exception as e:\n        if options.show_traceback:\n            traceback.print_exc()\n        print(six.text_type(e), file=sys.stderr)\n        result = 2\n        return result\n\n    return result\n\n# ------------------------------------------------------------------------------\n\nif __name__ == '__main__':\n    sys.exit(main())\nelse:\n    logger = logging.getLogger('keycloak-cli')\n", "target": 0}
{"idx": 901, "func": "# Copyright (c) 2010-2012 OpenStack, LLC.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n# implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport os\nfrom ConfigParser import ConfigParser, NoSectionError, NoOptionError\n\nfrom swift.common.memcached import MemcacheRing\n\n\nclass MemcacheMiddleware(object):\n    \"\"\"\n    Caching middleware that manages caching in swift.\n    \"\"\"\n\n    def __init__(self, app, conf):\n        self.app = app\n        self.memcache_servers = conf.get('memcache_servers')\n        if not self.memcache_servers:\n            path = os.path.join(conf.get('swift_dir', '/etc/swift'),\n                                'memcache.conf')\n            memcache_conf = ConfigParser()\n            if memcache_conf.read(path):\n                try:\n                    self.memcache_servers = \\\n                        memcache_conf.get('memcache', 'memcache_servers')\n                except (NoSectionError, NoOptionError):\n                    pass\n        if not self.memcache_servers:\n            self.memcache_servers = '127.0.0.1:11211'\n        self.memcache = MemcacheRing(\n            [s.strip() for s in self.memcache_servers.split(',') if s.strip()])\n\n    def __call__(self, env, start_response):\n        env['swift.cache'] = self.memcache\n        return self.app(env, start_response)\n\n\ndef filter_factory(global_conf, **local_conf):\n    conf = global_conf.copy()\n    conf.update(local_conf)\n\n    def cache_filter(app):\n        return MemcacheMiddleware(app, conf)\n\n    return cache_filter\n", "target": 1}
{"idx": 902, "func": "# vim: tabstop=4 shiftwidth=4 softtabstop=4\n\n# Copyright 2012 OpenStack LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"); you may\n# not use this file except in compliance with the License. You may obtain\n# a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n# License for the specific language governing permissions and limitations\n# under the License.\n\n\"\"\"Main entry point into the Identity service.\"\"\"\n\nimport uuid\nimport urllib\nimport urlparse\n\nfrom keystone import config\nfrom keystone import exception\nfrom keystone import policy\nfrom keystone import token\nfrom keystone.common import logging\nfrom keystone.common import manager\nfrom keystone.common import wsgi\n\n\nCONF = config.CONF\n\nLOG = logging.getLogger(__name__)\n\n\nclass Manager(manager.Manager):\n    \"\"\"Default pivot point for the Identity backend.\n\n    See :mod:`keystone.common.manager.Manager` for more details on how this\n    dynamically calls the backend.\n\n    \"\"\"\n\n    def __init__(self):\n        super(Manager, self).__init__(CONF.identity.driver)\n\n\nclass Driver(object):\n    \"\"\"Interface description for an Identity driver.\"\"\"\n\n    def authenticate(self, user_id=None, tenant_id=None, password=None):\n        \"\"\"Authenticate a given user, tenant and password.\n\n        Returns: (user, tenant, metadata).\n\n        \"\"\"\n        raise exception.NotImplemented()\n\n    def get_tenant(self, tenant_id):\n        \"\"\"Get a tenant by id.\n\n        Returns: tenant_ref or None.\n\n        \"\"\"\n        raise exception.NotImplemented()\n\n    def get_tenant_by_name(self, tenant_name):\n        \"\"\"Get a tenant by name.\n\n        Returns: tenant_ref or None.\n\n        \"\"\"\n        raise exception.NotImplemented()\n\n    def get_user(self, user_id):\n        \"\"\"Get a user by id.\n\n        Returns: user_ref or None.\n\n        \"\"\"\n        raise exception.NotImplemented()\n\n    def get_user_by_name(self, user_name):\n        \"\"\"Get a user by name.\n\n        Returns: user_ref or None.\n\n        \"\"\"\n        raise exception.NotImplemented()\n\n    def get_role(self, role_id):\n        \"\"\"Get a role by id.\n\n        Returns: role_ref or None.\n\n        \"\"\"\n        raise exception.NotImplemented()\n\n    def list_users(self):\n        \"\"\"List all users in the system.\n\n        NOTE(termie): I'd prefer if this listed only the users for a given\n                      tenant.\n\n        Returns: a list of user_refs or an empty list.\n\n        \"\"\"\n        raise exception.NotImplemented()\n\n    def list_roles(self):\n        \"\"\"List all roles in the system.\n\n        Returns: a list of role_refs or an empty list.\n\n        \"\"\"\n        raise exception.NotImplemented()\n\n    # NOTE(termie): seven calls below should probably be exposed by the api\n    #               more clearly when the api redesign happens\n    def add_user_to_tenant(self, tenant_id, user_id):\n        raise exception.NotImplemented()\n\n    def remove_user_from_tenant(self, tenant_id, user_id):\n        raise exception.NotImplemented()\n\n    def get_all_tenants(self):\n        raise exception.NotImplemented()\n\n    def get_tenants_for_user(self, user_id):\n        \"\"\"Get the tenants associated with a given user.\n\n        Returns: a list of tenant ids.\n\n        \"\"\"\n        raise exception.NotImplemented()\n\n    def get_roles_for_user_and_tenant(self, user_id, tenant_id):\n        \"\"\"Get the roles associated with a user within given tenant.\n\n        Returns: a list of role ids.\n\n        \"\"\"\n        raise exception.NotImplemented()\n\n    def add_role_to_user_and_tenant(self, user_id, tenant_id, role_id):\n        \"\"\"Add a role to a user within given tenant.\"\"\"\n        raise exception.NotImplemented()\n\n    def remove_role_from_user_and_tenant(self, user_id, tenant_id, role_id):\n        \"\"\"Remove a role from a user within given tenant.\"\"\"\n        raise exception.NotImplemented()\n\n    # user crud\n    def create_user(self, user_id, user):\n        raise exception.NotImplemented()\n\n    def update_user(self, user_id, user):\n        raise exception.NotImplemented()\n\n    def delete_user(self, user_id):\n        raise exception.NotImplemented()\n\n    # tenant crud\n    def create_tenant(self, tenant_id, tenant):\n        raise exception.NotImplemented()\n\n    def update_tenant(self, tenant_id, tenant):\n        raise exception.NotImplemented()\n\n    def delete_tenant(self, tenant_id, tenant):\n        raise exception.NotImplemented()\n\n    # metadata crud\n\n    def get_metadata(self, user_id, tenant_id):\n        raise exception.NotImplemented()\n\n    def create_metadata(self, user_id, tenant_id, metadata):\n        raise exception.NotImplemented()\n\n    def update_metadata(self, user_id, tenant_id, metadata):\n        raise exception.NotImplemented()\n\n    def delete_metadata(self, user_id, tenant_id, metadata):\n        raise exception.NotImplemented()\n\n    # role crud\n    def create_role(self, role_id, role):\n        raise exception.NotImplemented()\n\n    def update_role(self, role_id, role):\n        raise exception.NotImplemented()\n\n    def delete_role(self, role_id):\n        raise exception.NotImplemented()\n\n\nclass PublicRouter(wsgi.ComposableRouter):\n    def add_routes(self, mapper):\n        tenant_controller = TenantController()\n        mapper.connect('/tenants',\n                       controller=tenant_controller,\n                       action='get_tenants_for_token',\n                       conditions=dict(methods=['GET']))\n\n\nclass AdminRouter(wsgi.ComposableRouter):\n    def add_routes(self, mapper):\n        # Tenant Operations\n        tenant_controller = TenantController()\n        mapper.connect('/tenants',\n                       controller=tenant_controller,\n                       action='get_all_tenants',\n                       conditions=dict(method=['GET']))\n        mapper.connect('/tenants/{tenant_id}',\n                       controller=tenant_controller,\n                       action='get_tenant',\n                       conditions=dict(method=['GET']))\n\n        # User Operations\n        user_controller = UserController()\n        mapper.connect('/users/{user_id}',\n                       controller=user_controller,\n                       action='get_user',\n                       conditions=dict(method=['GET']))\n\n        # Role Operations\n        roles_controller = RoleController()\n        mapper.connect('/tenants/{tenant_id}/users/{user_id}/roles',\n                       controller=roles_controller,\n                       action='get_user_roles',\n                       conditions=dict(method=['GET']))\n        mapper.connect('/users/{user_id}/roles',\n                       controller=user_controller,\n                       action='get_user_roles',\n                       conditions=dict(method=['GET']))\n\n\nclass TenantController(wsgi.Application):\n    def __init__(self):\n        self.identity_api = Manager()\n        self.policy_api = policy.Manager()\n        self.token_api = token.Manager()\n        super(TenantController, self).__init__()\n\n    def get_all_tenants(self, context, **kw):\n        \"\"\"Gets a list of all tenants for an admin user.\"\"\"\n        self.assert_admin(context)\n        tenant_refs = self.identity_api.get_tenants(context)\n        params = {\n            'limit': context['query_string'].get('limit'),\n            'marker': context['query_string'].get('marker'),\n        }\n        return self._format_tenant_list(tenant_refs, **params)\n\n    def get_tenants_for_token(self, context, **kw):\n        \"\"\"Get valid tenants for token based on token used to authenticate.\n\n        Pulls the token from the context, validates it and gets the valid\n        tenants for the user in the token.\n\n        Doesn't care about token scopedness.\n\n        \"\"\"\n        try:\n            token_ref = self.token_api.get_token(context=context,\n                                                 token_id=context['token_id'])\n        except exception.NotFound:\n            raise exception.Unauthorized()\n\n        user_ref = token_ref['user']\n        tenant_ids = self.identity_api.get_tenants_for_user(\n                context, user_ref['id'])\n        tenant_refs = []\n        for tenant_id in tenant_ids:\n            tenant_refs.append(self.identity_api.get_tenant(\n                    context=context,\n                    tenant_id=tenant_id))\n        params = {\n            'limit': context['query_string'].get('limit'),\n            'marker': context['query_string'].get('marker'),\n        }\n        return self._format_tenant_list(tenant_refs, **params)\n\n    def get_tenant(self, context, tenant_id):\n        # TODO(termie): this stuff should probably be moved to middleware\n        self.assert_admin(context)\n        tenant = self.identity_api.get_tenant(context, tenant_id)\n        if tenant is None:\n            raise exception.TenantNotFound(tenant_id=tenant_id)\n\n        return {'tenant': tenant}\n\n    # CRUD Extension\n    def create_tenant(self, context, tenant):\n        tenant_ref = self._normalize_dict(tenant)\n        self.assert_admin(context)\n        tenant_id = (tenant_ref.get('id')\n                     and tenant_ref.get('id')\n                     or uuid.uuid4().hex)\n        tenant_ref['id'] = tenant_id\n\n        tenant = self.identity_api.create_tenant(\n                context, tenant_id, tenant_ref)\n        return {'tenant': tenant}\n\n    def update_tenant(self, context, tenant_id, tenant):\n        self.assert_admin(context)\n        if self.identity_api.get_tenant(context, tenant_id) is None:\n            raise exception.TenantNotFound(tenant_id=tenant_id)\n\n        tenant_ref = self.identity_api.update_tenant(\n                context, tenant_id, tenant)\n        return {'tenant': tenant_ref}\n\n    def delete_tenant(self, context, tenant_id, **kw):\n        self.assert_admin(context)\n        if self.identity_api.get_tenant(context, tenant_id) is None:\n            raise exception.TenantNotFound(tenant_id=tenant_id)\n\n        self.identity_api.delete_tenant(context, tenant_id)\n\n    def get_tenant_users(self, context, tenant_id, **kw):\n        self.assert_admin(context)\n        if self.identity_api.get_tenant(context, tenant_id) is None:\n            raise exception.TenantNotFound(tenant_id=tenant_id)\n\n        user_refs = self.identity_api.get_tenant_users(context, tenant_id)\n        return {'users': user_refs}\n\n    def _format_tenant_list(self, tenant_refs, **kwargs):\n        marker = kwargs.get('marker')\n        page_idx = 0\n        if marker is not None:\n            for (marker_idx, tenant) in enumerate(tenant_refs):\n                if tenant['id'] == marker:\n                    # we start pagination after the marker\n                    page_idx = marker_idx + 1\n                    break\n            else:\n                msg = 'Marker could not be found'\n                raise exception.ValidationError(message=msg)\n\n        limit = kwargs.get('limit')\n        if limit is not None:\n            try:\n                limit = int(limit)\n                if limit < 0:\n                    raise AssertionError()\n            except (ValueError, AssertionError):\n                msg = 'Invalid limit value'\n                raise exception.ValidationError(message=msg)\n\n        tenant_refs = tenant_refs[page_idx:limit]\n\n        for x in tenant_refs:\n            if 'enabled' not in x:\n                x['enabled'] = True\n        o = {'tenants': tenant_refs,\n             'tenants_links': []}\n        return o\n\n\nclass UserController(wsgi.Application):\n    def __init__(self):\n        self.identity_api = Manager()\n        self.policy_api = policy.Manager()\n        self.token_api = token.Manager()\n        super(UserController, self).__init__()\n\n    def get_user(self, context, user_id):\n        self.assert_admin(context)\n        user_ref = self.identity_api.get_user(context, user_id)\n        if not user_ref:\n            raise exception.UserNotFound(user_id=user_id)\n\n        return {'user': user_ref}\n\n    def get_users(self, context):\n        # NOTE(termie): i can't imagine that this really wants all the data\n        #               about every single user in the system...\n        self.assert_admin(context)\n        user_refs = self.identity_api.list_users(context)\n        return {'users': user_refs}\n\n    # CRUD extension\n    def create_user(self, context, user):\n        user = self._normalize_dict(user)\n        self.assert_admin(context)\n        tenant_id = user.get('tenantId', None)\n        if (tenant_id is not None\n                and self.identity_api.get_tenant(context, tenant_id) is None):\n            raise exception.TenantNotFound(tenant_id=tenant_id)\n        user_id = uuid.uuid4().hex\n        user_ref = user.copy()\n        user_ref['id'] = user_id\n        new_user_ref = self.identity_api.create_user(\n                context, user_id, user_ref)\n        if tenant_id:\n            self.identity_api.add_user_to_tenant(context, tenant_id, user_id)\n        return {'user': new_user_ref}\n\n    def update_user(self, context, user_id, user):\n        # NOTE(termie): this is really more of a patch than a put\n        self.assert_admin(context)\n        if self.identity_api.get_user(context, user_id) is None:\n            raise exception.UserNotFound(user_id=user_id)\n\n        user_ref = self.identity_api.update_user(context, user_id, user)\n\n        # If the password was changed or the user was disabled we clear tokens\n        if user.get('password') or user.get('enabled', True) == False:\n            try:\n                for token_id in self.token_api.list_tokens(context, user_id):\n                    self.token_api.delete_token(context, token_id)\n            except exception.NotImplemented:\n                # The users status has been changed but tokens remain valid for\n                # backends that can't list tokens for users\n                LOG.warning('User %s status has changed, but existing tokens '\n                            'remain valid' % user_id)\n        return {'user': user_ref}\n\n    def delete_user(self, context, user_id):\n        self.assert_admin(context)\n        if self.identity_api.get_user(context, user_id) is None:\n            raise exception.UserNotFound(user_id=user_id)\n\n        self.identity_api.delete_user(context, user_id)\n\n    def set_user_enabled(self, context, user_id, user):\n        return self.update_user(context, user_id, user)\n\n    def set_user_password(self, context, user_id, user):\n        return self.update_user(context, user_id, user)\n\n    def update_user_tenant(self, context, user_id, user):\n        \"\"\"Update the default tenant.\"\"\"\n        # ensure that we're a member of that tenant\n        tenant_id = user.get('tenantId')\n        self.identity_api.add_user_to_tenant(context, tenant_id, user_id)\n        return self.update_user(context, user_id, user)\n\n\nclass RoleController(wsgi.Application):\n    def __init__(self):\n        self.identity_api = Manager()\n        self.token_api = token.Manager()\n        self.policy_api = policy.Manager()\n        super(RoleController, self).__init__()\n\n    # COMPAT(essex-3)\n    def get_user_roles(self, context, user_id, tenant_id=None):\n        \"\"\"Get the roles for a user and tenant pair.\n\n        Since we're trying to ignore the idea of user-only roles we're\n        not implementing them in hopes that the idea will die off.\n\n        \"\"\"\n        self.assert_admin(context)\n        if tenant_id is None:\n            raise exception.NotImplemented(message='User roles not supported: '\n                                                   'tenant ID required')\n\n        user = self.identity_api.get_user(context, user_id)\n        if user is None:\n            raise exception.UserNotFound(user_id=user_id)\n        tenant = self.identity_api.get_tenant(context, tenant_id)\n        if tenant is None:\n            raise exception.TenantNotFound(tenant_id=tenant_id)\n\n        roles = self.identity_api.get_roles_for_user_and_tenant(\n                context, user_id, tenant_id)\n        return {'roles': [self.identity_api.get_role(context, x)\n                          for x in roles]}\n\n    # CRUD extension\n    def get_role(self, context, role_id):\n        self.assert_admin(context)\n        role_ref = self.identity_api.get_role(context, role_id)\n        if not role_ref:\n            raise exception.RoleNotFound(role_id=role_id)\n        return {'role': role_ref}\n\n    def create_role(self, context, role):\n        role = self._normalize_dict(role)\n        self.assert_admin(context)\n        role_id = uuid.uuid4().hex\n        role['id'] = role_id\n        role_ref = self.identity_api.create_role(context, role_id, role)\n        return {'role': role_ref}\n\n    def delete_role(self, context, role_id):\n        self.assert_admin(context)\n        self.get_role(context, role_id)\n        self.identity_api.delete_role(context, role_id)\n\n    def get_roles(self, context):\n        self.assert_admin(context)\n        roles = self.identity_api.list_roles(context)\n        # TODO(termie): probably inefficient at some point\n        return {'roles': roles}\n\n    def add_role_to_user(self, context, user_id, role_id, tenant_id=None):\n        \"\"\"Add a role to a user and tenant pair.\n\n        Since we're trying to ignore the idea of user-only roles we're\n        not implementing them in hopes that the idea will die off.\n\n        \"\"\"\n        self.assert_admin(context)\n        if tenant_id is None:\n            raise exception.NotImplemented(message='User roles not supported: '\n                                                   'tenant_id required')\n        if self.identity_api.get_user(context, user_id) is None:\n            raise exception.UserNotFound(user_id=user_id)\n        if self.identity_api.get_tenant(context, tenant_id) is None:\n            raise exception.TenantNotFound(tenant_id=tenant_id)\n        if self.identity_api.get_role(context, role_id) is None:\n            raise exception.RoleNotFound(role_id=role_id)\n\n        # This still has the weird legacy semantics that adding a role to\n        # a user also adds them to a tenant\n        self.identity_api.add_user_to_tenant(context, tenant_id, user_id)\n        self.identity_api.add_role_to_user_and_tenant(\n                context, user_id, tenant_id, role_id)\n        role_ref = self.identity_api.get_role(context, role_id)\n        return {'role': role_ref}\n\n    def remove_role_from_user(self, context, user_id, role_id, tenant_id=None):\n        \"\"\"Remove a role from a user and tenant pair.\n\n        Since we're trying to ignore the idea of user-only roles we're\n        not implementing them in hopes that the idea will die off.\n\n        \"\"\"\n        self.assert_admin(context)\n        if tenant_id is None:\n            raise exception.NotImplemented(message='User roles not supported: '\n                                                   'tenant_id required')\n        if self.identity_api.get_user(context, user_id) is None:\n            raise exception.UserNotFound(user_id=user_id)\n        if self.identity_api.get_tenant(context, tenant_id) is None:\n            raise exception.TenantNotFound(tenant_id=tenant_id)\n        if self.identity_api.get_role(context, role_id) is None:\n            raise exception.RoleNotFound(role_id=role_id)\n\n        # This still has the weird legacy semantics that adding a role to\n        # a user also adds them to a tenant, so we must follow up on that\n        self.identity_api.remove_role_from_user_and_tenant(\n                context, user_id, tenant_id, role_id)\n        roles = self.identity_api.get_roles_for_user_and_tenant(\n                context, user_id, tenant_id)\n        if not roles:\n            self.identity_api.remove_user_from_tenant(\n                    context, tenant_id, user_id)\n        return\n\n    # COMPAT(diablo): CRUD extension\n    def get_role_refs(self, context, user_id):\n        \"\"\"Ultimate hack to get around having to make role_refs first-class.\n\n        This will basically iterate over the various roles the user has in\n        all tenants the user is a member of and create fake role_refs where\n        the id encodes the user-tenant-role information so we can look\n        up the appropriate data when we need to delete them.\n\n        \"\"\"\n        self.assert_admin(context)\n        user_ref = self.identity_api.get_user(context, user_id)\n        tenant_ids = self.identity_api.get_tenants_for_user(context, user_id)\n        o = []\n        for tenant_id in tenant_ids:\n            role_ids = self.identity_api.get_roles_for_user_and_tenant(\n                    context, user_id, tenant_id)\n            for role_id in role_ids:\n                ref = {'roleId': role_id,\n                       'tenantId': tenant_id,\n                       'userId': user_id}\n                ref['id'] = urllib.urlencode(ref)\n                o.append(ref)\n        return {'roles': o}\n\n    # COMPAT(diablo): CRUD extension\n    def create_role_ref(self, context, user_id, role):\n        \"\"\"This is actually used for adding a user to a tenant.\n\n        In the legacy data model adding a user to a tenant required setting\n        a role.\n\n        \"\"\"\n        self.assert_admin(context)\n        # TODO(termie): for now we're ignoring the actual role\n        tenant_id = role.get('tenantId')\n        role_id = role.get('roleId')\n        self.identity_api.add_user_to_tenant(context, tenant_id, user_id)\n        self.identity_api.add_role_to_user_and_tenant(\n                context, user_id, tenant_id, role_id)\n        role_ref = self.identity_api.get_role(context, role_id)\n        return {'role': role_ref}\n\n    # COMPAT(diablo): CRUD extension\n    def delete_role_ref(self, context, user_id, role_ref_id):\n        \"\"\"This is actually used for deleting a user from a tenant.\n\n        In the legacy data model removing a user from a tenant required\n        deleting a role.\n\n        To emulate this, we encode the tenant and role in the role_ref_id,\n        and if this happens to be the last role for the user-tenant pair,\n        we remove the user from the tenant.\n\n        \"\"\"\n        self.assert_admin(context)\n        # TODO(termie): for now we're ignoring the actual role\n        role_ref_ref = urlparse.parse_qs(role_ref_id)\n        tenant_id = role_ref_ref.get('tenantId')[0]\n        role_id = role_ref_ref.get('roleId')[0]\n        self.identity_api.remove_role_from_user_and_tenant(\n                context, user_id, tenant_id, role_id)\n        roles = self.identity_api.get_roles_for_user_and_tenant(\n                context, user_id, tenant_id)\n        if not roles:\n            self.identity_api.remove_user_from_tenant(\n                    context, tenant_id, user_id)\n", "target": 0}
{"idx": 903, "func": "\"\"\"\nCustom Authenticator to use GitLab OAuth with JupyterHub\n\"\"\"\n\n\nimport json\nimport os\nimport re\nimport sys\nimport warnings\nfrom urllib.parse import quote\n\nfrom tornado.auth import OAuth2Mixin\nfrom tornado import web\n\nfrom tornado.escape import url_escape\nfrom tornado.httputil import url_concat\nfrom tornado.httpclient import HTTPRequest, AsyncHTTPClient\n\nfrom jupyterhub.auth import LocalAuthenticator\n\nfrom traitlets import Set, CUnicode, Unicode, default, observe\n\nfrom .oauth2 import OAuthLoginHandler, OAuthenticator\n\n\ndef _api_headers(access_token):\n    return {\n        \"Accept\": \"application/json\",\n        \"User-Agent\": \"JupyterHub\",\n        \"Authorization\": \"Bearer {}\".format(access_token),\n    }\n\n\nclass GitLabOAuthenticator(OAuthenticator):\n    # see gitlab_scopes.md for details about scope config\n    # set scopes via config, e.g.\n    # c.GitLabOAuthenticator.scope = ['read_user']\n\n    _deprecated_oauth_aliases = {\n        \"gitlab_group_whitelist\": (\"allowed_gitlab_groups\", \"0.12.0\"),\n        \"gitlab_project_id_whitelist\": (\"allowed_project_ids\", \"0.12.0\"),\n        **OAuthenticator._deprecated_oauth_aliases,\n    }\n\n    login_service = \"GitLab\"\n\n    client_id_env = 'GITLAB_CLIENT_ID'\n    client_secret_env = 'GITLAB_CLIENT_SECRET'\n\n    gitlab_url = Unicode(\"https://gitlab.com\", config=True)\n\n    @default(\"gitlab_url\")\n    def _default_gitlab_url(self):\n        \"\"\"get default gitlab url from env\"\"\"\n        gitlab_url = os.getenv('GITLAB_URL')\n        gitlab_host = os.getenv('GITLAB_HOST')\n\n        if not gitlab_url and gitlab_host:\n            warnings.warn(\n                'Use of GITLAB_HOST might be deprecated in the future. '\n                'Rename GITLAB_HOST environment variable to GITLAB_URL.',\n                PendingDeprecationWarning,\n            )\n            if gitlab_host.startswith(('https:', 'http:')):\n                gitlab_url = gitlab_host\n            else:\n                # Hides common mistake of users which set the GITLAB_HOST\n                # without a protocol specification.\n                gitlab_url = 'https://{0}'.format(gitlab_host)\n                warnings.warn(\n                    'The https:// prefix has been added to GITLAB_HOST.'\n                    'Set GITLAB_URL=\"{0}\" instead.'.format(gitlab_host)\n                )\n\n        # default to gitlab.com\n        if not gitlab_url:\n            gitlab_url = 'https://gitlab.com'\n\n        return gitlab_url\n\n    gitlab_api_version = CUnicode('4', config=True)\n\n    @default('gitlab_api_version')\n    def _gitlab_api_version_default(self):\n        return os.environ.get('GITLAB_API_VERSION') or '4'\n\n    gitlab_api = Unicode(config=True)\n\n    @default(\"gitlab_api\")\n    def _default_gitlab_api(self):\n        return '%s/api/v%s' % (self.gitlab_url, self.gitlab_api_version)\n\n    @default(\"authorize_url\")\n    def _authorize_url_default(self):\n        return \"%s/oauth/authorize\" % self.gitlab_url\n\n    @default(\"token_url\")\n    def _token_url_default(self):\n        return \"%s/oauth/access_token\" % self.gitlab_url\n\n    gitlab_group_whitelist = Set(help=\"Deprecated, use `GitLabOAuthenticator.allowed_gitlab_groups`\", config=True,)\n\n    allowed_gitlab_groups = Set(\n        config=True, help=\"Automatically allow members of selected groups\"\n    )\n\n    gitlab_project_id_whitelist = Set(help=\"Deprecated, use `GitLabOAuthenticator.allowed_project_ids`\", config=True,)\n\n    allowed_project_ids = Set(\n        config=True,\n        help=\"Automatically allow members with Developer access to selected project ids\",\n    )\n\n    gitlab_version = None\n\n    async def authenticate(self, handler, data=None):\n        code = handler.get_argument(\"code\")\n        # TODO: Configure the curl_httpclient for tornado\n        http_client = AsyncHTTPClient()\n\n        # Exchange the OAuth code for a GitLab Access Token\n        #\n        # See: https://github.com/gitlabhq/gitlabhq/blob/master/doc/api/oauth2.md\n\n        # GitLab specifies a POST request yet requires URL parameters\n        params = dict(\n            client_id=self.client_id,\n            client_secret=self.client_secret,\n            code=code,\n            grant_type=\"authorization_code\",\n            redirect_uri=self.get_callback_url(handler),\n        )\n\n        validate_server_cert = self.validate_server_cert\n\n        url = url_concat(\"%s/oauth/token\" % self.gitlab_url, params)\n\n        req = HTTPRequest(\n            url,\n            method=\"POST\",\n            headers={\"Accept\": \"application/json\"},\n            validate_cert=validate_server_cert,\n            body='',  # Body is required for a POST...\n        )\n\n        resp = await http_client.fetch(req)\n        resp_json = json.loads(resp.body.decode('utf8', 'replace'))\n\n        access_token = resp_json['access_token']\n\n        # memoize gitlab version for class lifetime\n        if self.gitlab_version is None:\n            self.gitlab_version = await self._get_gitlab_version(access_token)\n            self.member_api_variant = 'all/' if self.gitlab_version >= [12, 4] else ''\n\n        # Determine who the logged in user is\n        req = HTTPRequest(\n            \"%s/user\" % self.gitlab_api,\n            method=\"GET\",\n            validate_cert=validate_server_cert,\n            headers=_api_headers(access_token),\n        )\n        resp = await http_client.fetch(req)\n        resp_json = json.loads(resp.body.decode('utf8', 'replace'))\n\n        username = resp_json[\"username\"]\n        user_id = resp_json[\"id\"]\n        is_admin = resp_json.get(\"is_admin\", False)\n\n        # Check if user is a member of any allowed groups or projects.\n        # These checks are performed here, as it requires `access_token`.\n        user_in_group = user_in_project = False\n        is_group_specified = is_project_id_specified = False\n\n        if self.allowed_gitlab_groups:\n            is_group_specified = True\n            user_in_group = await self._check_membership_allowed_groups(user_id, access_token)\n\n        # We skip project_id check if user is in allowed group.\n        if self.allowed_project_ids and not user_in_group:\n            is_project_id_specified = True\n            user_in_project = await self._check_membership_allowed_project_ids(\n                user_id, access_token\n            )\n\n        no_config_specified = not (is_group_specified or is_project_id_specified)\n\n        if (\n            (is_group_specified and user_in_group)\n            or (is_project_id_specified and user_in_project)\n            or no_config_specified\n        ):\n            return {\n                'name': username,\n                'auth_state': {'access_token': access_token, 'gitlab_user': resp_json},\n            }\n        else:\n            self.log.warning(\"%s not in group or project allowed list\", username)\n            return None\n\n    async def _get_gitlab_version(self, access_token):\n        url = '%s/version' % self.gitlab_api\n        req = HTTPRequest(\n            url,\n            method=\"GET\",\n            headers=_api_headers(access_token),\n            validate_cert=self.validate_server_cert,\n        )\n        resp = await AsyncHTTPClient().fetch(req, raise_error=True)\n        resp_json = json.loads(resp.body.decode('utf8', 'replace'))\n        version_strings = resp_json['version'].split('-')[0].split('.')[:3]\n        version_ints = list(map(int, version_strings))\n        return version_ints\n\n    async def _check_membership_allowed_groups(self, user_id, access_token):\n        http_client = AsyncHTTPClient()\n        headers = _api_headers(access_token)\n        # Check if user is a member of any group in the allowed list\n        for group in map(url_escape, self.allowed_gitlab_groups):\n            url = \"%s/groups/%s/members/%s%d\" % (\n                self.gitlab_api,\n                quote(group, safe=''),\n                self.member_api_variant,\n                user_id,\n            )\n            req = HTTPRequest(url, method=\"GET\", headers=headers)\n            resp = await http_client.fetch(req, raise_error=False)\n            if resp.code == 200:\n                return True  # user _is_ in group\n        return False\n\n    async def _check_membership_allowed_project_ids(self, user_id, access_token):\n        http_client = AsyncHTTPClient()\n        headers = _api_headers(access_token)\n        # Check if user has developer access to any project in the allowed list\n        for project in self.allowed_project_ids:\n            url = \"%s/projects/%s/members/%s%d\" % (\n                self.gitlab_api,\n                project,\n                self.member_api_variant,\n                user_id,\n            )\n            req = HTTPRequest(url, method=\"GET\", headers=headers)\n            resp = await http_client.fetch(req, raise_error=False)\n\n            if resp.body:\n                resp_json = json.loads(resp.body.decode('utf8', 'replace'))\n                access_level = resp_json.get('access_level', 0)\n\n                # We only allow access level Developer and above\n                # Reference: https://docs.gitlab.com/ee/api/members.html\n                if resp.code == 200 and access_level >= 30:\n                    return True\n        return False\n\n\nclass LocalGitLabOAuthenticator(LocalAuthenticator, GitLabOAuthenticator):\n\n    \"\"\"A version that mixes in local system user creation\"\"\"\n\n    pass\n", "target": 0}
{"idx": 904, "func": "#!/usr/bin/env python\nimport os\nimport sys\n\nif __name__ == \"__main__\":\n\n    os.environ.setdefault(\"DJANGO_SETTINGS_MODULE\", \"tests.settings\")\n\n    from django.core.management import execute_from_command_line\n\n    execute_from_command_line(sys.argv)\n", "target": 0}
{"idx": 905, "func": "import itertools\n\nfrom flask import request, abort, _app_ctx_stack, redirect\nfrom flask_security.core import AnonymousUser\nfrom security_monkey.datastore import User\n\ntry:\n    from flask.ext.login import current_user\nexcept ImportError:\n    current_user = None\n\nfrom .models import RBACRole, RBACUserMixin\n\nfrom . import anonymous\n\nfrom flask import Response\nimport json\n\n\nclass AccessControlList(object):\n    \"\"\"\n    This class record rules for access controling.\n    \"\"\"\n\n    def __init__(self):\n        self._allowed = []\n        self._exempt = []\n        self.seted = False\n\n    def allow(self, role, method, resource, with_children=True):\n        \"\"\"Add allowing rules.\n\n        :param role: Role of this rule.\n        :param method: Method to allow in rule, include GET, POST, PUT etc.\n        :param resource: Resource also view function.\n        :param with_children: Allow role's children in rule as well\n                              if with_children is `True`\n        \"\"\"\n\n        if with_children:\n            for r in role.get_children():\n                permission = (r.name, method, resource)\n                if permission not in self._allowed:\n                    self._allowed.append(permission)\n        permission = (role.name, method, resource)\n        if permission not in self._allowed:\n            self._allowed.append(permission)\n\n    def exempt(self, view_func):\n        \"\"\"Exempt a view function from being checked permission\n\n        :param view_func: The view function exempt from checking.\n        \"\"\"\n        if not view_func in self._exempt:\n            self._exempt.append(view_func)\n\n    def is_allowed(self, role, method, resource):\n        \"\"\"Check whether role is allowed to access resource\n\n        :param role: Role to be checked.\n        :param method: Method to be checked.\n        :param resource: View function to be checked.\n        \"\"\"\n        return (role, method, resource) in self._allowed\n\n    def is_exempt(self, view_func):\n        \"\"\"Return whether view_func is exempted.\n\n        :param view_func: View function to be checked.\n        \"\"\"\n        return view_func in self._exempt\n\n\nclass _RBACState(object):\n    \"\"\"Records configuration for Flask-RBAC\"\"\"\n    def __init__(self, rbac, app):\n        self.rbac = rbac\n        self.app = app\n\n\nclass RBAC(object):\n    \"\"\"\n    This class implements role-based access control module in Flask.\n    There are two way to initialize Flask-RBAC::\n\n        app = Flask(__name__)\n        rbac = RBAC(app)\n\n    :param app: the Flask object\n    \"\"\"\n\n    _role_model = RBACRole\n    _user_model = RBACUserMixin\n\n    def __init__(self, app):\n        self.acl = AccessControlList()\n        self.before_acl = []\n\n        self.app = app\n        self.init_app(app)\n\n    def init_app(self, app):\n        # Add (RBAC, app) to flask extensions.\n        # Add hook to authenticate permission before request.\n\n        if not hasattr(app, 'extensions'):\n            app.extensions = {}\n        app.extensions['rbac'] = _RBACState(self, app)\n\n        self.acl.allow(anonymous, 'GET', app.view_functions['static'].__name__)\n        app.before_first_request(self._setup_acl)\n        app.before_request(self._authenticate)\n\n    def has_permission(self, method, endpoint, user=None):\n        \"\"\"Return whether the current user can access the resource.\n        Example::\n\n            @app.route('/some_url', methods=['GET', 'POST'])\n            @rbac.allow(['anonymous'], ['GET'])\n            def a_view_func():\n                return Response('Blah Blah...')\n\n        If you are not logged.\n\n        `rbac.has_permission('GET', 'a_view_func')` return True.\n        `rbac.has_permission('POST', 'a_view_func')` return False.\n\n        :param method: The method wait to check.\n        :param endpoint: The application endpoint.\n        :param user: user who you need to check. Current user by default.\n        \"\"\"\n        app = self.get_app()\n        _user = user or current_user\n        roles = _user.get_roles()\n        view_func = app.view_functions[endpoint]\n        return self._check_permission(roles, method, view_func)\n\n    def check_perm(self, role, method, callback=None):\n        def decorator(view_func):\n            if not self._check_permission([role], method, view_func):\n                if callable(callback):\n                    callback()\n                else:\n                    self._deny_hook()\n            return view_func\n        return decorator\n\n    def allow(self, roles, methods, with_children=True):\n        \"\"\"Decorator: allow roles to access the view func with it.\n\n        :param roles: List, each name of roles. Please note that,\n                      `anonymous` is refered to anonymous.\n                      If you add `anonymous` to the rule,\n                      everyone can access the resource,\n                      unless you deny other roles.\n        :param methods: List, each name of methods.\n                        methods is valid in ['GET', 'POST', 'PUT', 'DELETE']\n        :param with_children: Whether allow children of roles as well.\n                              True by default.\n        \"\"\"\n        def decorator(view_func):\n            _methods = [m.upper() for m in methods]\n            for r, m, v in itertools.product(roles, _methods, [view_func.__name__]):\n                self.before_acl.append((r, m, v, with_children))\n            return view_func\n        return decorator\n\n    def exempt(self, view_func):\n        \"\"\"\n        Decorator function\n        Exempt a view function from being checked permission.\n        \"\"\"\n        self.acl.exempt(view_func.__name__)\n        return view_func\n\n    def get_app(self, reference_app=None):\n        \"\"\"\n        Helper to look up an app.\n        \"\"\"\n        if reference_app is not None:\n            return reference_app\n        if self.app is not None:\n            return self.app\n        ctx = _app_ctx_stack.top\n        if ctx is not None:\n            return ctx.app\n        raise RuntimeError('application not registered on rbac '\n                           'instance and no application bound '\n                           'to current context')\n\n    def _authenticate(self):\n        app = self.get_app()\n        assert app, \"Please initialize your application into Flask-RBAC.\"\n        assert self._role_model, \"Please set role model before authenticate.\"\n        assert self._user_model, \"Please set user model before authenticate.\"\n        user = current_user\n        if not isinstance(user._get_current_object(), self._user_model) and not isinstance(user._get_current_object(), AnonymousUser):\n            raise TypeError(\n                \"%s is not an instance of %s\" %\n                (user, self._user_model.__class__))\n\n        endpoint = request.endpoint\n        resource = app.view_functions.get(endpoint, None)\n\n        if not resource:\n            abort(404)\n\n        method = request.method\n        if not hasattr(user, 'get_roles'):\n            roles = [anonymous]\n        else:\n            roles = user.get_roles()\n\n        permit = self._check_permission(roles, method, resource)\n        if not permit:\n            return self._deny_hook(resource=resource)\n\n    def _check_permission(self, roles, method, resource):\n\n        resource = resource.__name__\n        if self.acl.is_exempt(resource):\n            return True\n\n        if not self.acl.seted:\n            self._setup_acl()\n\n        _roles = set()\n        _methods = {'*', method}\n        _resources = {None, resource}\n\n        _roles.add(anonymous)\n\n        _roles.update(roles)\n\n        for r, m, res in itertools.product(_roles, _methods, _resources):\n            if self.acl.is_allowed(r.name, m, res):\n                return True\n\n        return False\n\n    def _deny_hook(self, resource=None):\n        app = self.get_app()\n        if current_user.is_authenticated:\n            status = 403\n        else:\n            status = 401\n        #abort(status)\n\n        if app.config.get('FRONTED_BY_NGINX'):\n                url = \"https://{}:{}{}\".format(app.config.get('FQDN'), app.config.get('NGINX_PORT'), '/login')\n        else:\n                url = \"http://{}:{}{}\".format(app.config.get('FQDN'), app.config.get('API_PORT'), '/login')\n        if current_user.is_authenticated:\n            auth_dict = {\n                \"authenticated\": True,\n                \"user\": current_user.email,\n                \"roles\": current_user.role,\n            }\n        else:\n            auth_dict = {\n                \"authenticated\": False,\n                \"user\": None,\n                \"url\": url\n            }\n\n        return Response(response=json.dumps({\"auth\": auth_dict}), status=status, mimetype=\"application/json\")\n\n\n    def _setup_acl(self):\n        for rn, method, resource, with_children in self.before_acl:\n            role = self._role_model.get_by_name(rn)\n            self.acl.allow(role, method, resource, with_children)\n        self.acl.seted = True\n", "target": 0}
{"idx": 906, "func": "import socketio\nimport traceback\n\nfrom ajenti.http import HttpHandler\nfrom ajenti.api import BasePlugin, plugin, persistent, rootcontext\nfrom ajenti.api.http import HttpPlugin, SocketPlugin\nfrom ajenti.plugins import manager\nfrom ajenti.profiler import *\n\n\nclass SocketIORouteHandler (HttpHandler):\n    def __init__(self):\n        self.namespaces = {}\n        for cls in SocketPlugin.get_classes():\n            self.namespaces[cls.name] = cls\n\n    def handle(self, context):\n        return str(socketio.socketio_manage(context.env, self.namespaces, context))\n\n\nclass InvalidRouteHandler (HttpHandler):\n    def handle(self, context):\n        context.respond_not_found()\n        return 'Invalid URL'\n\n\n@plugin\n@persistent\n@rootcontext\nclass CentralDispatcher (BasePlugin, HttpHandler):\n    def __init__(self):\n        self.invalid = InvalidRouteHandler()\n        self.io = SocketIORouteHandler()\n\n    @profiled(lambda a, k: 'HTTP %s' % a[1].path)\n    def handle(self, context):\n        \"\"\"\n        Dispatch the request to every HttpPlugin\n        \"\"\"\n\n        if hasattr(context.session, 'appcontext'):\n            self.context = context.session.appcontext\n        else:\n            self.context = manager.context\n\n        if context.path.startswith('/ajenti:socket'):\n            return context.fallthrough(self.io)\n\n        if not hasattr(self.context, 'http_handlers'):\n            self.context.http_handlers = HttpPlugin.get_all()\n\n        for instance in self.context.http_handlers:\n            try:\n                output = instance.handle(context)\n            except Exception, e:\n                return [self.respond_error(context, e)]\n            if output is not None:\n                return output\n        return context.fallthrough(self.invalid)\n\n    def respond_error(self, context, exception):\n        context.respond_server_error()\n        stack = traceback.format_exc()\n        return \"\"\"\n        <html>\n            <body>\n\n                <style>\n                    body {\n                        font-family: sans-serif;\n                        color: #888;\n                        text-align: center;\n                    }\n\n                    body pre {\n                        width: 600px;\n                        text-align: left;\n                        margin: auto;\n                        font-family: monospace;\n                    }\n                </style>\n\n                <img src=\"/ajenti:static/main/error.jpeg\" />\n                <br/>\n                <p>\n                    Server error\n                </p>\n                <pre>\n%s\n                </pre>\n            </body>\n        </html>\n        \"\"\" % stack\n", "target": 1}
{"idx": 907, "func": "# -*- coding: utf-8 -*-\n\"\"\"\n    flask_security.views\n    ~~~~~~~~~~~~~~~~~~~~\n\n    Flask-Security views module\n\n    :copyright: (c) 2012 by Matt Wright.\n    :copyright: (c) 2019-2020 by J. Christopher Wagner (jwag).\n    :license: MIT, see LICENSE for more details.\n\n    CSRF is tricky. By default all our forms have CSRF protection built in via\n    Flask-WTF. This is regardless of authentication method or whether the request\n    is Form or JSON based. Form-based 'just works' since when rendering the form\n    (on GET), the CSRF token is automatically populated.\n    We want to handle:\n        - JSON requests where CSRF token is in a header (e.g. X-CSRF-Token)\n        - Option to skip CSRF when using a token to authenticate (rather than session)\n          (CSRF_PROTECT_MECHANISMS)\n        - Option to skip CSRF for 'login'/unauthenticated requests\n          (CSRF_IGNORE_UNAUTH_ENDPOINTS)\n    This is complicated by the fact that the only way to disable form CSRF is to\n    pass in meta={csrf: false} at form instantiation time.\n\n    Be aware that for CSRF to work, caller MUST pass in session cookie. So\n    for pure API, and no session cookie - there is no way to support CSRF-Login\n    so app must set CSRF_IGNORE_UNAUTH_ENDPOINTS (or use CSRF/session cookie for logging\n    in then once they have a token, no need for cookie).\n\n    TODO: two-factor routes such as tf_setup need work. They seem to support both\n    authenticated (via session?) as well as unauthenticated access.\n\"\"\"\n\nimport sys\nimport time\n\nfrom flask import (\n    Blueprint,\n    abort,\n    after_this_request,\n    current_app,\n    jsonify,\n    request,\n    session,\n)\nfrom flask_login import current_user\nfrom werkzeug.datastructures import MultiDict\nfrom werkzeug.local import LocalProxy\n\nfrom .changeable import change_user_password\nfrom .confirmable import (\n    confirm_email_token_status,\n    confirm_user,\n    send_confirmation_instructions,\n)\nfrom .decorators import anonymous_user_required, auth_required, unauth_csrf\nfrom .passwordless import login_token_status, send_login_instructions\nfrom .quart_compat import get_quart_status\nfrom .unified_signin import (\n    us_signin,\n    us_signin_send_code,\n    us_qrcode,\n    us_setup,\n    us_setup_validate,\n    us_verify,\n    us_verify_link,\n    us_verify_send_code,\n)\nfrom .recoverable import (\n    reset_password_token_status,\n    send_reset_password_instructions,\n    update_password,\n)\nfrom .registerable import register_user\nfrom .twofactor import (\n    complete_two_factor_process,\n    tf_clean_session,\n    tf_disable,\n    tf_login,\n)\nfrom .utils import (\n    base_render_json,\n    config_value,\n    do_flash,\n    get_message,\n    get_post_login_redirect,\n    get_post_logout_redirect,\n    get_post_register_redirect,\n    get_post_verify_redirect,\n    get_url,\n    json_error_response,\n    login_user,\n    logout_user,\n    slash_url_suffix,\n    suppress_form_csrf,\n    url_for_security,\n)\n\nif get_quart_status():  # pragma: no cover\n    from quart import make_response, redirect\nelse:\n    from flask import make_response, redirect\n\n# Convenient references\n_security = LocalProxy(lambda: current_app.extensions[\"security\"])\n_datastore = LocalProxy(lambda: _security.datastore)\n\n\ndef default_render_json(payload, code, headers, user):\n    \"\"\" Default JSON response handler.\n    \"\"\"\n    # Force Content-Type header to json.\n    if headers is None:\n        headers = dict()\n    headers[\"Content-Type\"] = \"application/json\"\n    payload = dict(meta=dict(code=code), response=payload)\n    return make_response(jsonify(payload), code, headers)\n\n\nPY3 = sys.version_info[0] == 3\nif PY3 and get_quart_status():  # pragma: no cover\n    from .async_compat import _commit  # noqa: F401\nelse:\n\n    def _commit(response=None):\n        _datastore.commit()\n        return response\n\n\ndef _ctx(endpoint):\n    return _security._run_ctx_processor(endpoint)\n\n\n@unauth_csrf(fall_through=True)\ndef login():\n    \"\"\"View function for login view\n\n    Allow already authenticated users. For GET this is useful for\n    single-page-applications on refresh - session still active but need to\n    access user info and csrf-token.\n    For POST - redirects to POST_LOGIN_VIEW (forms) or returns 400 (json).\n    \"\"\"\n\n    if current_user.is_authenticated and request.method == \"POST\":\n        # Just redirect current_user to POST_LOGIN_VIEW.\n        # While its tempting to try to logout the current user and login the\n        # new requested user - that simply doesn't work with CSRF.\n\n        # This does NOT use get_post_login_redirect() so that it doesn't look at\n        # 'next' - which can cause infinite redirect loops\n        # (see test_common::test_authenticated_loop)\n        if _security._want_json(request):\n            payload = json_error_response(\n                errors=get_message(\"ANONYMOUS_USER_REQUIRED\")[0]\n            )\n            return _security._render_json(payload, 400, None, None)\n        else:\n            return redirect(get_url(_security.post_login_view))\n\n    form_class = _security.login_form\n\n    if request.is_json:\n        # Allow GET so we can return csrf_token for pre-login.\n        if request.content_length:\n            form = form_class(MultiDict(request.get_json()), meta=suppress_form_csrf())\n        else:\n            form = form_class(MultiDict([]), meta=suppress_form_csrf())\n    else:\n        form = form_class(request.form, meta=suppress_form_csrf())\n\n    if form.validate_on_submit():\n        remember_me = form.remember.data if \"remember\" in form else None\n        if config_value(\"TWO_FACTOR\") and (\n            config_value(\"TWO_FACTOR_REQUIRED\")\n            or (form.user.tf_totp_secret and form.user.tf_primary_method)\n        ):\n            return tf_login(\n                form.user, remember=remember_me, primary_authn_via=\"password\"\n            )\n\n        login_user(form.user, remember=remember_me, authn_via=[\"password\"])\n        after_this_request(_commit)\n\n        if _security._want_json(request):\n            return base_render_json(form, include_auth_token=True)\n        return redirect(get_post_login_redirect())\n\n    if _security._want_json(request):\n        if current_user.is_authenticated:\n            form.user = current_user\n        return base_render_json(form)\n\n    if current_user.is_authenticated:\n        return redirect(get_url(_security.post_login_view))\n    else:\n        return _security.render_template(\n            config_value(\"LOGIN_USER_TEMPLATE\"), login_user_form=form, **_ctx(\"login\")\n        )\n\n\n@auth_required()\ndef verify():\n    \"\"\"View function which handles a authentication verification request.\n    \"\"\"\n    form_class = _security.verify_form\n\n    if request.is_json:\n        form = form_class(MultiDict(request.get_json()), meta=suppress_form_csrf())\n    else:\n        form = form_class(meta=suppress_form_csrf())\n\n    if form.validate_on_submit():\n        # form may have called verify_and_update_password()\n        after_this_request(_commit)\n\n        # verified - so set freshness time.\n        session[\"fs_paa\"] = time.time()\n\n        if _security._want_json(request):\n            return base_render_json(form)\n        do_flash(*get_message(\"REAUTHENTICATION_SUCCESSFUL\"))\n        return redirect(get_post_verify_redirect())\n\n    if _security._want_json(request):\n        assert form.user == current_user\n        return base_render_json(form)\n\n    return _security.render_template(\n        config_value(\"VERIFY_TEMPLATE\"), verify_form=form, **_ctx(\"verify\")\n    )\n\n\ndef logout():\n    \"\"\"View function which handles a logout request.\"\"\"\n    tf_clean_session()\n\n    if current_user.is_authenticated:\n        logout_user()\n\n    # No body is required - so if a POST and json - return OK\n    if request.method == \"POST\" and _security._want_json(request):\n        return _security._render_json({}, 200, headers=None, user=None)\n\n    return redirect(get_post_logout_redirect())\n\n\n@anonymous_user_required\ndef register():\n    \"\"\"View function which handles a registration request.\"\"\"\n\n    # For some unknown historic reason - if you don't require confirmation\n    # (via email) then you need to type in your password twice. That might\n    # make sense if you can't reset your password but in modern (2020) UX models\n    # don't ask twice.\n    if _security.confirmable or request.is_json:\n        form_class = _security.confirm_register_form\n    else:\n        form_class = _security.register_form\n\n    if request.is_json:\n        form_data = MultiDict(request.get_json())\n    else:\n        form_data = request.form\n\n    form = form_class(form_data, meta=suppress_form_csrf())\n    if form.validate_on_submit():\n        did_login = False\n        user = register_user(form)\n        form.user = user\n\n        # The 'auto-login' feature probably should be removed - I can't imagine\n        # an application that would want random email accounts. It has been like this\n        # since the beginning. Note that we still enforce 2FA - however for unified\n        # signin - we adhere to historic behavior.\n        if not _security.confirmable or _security.login_without_confirmation:\n            if config_value(\"TWO_FACTOR\") and config_value(\"TWO_FACTOR_REQUIRED\"):\n                return tf_login(user, primary_authn_via=\"register\")\n            after_this_request(_commit)\n            login_user(user, authn_via=[\"register\"])\n            did_login = True\n\n        if not _security._want_json(request):\n            return redirect(get_post_register_redirect())\n\n        # Only include auth token if in fact user is permitted to login\n        return base_render_json(form, include_auth_token=did_login)\n    if _security._want_json(request):\n        return base_render_json(form)\n\n    return _security.render_template(\n        config_value(\"REGISTER_USER_TEMPLATE\"),\n        register_user_form=form,\n        **_ctx(\"register\")\n    )\n\n\n@unauth_csrf(fall_through=True)\ndef send_login():\n    \"\"\"View function that sends login instructions for passwordless login\"\"\"\n\n    form_class = _security.passwordless_login_form\n\n    if request.is_json:\n        form = form_class(MultiDict(request.get_json()), meta=suppress_form_csrf())\n    else:\n        form = form_class(meta=suppress_form_csrf())\n\n    if form.validate_on_submit():\n        send_login_instructions(form.user)\n        if not _security._want_json(request):\n            do_flash(*get_message(\"LOGIN_EMAIL_SENT\", email=form.user.email))\n\n    if _security._want_json(request):\n        return base_render_json(form)\n\n    return _security.render_template(\n        config_value(\"SEND_LOGIN_TEMPLATE\"), send_login_form=form, **_ctx(\"send_login\")\n    )\n\n\n@anonymous_user_required\ndef token_login(token):\n    \"\"\"View function that handles passwordless login via a token\n    Like reset-password and confirm - this is usually a GET via an email\n    so from the request we can't differentiate form-based apps from non.\n    \"\"\"\n\n    expired, invalid, user = login_token_status(token)\n\n    if not user or invalid:\n        m, c = get_message(\"INVALID_LOGIN_TOKEN\")\n        if _security.redirect_behavior == \"spa\":\n            return redirect(get_url(_security.login_error_view, qparams={c: m}))\n        do_flash(m, c)\n        return redirect(url_for_security(\"login\"))\n    if expired:\n        send_login_instructions(user)\n        m, c = get_message(\n            \"LOGIN_EXPIRED\", email=user.email, within=_security.login_within\n        )\n        if _security.redirect_behavior == \"spa\":\n            return redirect(\n                get_url(\n                    _security.login_error_view,\n                    qparams=user.get_redirect_qparams({c: m}),\n                )\n            )\n        do_flash(m, c)\n        return redirect(url_for_security(\"login\"))\n\n    login_user(user, authn_via=[\"token\"])\n    after_this_request(_commit)\n    if _security.redirect_behavior == \"spa\":\n        return redirect(\n            get_url(_security.post_login_view, qparams=user.get_redirect_qparams())\n        )\n\n    do_flash(*get_message(\"PASSWORDLESS_LOGIN_SUCCESSFUL\"))\n\n    return redirect(get_post_login_redirect())\n\n\n@unauth_csrf(fall_through=True)\ndef send_confirmation():\n    \"\"\"View function which sends confirmation instructions.\"\"\"\n\n    form_class = _security.send_confirmation_form\n\n    if request.is_json:\n        form = form_class(MultiDict(request.get_json()), meta=suppress_form_csrf())\n    else:\n        form = form_class(meta=suppress_form_csrf())\n\n    if form.validate_on_submit():\n        send_confirmation_instructions(form.user)\n        if not _security._want_json(request):\n            do_flash(*get_message(\"CONFIRMATION_REQUEST\", email=form.user.email))\n\n    if _security._want_json(request):\n        return base_render_json(form)\n\n    return _security.render_template(\n        config_value(\"SEND_CONFIRMATION_TEMPLATE\"),\n        send_confirmation_form=form,\n        **_ctx(\"send_confirmation\")\n    )\n\n\ndef confirm_email(token):\n    \"\"\"View function which handles a email confirmation request.\"\"\"\n\n    expired, invalid, user = confirm_email_token_status(token)\n\n    if not user or invalid:\n        m, c = get_message(\"INVALID_CONFIRMATION_TOKEN\")\n        if _security.redirect_behavior == \"spa\":\n            return redirect(get_url(_security.confirm_error_view, qparams={c: m}))\n        do_flash(m, c)\n        return redirect(\n            get_url(_security.confirm_error_view)\n            or url_for_security(\"send_confirmation\")\n        )\n\n    already_confirmed = user.confirmed_at is not None\n\n    if expired or already_confirmed:\n        if already_confirmed:\n            m, c = get_message(\"ALREADY_CONFIRMED\")\n        else:\n            send_confirmation_instructions(user)\n            m, c = get_message(\n                \"CONFIRMATION_EXPIRED\",\n                email=user.email,\n                within=_security.confirm_email_within,\n            )\n\n        if _security.redirect_behavior == \"spa\":\n            return redirect(\n                get_url(\n                    _security.confirm_error_view,\n                    qparams=user.get_redirect_qparams({c: m}),\n                )\n            )\n\n        do_flash(m, c)\n        return redirect(\n            get_url(_security.confirm_error_view)\n            or url_for_security(\"send_confirmation\")\n        )\n\n    confirm_user(user)\n    after_this_request(_commit)\n\n    if user != current_user:\n        logout_user()\n        if config_value(\"AUTO_LOGIN_AFTER_CONFIRM\"):\n            # N.B. this is a (small) security risk if email went to wrong place.\n            # and you have the LOGIN_WITH_CONFIRMATION flag since in that case\n            # you can be logged in and doing stuff - but another person could\n            # get the email.\n            if config_value(\"TWO_FACTOR\") and config_value(\"TWO_FACTOR_REQUIRED\"):\n                return tf_login(user, primary_authn_via=\"confirm\")\n            login_user(user, authn_via=[\"confirm\"])\n\n    m, c = get_message(\"EMAIL_CONFIRMED\")\n    if _security.redirect_behavior == \"spa\":\n        return redirect(\n            get_url(\n                _security.post_confirm_view, qparams=user.get_redirect_qparams({c: m})\n            )\n        )\n    do_flash(m, c)\n    return redirect(\n        get_url(_security.post_confirm_view)\n        or get_url(\n            _security.post_login_view\n            if config_value(\"AUTO_LOGIN_AFTER_CONFIRM\")\n            else _security.login_url\n        )\n    )\n\n\n@anonymous_user_required\n@unauth_csrf(fall_through=True)\ndef forgot_password():\n    \"\"\"View function that handles a forgotten password request.\"\"\"\n\n    form_class = _security.forgot_password_form\n\n    if request.is_json:\n        form = form_class(MultiDict(request.get_json()), meta=suppress_form_csrf())\n    else:\n        form = form_class(meta=suppress_form_csrf())\n\n    if form.validate_on_submit():\n        send_reset_password_instructions(form.user)\n        if not _security._want_json(request):\n            do_flash(*get_message(\"PASSWORD_RESET_REQUEST\", email=form.user.email))\n\n    if _security._want_json(request):\n        return base_render_json(form, include_user=False)\n\n    return _security.render_template(\n        config_value(\"FORGOT_PASSWORD_TEMPLATE\"),\n        forgot_password_form=form,\n        **_ctx(\"forgot_password\")\n    )\n\n\n@anonymous_user_required\n@unauth_csrf(fall_through=True)\ndef reset_password(token):\n    \"\"\"View function that handles a reset password request.\n\n    This is usually called via GET as part of an email link and redirects to\n    a reset-password form\n    It is called via POST to actually update the password (and then redirects to\n    a post reset/login view)\n    If in either case the token is either invalid or expired it redirects to\n    the 'forgot-password' form.\n\n    In the case of non-form based configuration:\n    For GET normal case - redirect to RESET_VIEW?token={token}&email={email}\n    For GET invalid case - redirect to RESET_ERROR_VIEW?error={error}&email={email}\n    For POST normal/successful case - return 200 with new authentication token\n    For POST error case return 400 with form.errors\n    \"\"\"\n\n    expired, invalid, user = reset_password_token_status(token)\n    form_class = _security.reset_password_form\n    if request.is_json:\n        form = form_class(MultiDict(request.get_json()), meta=suppress_form_csrf())\n    else:\n        form = form_class(meta=suppress_form_csrf())\n    form.user = user\n\n    if request.method == \"GET\":\n        if not user or invalid:\n            m, c = get_message(\"INVALID_RESET_PASSWORD_TOKEN\")\n            if _security.redirect_behavior == \"spa\":\n                return redirect(get_url(_security.reset_error_view, qparams={c: m}))\n            do_flash(m, c)\n            return redirect(url_for_security(\"forgot_password\"))\n        if expired:\n            send_reset_password_instructions(user)\n            m, c = get_message(\n                \"PASSWORD_RESET_EXPIRED\",\n                email=user.email,\n                within=_security.reset_password_within,\n            )\n            if _security.redirect_behavior == \"spa\":\n                return redirect(\n                    get_url(\n                        _security.reset_error_view,\n                        qparams=user.get_redirect_qparams({c: m}),\n                    )\n                )\n            do_flash(m, c)\n            return redirect(url_for_security(\"forgot_password\"))\n\n        # All good - for SPA - redirect to the ``reset_view``\n        if _security.redirect_behavior == \"spa\":\n            return redirect(\n                get_url(\n                    _security.reset_view,\n                    qparams=user.get_redirect_qparams({\"token\": token}),\n                )\n            )\n        # for forms - render the reset password form\n        return _security.render_template(\n            config_value(\"RESET_PASSWORD_TEMPLATE\"),\n            reset_password_form=form,\n            reset_password_token=token,\n            **_ctx(\"reset_password\")\n        )\n\n    # This is the POST case.\n    m = None\n    if not user or invalid:\n        invalid = True\n        m, c = get_message(\"INVALID_RESET_PASSWORD_TOKEN\")\n        if not _security._want_json(request):\n            do_flash(m, c)\n\n    if expired:\n        send_reset_password_instructions(user)\n        m, c = get_message(\n            \"PASSWORD_RESET_EXPIRED\",\n            email=user.email,\n            within=_security.reset_password_within,\n        )\n        if not _security._want_json(request):\n            do_flash(m, c)\n\n    if invalid or expired:\n        if _security._want_json(request):\n            return _security._render_json(json_error_response(m), 400, None, None)\n        else:\n            return redirect(url_for_security(\"forgot_password\"))\n\n    if form.validate_on_submit():\n        after_this_request(_commit)\n        update_password(user, form.password.data)\n        if config_value(\"TWO_FACTOR\") and (\n            config_value(\"TWO_FACTOR_REQUIRED\")\n            or (form.user.tf_totp_secret and form.user.tf_primary_method)\n        ):\n            return tf_login(user, primary_authn_via=\"reset\")\n        login_user(user, authn_via=[\"reset\"])\n        if _security._want_json(request):\n            login_form = _security.login_form(MultiDict({\"email\": user.email}))\n            setattr(login_form, \"user\", user)\n            return base_render_json(login_form, include_auth_token=True)\n        else:\n            do_flash(*get_message(\"PASSWORD_RESET\"))\n            return redirect(\n                get_url(_security.post_reset_view) or get_url(_security.post_login_view)\n            )\n\n    # validation failure case - for forms - we try again including the token\n    # for non-forms -  we just return errors and assume caller remembers token.\n    if _security._want_json(request):\n        return base_render_json(form)\n    return _security.render_template(\n        config_value(\"RESET_PASSWORD_TEMPLATE\"),\n        reset_password_form=form,\n        reset_password_token=token,\n        **_ctx(\"reset_password\")\n    )\n\n\n@auth_required(\"basic\", \"token\", \"session\")\ndef change_password():\n    \"\"\"View function which handles a change password request.\"\"\"\n\n    form_class = _security.change_password_form\n\n    if request.is_json:\n        form = form_class(MultiDict(request.get_json()), meta=suppress_form_csrf())\n    else:\n        form = form_class(meta=suppress_form_csrf())\n\n    if form.validate_on_submit():\n        after_this_request(_commit)\n        change_user_password(current_user._get_current_object(), form.new_password.data)\n        if _security._want_json(request):\n            form.user = current_user\n            return base_render_json(form, include_auth_token=True)\n\n        do_flash(*get_message(\"PASSWORD_CHANGE\"))\n        return redirect(\n            get_url(_security.post_change_view) or get_url(_security.post_login_view)\n        )\n\n    if _security._want_json(request):\n        form.user = current_user\n        return base_render_json(form)\n\n    return _security.render_template(\n        config_value(\"CHANGE_PASSWORD_TEMPLATE\"),\n        change_password_form=form,\n        **_ctx(\"change_password\")\n    )\n\n\n@unauth_csrf(fall_through=True)\ndef two_factor_setup():\n    \"\"\"View function for two-factor setup.\n\n    This is used both for GET to fetch forms and POST to actually set configuration\n    (and send token).\n\n    There are 3 cases for setting up:\n    1) initial login and application requires 2FA\n    2) changing existing 2FA information\n    3) user wanting to enable or disable 2FA (assuming application doesn't require it)\n\n    In order to CHANGE/ENABLE/DISABLE a 2FA information, user must be properly logged in\n    AND must perform a fresh password validation by\n    calling POST /tf-confirm (which sets 'tf_confirmed' in the session).\n\n    For initial login when 2FA required of course user can't be logged in - in this\n    case we need to have been sent some\n    state via the session as part of login to show a) who and b) that they successfully\n    authenticated.\n    \"\"\"\n    form_class = _security.two_factor_setup_form\n\n    if request.is_json:\n        form = form_class(MultiDict(request.get_json()), meta=suppress_form_csrf())\n    else:\n        form = form_class(meta=suppress_form_csrf())\n\n    if not current_user.is_authenticated:\n        # This is the initial login case\n        # We can also get here from setup if they want to change\n        if not all(k in session for k in [\"tf_user_id\", \"tf_state\"]) or session[\n            \"tf_state\"\n        ] not in [\"setup_from_login\", \"validating_profile\"]:\n            # illegal call on this endpoint\n            tf_clean_session()\n            return _tf_illegal_state(form, _security.login_url)\n\n        user = _datastore.get_user(session[\"tf_user_id\"])\n        if not user:\n            tf_clean_session()\n            return _tf_illegal_state(form, _security.login_url)\n\n    else:\n        # all other cases require user to be logged in and have performed\n        # additional password verification as signified by 'tf_confirmed'\n        # in the session.\n        if \"tf_confirmed\" not in session:\n            tf_clean_session()\n            return _tf_illegal_state(form, _security.two_factor_confirm_url)\n        user = current_user\n\n    if form.validate_on_submit():\n        # Before storing in DB and therefore requiring 2FA we need to\n        # make sure it actually works.\n        # Requiring 2FA is triggered by having BOTH tf_totp_secret and\n        # tf_primary_method in the user record (or having the application\n        # global config TWO_FACTOR_REQUIRED)\n        # Until we correctly validate the 2FA - we don't set primary_method in\n        # user model but use the session to store it.\n        pm = form.setup.data\n        if pm == \"disable\":\n            tf_disable(user)\n            after_this_request(_commit)\n            do_flash(*get_message(\"TWO_FACTOR_DISABLED\"))\n            if not _security._want_json(request):\n                return redirect(get_url(_security.post_login_view))\n            else:\n                return base_render_json(form)\n\n        # Regenerate the TOTP secret on every call of 2FA setup unless it is\n        # within the same session and method (e.g. upon entering the phone number)\n        if pm != session.get(\"tf_primary_method\", None):\n            session[\"tf_totp_secret\"] = _security._totp_factory.generate_totp_secret()\n\n        session[\"tf_primary_method\"] = pm\n        session[\"tf_state\"] = \"validating_profile\"\n        new_phone = form.phone.data if len(form.phone.data) > 0 else None\n        if new_phone:\n            user.tf_phone_number = new_phone\n            _datastore.put(user)\n            after_this_request(_commit)\n\n        # This form is sort of bizarre - for SMS and authenticator\n        # you select, then get more info, and submit again.\n        # For authenticator of course, we don't actually send anything\n        # and for SMS it is the second time around that we get the phone number\n        if pm == \"email\" or (pm == \"sms\" and new_phone):\n            msg = user.tf_send_security_token(\n                method=pm,\n                totp_secret=session[\"tf_totp_secret\"],\n                phone_number=getattr(user, \"tf_phone_number\", None),\n            )\n            if msg:\n                # send code didn't work\n                form.setup.errors = list()\n                form.setup.errors.append(msg)\n                if _security._want_json(request):\n                    return base_render_json(\n                        form, include_user=False, error_status_code=500\n                    )\n        code_form = _security.two_factor_verify_code_form()\n        if not _security._want_json(request):\n            return _security.render_template(\n                config_value(\"TWO_FACTOR_SETUP_TEMPLATE\"),\n                two_factor_setup_form=form,\n                two_factor_verify_code_form=code_form,\n                choices=config_value(\"TWO_FACTOR_ENABLED_METHODS\"),\n                chosen_method=pm,\n                **_ctx(\"tf_setup\")\n            )\n\n    # We get here on GET and POST with failed validation.\n    # For things like phone number - we've already done one POST\n    # that succeeded and now if failed - so retain the initial info\n    if _security._want_json(request):\n        return base_render_json(form, include_user=False)\n\n    code_form = _security.two_factor_verify_code_form()\n    choices = config_value(\"TWO_FACTOR_ENABLED_METHODS\")\n    if not config_value(\"TWO_FACTOR_REQUIRED\"):\n        choices.append(\"disable\")\n\n    return _security.render_template(\n        config_value(\"TWO_FACTOR_SETUP_TEMPLATE\"),\n        two_factor_setup_form=form,\n        two_factor_verify_code_form=code_form,\n        choices=choices,\n        chosen_method=form.setup.data,\n        two_factor_required=config_value(\"TWO_FACTOR_REQUIRED\"),\n        **_ctx(\"tf_setup\")\n    )\n\n\n@unauth_csrf(fall_through=True)\ndef two_factor_token_validation():\n    \"\"\"View function for two-factor token validation\n\n    Two cases:\n    1) normal login case - everything setup correctly; normal 2FA validation\n       In this case - user not logged in -\n       but 'tf_state' == 'ready' or 'validating_profile'\n    2) validating after CHANGE/ENABLE 2FA. In this case user logged in/authenticated\n       they must have 'tf_confirmed' set meaning they re-entered their passwd\n\n    \"\"\"\n\n    form_class = _security.two_factor_verify_code_form\n\n    if request.is_json:\n        form = form_class(MultiDict(request.get_json()), meta=suppress_form_csrf())\n    else:\n        form = form_class(meta=suppress_form_csrf())\n\n    changing = current_user.is_authenticated\n    if not changing:\n        # This is the normal login case\n        if (\n            not all(k in session for k in [\"tf_user_id\", \"tf_state\"])\n            or session[\"tf_state\"] not in [\"ready\", \"validating_profile\"]\n            or (\n                session[\"tf_state\"] == \"validating_profile\"\n                and \"tf_primary_method\" not in session\n            )\n        ):\n            # illegal call on this endpoint\n            tf_clean_session()\n            return _tf_illegal_state(form, _security.login_url)\n\n        user = _datastore.get_user(session[\"tf_user_id\"])\n        form.user = user\n        if not user:\n            tf_clean_session()\n            return _tf_illegal_state(form, _security.login_url)\n\n        if session[\"tf_state\"] == \"ready\":\n            pm = user.tf_primary_method\n            totp_secret = user.tf_totp_secret\n        else:\n            pm = session[\"tf_primary_method\"]\n            totp_secret = session[\"tf_totp_secret\"]\n    else:\n        if (\n            not all(\n                k in session for k in [\"tf_confirmed\", \"tf_state\", \"tf_primary_method\"]\n            )\n            or session[\"tf_state\"] != \"validating_profile\"\n        ):\n            tf_clean_session()\n            # logout since this seems like attack-ish/logic error\n            logout_user()\n            return _tf_illegal_state(form, _security.login_url)\n        pm = session[\"tf_primary_method\"]\n        totp_secret = session[\"tf_totp_secret\"]\n        form.user = current_user\n\n    setattr(form, \"primary_method\", pm)\n    setattr(form, \"tf_totp_secret\", totp_secret)\n    if form.validate_on_submit():\n        # Success - log in user and clear all session variables\n        completion_message = complete_two_factor_process(\n            form.user, pm, totp_secret, changing, session.pop(\"tf_remember_login\", None)\n        )\n        after_this_request(_commit)\n        if not _security._want_json(request):\n            do_flash(*get_message(completion_message))\n            return redirect(get_post_login_redirect())\n\n    # GET or not successful POST\n    if _security._want_json(request):\n        return base_render_json(form)\n\n    # if we were trying to validate a new method\n    if changing:\n        setup_form = _security.two_factor_setup_form()\n\n        return _security.render_template(\n            config_value(\"TWO_FACTOR_SETUP_TEMPLATE\"),\n            two_factor_setup_form=setup_form,\n            two_factor_verify_code_form=form,\n            choices=config_value(\"TWO_FACTOR_ENABLED_METHODS\"),\n            **_ctx(\"tf_setup\")\n        )\n\n    # if we were trying to validate an existing method\n    else:\n        rescue_form = _security.two_factor_rescue_form()\n\n        return _security.render_template(\n            config_value(\"TWO_FACTOR_VERIFY_CODE_TEMPLATE\"),\n            two_factor_rescue_form=rescue_form,\n            two_factor_verify_code_form=form,\n            problem=None,\n            **_ctx(\"tf_token_validation\")\n        )\n\n\n@anonymous_user_required\n@unauth_csrf(fall_through=True)\ndef two_factor_rescue():\n    \"\"\" Function that handles a situation where user can't\n    enter his two-factor validation code\n\n    User must have already provided valid username/password.\n    User must have already established 2FA\n\n    \"\"\"\n\n    form_class = _security.two_factor_rescue_form\n\n    if request.is_json:\n        form = form_class(MultiDict(request.get_json()), meta=suppress_form_csrf())\n    else:\n        form = form_class(meta=suppress_form_csrf())\n\n    if (\n        not all(k in session for k in [\"tf_user_id\", \"tf_state\"])\n        or session[\"tf_state\"] != \"ready\"\n    ):\n        tf_clean_session()\n        return _tf_illegal_state(form, _security.login_url)\n\n    user = _datastore.get_user(session[\"tf_user_id\"])\n    form.user = user\n    if not user:\n        tf_clean_session()\n        return _tf_illegal_state(form, _security.login_url)\n\n    rproblem = \"\"\n    if form.validate_on_submit():\n        problem = form.data[\"help_setup\"]\n        rproblem = problem\n        # if the problem is that user can't access his device, w\n        # e send him code through mail\n        if problem == \"lost_device\":\n            msg = form.user.tf_send_security_token(\n                method=\"email\",\n                totp_secret=form.user.tf_totp_secret,\n                phone_number=getattr(form.user, \"tf_phone_number\", None),\n            )\n            if msg:\n                rproblem = \"\"\n                form.help_setup.errors.append(msg)\n                if _security._want_json(request):\n                    return base_render_json(\n                        form, include_user=False, error_status_code=500\n                    )\n        # send app provider a mail message regarding trouble\n        elif problem == \"no_mail_access\":\n            _security._send_mail(\n                config_value(\"EMAIL_SUBJECT_TWO_FACTOR_RESCUE\"),\n                config_value(\"TWO_FACTOR_RESCUE_MAIL\"),\n                \"two_factor_rescue\",\n                user=form.user,\n            )\n        else:\n            return \"\", 404\n\n    if _security._want_json(request):\n        return base_render_json(form, include_user=False)\n\n    code_form = _security.two_factor_verify_code_form()\n    return _security.render_template(\n        config_value(\"TWO_FACTOR_VERIFY_CODE_TEMPLATE\"),\n        two_factor_verify_code_form=code_form,\n        two_factor_rescue_form=form,\n        rescue_mail=config_value(\"TWO_FACTOR_RESCUE_MAIL\"),\n        problem=rproblem,\n        **_ctx(\"tf_token_validation\")\n    )\n\n\n@auth_required(\"basic\", \"session\", \"token\")\ndef two_factor_verify_password():\n    \"\"\"View function which handles a password verification request.\"\"\"\n    form_class = _security.two_factor_verify_password_form\n\n    if request.is_json:\n        form = form_class(MultiDict(request.get_json()), meta=suppress_form_csrf())\n    else:\n        form = form_class(meta=suppress_form_csrf())\n\n    if form.validate_on_submit():\n        # form called verify_and_update_password()\n        after_this_request(_commit)\n        session[\"tf_confirmed\"] = True\n        m, c = get_message(\"TWO_FACTOR_PASSWORD_CONFIRMATION_DONE\")\n        if not _security._want_json(request):\n            do_flash(m, c)\n            return redirect(url_for_security(\"two_factor_setup\"))\n        else:\n            return _security._render_json(json_error_response(m), 400, None, None)\n\n    if _security._want_json(request):\n        assert form.user == current_user\n        # form.user = current_user\n        return base_render_json(form)\n\n    return _security.render_template(\n        config_value(\"TWO_FACTOR_VERIFY_PASSWORD_TEMPLATE\"),\n        two_factor_verify_password_form=form,\n        **_ctx(\"tf_verify_password\")\n    )\n\n\n@unauth_csrf(fall_through=True)\ndef two_factor_qrcode():\n    if current_user.is_authenticated:\n        user = current_user\n    else:\n        if \"tf_user_id\" not in session:\n            abort(404)\n        user = _datastore.get_user(session[\"tf_user_id\"])\n        if not user:\n            # Seems like we should be careful here if user_id is gone.\n            tf_clean_session()\n            abort(404)\n\n    if \"authenticator\" not in config_value(\"TWO_FACTOR_ENABLED_METHODS\"):\n        return abort(404)\n    if (\n        \"tf_primary_method\" not in session\n        or session[\"tf_primary_method\"] != \"authenticator\"\n    ):\n        return abort(404)\n\n    totp = user.tf_totp_secret\n    if \"tf_totp_secret\" in session:\n        totp = session[\"tf_totp_secret\"]\n    try:\n        import pyqrcode\n\n        # By convention, the URI should have the username that the user\n        # logs in with.\n        username = user.calc_username()\n        url = pyqrcode.create(\n            _security._totp_factory.get_totp_uri(\n                username if username else \"Unknown\", totp\n            )\n        )\n    except ImportError:\n        # For TWO_FACTOR - this should have been checked at app init.\n        raise\n    from io import BytesIO\n\n    stream = BytesIO()\n    url.svg(stream, scale=3)\n    return (\n        stream.getvalue(),\n        200,\n        {\n            \"Content-Type\": \"image/svg+xml\",\n            \"Cache-Control\": \"no-cache, no-store, must-revalidate\",\n            \"Pragma\": \"no-cache\",\n            \"Expires\": \"0\",\n        },\n    )\n\n\ndef _tf_illegal_state(form, redirect_to):\n    m, c = get_message(\"TWO_FACTOR_PERMISSION_DENIED\")\n    if not _security._want_json(request):\n        do_flash(m, c)\n        return redirect(get_url(redirect_to))\n    else:\n        return _security._render_json(json_error_response(m), 400, None, None)\n\n\ndef create_blueprint(app, state, import_name, json_encoder=None):\n    \"\"\"Creates the security extension blueprint\"\"\"\n\n    bp = Blueprint(\n        state.blueprint_name,\n        import_name,\n        url_prefix=state.url_prefix,\n        subdomain=state.subdomain,\n        template_folder=\"templates\",\n    )\n    if json_encoder:\n        bp.json_encoder = json_encoder\n\n    if state.logout_methods is not None:\n        bp.route(state.logout_url, methods=state.logout_methods, endpoint=\"logout\")(\n            logout\n        )\n\n    if state.passwordless:\n        bp.route(state.login_url, methods=[\"GET\", \"POST\"], endpoint=\"login\")(send_login)\n        bp.route(\n            state.login_url + slash_url_suffix(state.login_url, \"<token>\"),\n            endpoint=\"token_login\",\n        )(token_login)\n    elif config_value(\"US_SIGNIN_REPLACES_LOGIN\", app=app):\n        bp.route(state.login_url, methods=[\"GET\", \"POST\"], endpoint=\"login\")(us_signin)\n\n    else:\n        bp.route(state.login_url, methods=[\"GET\", \"POST\"], endpoint=\"login\")(login)\n\n    bp.route(state.verify_url, methods=[\"GET\", \"POST\"], endpoint=\"verify\")(verify)\n\n    if state.unified_signin:\n        bp.route(state.us_signin_url, methods=[\"GET\", \"POST\"], endpoint=\"us_signin\")(\n            us_signin\n        )\n        bp.route(\n            state.us_signin_send_code_url,\n            methods=[\"GET\", \"POST\"],\n            endpoint=\"us_signin_send_code\",\n        )(us_signin_send_code)\n        bp.route(state.us_setup_url, methods=[\"GET\", \"POST\"], endpoint=\"us_setup\")(\n            us_setup\n        )\n        bp.route(\n            state.us_setup_url + slash_url_suffix(state.us_setup_url, \"<token>\"),\n            methods=[\"GET\", \"POST\"],\n            endpoint=\"us_setup_validate\",\n        )(us_setup_validate)\n\n        # Freshness verification\n        if config_value(\"FRESHNESS\", app=app).total_seconds() >= 0:\n            bp.route(\n                state.us_verify_url, methods=[\"GET\", \"POST\"], endpoint=\"us_verify\"\n            )(us_verify)\n            bp.route(\n                state.us_verify_send_code_url,\n                methods=[\"GET\", \"POST\"],\n                endpoint=\"us_verify_send_code\",\n            )(us_verify_send_code)\n\n        bp.route(state.us_verify_link_url, methods=[\"GET\"], endpoint=\"us_verify_link\")(\n            us_verify_link\n        )\n        bp.route(\n            state.us_qrcode_url + slash_url_suffix(state.us_setup_url, \"<token>\"),\n            endpoint=\"us_qrcode\",\n        )(us_qrcode)\n\n    if state.two_factor:\n        tf_token_validation = \"two_factor_token_validation\"\n        tf_qrcode = \"two_factor_qrcode\"\n        bp.route(\n            state.two_factor_setup_url,\n            methods=[\"GET\", \"POST\"],\n            endpoint=\"two_factor_setup\",\n        )(two_factor_setup)\n        bp.route(\n            state.two_factor_token_validation_url,\n            methods=[\"GET\", \"POST\"],\n            endpoint=tf_token_validation,\n        )(two_factor_token_validation)\n        bp.route(state.two_factor_qrcode_url, endpoint=tf_qrcode)(two_factor_qrcode)\n        bp.route(\n            state.two_factor_rescue_url,\n            methods=[\"GET\", \"POST\"],\n            endpoint=\"two_factor_rescue\",\n        )(two_factor_rescue)\n        bp.route(\n            state.two_factor_confirm_url,\n            methods=[\"GET\", \"POST\"],\n            endpoint=\"two_factor_verify_password\",\n        )(two_factor_verify_password)\n\n    if state.registerable:\n        bp.route(state.register_url, methods=[\"GET\", \"POST\"], endpoint=\"register\")(\n            register\n        )\n\n    if state.recoverable:\n        bp.route(state.reset_url, methods=[\"GET\", \"POST\"], endpoint=\"forgot_password\")(\n            forgot_password\n        )\n        bp.route(\n            state.reset_url + slash_url_suffix(state.reset_url, \"<token>\"),\n            methods=[\"GET\", \"POST\"],\n            endpoint=\"reset_password\",\n        )(reset_password)\n\n    if state.changeable:\n        bp.route(state.change_url, methods=[\"GET\", \"POST\"], endpoint=\"change_password\")(\n            change_password\n        )\n\n    if state.confirmable:\n        bp.route(\n            state.confirm_url, methods=[\"GET\", \"POST\"], endpoint=\"send_confirmation\"\n        )(send_confirmation)\n        bp.route(\n            state.confirm_url + slash_url_suffix(state.confirm_url, \"<token>\"),\n            methods=[\"GET\", \"POST\"],\n            endpoint=\"confirm_email\",\n        )(confirm_email)\n\n    return bp\n", "target": 0}
{"idx": 908, "func": "import base64\nimport re\n\nimport pyparsing as pp\n\nfrom .error import *\n\nUNQUOTE_PAIRS = re.compile(r\"\\\\(.)\")\nunquote = lambda s, l, t: UNQUOTE_PAIRS.sub(r\"\\1\", t[0][1:-1])\n\n# https://tools.ietf.org/html/rfc7235#section-1.2\n# https://tools.ietf.org/html/rfc7235#appendix-B\ntchar = \"!#$%&'*+-.^_`|~\" + pp.nums + pp.alphas\ntoken = pp.Word(tchar).setName(\"token\")\ntoken68 = pp.Combine(pp.Word(\"-._~+/\" + pp.nums + pp.alphas) + pp.ZeroOrMore(\"=\")).setName(\"token68\")\n\nquoted_string = pp.dblQuotedString.copy().setName(\"quoted-string\").setParseAction(unquote)\nauth_param_name = token.copy().setName(\"auth-param-name\").addParseAction(pp.downcaseTokens)\nauth_param = auth_param_name + pp.Suppress(\"=\") + (token ^ quoted_string)\nparams = pp.Dict(pp.delimitedList(pp.Group(auth_param)))\n\nscheme = token(\"scheme\")\nchallenge = scheme + (token68(\"token\") ^ params(\"params\"))\n\nauthentication_info = params.copy()\nwww_authenticate = pp.delimitedList(pp.Group(challenge))\n\n\ndef _parse_authentication_info(headers, headername=\"authentication-info\"):\n    \"\"\"https://tools.ietf.org/html/rfc7615\n    \"\"\"\n    header = headers.get(headername, \"\").strip()\n    if not header:\n        return {}\n    try:\n        parsed = authentication_info.parseString(header)\n    except pp.ParseException as ex:\n        # print(ex.explain(ex))\n        raise MalformedHeader(headername)\n\n    return parsed.asDict()\n\n\ndef _parse_www_authenticate(headers, headername=\"www-authenticate\"):\n    \"\"\"Returns a dictionary of dictionaries, one dict per auth_scheme.\"\"\"\n    header = headers.get(headername, \"\").strip()\n    if not header:\n        return {}\n    try:\n        parsed = www_authenticate.parseString(header)\n    except pp.ParseException as ex:\n        # print(ex.explain(ex))\n        raise MalformedHeader(headername)\n\n    retval = {\n        challenge[\"scheme\"].lower(): challenge[\"params\"].asDict()\n        if \"params\" in challenge\n        else {\"token\": challenge.get(\"token\")}\n        for challenge in parsed\n    }\n    return retval\n", "target": 0}
{"idx": 909, "func": "# Copyright 2011 OpenStack LLC.\n# Copyright 2012 Justin Santa Barbara\n# All Rights Reserved.\n#\n#    Licensed under the Apache License, Version 2.0 (the \"License\"); you may\n#    not use this file except in compliance with the License. You may obtain\n#    a copy of the License at\n#\n#         http://www.apache.org/licenses/LICENSE-2.0\n#\n#    Unless required by applicable law or agreed to in writing, software\n#    distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n#    License for the specific language governing permissions and limitations\n#    under the License.\n\n\"\"\"The security groups extension.\"\"\"\n\nimport urllib\nfrom xml.dom import minidom\n\nfrom webob import exc\nimport webob\n\nfrom nova.api.openstack import common\nfrom nova.api.openstack import extensions\nfrom nova.api.openstack import wsgi\nfrom nova.api.openstack import xmlutil\nfrom nova import compute\nfrom nova import db\nfrom nova import exception\nfrom nova import flags\nfrom nova import log as logging\nfrom nova import quota\nfrom nova import utils\n\n\nLOG = logging.getLogger(__name__)\nFLAGS = flags.FLAGS\nauthorize = extensions.extension_authorizer('compute', 'security_groups')\n\n\ndef make_rule(elem):\n    elem.set('id')\n    elem.set('parent_group_id')\n\n    proto = xmlutil.SubTemplateElement(elem, 'ip_protocol')\n    proto.text = 'ip_protocol'\n\n    from_port = xmlutil.SubTemplateElement(elem, 'from_port')\n    from_port.text = 'from_port'\n\n    to_port = xmlutil.SubTemplateElement(elem, 'to_port')\n    to_port.text = 'to_port'\n\n    group = xmlutil.SubTemplateElement(elem, 'group', selector='group')\n    name = xmlutil.SubTemplateElement(group, 'name')\n    name.text = 'name'\n    tenant_id = xmlutil.SubTemplateElement(group, 'tenant_id')\n    tenant_id.text = 'tenant_id'\n\n    ip_range = xmlutil.SubTemplateElement(elem, 'ip_range',\n                                          selector='ip_range')\n    cidr = xmlutil.SubTemplateElement(ip_range, 'cidr')\n    cidr.text = 'cidr'\n\n\ndef make_sg(elem):\n    elem.set('id')\n    elem.set('tenant_id')\n    elem.set('name')\n\n    desc = xmlutil.SubTemplateElement(elem, 'description')\n    desc.text = 'description'\n\n    rules = xmlutil.SubTemplateElement(elem, 'rules')\n    rule = xmlutil.SubTemplateElement(rules, 'rule', selector='rules')\n    make_rule(rule)\n\n\nsg_nsmap = {None: wsgi.XMLNS_V11}\n\n\nclass SecurityGroupRuleTemplate(xmlutil.TemplateBuilder):\n    def construct(self):\n        root = xmlutil.TemplateElement('security_group_rule',\n                                       selector='security_group_rule')\n        make_rule(root)\n        return xmlutil.MasterTemplate(root, 1, nsmap=sg_nsmap)\n\n\nclass SecurityGroupTemplate(xmlutil.TemplateBuilder):\n    def construct(self):\n        root = xmlutil.TemplateElement('security_group',\n                                       selector='security_group')\n        make_sg(root)\n        return xmlutil.MasterTemplate(root, 1, nsmap=sg_nsmap)\n\n\nclass SecurityGroupsTemplate(xmlutil.TemplateBuilder):\n    def construct(self):\n        root = xmlutil.TemplateElement('security_groups')\n        elem = xmlutil.SubTemplateElement(root, 'security_group',\n                                          selector='security_groups')\n        make_sg(elem)\n        return xmlutil.MasterTemplate(root, 1, nsmap=sg_nsmap)\n\n\nclass SecurityGroupXMLDeserializer(wsgi.MetadataXMLDeserializer):\n    \"\"\"\n    Deserializer to handle xml-formatted security group requests.\n    \"\"\"\n    def default(self, string):\n        \"\"\"Deserialize an xml-formatted security group create request\"\"\"\n        dom = minidom.parseString(string)\n        security_group = {}\n        sg_node = self.find_first_child_named(dom,\n                                               'security_group')\n        if sg_node is not None:\n            if sg_node.hasAttribute('name'):\n                security_group['name'] = sg_node.getAttribute('name')\n            desc_node = self.find_first_child_named(sg_node,\n                                                     \"description\")\n            if desc_node:\n                security_group['description'] = self.extract_text(desc_node)\n        return {'body': {'security_group': security_group}}\n\n\nclass SecurityGroupRulesXMLDeserializer(wsgi.MetadataXMLDeserializer):\n    \"\"\"\n    Deserializer to handle xml-formatted security group requests.\n    \"\"\"\n\n    def default(self, string):\n        \"\"\"Deserialize an xml-formatted security group create request\"\"\"\n        dom = minidom.parseString(string)\n        security_group_rule = self._extract_security_group_rule(dom)\n        return {'body': {'security_group_rule': security_group_rule}}\n\n    def _extract_security_group_rule(self, node):\n        \"\"\"Marshal the security group rule attribute of a parsed request\"\"\"\n        sg_rule = {}\n        sg_rule_node = self.find_first_child_named(node,\n                                                   'security_group_rule')\n        if sg_rule_node is not None:\n            ip_protocol_node = self.find_first_child_named(sg_rule_node,\n                                                           \"ip_protocol\")\n            if ip_protocol_node is not None:\n                sg_rule['ip_protocol'] = self.extract_text(ip_protocol_node)\n\n            from_port_node = self.find_first_child_named(sg_rule_node,\n                                                         \"from_port\")\n            if from_port_node is not None:\n                sg_rule['from_port'] = self.extract_text(from_port_node)\n\n            to_port_node = self.find_first_child_named(sg_rule_node, \"to_port\")\n            if to_port_node is not None:\n                sg_rule['to_port'] = self.extract_text(to_port_node)\n\n            parent_group_id_node = self.find_first_child_named(sg_rule_node,\n                                                            \"parent_group_id\")\n            if parent_group_id_node is not None:\n                sg_rule['parent_group_id'] = self.extract_text(\n                                                         parent_group_id_node)\n\n            group_id_node = self.find_first_child_named(sg_rule_node,\n                                                        \"group_id\")\n            if group_id_node is not None:\n                sg_rule['group_id'] = self.extract_text(group_id_node)\n\n            cidr_node = self.find_first_child_named(sg_rule_node, \"cidr\")\n            if cidr_node is not None:\n                sg_rule['cidr'] = self.extract_text(cidr_node)\n\n        return sg_rule\n\n\nclass SecurityGroupControllerBase(object):\n    \"\"\"Base class for Security Group controllers.\"\"\"\n\n    def __init__(self):\n        self.compute_api = compute.API()\n        self.sgh = utils.import_object(FLAGS.security_group_handler)\n\n    def _format_security_group_rule(self, context, rule):\n        sg_rule = {}\n        sg_rule['id'] = rule.id\n        sg_rule['parent_group_id'] = rule.parent_group_id\n        sg_rule['ip_protocol'] = rule.protocol\n        sg_rule['from_port'] = rule.from_port\n        sg_rule['to_port'] = rule.to_port\n        sg_rule['group'] = {}\n        sg_rule['ip_range'] = {}\n        if rule.group_id:\n            source_group = db.security_group_get(context, rule.group_id)\n            sg_rule['group'] = {'name': source_group.name,\n                             'tenant_id': source_group.project_id}\n        else:\n            sg_rule['ip_range'] = {'cidr': rule.cidr}\n        return sg_rule\n\n    def _format_security_group(self, context, group):\n        security_group = {}\n        security_group['id'] = group.id\n        security_group['description'] = group.description\n        security_group['name'] = group.name\n        security_group['tenant_id'] = group.project_id\n        security_group['rules'] = []\n        for rule in group.rules:\n            security_group['rules'] += [self._format_security_group_rule(\n                    context, rule)]\n        return security_group\n\n\nclass SecurityGroupController(SecurityGroupControllerBase):\n    \"\"\"The Security group API controller for the OpenStack API.\"\"\"\n\n    def _get_security_group(self, context, id):\n        try:\n            id = int(id)\n            security_group = db.security_group_get(context, id)\n        except ValueError:\n            msg = _(\"Security group id should be integer\")\n            raise exc.HTTPBadRequest(explanation=msg)\n        except exception.NotFound as exp:\n            raise exc.HTTPNotFound(explanation=unicode(exp))\n        return security_group\n\n    @wsgi.serializers(xml=SecurityGroupTemplate)\n    def show(self, req, id):\n        \"\"\"Return data about the given security group.\"\"\"\n        context = req.environ['nova.context']\n        authorize(context)\n        security_group = self._get_security_group(context, id)\n        return {'security_group': self._format_security_group(context,\n                                                              security_group)}\n\n    def delete(self, req, id):\n        \"\"\"Delete a security group.\"\"\"\n        context = req.environ['nova.context']\n        authorize(context)\n        security_group = self._get_security_group(context, id)\n        if db.security_group_in_use(context, security_group.id):\n            msg = _(\"Security group is still in use\")\n            raise exc.HTTPBadRequest(explanation=msg)\n        LOG.audit(_(\"Delete security group %s\"), id, context=context)\n        db.security_group_destroy(context, security_group.id)\n        self.sgh.trigger_security_group_destroy_refresh(\n            context, security_group.id)\n\n        return webob.Response(status_int=202)\n\n    @wsgi.serializers(xml=SecurityGroupsTemplate)\n    def index(self, req):\n        \"\"\"Returns a list of security groups\"\"\"\n        context = req.environ['nova.context']\n        authorize(context)\n\n        self.compute_api.ensure_default_security_group(context)\n        groups = db.security_group_get_by_project(context,\n                                                  context.project_id)\n        limited_list = common.limited(groups, req)\n        result = [self._format_security_group(context, group)\n                     for group in limited_list]\n\n        return {'security_groups':\n                list(sorted(result,\n                            key=lambda k: (k['tenant_id'], k['name'])))}\n\n    @wsgi.serializers(xml=SecurityGroupTemplate)\n    @wsgi.deserializers(xml=SecurityGroupXMLDeserializer)\n    def create(self, req, body):\n        \"\"\"Creates a new security group.\"\"\"\n        context = req.environ['nova.context']\n        authorize(context)\n        if not body:\n            raise exc.HTTPUnprocessableEntity()\n\n        security_group = body.get('security_group', None)\n\n        if security_group is None:\n            raise exc.HTTPUnprocessableEntity()\n\n        group_name = security_group.get('name', None)\n        group_description = security_group.get('description', None)\n\n        self._validate_security_group_property(group_name, \"name\")\n        self._validate_security_group_property(group_description,\n                                               \"description\")\n        group_name = group_name.strip()\n        group_description = group_description.strip()\n\n        if quota.allowed_security_groups(context, 1) < 1:\n            msg = _(\"Quota exceeded, too many security groups.\")\n            raise exc.HTTPBadRequest(explanation=msg)\n\n        LOG.audit(_(\"Create Security Group %s\"), group_name, context=context)\n        self.compute_api.ensure_default_security_group(context)\n        if db.security_group_exists(context, context.project_id, group_name):\n            msg = _('Security group %s already exists') % group_name\n            raise exc.HTTPBadRequest(explanation=msg)\n\n        group = {'user_id': context.user_id,\n                 'project_id': context.project_id,\n                 'name': group_name,\n                 'description': group_description}\n        group_ref = db.security_group_create(context, group)\n        self.sgh.trigger_security_group_create_refresh(context, group)\n\n        return {'security_group': self._format_security_group(context,\n                                                                 group_ref)}\n\n    def _validate_security_group_property(self, value, typ):\n        \"\"\" typ will be either 'name' or 'description',\n            depending on the caller\n        \"\"\"\n        try:\n            val = value.strip()\n        except AttributeError:\n            msg = _(\"Security group %s is not a string or unicode\") % typ\n            raise exc.HTTPBadRequest(explanation=msg)\n        if not val:\n            msg = _(\"Security group %s cannot be empty.\") % typ\n            raise exc.HTTPBadRequest(explanation=msg)\n        if len(val) > 255:\n            msg = _(\"Security group %s should not be greater \"\n                            \"than 255 characters.\") % typ\n            raise exc.HTTPBadRequest(explanation=msg)\n\n\nclass SecurityGroupRulesController(SecurityGroupControllerBase):\n\n    @wsgi.serializers(xml=SecurityGroupRuleTemplate)\n    @wsgi.deserializers(xml=SecurityGroupRulesXMLDeserializer)\n    def create(self, req, body):\n        context = req.environ['nova.context']\n        authorize(context)\n\n        if not body:\n            raise exc.HTTPUnprocessableEntity()\n\n        if not 'security_group_rule' in body:\n            raise exc.HTTPUnprocessableEntity()\n\n        self.compute_api.ensure_default_security_group(context)\n\n        sg_rule = body['security_group_rule']\n        parent_group_id = sg_rule.get('parent_group_id', None)\n        try:\n            parent_group_id = int(parent_group_id)\n            security_group = db.security_group_get(context, parent_group_id)\n        except ValueError:\n            msg = _(\"Parent group id is not integer\")\n            raise exc.HTTPBadRequest(explanation=msg)\n        except exception.NotFound as exp:\n            msg = _(\"Security group (%s) not found\") % parent_group_id\n            raise exc.HTTPNotFound(explanation=msg)\n\n        msg = _(\"Authorize security group ingress %s\")\n        LOG.audit(msg, security_group['name'], context=context)\n\n        try:\n            values = self._rule_args_to_dict(context,\n                              to_port=sg_rule.get('to_port'),\n                              from_port=sg_rule.get('from_port'),\n                              parent_group_id=sg_rule.get('parent_group_id'),\n                              ip_protocol=sg_rule.get('ip_protocol'),\n                              cidr=sg_rule.get('cidr'),\n                              group_id=sg_rule.get('group_id'))\n        except Exception as exp:\n            raise exc.HTTPBadRequest(explanation=unicode(exp))\n\n        if values is None:\n            msg = _(\"Not enough parameters to build a \"\n                                       \"valid rule.\")\n            raise exc.HTTPBadRequest(explanation=msg)\n\n        values['parent_group_id'] = security_group.id\n\n        if self._security_group_rule_exists(security_group, values):\n            msg = _('This rule already exists in group %s') % parent_group_id\n            raise exc.HTTPBadRequest(explanation=msg)\n\n        allowed = quota.allowed_security_group_rules(context,\n                                                   parent_group_id,\n                                                   1)\n        if allowed < 1:\n            msg = _(\"Quota exceeded, too many security group rules.\")\n            raise exc.HTTPBadRequest(explanation=msg)\n\n        security_group_rule = db.security_group_rule_create(context, values)\n        self.sgh.trigger_security_group_rule_create_refresh(\n            context, [security_group_rule['id']])\n        self.compute_api.trigger_security_group_rules_refresh(context,\n                                    security_group_id=security_group['id'])\n\n        return {\"security_group_rule\": self._format_security_group_rule(\n                                                        context,\n                                                        security_group_rule)}\n\n    def _security_group_rule_exists(self, security_group, values):\n        \"\"\"Indicates whether the specified rule values are already\n           defined in the given security group.\n        \"\"\"\n        for rule in security_group.rules:\n            is_duplicate = True\n            keys = ('group_id', 'cidr', 'from_port', 'to_port', 'protocol')\n            for key in keys:\n                if rule.get(key) != values.get(key):\n                    is_duplicate = False\n                    break\n            if is_duplicate:\n                return True\n        return False\n\n    def _rule_args_to_dict(self, context, to_port=None, from_port=None,\n                                  parent_group_id=None, ip_protocol=None,\n                                  cidr=None, group_id=None):\n        values = {}\n\n        if group_id is not None:\n            try:\n                parent_group_id = int(parent_group_id)\n                group_id = int(group_id)\n            except ValueError:\n                msg = _(\"Parent or group id is not integer\")\n                raise exception.InvalidInput(reason=msg)\n\n            values['group_id'] = group_id\n            #check if groupId exists\n            db.security_group_get(context, group_id)\n        elif cidr:\n            # If this fails, it throws an exception. This is what we want.\n            try:\n                cidr = urllib.unquote(cidr).decode()\n            except Exception:\n                raise exception.InvalidCidr(cidr=cidr)\n\n            if not utils.is_valid_cidr(cidr):\n                # Raise exception for non-valid address\n                raise exception.InvalidCidr(cidr=cidr)\n\n            values['cidr'] = cidr\n        else:\n            values['cidr'] = '0.0.0.0/0'\n\n        if group_id:\n            # Open everything if an explicit port range or type/code are not\n            # specified, but only if a source group was specified.\n            ip_proto_upper = ip_protocol.upper() if ip_protocol else ''\n            if (ip_proto_upper == 'ICMP' and\n                from_port is None and to_port is None):\n                from_port = -1\n                to_port = -1\n            elif (ip_proto_upper in ['TCP', 'UDP'] and from_port is None\n                  and to_port is None):\n                from_port = 1\n                to_port = 65535\n\n        if ip_protocol and from_port is not None and to_port is not None:\n\n            ip_protocol = str(ip_protocol)\n            try:\n                from_port = int(from_port)\n                to_port = int(to_port)\n            except ValueError:\n                if ip_protocol.upper() == 'ICMP':\n                    raise exception.InvalidInput(reason=\"Type and\"\n                         \" Code must be integers for ICMP protocol type\")\n                else:\n                    raise exception.InvalidInput(reason=\"To and From ports \"\n                          \"must be integers\")\n\n            if ip_protocol.upper() not in ['TCP', 'UDP', 'ICMP']:\n                raise exception.InvalidIpProtocol(protocol=ip_protocol)\n\n            # Verify that from_port must always be less than\n            # or equal to to_port\n            if (ip_protocol.upper() in ['TCP', 'UDP'] and\n                from_port > to_port):\n                raise exception.InvalidPortRange(from_port=from_port,\n                      to_port=to_port, msg=\"Former value cannot\"\n                                            \" be greater than the later\")\n\n            # Verify valid TCP, UDP port ranges\n            if (ip_protocol.upper() in ['TCP', 'UDP'] and\n                (from_port < 1 or to_port > 65535)):\n                raise exception.InvalidPortRange(from_port=from_port,\n                      to_port=to_port, msg=\"Valid TCP ports should\"\n                                           \" be between 1-65535\")\n\n            # Verify ICMP type and code\n            if (ip_protocol.upper() == \"ICMP\" and\n                (from_port < -1 or from_port > 255 or\n                to_port < -1 or to_port > 255)):\n                raise exception.InvalidPortRange(from_port=from_port,\n                      to_port=to_port, msg=\"For ICMP, the\"\n                                           \" type:code must be valid\")\n\n            values['protocol'] = ip_protocol.lower()\n            values['from_port'] = from_port\n            values['to_port'] = to_port\n        else:\n            # If cidr based filtering, protocol and ports are mandatory\n            if 'cidr' in values:\n                return None\n\n        return values\n\n    def delete(self, req, id):\n        context = req.environ['nova.context']\n        authorize(context)\n\n        self.compute_api.ensure_default_security_group(context)\n        try:\n            id = int(id)\n            rule = db.security_group_rule_get(context, id)\n        except ValueError:\n            msg = _(\"Rule id is not integer\")\n            raise exc.HTTPBadRequest(explanation=msg)\n        except exception.NotFound:\n            msg = _(\"Rule (%s) not found\") % id\n            raise exc.HTTPNotFound(explanation=msg)\n\n        group_id = rule.parent_group_id\n        self.compute_api.ensure_default_security_group(context)\n        security_group = db.security_group_get(context, group_id)\n\n        msg = _(\"Revoke security group ingress %s\")\n        LOG.audit(msg, security_group['name'], context=context)\n\n        db.security_group_rule_destroy(context, rule['id'])\n        self.sgh.trigger_security_group_rule_destroy_refresh(\n            context, [rule['id']])\n        self.compute_api.trigger_security_group_rules_refresh(context,\n                                    security_group_id=security_group['id'])\n\n        return webob.Response(status_int=202)\n\n\nclass ServerSecurityGroupController(SecurityGroupControllerBase):\n\n    @wsgi.serializers(xml=SecurityGroupsTemplate)\n    def index(self, req, server_id):\n        \"\"\"Returns a list of security groups for the given instance.\"\"\"\n        context = req.environ['nova.context']\n        authorize(context)\n\n        self.compute_api.ensure_default_security_group(context)\n\n        try:\n            instance = self.compute_api.get(context, server_id)\n            groups = db.security_group_get_by_instance(context,\n                                                       instance['id'])\n        except exception.ApiError, e:\n            raise webob.exc.HTTPBadRequest(explanation=e.message)\n        except exception.NotAuthorized, e:\n            raise webob.exc.HTTPUnauthorized()\n\n        result = [self._format_security_group(context, group)\n                    for group in groups]\n\n        return {'security_groups':\n                list(sorted(result,\n                            key=lambda k: (k['tenant_id'], k['name'])))}\n\n\nclass SecurityGroupActionController(wsgi.Controller):\n    def __init__(self, *args, **kwargs):\n        super(SecurityGroupActionController, self).__init__(*args, **kwargs)\n        self.compute_api = compute.API()\n        self.sgh = utils.import_object(FLAGS.security_group_handler)\n\n    @wsgi.action('addSecurityGroup')\n    def _addSecurityGroup(self, req, id, body):\n        context = req.environ['nova.context']\n        authorize(context)\n\n        try:\n            body = body['addSecurityGroup']\n            group_name = body['name']\n        except TypeError:\n            msg = _(\"Missing parameter dict\")\n            raise webob.exc.HTTPBadRequest(explanation=msg)\n        except KeyError:\n            msg = _(\"Security group not specified\")\n            raise webob.exc.HTTPBadRequest(explanation=msg)\n\n        if not group_name or group_name.strip() == '':\n            msg = _(\"Security group name cannot be empty\")\n            raise webob.exc.HTTPBadRequest(explanation=msg)\n\n        try:\n            instance = self.compute_api.get(context, id)\n            self.compute_api.add_security_group(context, instance, group_name)\n            self.sgh.trigger_instance_add_security_group_refresh(\n                context, instance, group_name)\n        except exception.SecurityGroupNotFound as exp:\n            raise exc.HTTPNotFound(explanation=unicode(exp))\n        except exception.InstanceNotFound as exp:\n            raise exc.HTTPNotFound(explanation=unicode(exp))\n        except exception.Invalid as exp:\n            raise exc.HTTPBadRequest(explanation=unicode(exp))\n\n        return webob.Response(status_int=202)\n\n    @wsgi.action('removeSecurityGroup')\n    def _removeSecurityGroup(self, req, id, body):\n        context = req.environ['nova.context']\n        authorize(context)\n\n        try:\n            body = body['removeSecurityGroup']\n            group_name = body['name']\n        except TypeError:\n            msg = _(\"Missing parameter dict\")\n            raise webob.exc.HTTPBadRequest(explanation=msg)\n        except KeyError:\n            msg = _(\"Security group not specified\")\n            raise webob.exc.HTTPBadRequest(explanation=msg)\n\n        if not group_name or group_name.strip() == '':\n            msg = _(\"Security group name cannot be empty\")\n            raise webob.exc.HTTPBadRequest(explanation=msg)\n\n        try:\n            instance = self.compute_api.get(context, id)\n            self.compute_api.remove_security_group(context, instance,\n                                                   group_name)\n            self.sgh.trigger_instance_remove_security_group_refresh(\n                context, instance, group_name)\n        except exception.SecurityGroupNotFound as exp:\n            raise exc.HTTPNotFound(explanation=unicode(exp))\n        except exception.InstanceNotFound as exp:\n            raise exc.HTTPNotFound(explanation=unicode(exp))\n        except exception.Invalid as exp:\n            raise exc.HTTPBadRequest(explanation=unicode(exp))\n\n        return webob.Response(status_int=202)\n\n\nclass Security_groups(extensions.ExtensionDescriptor):\n    \"\"\"Security group support\"\"\"\n\n    name = \"SecurityGroups\"\n    alias = \"security_groups\"\n    namespace = \"http://docs.openstack.org/compute/ext/securitygroups/api/v1.1\"\n    updated = \"2011-07-21T00:00:00+00:00\"\n\n    def get_controller_extensions(self):\n        controller = SecurityGroupActionController()\n        extension = extensions.ControllerExtension(self, 'servers', controller)\n        return [extension]\n\n    def get_resources(self):\n        resources = []\n\n        res = extensions.ResourceExtension('os-security-groups',\n                                controller=SecurityGroupController())\n\n        resources.append(res)\n\n        res = extensions.ResourceExtension('os-security-group-rules',\n                                controller=SecurityGroupRulesController())\n        resources.append(res)\n\n        res = extensions.ResourceExtension(\n            'os-security-groups',\n            controller=ServerSecurityGroupController(),\n            parent=dict(member_name='server', collection_name='servers'))\n        resources.append(res)\n\n        return resources\n", "target": 0}
{"idx": 910, "func": "import os\nimport re\n\nfrom django.conf import global_settings, settings\nfrom django.contrib.sites.models import Site, RequestSite\nfrom django.contrib.auth.models import User\nfrom django.core import mail\nfrom django.core.exceptions import SuspiciousOperation\nfrom django.core.urlresolvers import reverse, NoReverseMatch\nfrom django.http import QueryDict, HttpRequest\nfrom django.utils.encoding import force_text\nfrom django.utils.html import escape\nfrom django.utils.http import urlquote\nfrom django.utils._os import upath\nfrom django.test import TestCase\nfrom django.test.utils import override_settings\nfrom django.middleware.csrf import CsrfViewMiddleware\nfrom django.contrib.sessions.middleware import SessionMiddleware\n\nfrom django.contrib.auth import SESSION_KEY, REDIRECT_FIELD_NAME\nfrom django.contrib.auth.forms import (AuthenticationForm, PasswordChangeForm,\n                SetPasswordForm, PasswordResetForm)\nfrom django.contrib.auth.tests.utils import skipIfCustomUser\nfrom django.contrib.auth.views import login as login_view\n\n\n@override_settings(\n    LANGUAGES=(\n        ('en', 'English'),\n    ),\n    LANGUAGE_CODE='en',\n    TEMPLATE_LOADERS=global_settings.TEMPLATE_LOADERS,\n    TEMPLATE_DIRS=(\n        os.path.join(os.path.dirname(upath(__file__)), 'templates'),\n    ),\n    USE_TZ=False,\n    PASSWORD_HASHERS=('django.contrib.auth.hashers.SHA1PasswordHasher',),\n)\nclass AuthViewsTestCase(TestCase):\n    \"\"\"\n    Helper base class for all the follow test cases.\n    \"\"\"\n    fixtures = ['authtestdata.json']\n    urls = 'django.contrib.auth.tests.urls'\n\n    def login(self, password='password'):\n        response = self.client.post('/login/', {\n            'username': 'testclient',\n            'password': password,\n            })\n        self.assertEqual(response.status_code, 302)\n        self.assertTrue(response['Location'].endswith(settings.LOGIN_REDIRECT_URL))\n        self.assertTrue(SESSION_KEY in self.client.session)\n\n    def assertContainsEscaped(self, response, text, **kwargs):\n        return self.assertContains(response, escape(force_text(text)), **kwargs)\n\n\n@skipIfCustomUser\nclass AuthViewNamedURLTests(AuthViewsTestCase):\n    urls = 'django.contrib.auth.urls'\n\n    def test_named_urls(self):\n        \"Named URLs should be reversible\"\n        expected_named_urls = [\n            ('login', [], {}),\n            ('logout', [], {}),\n            ('password_change', [], {}),\n            ('password_change_done', [], {}),\n            ('password_reset', [], {}),\n            ('password_reset_done', [], {}),\n            ('password_reset_confirm', [], {\n                'uidb36': 'aaaaaaa',\n                'token': '1111-aaaaa',\n            }),\n            ('password_reset_complete', [], {}),\n        ]\n        for name, args, kwargs in expected_named_urls:\n            try:\n                reverse(name, args=args, kwargs=kwargs)\n            except NoReverseMatch:\n                self.fail(\"Reversal of url named '%s' failed with NoReverseMatch\" % name)\n\n\n@skipIfCustomUser\nclass PasswordResetTest(AuthViewsTestCase):\n\n    def test_email_not_found(self):\n        \"Error is raised if the provided email address isn't currently registered\"\n        response = self.client.get('/password_reset/')\n        self.assertEqual(response.status_code, 200)\n        response = self.client.post('/password_reset/', {'email': 'not_a_real_email@email.com'})\n        self.assertContainsEscaped(response, PasswordResetForm.error_messages['unknown'])\n        self.assertEqual(len(mail.outbox), 0)\n\n    def test_email_found(self):\n        \"Email is sent if a valid email address is provided for password reset\"\n        response = self.client.post('/password_reset/', {'email': 'staffmember@example.com'})\n        self.assertEqual(response.status_code, 302)\n        self.assertEqual(len(mail.outbox), 1)\n        self.assertTrue(\"http://\" in mail.outbox[0].body)\n        self.assertEqual(settings.DEFAULT_FROM_EMAIL, mail.outbox[0].from_email)\n\n    def test_email_found_custom_from(self):\n        \"Email is sent if a valid email address is provided for password reset when a custom from_email is provided.\"\n        response = self.client.post('/password_reset_from_email/', {'email': 'staffmember@example.com'})\n        self.assertEqual(response.status_code, 302)\n        self.assertEqual(len(mail.outbox), 1)\n        self.assertEqual(\"staffmember@example.com\", mail.outbox[0].from_email)\n\n    @override_settings(ALLOWED_HOSTS=['adminsite.com'])\n    def test_admin_reset(self):\n        \"If the reset view is marked as being for admin, the HTTP_HOST header is used for a domain override.\"\n        response = self.client.post('/admin_password_reset/',\n            {'email': 'staffmember@example.com'},\n            HTTP_HOST='adminsite.com'\n        )\n        self.assertEqual(response.status_code, 302)\n        self.assertEqual(len(mail.outbox), 1)\n        self.assertTrue(\"http://adminsite.com\" in mail.outbox[0].body)\n        self.assertEqual(settings.DEFAULT_FROM_EMAIL, mail.outbox[0].from_email)\n\n    # Skip any 500 handler action (like sending more mail...)\n    @override_settings(DEBUG_PROPAGATE_EXCEPTIONS=True)\n    def test_poisoned_http_host(self):\n        \"Poisoned HTTP_HOST headers can't be used for reset emails\"\n        # This attack is based on the way browsers handle URLs. The colon\n        # should be used to separate the port, but if the URL contains an @,\n        # the colon is interpreted as part of a username for login purposes,\n        # making 'evil.com' the request domain. Since HTTP_HOST is used to\n        # produce a meaningful reset URL, we need to be certain that the\n        # HTTP_HOST header isn't poisoned. This is done as a check when get_host()\n        # is invoked, but we check here as a practical consequence.\n        with self.assertRaises(SuspiciousOperation):\n            self.client.post('/password_reset/',\n                {'email': 'staffmember@example.com'},\n                HTTP_HOST='www.example:dr.frankenstein@evil.tld'\n            )\n        self.assertEqual(len(mail.outbox), 0)\n\n    # Skip any 500 handler action (like sending more mail...)\n    @override_settings(DEBUG_PROPAGATE_EXCEPTIONS=True)\n    def test_poisoned_http_host_admin_site(self):\n        \"Poisoned HTTP_HOST headers can't be used for reset emails on admin views\"\n        with self.assertRaises(SuspiciousOperation):\n            self.client.post('/admin_password_reset/',\n                {'email': 'staffmember@example.com'},\n                HTTP_HOST='www.example:dr.frankenstein@evil.tld'\n            )\n        self.assertEqual(len(mail.outbox), 0)\n\n    def _test_confirm_start(self):\n        # Start by creating the email\n        response = self.client.post('/password_reset/', {'email': 'staffmember@example.com'})\n        self.assertEqual(response.status_code, 302)\n        self.assertEqual(len(mail.outbox), 1)\n        return self._read_signup_email(mail.outbox[0])\n\n    def _read_signup_email(self, email):\n        urlmatch = re.search(r\"https?://[^/]*(/.*reset/\\S*)\", email.body)\n        self.assertTrue(urlmatch is not None, \"No URL found in sent email\")\n        return urlmatch.group(), urlmatch.groups()[0]\n\n    def test_confirm_valid(self):\n        url, path = self._test_confirm_start()\n        response = self.client.get(path)\n        # redirect to a 'complete' page:\n        self.assertContains(response, \"Please enter your new password\")\n\n    def test_confirm_invalid(self):\n        url, path = self._test_confirm_start()\n        # Let's munge the token in the path, but keep the same length,\n        # in case the URLconf will reject a different length.\n        path = path[:-5] + (\"0\" * 4) + path[-1]\n\n        response = self.client.get(path)\n        self.assertContains(response, \"The password reset link was invalid\")\n\n    def test_confirm_invalid_user(self):\n        # Ensure that we get a 200 response for a non-existant user, not a 404\n        response = self.client.get('/reset/123456-1-1/')\n        self.assertContains(response, \"The password reset link was invalid\")\n\n    def test_confirm_overflow_user(self):\n        # Ensure that we get a 200 response for a base36 user id that overflows int\n        response = self.client.get('/reset/zzzzzzzzzzzzz-1-1/')\n        self.assertContains(response, \"The password reset link was invalid\")\n\n    def test_confirm_invalid_post(self):\n        # Same as test_confirm_invalid, but trying\n        # to do a POST instead.\n        url, path = self._test_confirm_start()\n        path = path[:-5] + (\"0\" * 4) + path[-1]\n\n        self.client.post(path, {\n            'new_password1': 'anewpassword',\n            'new_password2': ' anewpassword',\n        })\n        # Check the password has not been changed\n        u = User.objects.get(email='staffmember@example.com')\n        self.assertTrue(not u.check_password(\"anewpassword\"))\n\n    def test_confirm_complete(self):\n        url, path = self._test_confirm_start()\n        response = self.client.post(path, {'new_password1': 'anewpassword',\n                                           'new_password2': 'anewpassword'})\n        # It redirects us to a 'complete' page:\n        self.assertEqual(response.status_code, 302)\n        # Check the password has been changed\n        u = User.objects.get(email='staffmember@example.com')\n        self.assertTrue(u.check_password(\"anewpassword\"))\n\n        # Check we can't use the link again\n        response = self.client.get(path)\n        self.assertContains(response, \"The password reset link was invalid\")\n\n    def test_confirm_different_passwords(self):\n        url, path = self._test_confirm_start()\n        response = self.client.post(path, {'new_password1': 'anewpassword',\n                                           'new_password2': 'x'})\n        self.assertContainsEscaped(response, SetPasswordForm.error_messages['password_mismatch'])\n\n\n@override_settings(AUTH_USER_MODEL='auth.CustomUser')\nclass CustomUserPasswordResetTest(AuthViewsTestCase):\n    fixtures = ['custom_user.json']\n\n    def _test_confirm_start(self):\n        # Start by creating the email\n        response = self.client.post('/password_reset/', {'email': 'staffmember@example.com'})\n        self.assertEqual(response.status_code, 302)\n        self.assertEqual(len(mail.outbox), 1)\n        return self._read_signup_email(mail.outbox[0])\n\n    def _read_signup_email(self, email):\n        urlmatch = re.search(r\"https?://[^/]*(/.*reset/\\S*)\", email.body)\n        self.assertTrue(urlmatch is not None, \"No URL found in sent email\")\n        return urlmatch.group(), urlmatch.groups()[0]\n\n    def test_confirm_valid_custom_user(self):\n        url, path = self._test_confirm_start()\n        response = self.client.get(path)\n        # redirect to a 'complete' page:\n        self.assertContains(response, \"Please enter your new password\")\n\n\n@skipIfCustomUser\nclass ChangePasswordTest(AuthViewsTestCase):\n\n    def fail_login(self, password='password'):\n        response = self.client.post('/login/', {\n            'username': 'testclient',\n            'password': password,\n        })\n        self.assertContainsEscaped(response, AuthenticationForm.error_messages['invalid_login'] % {\n                'username': User._meta.get_field('username').verbose_name\n            })\n\n    def logout(self):\n        response = self.client.get('/logout/')\n\n    def test_password_change_fails_with_invalid_old_password(self):\n        self.login()\n        response = self.client.post('/password_change/', {\n            'old_password': 'donuts',\n            'new_password1': 'password1',\n            'new_password2': 'password1',\n        })\n        self.assertContainsEscaped(response, PasswordChangeForm.error_messages['password_incorrect'])\n\n    def test_password_change_fails_with_mismatched_passwords(self):\n        self.login()\n        response = self.client.post('/password_change/', {\n            'old_password': 'password',\n            'new_password1': 'password1',\n            'new_password2': 'donuts',\n        })\n        self.assertContainsEscaped(response, SetPasswordForm.error_messages['password_mismatch'])\n\n    def test_password_change_succeeds(self):\n        self.login()\n        response = self.client.post('/password_change/', {\n            'old_password': 'password',\n            'new_password1': 'password1',\n            'new_password2': 'password1',\n        })\n        self.assertEqual(response.status_code, 302)\n        self.assertTrue(response['Location'].endswith('/password_change/done/'))\n        self.fail_login()\n        self.login(password='password1')\n\n    def test_password_change_done_succeeds(self):\n        self.login()\n        response = self.client.post('/password_change/', {\n            'old_password': 'password',\n            'new_password1': 'password1',\n            'new_password2': 'password1',\n        })\n        self.assertEqual(response.status_code, 302)\n        self.assertTrue(response['Location'].endswith('/password_change/done/'))\n\n    def test_password_change_done_fails(self):\n        with self.settings(LOGIN_URL='/login/'):\n            response = self.client.get('/password_change/done/')\n            self.assertEqual(response.status_code, 302)\n            self.assertTrue(response['Location'].endswith('/login/?next=/password_change/done/'))\n\n\n@skipIfCustomUser\nclass LoginTest(AuthViewsTestCase):\n\n    def test_current_site_in_context_after_login(self):\n        response = self.client.get(reverse('django.contrib.auth.views.login'))\n        self.assertEqual(response.status_code, 200)\n        if Site._meta.installed:\n            site = Site.objects.get_current()\n            self.assertEqual(response.context['site'], site)\n            self.assertEqual(response.context['site_name'], site.name)\n        else:\n            self.assertIsInstance(response.context['site'], RequestSite)\n        self.assertTrue(isinstance(response.context['form'], AuthenticationForm),\n                     'Login form is not an AuthenticationForm')\n\n    def test_security_check(self, password='password'):\n        login_url = reverse('django.contrib.auth.views.login')\n\n        # Those URLs should not pass the security check\n        for bad_url in ('http://example.com',\n                        'https://example.com',\n                        'ftp://exampel.com',\n                        '//example.com',\n                        'javascript:alert(\"XSS\")'):\n\n            nasty_url = '%(url)s?%(next)s=%(bad_url)s' % {\n                'url': login_url,\n                'next': REDIRECT_FIELD_NAME,\n                'bad_url': urlquote(bad_url),\n            }\n            response = self.client.post(nasty_url, {\n                'username': 'testclient',\n                'password': password,\n            })\n            self.assertEqual(response.status_code, 302)\n            self.assertFalse(bad_url in response['Location'],\n                             \"%s should be blocked\" % bad_url)\n\n        # These URLs *should* still pass the security check\n        for good_url in ('/view/?param=http://example.com',\n                         '/view/?param=https://example.com',\n                         '/view?param=ftp://exampel.com',\n                         'view/?param=//example.com',\n                         'https:///',\n                         'HTTPS:///',\n                         '//testserver/',\n                         '/url%20with%20spaces/'):  # see ticket #12534\n            safe_url = '%(url)s?%(next)s=%(good_url)s' % {\n                'url': login_url,\n                'next': REDIRECT_FIELD_NAME,\n                'good_url': urlquote(good_url),\n            }\n            response = self.client.post(safe_url, {\n                    'username': 'testclient',\n                    'password': password,\n            })\n            self.assertEqual(response.status_code, 302)\n            self.assertTrue(good_url in response['Location'],\n                            \"%s should be allowed\" % good_url)\n\n    def test_login_csrf_rotate(self, password='password'):\n        \"\"\"\n        Makes sure that a login rotates the currently-used CSRF token.\n        \"\"\"\n        # Do a GET to establish a CSRF token\n        # TestClient isn't used here as we're testing middleware, essentially.\n        req = HttpRequest()\n        CsrfViewMiddleware().process_view(req, login_view, (), {})\n        req.META[\"CSRF_COOKIE_USED\"] = True\n        resp = login_view(req)\n        resp2 = CsrfViewMiddleware().process_response(req, resp)\n        csrf_cookie = resp2.cookies.get(settings.CSRF_COOKIE_NAME, None)\n        token1 = csrf_cookie.coded_value\n\n        # Prepare the POST request\n        req = HttpRequest()\n        req.COOKIES[settings.CSRF_COOKIE_NAME] = token1\n        req.method = \"POST\"\n        req.POST = {'username': 'testclient', 'password': password, 'csrfmiddlewaretoken': token1}\n        req.REQUEST = req.POST\n\n        # Use POST request to log in\n        SessionMiddleware().process_request(req)\n        CsrfViewMiddleware().process_view(req, login_view, (), {})\n        req.META[\"SERVER_NAME\"] = \"testserver\"  # Required to have redirect work in login view\n        req.META[\"SERVER_PORT\"] = 80\n        req.META[\"CSRF_COOKIE_USED\"] = True\n        resp = login_view(req)\n        resp2 = CsrfViewMiddleware().process_response(req, resp)\n        csrf_cookie = resp2.cookies.get(settings.CSRF_COOKIE_NAME, None)\n        token2 = csrf_cookie.coded_value\n\n        # Check the CSRF token switched\n        self.assertNotEqual(token1, token2)\n\n\n@skipIfCustomUser\nclass LoginURLSettings(AuthViewsTestCase):\n\n    def setUp(self):\n        super(LoginURLSettings, self).setUp()\n        self.old_LOGIN_URL = settings.LOGIN_URL\n\n    def tearDown(self):\n        super(LoginURLSettings, self).tearDown()\n        settings.LOGIN_URL = self.old_LOGIN_URL\n\n    def get_login_required_url(self, login_url):\n        settings.LOGIN_URL = login_url\n        response = self.client.get('/login_required/')\n        self.assertEqual(response.status_code, 302)\n        return response['Location']\n\n    def test_standard_login_url(self):\n        login_url = '/login/'\n        login_required_url = self.get_login_required_url(login_url)\n        querystring = QueryDict('', mutable=True)\n        querystring['next'] = '/login_required/'\n        self.assertEqual(login_required_url, 'http://testserver%s?%s' %\n                         (login_url, querystring.urlencode('/')))\n\n    def test_remote_login_url(self):\n        login_url = 'http://remote.example.com/login'\n        login_required_url = self.get_login_required_url(login_url)\n        querystring = QueryDict('', mutable=True)\n        querystring['next'] = 'http://testserver/login_required/'\n        self.assertEqual(login_required_url,\n                         '%s?%s' % (login_url, querystring.urlencode('/')))\n\n    def test_https_login_url(self):\n        login_url = 'https:///login/'\n        login_required_url = self.get_login_required_url(login_url)\n        querystring = QueryDict('', mutable=True)\n        querystring['next'] = 'http://testserver/login_required/'\n        self.assertEqual(login_required_url,\n                         '%s?%s' % (login_url, querystring.urlencode('/')))\n\n    def test_login_url_with_querystring(self):\n        login_url = '/login/?pretty=1'\n        login_required_url = self.get_login_required_url(login_url)\n        querystring = QueryDict('pretty=1', mutable=True)\n        querystring['next'] = '/login_required/'\n        self.assertEqual(login_required_url, 'http://testserver/login/?%s' %\n                         querystring.urlencode('/'))\n\n    def test_remote_login_url_with_next_querystring(self):\n        login_url = 'http://remote.example.com/login/'\n        login_required_url = self.get_login_required_url('%s?next=/default/' %\n                                                         login_url)\n        querystring = QueryDict('', mutable=True)\n        querystring['next'] = 'http://testserver/login_required/'\n        self.assertEqual(login_required_url, '%s?%s' % (login_url,\n                                                    querystring.urlencode('/')))\n\n\n@skipIfCustomUser\nclass LogoutTest(AuthViewsTestCase):\n\n    def confirm_logged_out(self):\n        self.assertTrue(SESSION_KEY not in self.client.session)\n\n    def test_logout_default(self):\n        \"Logout without next_page option renders the default template\"\n        self.login()\n        response = self.client.get('/logout/')\n        self.assertContains(response, 'Logged out')\n        self.confirm_logged_out()\n\n    def test_14377(self):\n        # Bug 14377\n        self.login()\n        response = self.client.get('/logout/')\n        self.assertTrue('site' in response.context)\n\n    def test_logout_with_overridden_redirect_url(self):\n        # Bug 11223\n        self.login()\n        response = self.client.get('/logout/next_page/')\n        self.assertEqual(response.status_code, 302)\n        self.assertTrue(response['Location'].endswith('/somewhere/'))\n\n        response = self.client.get('/logout/next_page/?next=/login/')\n        self.assertEqual(response.status_code, 302)\n        self.assertTrue(response['Location'].endswith('/login/'))\n\n        self.confirm_logged_out()\n\n    def test_logout_with_next_page_specified(self):\n        \"Logout with next_page option given redirects to specified resource\"\n        self.login()\n        response = self.client.get('/logout/next_page/')\n        self.assertEqual(response.status_code, 302)\n        self.assertTrue(response['Location'].endswith('/somewhere/'))\n        self.confirm_logged_out()\n\n    def test_logout_with_redirect_argument(self):\n        \"Logout with query string redirects to specified resource\"\n        self.login()\n        response = self.client.get('/logout/?next=/login/')\n        self.assertEqual(response.status_code, 302)\n        self.assertTrue(response['Location'].endswith('/login/'))\n        self.confirm_logged_out()\n\n    def test_logout_with_custom_redirect_argument(self):\n        \"Logout with custom query string redirects to specified resource\"\n        self.login()\n        response = self.client.get('/logout/custom_query/?follow=/somewhere/')\n        self.assertEqual(response.status_code, 302)\n        self.assertTrue(response['Location'].endswith('/somewhere/'))\n        self.confirm_logged_out()\n\n    def test_security_check(self, password='password'):\n        logout_url = reverse('django.contrib.auth.views.logout')\n\n        # Those URLs should not pass the security check\n        for bad_url in ('http://example.com',\n                        'https://example.com',\n                        'ftp://exampel.com',\n                        '//example.com',\n                        'javascript:alert(\"XSS\")'):\n            nasty_url = '%(url)s?%(next)s=%(bad_url)s' % {\n                'url': logout_url,\n                'next': REDIRECT_FIELD_NAME,\n                'bad_url': urlquote(bad_url),\n            }\n            self.login()\n            response = self.client.get(nasty_url)\n            self.assertEqual(response.status_code, 302)\n            self.assertFalse(bad_url in response['Location'],\n                             \"%s should be blocked\" % bad_url)\n            self.confirm_logged_out()\n\n        # These URLs *should* still pass the security check\n        for good_url in ('/view/?param=http://example.com',\n                         '/view/?param=https://example.com',\n                         '/view?param=ftp://exampel.com',\n                         'view/?param=//example.com',\n                         'https:///',\n                         'HTTPS:///',\n                         '//testserver/',\n                         '/url%20with%20spaces/'):  # see ticket #12534\n            safe_url = '%(url)s?%(next)s=%(good_url)s' % {\n                'url': logout_url,\n                'next': REDIRECT_FIELD_NAME,\n                'good_url': urlquote(good_url),\n            }\n            self.login()\n            response = self.client.get(safe_url)\n            self.assertEqual(response.status_code, 302)\n            self.assertTrue(good_url in response['Location'],\n                            \"%s should be allowed\" % good_url)\n            self.confirm_logged_out()\n\n@skipIfCustomUser\nclass ChangelistTests(AuthViewsTestCase):\n    urls = 'django.contrib.auth.tests.urls_admin'\n\n    # #20078 - users shouldn't be allowed to guess password hashes via\n    # repeated password__startswith queries.\n    def test_changelist_disallows_password_lookups(self):\n        # Make me a superuser before loging in.\n        User.objects.filter(username='testclient').update(is_staff=True, is_superuser=True)\n        self.login()\n\n        # A lookup that tries to filter on password isn't OK\n        with self.assertRaises(SuspiciousOperation):\n            response = self.client.get('/admin/auth/user/?password__startswith=sha1$')\n", "target": 0}
{"idx": 911, "func": "import discord\nfrom redbot.core.bot import Red\nfrom redbot.core import checks, commands, Config\nfrom redbot.core.i18n import cog_i18n, Translator\nfrom redbot.core.utils._internal_utils import send_to_owners_with_prefix_replaced\nfrom redbot.core.utils.chat_formatting import escape, pagify\n\nfrom .streamtypes import (\n    HitboxStream,\n    PicartoStream,\n    Stream,\n    TwitchStream,\n    YoutubeStream,\n)\nfrom .errors import (\n    APIError,\n    InvalidTwitchCredentials,\n    InvalidYoutubeCredentials,\n    OfflineStream,\n    StreamNotFound,\n    StreamsError,\n)\nfrom . import streamtypes as _streamtypes\n\nimport re\nimport logging\nimport asyncio\nimport aiohttp\nimport contextlib\nfrom datetime import datetime\nfrom collections import defaultdict\nfrom typing import Optional, List, Tuple, Union, Dict\n\n_ = Translator(\"Streams\", __file__)\nlog = logging.getLogger(\"red.core.cogs.Streams\")\n\n\n@cog_i18n(_)\nclass Streams(commands.Cog):\n    \"\"\"Various commands relating to streaming platforms.\n\n    You can check if a Twitch, YouTube or Picarto stream is\n    currently live.\n    \"\"\"\n\n    global_defaults = {\n        \"refresh_timer\": 300,\n        \"tokens\": {},\n        \"streams\": [],\n        \"notified_owner_missing_twitch_secret\": False,\n    }\n\n    guild_defaults = {\n        \"autodelete\": False,\n        \"mention_everyone\": False,\n        \"mention_here\": False,\n        \"live_message_mention\": False,\n        \"live_message_nomention\": False,\n        \"ignore_reruns\": False,\n    }\n\n    role_defaults = {\"mention\": False}\n\n    def __init__(self, bot: Red):\n        super().__init__()\n        self.config: Config = Config.get_conf(self, 26262626)\n        self.ttv_bearer_cache: dict = {}\n        self.config.register_global(**self.global_defaults)\n        self.config.register_guild(**self.guild_defaults)\n        self.config.register_role(**self.role_defaults)\n\n        self.bot: Red = bot\n\n        self.streams: List[Stream] = []\n        self.task: Optional[asyncio.Task] = None\n\n        self.yt_cid_pattern = re.compile(\"^UC[-_A-Za-z0-9]{21}[AQgw]$\")\n\n        self._ready_event: asyncio.Event = asyncio.Event()\n        self._init_task: asyncio.Task = self.bot.loop.create_task(self.initialize())\n\n    async def red_delete_data_for_user(self, **kwargs):\n        \"\"\" Nothing to delete \"\"\"\n        return\n\n    def check_name_or_id(self, data: str) -> bool:\n        matched = self.yt_cid_pattern.fullmatch(data)\n        if matched is None:\n            return True\n        return False\n\n    async def initialize(self) -> None:\n        \"\"\"Should be called straight after cog instantiation.\"\"\"\n        await self.bot.wait_until_ready()\n\n        try:\n            await self.move_api_keys()\n            await self.get_twitch_bearer_token()\n            self.streams = await self.load_streams()\n            self.task = self.bot.loop.create_task(self._stream_alerts())\n        except Exception as error:\n            log.exception(\"Failed to initialize Streams cog:\", exc_info=error)\n\n        self._ready_event.set()\n\n    @commands.Cog.listener()\n    async def on_red_api_tokens_update(self, service_name, api_tokens):\n        if service_name == \"twitch\":\n            await self.get_twitch_bearer_token(api_tokens)\n\n    async def cog_before_invoke(self, ctx: commands.Context):\n        await self._ready_event.wait()\n\n    async def move_api_keys(self) -> None:\n        \"\"\"Move the API keys from cog stored config to core bot config if they exist.\"\"\"\n        tokens = await self.config.tokens()\n        youtube = await self.bot.get_shared_api_tokens(\"youtube\")\n        twitch = await self.bot.get_shared_api_tokens(\"twitch\")\n        for token_type, token in tokens.items():\n            if token_type == \"YoutubeStream\" and \"api_key\" not in youtube:\n                await self.bot.set_shared_api_tokens(\"youtube\", api_key=token)\n            if token_type == \"TwitchStream\" and \"client_id\" not in twitch:\n                # Don't need to check Community since they're set the same\n                await self.bot.set_shared_api_tokens(\"twitch\", client_id=token)\n        await self.config.tokens.clear()\n\n    async def get_twitch_bearer_token(self, api_tokens: Optional[Dict] = None) -> None:\n        tokens = (\n            await self.bot.get_shared_api_tokens(\"twitch\") if api_tokens is None else api_tokens\n        )\n        if tokens.get(\"client_id\"):\n            notified_owner_missing_twitch_secret = (\n                await self.config.notified_owner_missing_twitch_secret()\n            )\n            try:\n                tokens[\"client_secret\"]\n                if notified_owner_missing_twitch_secret is True:\n                    await self.config.notified_owner_missing_twitch_secret.set(False)\n            except KeyError:\n                message = _(\n                    \"You need a client secret key if you want to use the Twitch API on this cog.\\n\"\n                    \"Follow these steps:\\n\"\n                    \"1. Go to this page: https://dev.twitch.tv/console/apps.\\n\"\n                    '2. Click \"Manage\" on your application.\\n'\n                    '3. Click on \"New secret\".\\n'\n                    \"5. Copy your client ID and your client secret into:\\n\"\n                    \"{command}\"\n                    \"\\n\\n\"\n                    \"Note: These tokens are sensitive and should only be used in a private channel \"\n                    \"or in DM with the bot.\"\n                ).format(\n                    command=\"`[p]set api twitch client_id {} client_secret {}`\".format(\n                        _(\"<your_client_id_here>\"), _(\"<your_client_secret_here>\")\n                    )\n                )\n                if notified_owner_missing_twitch_secret is False:\n                    await send_to_owners_with_prefix_replaced(self.bot, message)\n                    await self.config.notified_owner_missing_twitch_secret.set(True)\n        async with aiohttp.ClientSession() as session:\n            async with session.post(\n                \"https://id.twitch.tv/oauth2/token\",\n                params={\n                    \"client_id\": tokens.get(\"client_id\", \"\"),\n                    \"client_secret\": tokens.get(\"client_secret\", \"\"),\n                    \"grant_type\": \"client_credentials\",\n                },\n            ) as req:\n                try:\n                    data = await req.json()\n                except aiohttp.ContentTypeError:\n                    data = {}\n\n                if req.status == 200:\n                    pass\n                elif req.status == 400 and data.get(\"message\") == \"invalid client\":\n                    log.error(\n                        \"Twitch API request failed authentication: set Client ID is invalid.\"\n                    )\n                elif req.status == 403 and data.get(\"message\") == \"invalid client secret\":\n                    log.error(\n                        \"Twitch API request failed authentication: set Client Secret is invalid.\"\n                    )\n                elif \"message\" in data:\n                    log.error(\n                        \"Twitch OAuth2 API request failed with status code %s\"\n                        \" and error message: %s\",\n                        req.status,\n                        data[\"message\"],\n                    )\n                else:\n                    log.error(\"Twitch OAuth2 API request failed with status code %s\", req.status)\n\n                if req.status != 200:\n                    return\n\n        self.ttv_bearer_cache = data\n        self.ttv_bearer_cache[\"expires_at\"] = datetime.now().timestamp() + data.get(\"expires_in\")\n\n    async def maybe_renew_twitch_bearer_token(self) -> None:\n        if self.ttv_bearer_cache:\n            if self.ttv_bearer_cache[\"expires_at\"] - datetime.now().timestamp() <= 60:\n                await self.get_twitch_bearer_token()\n\n    @commands.command()\n    async def twitchstream(self, ctx: commands.Context, channel_name: str):\n        \"\"\"Check if a Twitch channel is live.\"\"\"\n        await self.maybe_renew_twitch_bearer_token()\n        token = (await self.bot.get_shared_api_tokens(\"twitch\")).get(\"client_id\")\n        stream = TwitchStream(\n            name=channel_name, token=token, bearer=self.ttv_bearer_cache.get(\"access_token\", None),\n        )\n        await self.check_online(ctx, stream)\n\n    @commands.command()\n    @commands.cooldown(1, 30, commands.BucketType.guild)\n    async def youtubestream(self, ctx: commands.Context, channel_id_or_name: str):\n        \"\"\"Check if a YouTube channel is live.\"\"\"\n        # TODO: Write up a custom check to look up cooldown set by botowner\n        # This check is here to avoid people spamming this command and eating up quota\n        apikey = await self.bot.get_shared_api_tokens(\"youtube\")\n        is_name = self.check_name_or_id(channel_id_or_name)\n        if is_name:\n            stream = YoutubeStream(name=channel_id_or_name, token=apikey)\n        else:\n            stream = YoutubeStream(id=channel_id_or_name, token=apikey)\n        await self.check_online(ctx, stream)\n\n    @commands.command()\n    async def smashcast(self, ctx: commands.Context, channel_name: str):\n        \"\"\"Check if a smashcast channel is live.\"\"\"\n        stream = HitboxStream(name=channel_name)\n        await self.check_online(ctx, stream)\n\n    @commands.command()\n    async def picarto(self, ctx: commands.Context, channel_name: str):\n        \"\"\"Check if a Picarto channel is live.\"\"\"\n        stream = PicartoStream(name=channel_name)\n        await self.check_online(ctx, stream)\n\n    async def check_online(\n        self,\n        ctx: commands.Context,\n        stream: Union[PicartoStream, HitboxStream, YoutubeStream, TwitchStream],\n    ):\n        try:\n            info = await stream.is_online()\n        except OfflineStream:\n            await ctx.send(_(\"That user is offline.\"))\n        except StreamNotFound:\n            await ctx.send(_(\"That channel doesn't seem to exist.\"))\n        except InvalidTwitchCredentials:\n            await ctx.send(\n                _(\"The Twitch token is either invalid or has not been set. See {command}.\").format(\n                    command=f\"`{ctx.clean_prefix}streamset twitchtoken`\"\n                )\n            )\n        except InvalidYoutubeCredentials:\n            await ctx.send(\n                _(\n                    \"The YouTube API key is either invalid or has not been set. See {command}.\"\n                ).format(command=f\"`{ctx.clean_prefix}streamset youtubekey`\")\n            )\n        except APIError:\n            await ctx.send(\n                _(\"Something went wrong whilst trying to contact the stream service's API.\")\n            )\n        else:\n            if isinstance(info, tuple):\n                embed, is_rerun = info\n                ignore_reruns = await self.config.guild(ctx.channel.guild).ignore_reruns()\n                if ignore_reruns and is_rerun:\n                    await ctx.send(_(\"That user is offline.\"))\n                    return\n            else:\n                embed = info\n            await ctx.send(embed=embed)\n\n    @commands.group()\n    @commands.guild_only()\n    @checks.mod_or_permissions(manage_channels=True)\n    async def streamalert(self, ctx: commands.Context):\n        \"\"\"Manage automated stream alerts.\"\"\"\n        pass\n\n    @streamalert.group(name=\"twitch\", invoke_without_command=True)\n    async def _twitch(self, ctx: commands.Context, channel_name: str = None):\n        \"\"\"Manage Twitch stream notifications.\"\"\"\n        if channel_name is not None:\n            await ctx.invoke(self.twitch_alert_channel, channel_name)\n        else:\n            await ctx.send_help()\n\n    @_twitch.command(name=\"channel\")\n    async def twitch_alert_channel(self, ctx: commands.Context, channel_name: str):\n        \"\"\"Toggle alerts in this channel for a Twitch stream.\"\"\"\n        if re.fullmatch(r\"<#\\d+>\", channel_name):\n            await ctx.send(\n                _(\"Please supply the name of a *Twitch* channel, not a Discord channel.\")\n            )\n            return\n        await self.stream_alert(ctx, TwitchStream, channel_name.lower())\n\n    @streamalert.command(name=\"youtube\")\n    async def youtube_alert(self, ctx: commands.Context, channel_name_or_id: str):\n        \"\"\"Toggle alerts in this channel for a YouTube stream.\"\"\"\n        await self.stream_alert(ctx, YoutubeStream, channel_name_or_id)\n\n    @streamalert.command(name=\"smashcast\")\n    async def smashcast_alert(self, ctx: commands.Context, channel_name: str):\n        \"\"\"Toggle alerts in this channel for a Smashcast stream.\"\"\"\n        await self.stream_alert(ctx, HitboxStream, channel_name)\n\n    @streamalert.command(name=\"picarto\")\n    async def picarto_alert(self, ctx: commands.Context, channel_name: str):\n        \"\"\"Toggle alerts in this channel for a Picarto stream.\"\"\"\n        await self.stream_alert(ctx, PicartoStream, channel_name)\n\n    @streamalert.command(name=\"stop\", usage=\"[disable_all=No]\")\n    async def streamalert_stop(self, ctx: commands.Context, _all: bool = False):\n        \"\"\"Disable all stream alerts in this channel or server.\n\n        `[p]streamalert stop` will disable this channel's stream\n        alerts.\n\n        Do `[p]streamalert stop yes` to disable all stream alerts in\n        this server.\n        \"\"\"\n        streams = self.streams.copy()\n        local_channel_ids = [c.id for c in ctx.guild.channels]\n        to_remove = []\n\n        for stream in streams:\n            for channel_id in stream.channels:\n                if channel_id == ctx.channel.id:\n                    stream.channels.remove(channel_id)\n                elif _all and ctx.channel.id in local_channel_ids:\n                    if channel_id in stream.channels:\n                        stream.channels.remove(channel_id)\n\n            if not stream.channels:\n                to_remove.append(stream)\n\n        for stream in to_remove:\n            streams.remove(stream)\n\n        self.streams = streams\n        await self.save_streams()\n\n        if _all:\n            msg = _(\"All the stream alerts in this server have been disabled.\")\n        else:\n            msg = _(\"All the stream alerts in this channel have been disabled.\")\n\n        await ctx.send(msg)\n\n    @streamalert.command(name=\"list\")\n    async def streamalert_list(self, ctx: commands.Context):\n        \"\"\"List all active stream alerts in this server.\"\"\"\n        streams_list = defaultdict(list)\n        guild_channels_ids = [c.id for c in ctx.guild.channels]\n        msg = _(\"Active alerts:\\n\\n\")\n\n        for stream in self.streams:\n            for channel_id in stream.channels:\n                if channel_id in guild_channels_ids:\n                    streams_list[channel_id].append(stream.name.lower())\n\n        if not streams_list:\n            await ctx.send(_(\"There are no active alerts in this server.\"))\n            return\n\n        for channel_id, streams in streams_list.items():\n            channel = ctx.guild.get_channel(channel_id)\n            msg += \"** - #{}**\\n{}\\n\".format(channel, \", \".join(streams))\n\n        for page in pagify(msg):\n            await ctx.send(page)\n\n    async def stream_alert(self, ctx: commands.Context, _class, channel_name):\n        stream = self.get_stream(_class, channel_name)\n        if not stream:\n            token = await self.bot.get_shared_api_tokens(_class.token_name)\n            is_yt = _class.__name__ == \"YoutubeStream\"\n            is_twitch = _class.__name__ == \"TwitchStream\"\n            if is_yt and not self.check_name_or_id(channel_name):\n                stream = _class(id=channel_name, token=token)\n            elif is_twitch:\n                await self.maybe_renew_twitch_bearer_token()\n                stream = _class(\n                    name=channel_name,\n                    token=token.get(\"client_id\"),\n                    bearer=self.ttv_bearer_cache.get(\"access_token\", None),\n                )\n            else:\n                stream = _class(name=channel_name, token=token)\n            try:\n                exists = await self.check_exists(stream)\n            except InvalidTwitchCredentials:\n                await ctx.send(\n                    _(\n                        \"The Twitch token is either invalid or has not been set. See {command}.\"\n                    ).format(command=f\"`{ctx.clean_prefix}streamset twitchtoken`\")\n                )\n                return\n            except InvalidYoutubeCredentials:\n                await ctx.send(\n                    _(\n                        \"The YouTube API key is either invalid or has not been set. See \"\n                        \"{command}.\"\n                    ).format(command=f\"`{ctx.clean_prefix}streamset youtubekey`\")\n                )\n                return\n            except APIError:\n                await ctx.send(\n                    _(\"Something went wrong whilst trying to contact the stream service's API.\")\n                )\n                return\n            else:\n                if not exists:\n                    await ctx.send(_(\"That channel doesn't seem to exist.\"))\n                    return\n\n        await self.add_or_remove(ctx, stream)\n\n    @commands.group()\n    @checks.mod_or_permissions(manage_channels=True)\n    async def streamset(self, ctx: commands.Context):\n        \"\"\"Manage stream alert settings.\"\"\"\n        pass\n\n    @streamset.command(name=\"timer\")\n    @checks.is_owner()\n    async def _streamset_refresh_timer(self, ctx: commands.Context, refresh_time: int):\n        \"\"\"Set stream check refresh time.\"\"\"\n        if refresh_time < 60:\n            return await ctx.send(_(\"You cannot set the refresh timer to less than 60 seconds\"))\n\n        await self.config.refresh_timer.set(refresh_time)\n        await ctx.send(\n            _(\"Refresh timer set to {refresh_time} seconds\".format(refresh_time=refresh_time))\n        )\n\n    @streamset.command()\n    @checks.is_owner()\n    async def twitchtoken(self, ctx: commands.Context):\n        \"\"\"Explain how to set the twitch token.\"\"\"\n        message = _(\n            \"To set the twitch API tokens, follow these steps:\\n\"\n            \"1. Go to this page: https://dev.twitch.tv/dashboard/apps.\\n\"\n            \"2. Click *Register Your Application*.\\n\"\n            \"3. Enter a name, set the OAuth Redirect URI to `http://localhost`, and \"\n            \"select an Application Category of your choosing.\\n\"\n            \"4. Click *Register*.\\n\"\n            \"5. Copy your client ID and your client secret into:\\n\"\n            \"{command}\"\n            \"\\n\\n\"\n            \"Note: These tokens are sensitive and should only be used in a private channel\\n\"\n            \"or in DM with the bot.\\n\"\n        ).format(\n            command=\"`{}set api twitch client_id {} client_secret {}`\".format(\n                ctx.clean_prefix, _(\"<your_client_id_here>\"), _(\"<your_client_secret_here>\")\n            )\n        )\n\n        await ctx.maybe_send_embed(message)\n\n    @streamset.command()\n    @checks.is_owner()\n    async def youtubekey(self, ctx: commands.Context):\n        \"\"\"Explain how to set the YouTube token.\"\"\"\n\n        message = _(\n            \"To get one, do the following:\\n\"\n            \"1. Create a project\\n\"\n            \"(see https://support.google.com/googleapi/answer/6251787 for details)\\n\"\n            \"2. Enable the YouTube Data API v3 \\n\"\n            \"(see https://support.google.com/googleapi/answer/6158841 for instructions)\\n\"\n            \"3. Set up your API key \\n\"\n            \"(see https://support.google.com/googleapi/answer/6158862 for instructions)\\n\"\n            \"4. Copy your API key and run the command \"\n            \"{command}\\n\\n\"\n            \"Note: These tokens are sensitive and should only be used in a private channel\\n\"\n            \"or in DM with the bot.\\n\"\n        ).format(\n            command=\"`{}set api youtube api_key {}`\".format(\n                ctx.clean_prefix, _(\"<your_api_key_here>\")\n            )\n        )\n\n        await ctx.maybe_send_embed(message)\n\n    @streamset.group()\n    @commands.guild_only()\n    async def message(self, ctx: commands.Context):\n        \"\"\"Manage custom message for stream alerts.\"\"\"\n        pass\n\n    @message.command(name=\"mention\")\n    @commands.guild_only()\n    async def with_mention(self, ctx: commands.Context, message: str = None):\n        \"\"\"Set stream alert message when mentions are enabled.\n\n        Use `{mention}` in the message to insert the selected mentions.\n\n        Use `{stream.name}` in the message to insert the channel or user name.\n\n        For example: `[p]streamset message mention \"{mention}, {stream.name} is live!\"`\n        \"\"\"\n        if message is not None:\n            guild = ctx.guild\n            await self.config.guild(guild).live_message_mention.set(message)\n            await ctx.send(_(\"Stream alert message set!\"))\n        else:\n            await ctx.send_help()\n\n    @message.command(name=\"nomention\")\n    @commands.guild_only()\n    async def without_mention(self, ctx: commands.Context, message: str = None):\n        \"\"\"Set stream alert message when mentions are disabled.\n\n        Use `{stream.name}` in the message to insert the channel or user name.\n\n        For example: `[p]streamset message nomention \"{stream.name} is live!\"`\n        \"\"\"\n        if message is not None:\n            guild = ctx.guild\n            await self.config.guild(guild).live_message_nomention.set(message)\n            await ctx.send(_(\"Stream alert message set!\"))\n        else:\n            await ctx.send_help()\n\n    @message.command(name=\"clear\")\n    @commands.guild_only()\n    async def clear_message(self, ctx: commands.Context):\n        \"\"\"Reset the stream alert messages in this server.\"\"\"\n        guild = ctx.guild\n        await self.config.guild(guild).live_message_mention.set(False)\n        await self.config.guild(guild).live_message_nomention.set(False)\n        await ctx.send(_(\"Stream alerts in this server will now use the default alert message.\"))\n\n    @streamset.group()\n    @commands.guild_only()\n    async def mention(self, ctx: commands.Context):\n        \"\"\"Manage mention settings for stream alerts.\"\"\"\n        pass\n\n    @mention.command(aliases=[\"everyone\"])\n    @commands.guild_only()\n    async def all(self, ctx: commands.Context):\n        \"\"\"Toggle the `@\\u200beveryone` mention.\"\"\"\n        guild = ctx.guild\n        current_setting = await self.config.guild(guild).mention_everyone()\n        if current_setting:\n            await self.config.guild(guild).mention_everyone.set(False)\n            await ctx.send(_(\"`@\\u200beveryone` will no longer be mentioned for stream alerts.\"))\n        else:\n            await self.config.guild(guild).mention_everyone.set(True)\n            await ctx.send(_(\"When a stream is live, `@\\u200beveryone` will be mentioned.\"))\n\n    @mention.command(aliases=[\"here\"])\n    @commands.guild_only()\n    async def online(self, ctx: commands.Context):\n        \"\"\"Toggle the `@\\u200bhere` mention.\"\"\"\n        guild = ctx.guild\n        current_setting = await self.config.guild(guild).mention_here()\n        if current_setting:\n            await self.config.guild(guild).mention_here.set(False)\n            await ctx.send(_(\"`@\\u200bhere` will no longer be mentioned for stream alerts.\"))\n        else:\n            await self.config.guild(guild).mention_here.set(True)\n            await ctx.send(_(\"When a stream is live, `@\\u200bhere` will be mentioned.\"))\n\n    @mention.command()\n    @commands.guild_only()\n    async def role(self, ctx: commands.Context, *, role: discord.Role):\n        \"\"\"Toggle a role mention.\"\"\"\n        current_setting = await self.config.role(role).mention()\n        if current_setting:\n            await self.config.role(role).mention.set(False)\n            await ctx.send(\n                _(\"`@\\u200b{role.name}` will no longer be mentioned for stream alerts.\").format(\n                    role=role\n                )\n            )\n        else:\n            await self.config.role(role).mention.set(True)\n            msg = _(\n                \"When a stream or community is live, `@\\u200b{role.name}` will be mentioned.\"\n            ).format(role=role)\n            if not role.mentionable:\n                msg += \" \" + _(\n                    \"Since the role is not mentionable, it will be momentarily made mentionable \"\n                    \"when announcing a streamalert. Please make sure I have the correct \"\n                    \"permissions to manage this role, or else members of this role won't receive \"\n                    \"a notification.\"\n                )\n            await ctx.send(msg)\n\n    @streamset.command()\n    @commands.guild_only()\n    async def autodelete(self, ctx: commands.Context, on_off: bool):\n        \"\"\"Toggle alert deletion for when streams go offline.\"\"\"\n        await self.config.guild(ctx.guild).autodelete.set(on_off)\n        if on_off:\n            await ctx.send(_(\"The notifications will be deleted once streams go offline.\"))\n        else:\n            await ctx.send(_(\"Notifications will no longer be deleted.\"))\n\n    @streamset.command(name=\"ignorereruns\")\n    @commands.guild_only()\n    async def ignore_reruns(self, ctx: commands.Context):\n        \"\"\"Toggle excluding rerun streams from alerts.\"\"\"\n        guild = ctx.guild\n        current_setting = await self.config.guild(guild).ignore_reruns()\n        if current_setting:\n            await self.config.guild(guild).ignore_reruns.set(False)\n            await ctx.send(_(\"Streams of type 'rerun' will be included in alerts.\"))\n        else:\n            await self.config.guild(guild).ignore_reruns.set(True)\n            await ctx.send(_(\"Streams of type 'rerun' will no longer send an alert.\"))\n\n    async def add_or_remove(self, ctx: commands.Context, stream):\n        if ctx.channel.id not in stream.channels:\n            stream.channels.append(ctx.channel.id)\n            if stream not in self.streams:\n                self.streams.append(stream)\n            await ctx.send(\n                _(\n                    \"I'll now send a notification in this channel when {stream.name} is live.\"\n                ).format(stream=stream)\n            )\n        else:\n            stream.channels.remove(ctx.channel.id)\n            if not stream.channels:\n                self.streams.remove(stream)\n            await ctx.send(\n                _(\n                    \"I won't send notifications about {stream.name} in this channel anymore.\"\n                ).format(stream=stream)\n            )\n\n        await self.save_streams()\n\n    def get_stream(self, _class, name):\n        for stream in self.streams:\n            # if isinstance(stream, _class) and stream.name == name:\n            #    return stream\n            # Reloading this cog causes an issue with this check ^\n            # isinstance will always return False\n            # As a workaround, we'll compare the class' name instead.\n            # Good enough.\n            if _class.__name__ == \"YoutubeStream\" and stream.type == _class.__name__:\n                # Because name could be a username or a channel id\n                if self.check_name_or_id(name) and stream.name.lower() == name.lower():\n                    return stream\n                elif not self.check_name_or_id(name) and stream.id == name:\n                    return stream\n            elif stream.type == _class.__name__ and stream.name.lower() == name.lower():\n                return stream\n\n    @staticmethod\n    async def check_exists(stream):\n        try:\n            await stream.is_online()\n        except OfflineStream:\n            pass\n        except StreamNotFound:\n            return False\n        except StreamsError:\n            raise\n        return True\n\n    async def _stream_alerts(self):\n        await self.bot.wait_until_ready()\n        while True:\n            try:\n                await self.check_streams()\n            except asyncio.CancelledError:\n                pass\n            await asyncio.sleep(await self.config.refresh_timer())\n\n    async def check_streams(self):\n        for stream in self.streams:\n            with contextlib.suppress(Exception):\n                try:\n                    if stream.__class__.__name__ == \"TwitchStream\":\n                        await self.maybe_renew_twitch_bearer_token()\n                        embed, is_rerun = await stream.is_online()\n                    else:\n                        embed = await stream.is_online()\n                        is_rerun = False\n                except OfflineStream:\n                    if not stream._messages_cache:\n                        continue\n                    for message in stream._messages_cache:\n                        with contextlib.suppress(Exception):\n                            if await self.bot.cog_disabled_in_guild(self, message.guild):\n                                continue\n                            autodelete = await self.config.guild(message.guild).autodelete()\n                            if autodelete:\n                                await message.delete()\n                    stream._messages_cache.clear()\n                    await self.save_streams()\n                else:\n                    if stream._messages_cache:\n                        continue\n                    for channel_id in stream.channels:\n                        channel = self.bot.get_channel(channel_id)\n                        if not channel:\n                            continue\n                        if await self.bot.cog_disabled_in_guild(self, channel.guild):\n                            continue\n                        ignore_reruns = await self.config.guild(channel.guild).ignore_reruns()\n                        if ignore_reruns and is_rerun:\n                            continue\n                        mention_str, edited_roles = await self._get_mention_str(channel.guild)\n\n                        if mention_str:\n                            alert_msg = await self.config.guild(\n                                channel.guild\n                            ).live_message_mention()\n                            if alert_msg:\n                                content = alert_msg.format(mention=mention_str, stream=stream)\n                            else:\n                                content = _(\"{mention}, {stream} is live!\").format(\n                                    mention=mention_str,\n                                    stream=escape(\n                                        str(stream.name), mass_mentions=True, formatting=True\n                                    ),\n                                )\n                        else:\n                            alert_msg = await self.config.guild(\n                                channel.guild\n                            ).live_message_nomention()\n                            if alert_msg:\n                                content = alert_msg.format(stream=stream)\n                            else:\n                                content = _(\"{stream} is live!\").format(\n                                    stream=escape(\n                                        str(stream.name), mass_mentions=True, formatting=True\n                                    )\n                                )\n\n                        m = await channel.send(content, embed=embed)\n                        stream._messages_cache.append(m)\n                        if edited_roles:\n                            for role in edited_roles:\n                                await role.edit(mentionable=False)\n                        await self.save_streams()\n\n    async def _get_mention_str(self, guild: discord.Guild) -> Tuple[str, List[discord.Role]]:\n        \"\"\"Returns a 2-tuple with the string containing the mentions, and a list of\n        all roles which need to have their `mentionable` property set back to False.\n        \"\"\"\n        settings = self.config.guild(guild)\n        mentions = []\n        edited_roles = []\n        if await settings.mention_everyone():\n            mentions.append(\"@everyone\")\n        if await settings.mention_here():\n            mentions.append(\"@here\")\n        can_manage_roles = guild.me.guild_permissions.manage_roles\n        for role in guild.roles:\n            if await self.config.role(role).mention():\n                if can_manage_roles and not role.mentionable:\n                    try:\n                        await role.edit(mentionable=True)\n                    except discord.Forbidden:\n                        # Might still be unable to edit role based on hierarchy\n                        pass\n                    else:\n                        edited_roles.append(role)\n                mentions.append(role.mention)\n        return \" \".join(mentions), edited_roles\n\n    async def filter_streams(self, streams: list, channel: discord.TextChannel) -> list:\n        filtered = []\n        for stream in streams:\n            tw_id = str(stream[\"channel\"][\"_id\"])\n            for alert in self.streams:\n                if isinstance(alert, TwitchStream) and alert.id == tw_id:\n                    if channel.id in alert.channels:\n                        break\n            else:\n                filtered.append(stream)\n        return filtered\n\n    async def load_streams(self):\n        streams = []\n        for raw_stream in await self.config.streams():\n            _class = getattr(_streamtypes, raw_stream[\"type\"], None)\n            if not _class:\n                continue\n            raw_msg_cache = raw_stream[\"messages\"]\n            raw_stream[\"_messages_cache\"] = []\n            for raw_msg in raw_msg_cache:\n                chn = self.bot.get_channel(raw_msg[\"channel\"])\n                if chn is not None:\n                    try:\n                        msg = await chn.fetch_message(raw_msg[\"message\"])\n                    except discord.HTTPException:\n                        pass\n                    else:\n                        raw_stream[\"_messages_cache\"].append(msg)\n            token = await self.bot.get_shared_api_tokens(_class.token_name)\n            if token:\n                if _class.__name__ == \"TwitchStream\":\n                    raw_stream[\"token\"] = token.get(\"client_id\")\n                    raw_stream[\"bearer\"] = self.ttv_bearer_cache.get(\"access_token\", None)\n                else:\n                    raw_stream[\"token\"] = token\n            streams.append(_class(**raw_stream))\n\n        return streams\n\n    async def save_streams(self):\n        raw_streams = []\n        for stream in self.streams:\n            raw_streams.append(stream.export())\n\n        await self.config.streams.set(raw_streams)\n\n    def cog_unload(self):\n        if self.task:\n            self.task.cancel()\n\n    __del__ = cog_unload\n", "target": 1}
{"idx": 912, "func": "#     Copyright 2014 Netflix, Inc.\n#\n#     Licensed under the Apache License, Version 2.0 (the \"License\");\n#     you may not use this file except in compliance with the License.\n#     You may obtain a copy of the License at\n#\n#         http://www.apache.org/licenses/LICENSE-2.0\n#\n#     Unless required by applicable law or agreed to in writing, software\n#     distributed under the License is distributed on an \"AS IS\" BASIS,\n#     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n#     See the License for the specific language governing permissions and\n#     limitations under the License.\nfrom setuptools import setup\n\nsetup(\n    name='security_monkey',\n    version='0.8.0',\n    long_description=__doc__,\n    packages=['security_monkey'],\n    include_package_data=True,\n    zip_safe=False,\n    install_requires=[\n        'APScheduler==2.1.2',\n        'Flask==0.10.1',\n        'Flask-Mail==0.9.0',\n        'Flask-Migrate==1.3.1',\n        'Flask-Principal==0.4.0',\n        'Flask-RESTful==0.3.3',\n        'Flask-SQLAlchemy==1.0',\n        'Flask-Script==0.6.3',\n        # 'Flask-Security==1.7.4',\n        'Flask-Security-Fork==1.8.2',\n        'Jinja2==2.8',\n        'SQLAlchemy==0.9.2',\n        'boto>=2.41.0',\n        'ipaddr==2.1.11',\n        'itsdangerous==0.23',\n        'psycopg2==2.6.2',\n        'bcrypt==3.1.2',\n        'Sphinx==1.2.2',\n        'gunicorn==18.0',\n        'cryptography==1.7.1',\n        'boto3>=1.4.2',\n        'botocore>=1.4.81',\n        'dpath==1.3.2',\n        'pyyaml==3.11',\n        'jira==0.32',\n        'cloudaux>=1.0.6',\n        'joblib>=0.9.4',\n        'pyjwt>=1.01',\n    ],\n    extras_require = {\n        'onelogin': ['python-saml>=2.2.0'],\n        'tests': [\n            'nose==1.3.0',\n            'mock==1.0.1',\n            'moto==0.4.30',\n            'freezegun>=0.3.7'\n        ]\n    }\n)\n", "target": 0}
{"idx": 913, "func": "# Author: Trevor Perrin\n# See the LICENSE file for legal information regarding use of this file.\n\n\"\"\"Factory functions for asymmetric cryptography.\"\"\"\n\nfrom .compat import *\n\nfrom .rsakey import RSAKey\nfrom .python_rsakey import Python_RSAKey\nfrom tlslite.utils import cryptomath\n\nif cryptomath.m2cryptoLoaded:\n    from .openssl_rsakey import OpenSSL_RSAKey\n\nif cryptomath.pycryptoLoaded:\n    from .pycrypto_rsakey import PyCrypto_RSAKey\n\n# **************************************************************************\n# Factory Functions for RSA Keys\n# **************************************************************************\n\ndef generateRSAKey(bits, implementations=[\"openssl\", \"python\"]):\n    \"\"\"Generate an RSA key with the specified bit length.\n\n    :type bits: int\n    :param bits: Desired bit length of the new key's modulus.\n\n    :rtype: ~tlslite.utils.rsakey.RSAKey\n    :returns: A new RSA private key.\n    \"\"\"\n    for implementation in implementations:\n        if implementation == \"openssl\" and cryptomath.m2cryptoLoaded:\n            return OpenSSL_RSAKey.generate(bits)\n        elif implementation == \"python\":\n            return Python_RSAKey.generate(bits)\n    raise ValueError(\"No acceptable implementations\")\n\n#Parse as an OpenSSL or Python key\ndef parsePEMKey(s, private=False, public=False, passwordCallback=None,\n                implementations=[\"openssl\", \"python\"]):\n    \"\"\"Parse a PEM-format key.\n\n    The PEM format is used by OpenSSL and other tools.  The\n    format is typically used to store both the public and private\n    components of a key.  For example::\n\n       -----BEGIN RSA PRIVATE KEY-----\n        MIICXQIBAAKBgQDYscuoMzsGmW0pAYsmyHltxB2TdwHS0dImfjCMfaSDkfLdZY5+\n        dOWORVns9etWnr194mSGA1F0Pls/VJW8+cX9+3vtJV8zSdANPYUoQf0TP7VlJxkH\n        dSRkUbEoz5bAAs/+970uos7n7iXQIni+3erUTdYEk2iWnMBjTljfgbK/dQIDAQAB\n        AoGAJHoJZk75aKr7DSQNYIHuruOMdv5ZeDuJvKERWxTrVJqE32/xBKh42/IgqRrc\n        esBN9ZregRCd7YtxoL+EVUNWaJNVx2mNmezEznrc9zhcYUrgeaVdFO2yBF1889zO\n        gCOVwrO8uDgeyj6IKa25H6c1N13ih/o7ZzEgWbGG+ylU1yECQQDv4ZSJ4EjSh/Fl\n        aHdz3wbBa/HKGTjC8iRy476Cyg2Fm8MZUe9Yy3udOrb5ZnS2MTpIXt5AF3h2TfYV\n        VoFXIorjAkEA50FcJmzT8sNMrPaV8vn+9W2Lu4U7C+K/O2g1iXMaZms5PC5zV5aV\n        CKXZWUX1fq2RaOzlbQrpgiolhXpeh8FjxwJBAOFHzSQfSsTNfttp3KUpU0LbiVvv\n        i+spVSnA0O4rq79KpVNmK44Mq67hsW1P11QzrzTAQ6GVaUBRv0YS061td1kCQHnP\n        wtN2tboFR6lABkJDjxoGRvlSt4SOPr7zKGgrWjeiuTZLHXSAnCY+/hr5L9Q3ZwXG\n        6x6iBdgLjVIe4BZQNtcCQQDXGv/gWinCNTN3MPWfTW/RGzuMYVmyBFais0/VrgdH\n        h1dLpztmpQqfyH/zrBXQ9qL/zR4ojS6XYneO/U18WpEe\n        -----END RSA PRIVATE KEY-----\n\n    To generate a key like this with OpenSSL, run::\n\n        openssl genrsa 2048 > key.pem\n\n    This format also supports password-encrypted private keys.  TLS\n    Lite can only handle password-encrypted private keys when OpenSSL\n    and M2Crypto are installed.  In this case, passwordCallback will be\n    invoked to query the user for the password.\n\n    :type s: str\n    :param s: A string containing a PEM-encoded public or private key.\n\n    :type private: bool\n    :param private: If True, a :py:class:`SyntaxError` will be raised if the\n        private key component is not present.\n\n    :type public: bool\n    :param public: If True, the private key component (if present) will\n        be discarded, so this function will always return a public key.\n\n    :type passwordCallback: callable\n    :param passwordCallback: This function will be called, with no\n        arguments, if the PEM-encoded private key is password-encrypted.\n        The callback should return the password string.  If the password is\n        incorrect, SyntaxError will be raised.  If no callback is passed\n        and the key is password-encrypted, a prompt will be displayed at\n        the console.\n\n    :rtype: ~tlslite.utils.rsakey.RSAKey\n    :returns: An RSA key.\n\n    :raises SyntaxError: If the key is not properly formatted.\n    \"\"\"\n    for implementation in implementations:\n        if implementation == \"openssl\" and cryptomath.m2cryptoLoaded:\n            key = OpenSSL_RSAKey.parse(s, passwordCallback)\n            break\n        elif implementation == \"python\":\n            key = Python_RSAKey.parsePEM(s)\n            break\n    else:\n        raise ValueError(\"No acceptable implementations\")\n\n    return _parseKeyHelper(key, private, public)\n\n\ndef _parseKeyHelper(key, private, public):\n    if private:\n        if not key.hasPrivateKey():\n            raise SyntaxError(\"Not a private key!\")\n\n    if public:\n        return _createPublicKey(key)\n\n    if private:\n        if hasattr(key, \"d\"):\n            return _createPrivateKey(key)\n        else:\n            return key\n\n    return key\n\ndef parseAsPublicKey(s):\n    \"\"\"Parse a PEM-formatted public key.\n\n    :type s: str\n    :param s: A string containing a PEM-encoded public or private key.\n\n    :rtype: ~tlslite.utils.rsakey.RSAKey\n    :returns: An RSA public key.\n\n    :raises SyntaxError: If the key is not properly formatted.\n    \"\"\"\n    return parsePEMKey(s, public=True)\n\ndef parsePrivateKey(s):\n    \"\"\"Parse a PEM-formatted private key.\n\n    :type s: str\n    :param s: A string containing a PEM-encoded private key.\n\n    :rtype: ~tlslite.utils.rsakey.RSAKey\n    :returns: An RSA private key.\n\n    :raises SyntaxError: If the key is not properly formatted.\n    \"\"\"\n    return parsePEMKey(s, private=True)\n\ndef _createPublicKey(key):\n    \"\"\"\n    Create a new public key.  Discard any private component,\n    and return the most efficient key possible.\n    \"\"\"\n    if not isinstance(key, RSAKey):\n        raise AssertionError()\n    return _createPublicRSAKey(key.n, key.e)\n\ndef _createPrivateKey(key):\n    \"\"\"\n    Create a new private key.  Return the most efficient key possible.\n    \"\"\"\n    if not isinstance(key, RSAKey):\n        raise AssertionError()\n    if not key.hasPrivateKey():\n        raise AssertionError()\n    return _createPrivateRSAKey(key.n, key.e, key.d, key.p, key.q, key.dP,\n                                key.dQ, key.qInv)\n\ndef _createPublicRSAKey(n, e, implementations = [\"openssl\", \"pycrypto\",\n                                                \"python\"]):\n    for implementation in implementations:\n        if implementation == \"openssl\" and cryptomath.m2cryptoLoaded:\n            return OpenSSL_RSAKey(n, e)\n        elif implementation == \"pycrypto\" and cryptomath.pycryptoLoaded:\n            return PyCrypto_RSAKey(n, e)\n        elif implementation == \"python\":\n            return Python_RSAKey(n, e)\n    raise ValueError(\"No acceptable implementations\")\n\ndef _createPrivateRSAKey(n, e, d, p, q, dP, dQ, qInv,\n                        implementations = [\"pycrypto\", \"python\"]):\n    for implementation in implementations:\n        if implementation == \"pycrypto\" and cryptomath.pycryptoLoaded:\n            return PyCrypto_RSAKey(n, e, d, p, q, dP, dQ, qInv)\n        elif implementation == \"python\":\n            return Python_RSAKey(n, e, d, p, q, dP, dQ, qInv)\n    raise ValueError(\"No acceptable implementations\")\n", "target": 1}
{"idx": 914, "func": "# vim: tabstop=4 shiftwidth=4 softtabstop=4\n\n# Copyright (c) 2011 X.commerce, a business unit of eBay Inc.\n# Copyright 2010 United States Government as represented by the\n# Administrator of the National Aeronautics and Space Administration.\n# All Rights Reserved.\n#\n#    Licensed under the Apache License, Version 2.0 (the \"License\"); you may\n#    not use this file except in compliance with the License. You may obtain\n#    a copy of the License at\n#\n#         http://www.apache.org/licenses/LICENSE-2.0\n#\n#    Unless required by applicable law or agreed to in writing, software\n#    distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n#    License for the specific language governing permissions and limitations\n#    under the License.\n\n\"\"\"Defines interface for DB access.\n\nThe underlying driver is loaded as a :class:`LazyPluggable`.\n\nFunctions in this module are imported into the nova.db namespace. Call these\nfunctions from nova.db namespace, not the nova.db.api namespace.\n\nAll functions in this module return objects that implement a dictionary-like\ninterface. Currently, many of these objects are sqlalchemy objects that\nimplement a dictionary interface. However, a future goal is to have all of\nthese objects be simple dictionaries.\n\n\n**Related Flags**\n\n:db_backend:  string to lookup in the list of LazyPluggable backends.\n              `sqlalchemy` is the only supported backend right now.\n\n:sql_connection:  string specifying the sqlalchemy connection to use, like:\n                  `sqlite:///var/lib/nova/nova.sqlite`.\n\n:enable_new_services:  when adding a new service to the database, is it in the\n                       pool of available hardware (Default: True)\n\n\"\"\"\n\nfrom nova import exception\nfrom nova import flags\nfrom nova.openstack.common import cfg\nfrom nova import utils\n\n\ndb_opts = [\n    cfg.StrOpt('db_backend',\n               default='sqlalchemy',\n               help='The backend to use for db'),\n    cfg.BoolOpt('enable_new_services',\n                default=True,\n                help='Services to be added to the available pool on create'),\n    cfg.StrOpt('instance_name_template',\n               default='instance-%08x',\n               help='Template string to be used to generate instance names'),\n    cfg.StrOpt('volume_name_template',\n               default='volume-%08x',\n               help='Template string to be used to generate instance names'),\n    cfg.StrOpt('snapshot_name_template',\n               default='snapshot-%08x',\n               help='Template string to be used to generate snapshot names'),\n    ]\n\nFLAGS = flags.FLAGS\nFLAGS.register_opts(db_opts)\n\nIMPL = utils.LazyPluggable('db_backend',\n                           sqlalchemy='nova.db.sqlalchemy.api')\n\n\nclass NoMoreNetworks(exception.Error):\n    \"\"\"No more available networks.\"\"\"\n    pass\n\n\nclass NoMoreTargets(exception.Error):\n    \"\"\"No more available targets\"\"\"\n    pass\n\n\n###################\n\n\ndef service_destroy(context, instance_id):\n    \"\"\"Destroy the service or raise if it does not exist.\"\"\"\n    return IMPL.service_destroy(context, instance_id)\n\n\ndef service_get(context, service_id):\n    \"\"\"Get a service or raise if it does not exist.\"\"\"\n    return IMPL.service_get(context, service_id)\n\n\ndef service_get_by_host_and_topic(context, host, topic):\n    \"\"\"Get a service by host it's on and topic it listens to.\"\"\"\n    return IMPL.service_get_by_host_and_topic(context, host, topic)\n\n\ndef service_get_all(context, disabled=None):\n    \"\"\"Get all services.\"\"\"\n    return IMPL.service_get_all(context, disabled)\n\n\ndef service_get_all_by_topic(context, topic):\n    \"\"\"Get all services for a given topic.\"\"\"\n    return IMPL.service_get_all_by_topic(context, topic)\n\n\ndef service_get_all_by_host(context, host):\n    \"\"\"Get all services for a given host.\"\"\"\n    return IMPL.service_get_all_by_host(context, host)\n\n\ndef service_get_all_compute_by_host(context, host):\n    \"\"\"Get all compute services for a given host.\"\"\"\n    return IMPL.service_get_all_compute_by_host(context, host)\n\n\ndef service_get_all_compute_sorted(context):\n    \"\"\"Get all compute services sorted by instance count.\n\n    :returns: a list of (Service, instance_count) tuples.\n\n    \"\"\"\n    return IMPL.service_get_all_compute_sorted(context)\n\n\ndef service_get_all_volume_sorted(context):\n    \"\"\"Get all volume services sorted by volume count.\n\n    :returns: a list of (Service, volume_count) tuples.\n\n    \"\"\"\n    return IMPL.service_get_all_volume_sorted(context)\n\n\ndef service_get_by_args(context, host, binary):\n    \"\"\"Get the state of an service by node name and binary.\"\"\"\n    return IMPL.service_get_by_args(context, host, binary)\n\n\ndef service_create(context, values):\n    \"\"\"Create a service from the values dictionary.\"\"\"\n    return IMPL.service_create(context, values)\n\n\ndef service_update(context, service_id, values):\n    \"\"\"Set the given properties on an service and update it.\n\n    Raises NotFound if service does not exist.\n\n    \"\"\"\n    return IMPL.service_update(context, service_id, values)\n\n\n###################\n\n\ndef compute_node_get(context, compute_id):\n    \"\"\"Get an computeNode or raise if it does not exist.\"\"\"\n    return IMPL.compute_node_get(context, compute_id)\n\n\ndef compute_node_get_all(context):\n    \"\"\"Get all computeNodes.\"\"\"\n    return IMPL.compute_node_get_all(context)\n\n\ndef compute_node_create(context, values):\n    \"\"\"Create a computeNode from the values dictionary.\"\"\"\n    return IMPL.compute_node_create(context, values)\n\n\ndef compute_node_update(context, compute_id, values, auto_adjust=True):\n    \"\"\"Set the given properties on an computeNode and update it.\n\n    Raises NotFound if computeNode does not exist.\n    \"\"\"\n    return IMPL.compute_node_update(context, compute_id, values, auto_adjust)\n\n\ndef compute_node_get_by_host(context, host):\n    return IMPL.compute_node_get_by_host(context, host)\n\n\ndef compute_node_utilization_update(context, host, free_ram_mb_delta=0,\n                          free_disk_gb_delta=0, work_delta=0, vm_delta=0):\n    return IMPL.compute_node_utilization_update(context, host,\n                          free_ram_mb_delta, free_disk_gb_delta, work_delta,\n                          vm_delta)\n\n\ndef compute_node_utilization_set(context, host, free_ram_mb=None,\n                                 free_disk_gb=None, work=None, vms=None):\n    return IMPL.compute_node_utilization_set(context, host, free_ram_mb,\n                                             free_disk_gb, work, vms)\n\n###################\n\n\ndef certificate_create(context, values):\n    \"\"\"Create a certificate from the values dictionary.\"\"\"\n    return IMPL.certificate_create(context, values)\n\n\ndef certificate_get_all_by_project(context, project_id):\n    \"\"\"Get all certificates for a project.\"\"\"\n    return IMPL.certificate_get_all_by_project(context, project_id)\n\n\ndef certificate_get_all_by_user(context, user_id):\n    \"\"\"Get all certificates for a user.\"\"\"\n    return IMPL.certificate_get_all_by_user(context, user_id)\n\n\ndef certificate_get_all_by_user_and_project(context, user_id, project_id):\n    \"\"\"Get all certificates for a user and project.\"\"\"\n    return IMPL.certificate_get_all_by_user_and_project(context,\n                                                        user_id,\n                                                        project_id)\n\n\n###################\n\ndef floating_ip_get(context, id):\n    return IMPL.floating_ip_get(context, id)\n\n\ndef floating_ip_get_pools(context):\n    \"\"\"Returns a list of floating ip pools\"\"\"\n    return IMPL.floating_ip_get_pools(context)\n\n\ndef floating_ip_allocate_address(context, project_id, pool):\n    \"\"\"Allocate free floating ip from specified pool and return the address.\n\n    Raises if one is not available.\n\n    \"\"\"\n    return IMPL.floating_ip_allocate_address(context, project_id, pool)\n\n\ndef floating_ip_create(context, values):\n    \"\"\"Create a floating ip from the values dictionary.\"\"\"\n    return IMPL.floating_ip_create(context, values)\n\n\ndef floating_ip_count_by_project(context, project_id):\n    \"\"\"Count floating ips used by project.\"\"\"\n    return IMPL.floating_ip_count_by_project(context, project_id)\n\n\ndef floating_ip_deallocate(context, address):\n    \"\"\"Deallocate an floating ip by address.\"\"\"\n    return IMPL.floating_ip_deallocate(context, address)\n\n\ndef floating_ip_destroy(context, address):\n    \"\"\"Destroy the floating_ip or raise if it does not exist.\"\"\"\n    return IMPL.floating_ip_destroy(context, address)\n\n\ndef floating_ip_disassociate(context, address):\n    \"\"\"Disassociate an floating ip from a fixed ip by address.\n\n    :returns: the address of the existing fixed ip.\n\n    \"\"\"\n    return IMPL.floating_ip_disassociate(context, address)\n\n\ndef floating_ip_fixed_ip_associate(context, floating_address,\n                                   fixed_address, host):\n    \"\"\"Associate an floating ip to a fixed_ip by address.\"\"\"\n    return IMPL.floating_ip_fixed_ip_associate(context,\n                                               floating_address,\n                                               fixed_address,\n                                               host)\n\n\ndef floating_ip_get_all(context):\n    \"\"\"Get all floating ips.\"\"\"\n    return IMPL.floating_ip_get_all(context)\n\n\ndef floating_ip_get_all_by_host(context, host):\n    \"\"\"Get all floating ips by host.\"\"\"\n    return IMPL.floating_ip_get_all_by_host(context, host)\n\n\ndef floating_ip_get_all_by_project(context, project_id):\n    \"\"\"Get all floating ips by project.\"\"\"\n    return IMPL.floating_ip_get_all_by_project(context, project_id)\n\n\ndef floating_ip_get_by_address(context, address):\n    \"\"\"Get a floating ip by address or raise if it doesn't exist.\"\"\"\n    return IMPL.floating_ip_get_by_address(context, address)\n\n\ndef floating_ip_get_by_fixed_address(context, fixed_address):\n    \"\"\"Get a floating ips by fixed address\"\"\"\n    return IMPL.floating_ip_get_by_fixed_address(context, fixed_address)\n\n\ndef floating_ip_get_by_fixed_ip_id(context, fixed_ip_id):\n    \"\"\"Get a floating ips by fixed address\"\"\"\n    return IMPL.floating_ip_get_by_fixed_ip_id(context, fixed_ip_id)\n\n\ndef floating_ip_update(context, address, values):\n    \"\"\"Update a floating ip by address or raise if it doesn't exist.\"\"\"\n    return IMPL.floating_ip_update(context, address, values)\n\n\ndef floating_ip_set_auto_assigned(context, address):\n    \"\"\"Set auto_assigned flag to floating ip\"\"\"\n    return IMPL.floating_ip_set_auto_assigned(context, address)\n\n\ndef dnsdomain_list(context):\n    \"\"\"Get a list of all zones in our database, public and private.\"\"\"\n    return IMPL.dnsdomain_list(context)\n\n\ndef dnsdomain_register_for_zone(context, fqdomain, zone):\n    \"\"\"Associated a DNS domain with an availability zone\"\"\"\n    return IMPL.dnsdomain_register_for_zone(context, fqdomain, zone)\n\n\ndef dnsdomain_register_for_project(context, fqdomain, project):\n    \"\"\"Associated a DNS domain with a project id\"\"\"\n    return IMPL.dnsdomain_register_for_project(context, fqdomain, project)\n\n\ndef dnsdomain_unregister(context, fqdomain):\n    \"\"\"Purge associations for the specified DNS zone\"\"\"\n    return IMPL.dnsdomain_unregister(context, fqdomain)\n\n\ndef dnsdomain_get(context, fqdomain):\n    \"\"\"Get the db record for the specified domain.\"\"\"\n    return IMPL.dnsdomain_get(context, fqdomain)\n\n\n####################\n\n\ndef migration_update(context, id, values):\n    \"\"\"Update a migration instance.\"\"\"\n    return IMPL.migration_update(context, id, values)\n\n\ndef migration_create(context, values):\n    \"\"\"Create a migration record.\"\"\"\n    return IMPL.migration_create(context, values)\n\n\ndef migration_get(context, migration_id):\n    \"\"\"Finds a migration by the id.\"\"\"\n    return IMPL.migration_get(context, migration_id)\n\n\ndef migration_get_by_instance_and_status(context, instance_uuid, status):\n    \"\"\"Finds a migration by the instance uuid its migrating.\"\"\"\n    return IMPL.migration_get_by_instance_and_status(context, instance_uuid,\n            status)\n\n\ndef migration_get_all_unconfirmed(context, confirm_window):\n    \"\"\"Finds all unconfirmed migrations within the confirmation window.\"\"\"\n    return IMPL.migration_get_all_unconfirmed(context, confirm_window)\n\n\n####################\n\n\ndef fixed_ip_associate(context, address, instance_id, network_id=None,\n                       reserved=False):\n    \"\"\"Associate fixed ip to instance.\n\n    Raises if fixed ip is not available.\n\n    \"\"\"\n    return IMPL.fixed_ip_associate(context, address, instance_id, network_id,\n                                   reserved)\n\n\ndef fixed_ip_associate_pool(context, network_id, instance_id=None, host=None):\n    \"\"\"Find free ip in network and associate it to instance or host.\n\n    Raises if one is not available.\n\n    \"\"\"\n    return IMPL.fixed_ip_associate_pool(context, network_id,\n                                        instance_id, host)\n\n\ndef fixed_ip_create(context, values):\n    \"\"\"Create a fixed ip from the values dictionary.\"\"\"\n    return IMPL.fixed_ip_create(context, values)\n\n\ndef fixed_ip_bulk_create(context, ips):\n    \"\"\"Create a lot of fixed ips from the values dictionary.\"\"\"\n    return IMPL.fixed_ip_bulk_create(context, ips)\n\n\ndef fixed_ip_disassociate(context, address):\n    \"\"\"Disassociate a fixed ip from an instance by address.\"\"\"\n    return IMPL.fixed_ip_disassociate(context, address)\n\n\ndef fixed_ip_disassociate_all_by_timeout(context, host, time):\n    \"\"\"Disassociate old fixed ips from host.\"\"\"\n    return IMPL.fixed_ip_disassociate_all_by_timeout(context, host, time)\n\n\ndef fixed_ip_get(context, id):\n    \"\"\"Get fixed ip by id or raise if it does not exist.\"\"\"\n    return IMPL.fixed_ip_get(context, id)\n\n\ndef fixed_ip_get_all(context):\n    \"\"\"Get all defined fixed ips.\"\"\"\n    return IMPL.fixed_ip_get_all(context)\n\n\ndef fixed_ip_get_by_address(context, address):\n    \"\"\"Get a fixed ip by address or raise if it does not exist.\"\"\"\n    return IMPL.fixed_ip_get_by_address(context, address)\n\n\ndef fixed_ip_get_by_instance(context, instance_id):\n    \"\"\"Get fixed ips by instance or raise if none exist.\"\"\"\n    return IMPL.fixed_ip_get_by_instance(context, instance_id)\n\n\ndef fixed_ip_get_by_network_host(context, network_id, host):\n    \"\"\"Get fixed ip for a host in a network.\"\"\"\n    return IMPL.fixed_ip_get_by_network_host(context, network_id, host)\n\n\ndef fixed_ips_by_virtual_interface(context, vif_id):\n    \"\"\"Get fixed ips by virtual interface or raise if none exist.\"\"\"\n    return IMPL.fixed_ips_by_virtual_interface(context, vif_id)\n\n\ndef fixed_ip_get_network(context, address):\n    \"\"\"Get a network for a fixed ip by address.\"\"\"\n    return IMPL.fixed_ip_get_network(context, address)\n\n\ndef fixed_ip_update(context, address, values):\n    \"\"\"Create a fixed ip from the values dictionary.\"\"\"\n    return IMPL.fixed_ip_update(context, address, values)\n\n####################\n\n\ndef virtual_interface_create(context, values):\n    \"\"\"Create a virtual interface record in the database.\"\"\"\n    return IMPL.virtual_interface_create(context, values)\n\n\ndef virtual_interface_get(context, vif_id):\n    \"\"\"Gets a virtual interface from the table,\"\"\"\n    return IMPL.virtual_interface_get(context, vif_id)\n\n\ndef virtual_interface_get_by_address(context, address):\n    \"\"\"Gets a virtual interface from the table filtering on address.\"\"\"\n    return IMPL.virtual_interface_get_by_address(context, address)\n\n\ndef virtual_interface_get_by_uuid(context, vif_uuid):\n    \"\"\"Gets a virtual interface from the table filtering on vif uuid.\"\"\"\n    return IMPL.virtual_interface_get_by_uuid(context, vif_uuid)\n\n\ndef virtual_interface_get_by_instance(context, instance_id):\n    \"\"\"Gets all virtual_interfaces for instance.\"\"\"\n    return IMPL.virtual_interface_get_by_instance(context, instance_id)\n\n\ndef virtual_interface_get_by_instance_and_network(context, instance_id,\n                                                           network_id):\n    \"\"\"Gets all virtual interfaces for instance.\"\"\"\n    return IMPL.virtual_interface_get_by_instance_and_network(context,\n                                                              instance_id,\n                                                              network_id)\n\n\ndef virtual_interface_delete(context, vif_id):\n    \"\"\"Delete virtual interface record from the database.\"\"\"\n    return IMPL.virtual_interface_delete(context, vif_id)\n\n\ndef virtual_interface_delete_by_instance(context, instance_id):\n    \"\"\"Delete virtual interface records associated with instance.\"\"\"\n    return IMPL.virtual_interface_delete_by_instance(context, instance_id)\n\n\ndef virtual_interface_get_all(context):\n    \"\"\"Gets all virtual interfaces from the table\"\"\"\n    return IMPL.virtual_interface_get_all(context)\n\n\n####################\n\n\ndef instance_create(context, values):\n    \"\"\"Create an instance from the values dictionary.\"\"\"\n    return IMPL.instance_create(context, values)\n\n\ndef instance_data_get_for_project(context, project_id):\n    \"\"\"Get (instance_count, total_cores, total_ram) for project.\"\"\"\n    return IMPL.instance_data_get_for_project(context, project_id)\n\n\ndef instance_destroy(context, instance_id):\n    \"\"\"Destroy the instance or raise if it does not exist.\"\"\"\n    return IMPL.instance_destroy(context, instance_id)\n\n\ndef instance_get_by_uuid(context, uuid):\n    \"\"\"Get an instance or raise if it does not exist.\"\"\"\n    return IMPL.instance_get_by_uuid(context, uuid)\n\n\ndef instance_get(context, instance_id):\n    \"\"\"Get an instance or raise if it does not exist.\"\"\"\n    return IMPL.instance_get(context, instance_id)\n\n\ndef instance_get_all(context):\n    \"\"\"Get all instances.\"\"\"\n    return IMPL.instance_get_all(context)\n\n\ndef instance_get_all_by_filters(context, filters, sort_key='created_at',\n                                sort_dir='desc'):\n    \"\"\"Get all instances that match all filters.\"\"\"\n    return IMPL.instance_get_all_by_filters(context, filters, sort_key,\n                                            sort_dir)\n\n\ndef instance_get_active_by_window(context, begin, end=None, project_id=None):\n    \"\"\"Get instances active during a certain time window.\n\n    Specifying a project_id will filter for a certain project.\"\"\"\n    return IMPL.instance_get_active_by_window(context, begin, end, project_id)\n\n\ndef instance_get_active_by_window_joined(context, begin, end=None,\n                                         project_id=None):\n    \"\"\"Get instances and joins active during a certain time window.\n\n    Specifying a project_id will filter for a certain project.\"\"\"\n    return IMPL.instance_get_active_by_window_joined(context, begin, end,\n                                              project_id)\n\n\ndef instance_get_all_by_project(context, project_id):\n    \"\"\"Get all instance belonging to a project.\"\"\"\n    return IMPL.instance_get_all_by_project(context, project_id)\n\n\ndef instance_get_all_by_host(context, host):\n    \"\"\"Get all instance belonging to a host.\"\"\"\n    return IMPL.instance_get_all_by_host(context, host)\n\n\ndef instance_get_all_by_reservation(context, reservation_id):\n    \"\"\"Get all instances belonging to a reservation.\"\"\"\n    return IMPL.instance_get_all_by_reservation(context, reservation_id)\n\n\ndef instance_get_floating_address(context, instance_id):\n    \"\"\"Get the first floating ip address of an instance.\"\"\"\n    return IMPL.instance_get_floating_address(context, instance_id)\n\n\ndef instance_get_all_hung_in_rebooting(context, reboot_window):\n    \"\"\"Get all instances stuck in a rebooting state.\"\"\"\n    return IMPL.instance_get_all_hung_in_rebooting(context, reboot_window)\n\n\ndef instance_test_and_set(context, instance_id, attr, ok_states,\n                          new_state):\n    \"\"\"Atomically check if an instance is in a valid state, and if it is, set\n    the instance into a new state.\n    \"\"\"\n    return IMPL.instance_test_and_set(\n            context, instance_id, attr, ok_states, new_state)\n\n\ndef instance_update(context, instance_id, values):\n    \"\"\"Set the given properties on an instance and update it.\n\n    Raises NotFound if instance does not exist.\n\n    \"\"\"\n    return IMPL.instance_update(context, instance_id, values)\n\n\ndef instance_add_security_group(context, instance_id, security_group_id):\n    \"\"\"Associate the given security group with the given instance.\"\"\"\n    return IMPL.instance_add_security_group(context, instance_id,\n                                            security_group_id)\n\n\ndef instance_remove_security_group(context, instance_id, security_group_id):\n    \"\"\"Disassociate the given security group from the given instance.\"\"\"\n    return IMPL.instance_remove_security_group(context, instance_id,\n                                            security_group_id)\n\n\ndef instance_action_create(context, values):\n    \"\"\"Create an instance action from the values dictionary.\"\"\"\n    return IMPL.instance_action_create(context, values)\n\n\ndef instance_get_actions(context, instance_uuid):\n    \"\"\"Get instance actions by instance uuid.\"\"\"\n    return IMPL.instance_get_actions(context, instance_uuid)\n\n\ndef instance_get_id_to_uuid_mapping(context, ids):\n    \"\"\"Return a dictionary containing 'ID: UUID' given the ids\"\"\"\n    return IMPL.instance_get_id_to_uuid_mapping(context, ids)\n\n\n###################\n\n\ndef instance_info_cache_create(context, values):\n    \"\"\"Create a new instance cache record in the table.\n\n    :param context: = request context object\n    :param values: = dict containing column values\n    \"\"\"\n    return IMPL.instance_info_cache_create(context, values)\n\n\ndef instance_info_cache_get(context, instance_uuid):\n    \"\"\"Gets an instance info cache from the table.\n\n    :param instance_uuid: = uuid of the info cache's instance\n    \"\"\"\n    return IMPL.instance_info_cache_get(context, instance_uuid)\n\n\ndef instance_info_cache_update(context, instance_uuid, values):\n    \"\"\"Update an instance info cache record in the table.\n\n    :param instance_uuid: = uuid of info cache's instance\n    :param values: = dict containing column values to update\n    \"\"\"\n    return IMPL.instance_info_cache_update(context, instance_uuid, values)\n\n\ndef instance_info_cache_delete(context, instance_uuid):\n    \"\"\"Deletes an existing instance_info_cache record\n\n    :param instance_uuid: = uuid of the instance tied to the cache record\n    \"\"\"\n    return IMPL.instance_info_cache_delete(context, instance_uuid)\n\n\n###################\n\n\ndef key_pair_create(context, values):\n    \"\"\"Create a key_pair from the values dictionary.\"\"\"\n    return IMPL.key_pair_create(context, values)\n\n\ndef key_pair_destroy(context, user_id, name):\n    \"\"\"Destroy the key_pair or raise if it does not exist.\"\"\"\n    return IMPL.key_pair_destroy(context, user_id, name)\n\n\ndef key_pair_destroy_all_by_user(context, user_id):\n    \"\"\"Destroy all key_pairs by user.\"\"\"\n    return IMPL.key_pair_destroy_all_by_user(context, user_id)\n\n\ndef key_pair_get(context, user_id, name):\n    \"\"\"Get a key_pair or raise if it does not exist.\"\"\"\n    return IMPL.key_pair_get(context, user_id, name)\n\n\ndef key_pair_get_all_by_user(context, user_id):\n    \"\"\"Get all key_pairs by user.\"\"\"\n    return IMPL.key_pair_get_all_by_user(context, user_id)\n\n\n####################\n\n\ndef network_associate(context, project_id, force=False):\n    \"\"\"Associate a free network to a project.\"\"\"\n    return IMPL.network_associate(context, project_id, force)\n\n\ndef network_count(context):\n    \"\"\"Return the number of networks.\"\"\"\n    return IMPL.network_count(context)\n\n\ndef network_count_reserved_ips(context, network_id):\n    \"\"\"Return the number of reserved ips in the network.\"\"\"\n    return IMPL.network_count_reserved_ips(context, network_id)\n\n\ndef network_create_safe(context, values):\n    \"\"\"Create a network from the values dict.\n\n    The network is only returned if the create succeeds. If the create violates\n    constraints because the network already exists, no exception is raised.\n\n    \"\"\"\n    return IMPL.network_create_safe(context, values)\n\n\ndef network_delete_safe(context, network_id):\n    \"\"\"Delete network with key network_id.\n\n    This method assumes that the network is not associated with any project\n\n    \"\"\"\n    return IMPL.network_delete_safe(context, network_id)\n\n\ndef network_create_fixed_ips(context, network_id, num_vpn_clients):\n    \"\"\"Create the ips for the network, reserving sepecified ips.\"\"\"\n    return IMPL.network_create_fixed_ips(context, network_id, num_vpn_clients)\n\n\ndef network_disassociate(context, network_id):\n    \"\"\"Disassociate the network from project or raise if it does not exist.\"\"\"\n    return IMPL.network_disassociate(context, network_id)\n\n\ndef network_get(context, network_id):\n    \"\"\"Get an network or raise if it does not exist.\"\"\"\n    return IMPL.network_get(context, network_id)\n\n\ndef network_get_all(context):\n    \"\"\"Return all defined networks.\"\"\"\n    return IMPL.network_get_all(context)\n\n\ndef network_get_all_by_uuids(context, network_uuids, project_id=None):\n    \"\"\"Return networks by ids.\"\"\"\n    return IMPL.network_get_all_by_uuids(context, network_uuids, project_id)\n\n\n# pylint: disable=C0103\n\n\ndef network_get_associated_fixed_ips(context, network_id, host=None):\n    \"\"\"Get all network's ips that have been associated.\"\"\"\n    return IMPL.network_get_associated_fixed_ips(context, network_id, host)\n\n\ndef network_get_by_bridge(context, bridge):\n    \"\"\"Get a network by bridge or raise if it does not exist.\"\"\"\n    return IMPL.network_get_by_bridge(context, bridge)\n\n\ndef network_get_by_uuid(context, uuid):\n    \"\"\"Get a network by uuid or raise if it does not exist.\"\"\"\n    return IMPL.network_get_by_uuid(context, uuid)\n\n\ndef network_get_by_cidr(context, cidr):\n    \"\"\"Get a network by cidr or raise if it does not exist\"\"\"\n    return IMPL.network_get_by_cidr(context, cidr)\n\n\ndef network_get_by_instance(context, instance_id):\n    \"\"\"Get a network by instance id or raise if it does not exist.\"\"\"\n    return IMPL.network_get_by_instance(context, instance_id)\n\n\ndef network_get_all_by_instance(context, instance_id):\n    \"\"\"Get all networks by instance id or raise if none exist.\"\"\"\n    return IMPL.network_get_all_by_instance(context, instance_id)\n\n\ndef network_get_all_by_host(context, host):\n    \"\"\"All networks for which the given host is the network host.\"\"\"\n    return IMPL.network_get_all_by_host(context, host)\n\n\ndef network_get_index(context, network_id):\n    \"\"\"Get non-conflicting index for network.\"\"\"\n    return IMPL.network_get_index(context, network_id)\n\n\ndef network_set_cidr(context, network_id, cidr):\n    \"\"\"Set the Classless Inner Domain Routing for the network.\"\"\"\n    return IMPL.network_set_cidr(context, network_id, cidr)\n\n\ndef network_set_host(context, network_id, host_id):\n    \"\"\"Safely set the host for network.\"\"\"\n    return IMPL.network_set_host(context, network_id, host_id)\n\n\ndef network_update(context, network_id, values):\n    \"\"\"Set the given properties on an network and update it.\n\n    Raises NotFound if network does not exist.\n\n    \"\"\"\n    return IMPL.network_update(context, network_id, values)\n\n\n###################\n\n\ndef queue_get_for(context, topic, physical_node_id):\n    \"\"\"Return a channel to send a message to a node with a topic.\"\"\"\n    return IMPL.queue_get_for(context, topic, physical_node_id)\n\n\n###################\n\n\ndef iscsi_target_count_by_host(context, host):\n    \"\"\"Return count of export devices.\"\"\"\n    return IMPL.iscsi_target_count_by_host(context, host)\n\n\ndef iscsi_target_create_safe(context, values):\n    \"\"\"Create an iscsi_target from the values dictionary.\n\n    The device is not returned. If the create violates the unique\n    constraints because the iscsi_target and host already exist,\n    no exception is raised.\n\n    \"\"\"\n    return IMPL.iscsi_target_create_safe(context, values)\n\n\n###############\n\n\ndef auth_token_destroy(context, token_id):\n    \"\"\"Destroy an auth token.\"\"\"\n    return IMPL.auth_token_destroy(context, token_id)\n\n\ndef auth_token_get(context, token_hash):\n    \"\"\"Retrieves a token given the hash representing it.\"\"\"\n    return IMPL.auth_token_get(context, token_hash)\n\n\ndef auth_token_update(context, token_hash, values):\n    \"\"\"Updates a token given the hash representing it.\"\"\"\n    return IMPL.auth_token_update(context, token_hash, values)\n\n\ndef auth_token_create(context, token):\n    \"\"\"Creates a new token.\"\"\"\n    return IMPL.auth_token_create(context, token)\n\n\n###################\n\n\ndef quota_create(context, project_id, resource, limit):\n    \"\"\"Create a quota for the given project and resource.\"\"\"\n    return IMPL.quota_create(context, project_id, resource, limit)\n\n\ndef quota_get(context, project_id, resource):\n    \"\"\"Retrieve a quota or raise if it does not exist.\"\"\"\n    return IMPL.quota_get(context, project_id, resource)\n\n\ndef quota_get_all_by_project(context, project_id):\n    \"\"\"Retrieve all quotas associated with a given project.\"\"\"\n    return IMPL.quota_get_all_by_project(context, project_id)\n\n\ndef quota_update(context, project_id, resource, limit):\n    \"\"\"Update a quota or raise if it does not exist.\"\"\"\n    return IMPL.quota_update(context, project_id, resource, limit)\n\n\ndef quota_destroy(context, project_id, resource):\n    \"\"\"Destroy the quota or raise if it does not exist.\"\"\"\n    return IMPL.quota_destroy(context, project_id, resource)\n\n\ndef quota_destroy_all_by_project(context, project_id):\n    \"\"\"Destroy all quotas associated with a given project.\"\"\"\n    return IMPL.quota_get_all_by_project(context, project_id)\n\n\n###################\n\n\ndef volume_allocate_iscsi_target(context, volume_id, host):\n    \"\"\"Atomically allocate a free iscsi_target from the pool.\"\"\"\n    return IMPL.volume_allocate_iscsi_target(context, volume_id, host)\n\n\ndef volume_attached(context, volume_id, instance_id, mountpoint):\n    \"\"\"Ensure that a volume is set as attached.\"\"\"\n    return IMPL.volume_attached(context, volume_id, instance_id, mountpoint)\n\n\ndef volume_create(context, values):\n    \"\"\"Create a volume from the values dictionary.\"\"\"\n    return IMPL.volume_create(context, values)\n\n\ndef volume_data_get_for_project(context, project_id):\n    \"\"\"Get (volume_count, gigabytes) for project.\"\"\"\n    return IMPL.volume_data_get_for_project(context, project_id)\n\n\ndef volume_destroy(context, volume_id):\n    \"\"\"Destroy the volume or raise if it does not exist.\"\"\"\n    return IMPL.volume_destroy(context, volume_id)\n\n\ndef volume_detached(context, volume_id):\n    \"\"\"Ensure that a volume is set as detached.\"\"\"\n    return IMPL.volume_detached(context, volume_id)\n\n\ndef volume_get(context, volume_id):\n    \"\"\"Get a volume or raise if it does not exist.\"\"\"\n    return IMPL.volume_get(context, volume_id)\n\n\ndef volume_get_all(context):\n    \"\"\"Get all volumes.\"\"\"\n    return IMPL.volume_get_all(context)\n\n\ndef volume_get_all_by_host(context, host):\n    \"\"\"Get all volumes belonging to a host.\"\"\"\n    return IMPL.volume_get_all_by_host(context, host)\n\n\ndef volume_get_all_by_instance(context, instance_id):\n    \"\"\"Get all volumes belonging to a instance.\"\"\"\n    return IMPL.volume_get_all_by_instance(context, instance_id)\n\n\ndef volume_get_all_by_project(context, project_id):\n    \"\"\"Get all volumes belonging to a project.\"\"\"\n    return IMPL.volume_get_all_by_project(context, project_id)\n\n\ndef volume_get_by_ec2_id(context, ec2_id):\n    \"\"\"Get a volume by ec2 id.\"\"\"\n    return IMPL.volume_get_by_ec2_id(context, ec2_id)\n\n\ndef volume_get_instance(context, volume_id):\n    \"\"\"Get the instance that a volume is attached to.\"\"\"\n    return IMPL.volume_get_instance(context, volume_id)\n\n\ndef volume_get_iscsi_target_num(context, volume_id):\n    \"\"\"Get the target num (tid) allocated to the volume.\"\"\"\n    return IMPL.volume_get_iscsi_target_num(context, volume_id)\n\n\ndef volume_update(context, volume_id, values):\n    \"\"\"Set the given properties on an volume and update it.\n\n    Raises NotFound if volume does not exist.\n\n    \"\"\"\n    return IMPL.volume_update(context, volume_id, values)\n\n\n####################\n\n\ndef snapshot_create(context, values):\n    \"\"\"Create a snapshot from the values dictionary.\"\"\"\n    return IMPL.snapshot_create(context, values)\n\n\ndef snapshot_destroy(context, snapshot_id):\n    \"\"\"Destroy the snapshot or raise if it does not exist.\"\"\"\n    return IMPL.snapshot_destroy(context, snapshot_id)\n\n\ndef snapshot_get(context, snapshot_id):\n    \"\"\"Get a snapshot or raise if it does not exist.\"\"\"\n    return IMPL.snapshot_get(context, snapshot_id)\n\n\ndef snapshot_get_all(context):\n    \"\"\"Get all snapshots.\"\"\"\n    return IMPL.snapshot_get_all(context)\n\n\ndef snapshot_get_all_by_project(context, project_id):\n    \"\"\"Get all snapshots belonging to a project.\"\"\"\n    return IMPL.snapshot_get_all_by_project(context, project_id)\n\n\ndef snapshot_get_all_for_volume(context, volume_id):\n    \"\"\"Get all snapshots for a volume.\"\"\"\n    return IMPL.snapshot_get_all_for_volume(context, volume_id)\n\n\ndef snapshot_update(context, snapshot_id, values):\n    \"\"\"Set the given properties on an snapshot and update it.\n\n    Raises NotFound if snapshot does not exist.\n\n    \"\"\"\n    return IMPL.snapshot_update(context, snapshot_id, values)\n\n\n####################\n\n\ndef block_device_mapping_create(context, values):\n    \"\"\"Create an entry of block device mapping\"\"\"\n    return IMPL.block_device_mapping_create(context, values)\n\n\ndef block_device_mapping_update(context, bdm_id, values):\n    \"\"\"Update an entry of block device mapping\"\"\"\n    return IMPL.block_device_mapping_update(context, bdm_id, values)\n\n\ndef block_device_mapping_update_or_create(context, values):\n    \"\"\"Update an entry of block device mapping.\n    If not existed, create a new entry\"\"\"\n    return IMPL.block_device_mapping_update_or_create(context, values)\n\n\ndef block_device_mapping_get_all_by_instance(context, instance_id):\n    \"\"\"Get all block device mapping belonging to a instance\"\"\"\n    return IMPL.block_device_mapping_get_all_by_instance(context, instance_id)\n\n\ndef block_device_mapping_destroy(context, bdm_id):\n    \"\"\"Destroy the block device mapping.\"\"\"\n    return IMPL.block_device_mapping_destroy(context, bdm_id)\n\n\ndef block_device_mapping_destroy_by_instance_and_volume(context, instance_id,\n                                                        volume_id):\n    \"\"\"Destroy the block device mapping or raise if it does not exist.\"\"\"\n    return IMPL.block_device_mapping_destroy_by_instance_and_volume(\n        context, instance_id, volume_id)\n\n\n####################\n\n\ndef security_group_get_all(context):\n    \"\"\"Get all security groups.\"\"\"\n    return IMPL.security_group_get_all(context)\n\n\ndef security_group_get(context, security_group_id):\n    \"\"\"Get security group by its id.\"\"\"\n    return IMPL.security_group_get(context, security_group_id)\n\n\ndef security_group_get_by_name(context, project_id, group_name):\n    \"\"\"Returns a security group with the specified name from a project.\"\"\"\n    return IMPL.security_group_get_by_name(context, project_id, group_name)\n\n\ndef security_group_get_by_project(context, project_id):\n    \"\"\"Get all security groups belonging to a project.\"\"\"\n    return IMPL.security_group_get_by_project(context, project_id)\n\n\ndef security_group_get_by_instance(context, instance_id):\n    \"\"\"Get security groups to which the instance is assigned.\"\"\"\n    return IMPL.security_group_get_by_instance(context, instance_id)\n\n\ndef security_group_exists(context, project_id, group_name):\n    \"\"\"Indicates if a group name exists in a project.\"\"\"\n    return IMPL.security_group_exists(context, project_id, group_name)\n\n\ndef security_group_in_use(context, group_id):\n    \"\"\"Indicates if a security group is currently in use.\"\"\"\n    return IMPL.security_group_in_use(context, group_id)\n\n\ndef security_group_create(context, values):\n    \"\"\"Create a new security group.\"\"\"\n    return IMPL.security_group_create(context, values)\n\n\ndef security_group_destroy(context, security_group_id):\n    \"\"\"Deletes a security group.\"\"\"\n    return IMPL.security_group_destroy(context, security_group_id)\n\n\n####################\n\n\ndef security_group_rule_create(context, values):\n    \"\"\"Create a new security group.\"\"\"\n    return IMPL.security_group_rule_create(context, values)\n\n\ndef security_group_rule_get_by_security_group(context, security_group_id):\n    \"\"\"Get all rules for a a given security group.\"\"\"\n    return IMPL.security_group_rule_get_by_security_group(context,\n                                                          security_group_id)\n\n\ndef security_group_rule_get_by_security_group_grantee(context,\n                                                      security_group_id):\n    \"\"\"Get all rules that grant access to the given security group.\"\"\"\n    return IMPL.security_group_rule_get_by_security_group_grantee(context,\n                                                             security_group_id)\n\n\ndef security_group_rule_destroy(context, security_group_rule_id):\n    \"\"\"Deletes a security group rule.\"\"\"\n    return IMPL.security_group_rule_destroy(context, security_group_rule_id)\n\n\ndef security_group_rule_get(context, security_group_rule_id):\n    \"\"\"Gets a security group rule.\"\"\"\n    return IMPL.security_group_rule_get(context, security_group_rule_id)\n\n\n###################\n\n\ndef provider_fw_rule_create(context, rule):\n    \"\"\"Add a firewall rule at the provider level (all hosts & instances).\"\"\"\n    return IMPL.provider_fw_rule_create(context, rule)\n\n\ndef provider_fw_rule_get_all(context):\n    \"\"\"Get all provider-level firewall rules.\"\"\"\n    return IMPL.provider_fw_rule_get_all(context)\n\n\ndef provider_fw_rule_destroy(context, rule_id):\n    \"\"\"Delete a provider firewall rule from the database.\"\"\"\n    return IMPL.provider_fw_rule_destroy(context, rule_id)\n\n\n###################\n\n\ndef user_get(context, id):\n    \"\"\"Get user by id.\"\"\"\n    return IMPL.user_get(context, id)\n\n\ndef user_get_by_uid(context, uid):\n    \"\"\"Get user by uid.\"\"\"\n    return IMPL.user_get_by_uid(context, uid)\n\n\ndef user_get_by_access_key(context, access_key):\n    \"\"\"Get user by access key.\"\"\"\n    return IMPL.user_get_by_access_key(context, access_key)\n\n\ndef user_create(context, values):\n    \"\"\"Create a new user.\"\"\"\n    return IMPL.user_create(context, values)\n\n\ndef user_delete(context, id):\n    \"\"\"Delete a user.\"\"\"\n    return IMPL.user_delete(context, id)\n\n\ndef user_get_all(context):\n    \"\"\"Create a new user.\"\"\"\n    return IMPL.user_get_all(context)\n\n\ndef user_add_role(context, user_id, role):\n    \"\"\"Add another global role for user.\"\"\"\n    return IMPL.user_add_role(context, user_id, role)\n\n\ndef user_remove_role(context, user_id, role):\n    \"\"\"Remove global role from user.\"\"\"\n    return IMPL.user_remove_role(context, user_id, role)\n\n\ndef user_get_roles(context, user_id):\n    \"\"\"Get global roles for user.\"\"\"\n    return IMPL.user_get_roles(context, user_id)\n\n\ndef user_add_project_role(context, user_id, project_id, role):\n    \"\"\"Add project role for user.\"\"\"\n    return IMPL.user_add_project_role(context, user_id, project_id, role)\n\n\ndef user_remove_project_role(context, user_id, project_id, role):\n    \"\"\"Remove project role from user.\"\"\"\n    return IMPL.user_remove_project_role(context, user_id, project_id, role)\n\n\ndef user_get_roles_for_project(context, user_id, project_id):\n    \"\"\"Return list of roles a user holds on project.\"\"\"\n    return IMPL.user_get_roles_for_project(context, user_id, project_id)\n\n\ndef user_update(context, user_id, values):\n    \"\"\"Update user.\"\"\"\n    return IMPL.user_update(context, user_id, values)\n\n\n###################\n\n\ndef project_get(context, id):\n    \"\"\"Get project by id.\"\"\"\n    return IMPL.project_get(context, id)\n\n\ndef project_create(context, values):\n    \"\"\"Create a new project.\"\"\"\n    return IMPL.project_create(context, values)\n\n\ndef project_add_member(context, project_id, user_id):\n    \"\"\"Add user to project.\"\"\"\n    return IMPL.project_add_member(context, project_id, user_id)\n\n\ndef project_get_all(context):\n    \"\"\"Get all projects.\"\"\"\n    return IMPL.project_get_all(context)\n\n\ndef project_get_by_user(context, user_id):\n    \"\"\"Get all projects of which the given user is a member.\"\"\"\n    return IMPL.project_get_by_user(context, user_id)\n\n\ndef project_remove_member(context, project_id, user_id):\n    \"\"\"Remove the given user from the given project.\"\"\"\n    return IMPL.project_remove_member(context, project_id, user_id)\n\n\ndef project_update(context, project_id, values):\n    \"\"\"Update Remove the given user from the given project.\"\"\"\n    return IMPL.project_update(context, project_id, values)\n\n\ndef project_delete(context, project_id):\n    \"\"\"Delete project.\"\"\"\n    return IMPL.project_delete(context, project_id)\n\n\ndef project_get_networks(context, project_id, associate=True):\n    \"\"\"Return the network associated with the project.\n\n    If associate is true, it will attempt to associate a new\n    network if one is not found, otherwise it returns None.\n\n    \"\"\"\n    return IMPL.project_get_networks(context, project_id, associate)\n\n\n###################\n\n\ndef console_pool_create(context, values):\n    \"\"\"Create console pool.\"\"\"\n    return IMPL.console_pool_create(context, values)\n\n\ndef console_pool_get(context, pool_id):\n    \"\"\"Get a console pool.\"\"\"\n    return IMPL.console_pool_get(context, pool_id)\n\n\ndef console_pool_get_by_host_type(context, compute_host, proxy_host,\n                                  console_type):\n    \"\"\"Fetch a console pool for a given proxy host, compute host, and type.\"\"\"\n    return IMPL.console_pool_get_by_host_type(context,\n                                              compute_host,\n                                              proxy_host,\n                                              console_type)\n\n\ndef console_pool_get_all_by_host_type(context, host, console_type):\n    \"\"\"Fetch all pools for given proxy host and type.\"\"\"\n    return IMPL.console_pool_get_all_by_host_type(context,\n                                                  host,\n                                                  console_type)\n\n\ndef console_create(context, values):\n    \"\"\"Create a console.\"\"\"\n    return IMPL.console_create(context, values)\n\n\ndef console_delete(context, console_id):\n    \"\"\"Delete a console.\"\"\"\n    return IMPL.console_delete(context, console_id)\n\n\ndef console_get_by_pool_instance(context, pool_id, instance_id):\n    \"\"\"Get console entry for a given instance and pool.\"\"\"\n    return IMPL.console_get_by_pool_instance(context, pool_id, instance_id)\n\n\ndef console_get_all_by_instance(context, instance_id):\n    \"\"\"Get consoles for a given instance.\"\"\"\n    return IMPL.console_get_all_by_instance(context, instance_id)\n\n\ndef console_get(context, console_id, instance_id=None):\n    \"\"\"Get a specific console (possibly on a given instance).\"\"\"\n    return IMPL.console_get(context, console_id, instance_id)\n\n\n    ##################\n\n\ndef instance_type_create(context, values):\n    \"\"\"Create a new instance type.\"\"\"\n    return IMPL.instance_type_create(context, values)\n\n\ndef instance_type_get_all(context, inactive=False, filters=None):\n    \"\"\"Get all instance types.\"\"\"\n    return IMPL.instance_type_get_all(\n        context, inactive=inactive, filters=filters)\n\n\ndef instance_type_get(context, id):\n    \"\"\"Get instance type by id.\"\"\"\n    return IMPL.instance_type_get(context, id)\n\n\ndef instance_type_get_by_name(context, name):\n    \"\"\"Get instance type by name.\"\"\"\n    return IMPL.instance_type_get_by_name(context, name)\n\n\ndef instance_type_get_by_flavor_id(context, id):\n    \"\"\"Get instance type by name.\"\"\"\n    return IMPL.instance_type_get_by_flavor_id(context, id)\n\n\ndef instance_type_destroy(context, name):\n    \"\"\"Delete a instance type.\"\"\"\n    return IMPL.instance_type_destroy(context, name)\n\n\n####################\n\n\ndef cell_create(context, values):\n    \"\"\"Create a new child Cell entry.\"\"\"\n    return IMPL.cell_create(context, values)\n\n\ndef cell_update(context, cell_id, values):\n    \"\"\"Update a child Cell entry.\"\"\"\n    return IMPL.cell_update(context, cell_id, values)\n\n\ndef cell_delete(context, cell_id):\n    \"\"\"Delete a child Cell.\"\"\"\n    return IMPL.cell_delete(context, cell_id)\n\n\ndef cell_get(context, cell_id):\n    \"\"\"Get a specific child Cell.\"\"\"\n    return IMPL.cell_get(context, cell_id)\n\n\ndef cell_get_all(context):\n    \"\"\"Get all child Cells.\"\"\"\n    return IMPL.cell_get_all(context)\n\n\n####################\n\n\ndef instance_metadata_get(context, instance_id):\n    \"\"\"Get all metadata for an instance.\"\"\"\n    return IMPL.instance_metadata_get(context, instance_id)\n\n\ndef instance_metadata_delete(context, instance_id, key):\n    \"\"\"Delete the given metadata item.\"\"\"\n    IMPL.instance_metadata_delete(context, instance_id, key)\n\n\ndef instance_metadata_update(context, instance_id, metadata, delete):\n    \"\"\"Update metadata if it exists, otherwise create it.\"\"\"\n    IMPL.instance_metadata_update(context, instance_id, metadata, delete)\n\n\n####################\n\n\ndef agent_build_create(context, values):\n    \"\"\"Create a new agent build entry.\"\"\"\n    return IMPL.agent_build_create(context, values)\n\n\ndef agent_build_get_by_triple(context, hypervisor, os, architecture):\n    \"\"\"Get agent build by hypervisor/OS/architecture triple.\"\"\"\n    return IMPL.agent_build_get_by_triple(context, hypervisor, os,\n            architecture)\n\n\ndef agent_build_get_all(context):\n    \"\"\"Get all agent builds.\"\"\"\n    return IMPL.agent_build_get_all(context)\n\n\ndef agent_build_destroy(context, agent_update_id):\n    \"\"\"Destroy agent build entry.\"\"\"\n    IMPL.agent_build_destroy(context, agent_update_id)\n\n\ndef agent_build_update(context, agent_build_id, values):\n    \"\"\"Update agent build entry.\"\"\"\n    IMPL.agent_build_update(context, agent_build_id, values)\n\n\n####################\n\n\ndef bw_usage_get_by_macs(context, macs, start_period):\n    \"\"\"Return bw usages for an instance in a given audit period.\"\"\"\n    return IMPL.bw_usage_get_by_macs(context, macs, start_period)\n\n\ndef bw_usage_update(context,\n                    mac,\n                    start_period,\n                    bw_in, bw_out):\n    \"\"\"Update cached bw usage for an instance and network\n       Creates new record if needed.\"\"\"\n    return IMPL.bw_usage_update(context,\n                                mac,\n                                start_period,\n                                bw_in, bw_out)\n\n\n####################\n\n\ndef instance_type_extra_specs_get(context, instance_type_id):\n    \"\"\"Get all extra specs for an instance type.\"\"\"\n    return IMPL.instance_type_extra_specs_get(context, instance_type_id)\n\n\ndef instance_type_extra_specs_delete(context, instance_type_id, key):\n    \"\"\"Delete the given extra specs item.\"\"\"\n    IMPL.instance_type_extra_specs_delete(context, instance_type_id, key)\n\n\ndef instance_type_extra_specs_update_or_create(context, instance_type_id,\n                                               extra_specs):\n    \"\"\"Create or update instance type extra specs. This adds or modifies the\n    key/value pairs specified in the extra specs dict argument\"\"\"\n    IMPL.instance_type_extra_specs_update_or_create(context, instance_type_id,\n                                                    extra_specs)\n\n\n##################\n\n\ndef volume_metadata_get(context, volume_id):\n    \"\"\"Get all metadata for a volume.\"\"\"\n    return IMPL.volume_metadata_get(context, volume_id)\n\n\ndef volume_metadata_delete(context, volume_id, key):\n    \"\"\"Delete the given metadata item.\"\"\"\n    IMPL.volume_metadata_delete(context, volume_id, key)\n\n\ndef volume_metadata_update(context, volume_id, metadata, delete):\n    \"\"\"Update metadata if it exists, otherwise create it.\"\"\"\n    IMPL.volume_metadata_update(context, volume_id, metadata, delete)\n\n\n##################\n\n\ndef volume_type_create(context, values):\n    \"\"\"Create a new volume type.\"\"\"\n    return IMPL.volume_type_create(context, values)\n\n\ndef volume_type_get_all(context, inactive=False):\n    \"\"\"Get all volume types.\"\"\"\n    return IMPL.volume_type_get_all(context, inactive)\n\n\ndef volume_type_get(context, id):\n    \"\"\"Get volume type by id.\"\"\"\n    return IMPL.volume_type_get(context, id)\n\n\ndef volume_type_get_by_name(context, name):\n    \"\"\"Get volume type by name.\"\"\"\n    return IMPL.volume_type_get_by_name(context, name)\n\n\ndef volume_type_destroy(context, name):\n    \"\"\"Delete a volume type.\"\"\"\n    return IMPL.volume_type_destroy(context, name)\n\n\n####################\n\n\ndef volume_type_extra_specs_get(context, volume_type_id):\n    \"\"\"Get all extra specs for a volume type.\"\"\"\n    return IMPL.volume_type_extra_specs_get(context, volume_type_id)\n\n\ndef volume_type_extra_specs_delete(context, volume_type_id, key):\n    \"\"\"Delete the given extra specs item.\"\"\"\n    IMPL.volume_type_extra_specs_delete(context, volume_type_id, key)\n\n\ndef volume_type_extra_specs_update_or_create(context, volume_type_id,\n                                               extra_specs):\n    \"\"\"Create or update volume type extra specs. This adds or modifies the\n    key/value pairs specified in the extra specs dict argument\"\"\"\n    IMPL.volume_type_extra_specs_update_or_create(context, volume_type_id,\n                                                    extra_specs)\n\n\n###################\n\n\ndef s3_image_get(context, image_id):\n    \"\"\"Find local s3 image represented by the provided id\"\"\"\n    return IMPL.s3_image_get(context, image_id)\n\n\ndef s3_image_get_by_uuid(context, image_uuid):\n    \"\"\"Find local s3 image represented by the provided uuid\"\"\"\n    return IMPL.s3_image_get_by_uuid(context, image_uuid)\n\n\ndef s3_image_create(context, image_uuid):\n    \"\"\"Create local s3 image represented by provided uuid\"\"\"\n    return IMPL.s3_image_create(context, image_uuid)\n\n\n####################\n\n\ndef sm_backend_conf_create(context, values):\n    \"\"\"Create a new SM Backend Config entry.\"\"\"\n    return IMPL.sm_backend_conf_create(context, values)\n\n\ndef sm_backend_conf_update(context, sm_backend_conf_id, values):\n    \"\"\"Update a SM Backend Config entry.\"\"\"\n    return IMPL.sm_backend_conf_update(context, sm_backend_conf_id, values)\n\n\ndef sm_backend_conf_delete(context, sm_backend_conf_id):\n    \"\"\"Delete a SM Backend Config.\"\"\"\n    return IMPL.sm_backend_conf_delete(context, sm_backend_conf_id)\n\n\ndef sm_backend_conf_get(context, sm_backend_conf_id):\n    \"\"\"Get a specific SM Backend Config.\"\"\"\n    return IMPL.sm_backend_conf_get(context, sm_backend_conf_id)\n\n\ndef sm_backend_conf_get_by_sr(context, sr_uuid):\n    \"\"\"Get a specific SM Backend Config.\"\"\"\n    return IMPL.sm_backend_conf_get_by_sr(context, sr_uuid)\n\n\ndef sm_backend_conf_get_all(context):\n    \"\"\"Get all SM Backend Configs.\"\"\"\n    return IMPL.sm_backend_conf_get_all(context)\n\n\n####################\n\n\ndef sm_flavor_create(context, values):\n    \"\"\"Create a new SM Flavor entry.\"\"\"\n    return IMPL.sm_flavor_create(context, values)\n\n\ndef sm_flavor_update(context, sm_flavor_id, values):\n    \"\"\"Update a SM Flavor entry.\"\"\"\n    return IMPL.sm_flavor_update(context, values)\n\n\ndef sm_flavor_delete(context, sm_flavor_id):\n    \"\"\"Delete a SM Flavor.\"\"\"\n    return IMPL.sm_flavor_delete(context, sm_flavor_id)\n\n\ndef sm_flavor_get(context, sm_flavor):\n    \"\"\"Get a specific SM Flavor.\"\"\"\n    return IMPL.sm_flavor_get(context, sm_flavor)\n\n\ndef sm_flavor_get_all(context):\n    \"\"\"Get all SM Flavors.\"\"\"\n    return IMPL.sm_flavor_get_all(context)\n\n\n####################\n\n\ndef sm_volume_create(context, values):\n    \"\"\"Create a new child Zone entry.\"\"\"\n    return IMPL.sm_volume_create(context, values)\n\n\ndef sm_volume_update(context, volume_id, values):\n    \"\"\"Update a child Zone entry.\"\"\"\n    return IMPL.sm_volume_update(context, values)\n\n\ndef sm_volume_delete(context, volume_id):\n    \"\"\"Delete a child Zone.\"\"\"\n    return IMPL.sm_volume_delete(context, volume_id)\n\n\ndef sm_volume_get(context, volume_id):\n    \"\"\"Get a specific child Zone.\"\"\"\n    return IMPL.sm_volume_get(context, volume_id)\n\n\ndef sm_volume_get_all(context):\n    \"\"\"Get all child Zones.\"\"\"\n    return IMPL.sm_volume_get_all(context)\n\n\n####################\n\n\ndef aggregate_create(context, values, metadata=None):\n    \"\"\"Create a new aggregate with metadata.\"\"\"\n    return IMPL.aggregate_create(context, values, metadata)\n\n\ndef aggregate_get(context, aggregate_id, read_deleted='no'):\n    \"\"\"Get a specific aggregate by id.\"\"\"\n    return IMPL.aggregate_get(context, aggregate_id, read_deleted)\n\n\ndef aggregate_get_by_host(context, host, read_deleted='no'):\n    \"\"\"Get a specific aggregate by host\"\"\"\n    return IMPL.aggregate_get_by_host(context, host, read_deleted)\n\n\ndef aggregate_update(context, aggregate_id, values):\n    \"\"\"Update the attributes of an aggregates. If values contains a metadata\n    key, it updates the aggregate metadata too.\"\"\"\n    return IMPL.aggregate_update(context, aggregate_id, values)\n\n\ndef aggregate_delete(context, aggregate_id):\n    \"\"\"Delete an aggregate.\"\"\"\n    return IMPL.aggregate_delete(context, aggregate_id)\n\n\ndef aggregate_get_all(context, read_deleted='yes'):\n    \"\"\"Get all aggregates.\"\"\"\n    return IMPL.aggregate_get_all(context, read_deleted)\n\n\ndef aggregate_metadata_add(context, aggregate_id, metadata, set_delete=False):\n    \"\"\"Add/update metadata. If set_delete=True, it adds only.\"\"\"\n    IMPL.aggregate_metadata_add(context, aggregate_id, metadata, set_delete)\n\n\ndef aggregate_metadata_get(context, aggregate_id, read_deleted='no'):\n    \"\"\"Get metadata for the specified aggregate.\"\"\"\n    return IMPL.aggregate_metadata_get(context, aggregate_id, read_deleted)\n\n\ndef aggregate_metadata_delete(context, aggregate_id, key):\n    \"\"\"Delete the given metadata key.\"\"\"\n    IMPL.aggregate_metadata_delete(context, aggregate_id, key)\n\n\ndef aggregate_host_add(context, aggregate_id, host):\n    \"\"\"Add host to the aggregate.\"\"\"\n    IMPL.aggregate_host_add(context, aggregate_id, host)\n\n\ndef aggregate_host_get_all(context, aggregate_id, read_deleted='yes'):\n    \"\"\"Get hosts for the specified aggregate.\"\"\"\n    return IMPL.aggregate_host_get_all(context, aggregate_id, read_deleted)\n\n\ndef aggregate_host_delete(context, aggregate_id, host):\n    \"\"\"Delete the given host from the aggregate.\"\"\"\n    IMPL.aggregate_host_delete(context, aggregate_id, host)\n\n\n####################\n\n\ndef instance_fault_create(context, values):\n    \"\"\"Create a new Instance Fault.\"\"\"\n    return IMPL.instance_fault_create(context, values)\n\n\ndef instance_fault_get_by_instance_uuids(context, instance_uuids):\n    \"\"\"Get all instance faults for the provided instance_uuids.\"\"\"\n    return IMPL.instance_fault_get_by_instance_uuids(context, instance_uuids)\n", "target": 1}
{"idx": 915, "func": "from django.db.models.expressions import F, OrderBy\n\n\nclass OrderableAggMixin:\n\n    def __init__(self, expression, ordering=(), **extra):\n        if not isinstance(ordering, (list, tuple)):\n            ordering = [ordering]\n        ordering = ordering or []\n        # Transform minus sign prefixed strings into an OrderBy() expression.\n        ordering = (\n            (OrderBy(F(o[1:]), descending=True) if isinstance(o, str) and o[0] == '-' else o)\n            for o in ordering\n        )\n        super().__init__(expression, **extra)\n        self.ordering = self._parse_expressions(*ordering)\n\n    def resolve_expression(self, *args, **kwargs):\n        self.ordering = [expr.resolve_expression(*args, **kwargs) for expr in self.ordering]\n        return super().resolve_expression(*args, **kwargs)\n\n    def as_sql(self, compiler, connection):\n        if self.ordering:\n            ordering_params = []\n            ordering_expr_sql = []\n            for expr in self.ordering:\n                expr_sql, expr_params = expr.as_sql(compiler, connection)\n                ordering_expr_sql.append(expr_sql)\n                ordering_params.extend(expr_params)\n            sql, sql_params = super().as_sql(compiler, connection, ordering=(\n                'ORDER BY ' + ', '.join(ordering_expr_sql)\n            ))\n            return sql, sql_params + ordering_params\n        return super().as_sql(compiler, connection, ordering='')\n\n    def set_source_expressions(self, exprs):\n        # Extract the ordering expressions because ORDER BY clause is handled\n        # in a custom way.\n        self.ordering = exprs[self._get_ordering_expressions_index():]\n        return super().set_source_expressions(exprs[:self._get_ordering_expressions_index()])\n\n    def get_source_expressions(self):\n        return super().get_source_expressions() + self.ordering\n\n    def _get_ordering_expressions_index(self):\n        \"\"\"Return the index at which the ordering expressions start.\"\"\"\n        source_expressions = self.get_source_expressions()\n        return len(source_expressions) - len(self.ordering)\n", "target": 1}
{"idx": 916, "func": "import time\nfrom pydoc import locate\n\nfrom django.conf import settings\n\nDEFAULT_CONFIG = {\n    'config_version': 4,\n    'flag_prefix': 'ractf',\n    'graph_members': 10,\n    'register_end_time': -1,\n    'end_time': time.time() + 7 * 24 * 60 * 60,\n    'start_time': time.time(),\n    'register_start_time': time.time(),\n    'team_size': -1,\n    'email_regex': '',\n    'email_domain': '',\n    'login_provider': 'basic_auth',\n    'registration_provider': 'basic_auth',\n    'token_provider': 'basic_auth',\n    'enable_bot_users': True,\n    'enable_ctftime': True,\n    'enable_flag_submission': True,\n    'enable_flag_submission_after_competition': True,\n    'enable_force_admin_2fa': False,\n    'enable_track_incorrect_submissions': True,\n    'enable_login': True,\n    'enable_prelogin': True,\n    'enable_maintenance_mode': False,\n    'enable_registration': True,\n    'enable_scoreboard': True,\n    'enable_scoring': True,\n    'enable_solve_broadcast': True,\n    'enable_teams': True,\n    'enable_team_join': True,\n    'enable_view_challenges_after_competion': True,\n    'enable_team_leave': False,\n    'invite_required': False,\n    'hide_scoreboard_at': -1,\n    'setup_wizard_complete': False,\n    'sensitive_fields': ['sensitive_fields', 'enable_force_admin_2fa']\n}\n\nbackend = locate(settings.CONFIG['BACKEND'])()\nbackend.load(defaults=DEFAULT_CONFIG)\n\n\ndef get(key):\n    return backend.get(key)\n\n\ndef set(key, value):\n    backend.set(key, value)\n\n\ndef get_all():\n    return backend.get_all()\n\n\ndef get_all_non_sensitive():\n    sensitive = backend.get('sensitive_fields')\n    config = backend.get_all()\n    for field in sensitive:\n        del config[field]\n    return config\n\n\ndef set_bulk(values: dict):\n    for key, value in values.items():\n        set(key, value)\n\n\ndef add_plugin_config(name, config):\n    DEFAULT_CONFIG[name] = config\n", "target": 1}
{"idx": 917, "func": "# -*- coding: utf-8 -*-\n#\n# This file is part of Radicale Server - Calendar Server\n# Copyright \u00a9 2012-2015 Guillaume Ayoub\n#\n# This library is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# This library is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with Radicale.  If not, see <http://www.gnu.org/licenses/>.\n\n\"\"\"\nFilesystem storage backend.\n\n\"\"\"\n\nimport codecs\nimport os\nimport posixpath\nimport json\nimport time\nimport sys\nfrom contextlib import contextmanager\n\nfrom .. import config, ical, pathutils\n\n\nFOLDER = os.path.expanduser(config.get(\"storage\", \"filesystem_folder\"))\nFILESYSTEM_ENCODING = sys.getfilesystemencoding()\n\ntry:\n    from dulwich.repo import Repo\n    GIT_REPOSITORY = Repo(FOLDER)\nexcept:\n    GIT_REPOSITORY = None\n\n\n# This function overrides the builtin ``open`` function for this module\n# pylint: disable=W0622\n@contextmanager\ndef open(path, mode=\"r\"):\n    \"\"\"Open a file at ``path`` with encoding set in the configuration.\"\"\"\n    # On enter\n    abs_path = os.path.join(FOLDER, path.replace(\"/\", os.sep))\n    with codecs.open(abs_path, mode, config.get(\"encoding\", \"stock\")) as fd:\n        yield fd\n    # On exit\n    if GIT_REPOSITORY and mode == \"w\":\n        path = os.path.relpath(abs_path, FOLDER)\n        GIT_REPOSITORY.stage([path])\n        committer = config.get(\"git\", \"committer\")\n        GIT_REPOSITORY.do_commit(\n            path.encode(\"utf-8\"), committer=committer.encode(\"utf-8\"))\n# pylint: enable=W0622\n\n\nclass Collection(ical.Collection):\n    \"\"\"Collection stored in a flat ical file.\"\"\"\n    @property\n    def _filesystem_path(self):\n        \"\"\"Absolute path of the file at local ``path``.\"\"\"\n        return pathutils.path_to_filesystem(self.path, FOLDER)\n\n    @property\n    def _props_path(self):\n        \"\"\"Absolute path of the file storing the collection properties.\"\"\"\n        return self._filesystem_path + \".props\"\n\n    def _create_dirs(self):\n        \"\"\"Create folder storing the collection if absent.\"\"\"\n        if not os.path.exists(os.path.dirname(self._filesystem_path)):\n            os.makedirs(os.path.dirname(self._filesystem_path))\n\n    def save(self, text):\n        self._create_dirs()\n        with open(self._filesystem_path, \"w\") as fd:\n            fd.write(text)\n\n    def delete(self):\n        os.remove(self._filesystem_path)\n        os.remove(self._props_path)\n\n    @property\n    def text(self):\n        try:\n            with open(self._filesystem_path) as fd:\n                return fd.read()\n        except IOError:\n            return \"\"\n\n    @classmethod\n    def children(cls, path):\n        filesystem_path = pathutils.path_to_filesystem(path, FOLDER)\n        _, directories, files = next(os.walk(filesystem_path))\n        for filename in directories + files:\n            rel_filename = posixpath.join(path, filename)\n            if cls.is_node(rel_filename) or cls.is_leaf(rel_filename):\n                yield cls(rel_filename)\n\n    @classmethod\n    def is_node(cls, path):\n        filesystem_path = pathutils.path_to_filesystem(path, FOLDER)\n        return os.path.isdir(filesystem_path)\n\n    @classmethod\n    def is_leaf(cls, path):\n        filesystem_path = pathutils.path_to_filesystem(path, FOLDER)\n        return (os.path.isfile(filesystem_path) and not\n                filesystem_path.endswith(\".props\"))\n\n    @property\n    def last_modified(self):\n        modification_time = \\\n            time.gmtime(os.path.getmtime(self._filesystem_path))\n        return time.strftime(\"%a, %d %b %Y %H:%M:%S +0000\", modification_time)\n\n    @property\n    @contextmanager\n    def props(self):\n        # On enter\n        properties = {}\n        if os.path.exists(self._props_path):\n            with open(self._props_path) as prop_file:\n                properties.update(json.load(prop_file))\n        old_properties = properties.copy()\n        yield properties\n        # On exit\n        self._create_dirs()\n        if old_properties != properties:\n            with open(self._props_path, \"w\") as prop_file:\n                json.dump(properties, prop_file)\n", "target": 0}
{"idx": 918, "func": "# -*- coding: utf-8 -*-\n#\n# This file is part of Radicale Server - Calendar Server\n# Copyright \u00a9 2008 Nicolas Kandel\n# Copyright \u00a9 2008 Pascal Halter\n# Copyright \u00a9 2008-2013 Guillaume Ayoub\n#\n# This library is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# This library is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with Radicale.  If not, see <http://www.gnu.org/licenses/>.\n\n\"\"\"\nRights management.\n\nRights are based on a regex-based file whose name is specified in the config\n(section \"right\", key \"file\").\n\nAuthentication login is matched against the \"user\" key, and collection's path\nis matched against the \"collection\" key. You can use Python's ConfigParser\ninterpolation values %(login)s and %(path)s. You can also get groups from the\nuser regex in the collection with {0}, {1}, etc.\n\nFor example, for the \"user\" key, \".+\" means \"authenticated user\" and \".*\"\nmeans \"anybody\" (including anonymous users).\n\nSection names are only used for naming the rule.\n\nLeading or ending slashes are trimmed from collection's path.\n\n\"\"\"\n\nimport re\nimport sys\nimport os.path\n\nfrom .. import config, log\n\n# Manage Python2/3 different modules\nif sys.version_info[0] == 2:\n    from ConfigParser import ConfigParser\n    from StringIO import StringIO\nelse:\n    from configparser import ConfigParser\n    from io import StringIO\n\n\nDEFINED_RIGHTS = {\n    \"authenticated\": \"[rw]\\nuser:.+\\ncollection:.*\\npermission:rw\",\n    \"owner_write\": \"[r]\\nuser:.+\\ncollection:.*\\npermission:r\\n\"\n                   \"[w]\\nuser:.+\\ncollection:^%(login)s(/.*)?$\\npermission:w\",\n    \"owner_only\": \"[rw]\\nuser:.+\\ncollection:^%(login)s(/.*)?$\\npermission:rw\",\n}\n\n\ndef _read_from_sections(user, collection_url, permission):\n    \"\"\"Get regex sections.\"\"\"\n    filename = os.path.expanduser(config.get(\"rights\", \"file\"))\n    rights_type = config.get(\"rights\", \"type\").lower()\n    # Prevent \"regex injection\"\n    user_escaped = re.escape(user)\n    collection_url_escaped = re.escape(collection_url)\n    regex = ConfigParser({\"login\": user_escaped, \"path\": collection_url_escaped})\n    if rights_type in DEFINED_RIGHTS:\n        log.LOGGER.debug(\"Rights type '%s'\" % rights_type)\n        regex.readfp(StringIO(DEFINED_RIGHTS[rights_type]))\n    elif rights_type == \"from_file\":\n        log.LOGGER.debug(\"Reading rights from file %s\" % filename)\n        if not regex.read(filename):\n            log.LOGGER.error(\"File '%s' not found for rights\" % filename)\n            return False\n    else:\n        log.LOGGER.error(\"Unknown rights type '%s'\" % rights_type)\n        return False\n\n    for section in regex.sections():\n        re_user = regex.get(section, \"user\")\n        re_collection = regex.get(section, \"collection\")\n        log.LOGGER.debug(\n            \"Test if '%s:%s' matches against '%s:%s' from section '%s'\" % (\n                user, collection_url, re_user, re_collection, section))\n        user_match = re.match(re_user, user)\n        if user_match:\n            re_collection = re_collection.format(*user_match.groups())\n            if re.match(re_collection, collection_url):\n                log.LOGGER.debug(\"Section '%s' matches\" % section)\n                if permission in regex.get(section, \"permission\"):\n                    return True\n            else:\n                log.LOGGER.debug(\"Section '%s' does not match\" % section)\n    return False\n\n\ndef authorized(user, collection, permission):\n    \"\"\"Check if the user is allowed to read or write the collection.\n\n       If the user is empty it checks for anonymous rights\n    \"\"\"\n    collection_url = collection.url.rstrip(\"/\") or \"/\"\n    if collection_url in (\".well-known/carddav\", \".well-known/caldav\"):\n        return permission == \"r\"\n    rights_type = config.get(\"rights\", \"type\").lower()\n    return (\n        rights_type == \"none\" or\n        _read_from_sections(user or \"\", collection_url, permission))\n", "target": 0}
{"idx": 919, "func": "#\n# The Python Imaging Library.\n# $Id$\n#\n# JPEG (JFIF) file handling\n#\n# See \"Digital Compression and Coding of Continous-Tone Still Images,\n# Part 1, Requirements and Guidelines\" (CCITT T.81 / ISO 10918-1)\n#\n# History:\n# 1995-09-09 fl   Created\n# 1995-09-13 fl   Added full parser\n# 1996-03-25 fl   Added hack to use the IJG command line utilities\n# 1996-05-05 fl   Workaround Photoshop 2.5 CMYK polarity bug\n# 1996-05-28 fl   Added draft support, JFIF version (0.1)\n# 1996-12-30 fl   Added encoder options, added progression property (0.2)\n# 1997-08-27 fl   Save mode 1 images as BW (0.3)\n# 1998-07-12 fl   Added YCbCr to draft and save methods (0.4)\n# 1998-10-19 fl   Don't hang on files using 16-bit DQT's (0.4.1)\n# 2001-04-16 fl   Extract DPI settings from JFIF files (0.4.2)\n# 2002-07-01 fl   Skip pad bytes before markers; identify Exif files (0.4.3)\n# 2003-04-25 fl   Added experimental EXIF decoder (0.5)\n# 2003-06-06 fl   Added experimental EXIF GPSinfo decoder\n# 2003-09-13 fl   Extract COM markers\n# 2009-09-06 fl   Added icc_profile support (from Florian Hoech)\n# 2009-03-06 fl   Changed CMYK handling; always use Adobe polarity (0.6)\n# 2009-03-08 fl   Added subsampling support (from Justin Huff).\n#\n# Copyright (c) 1997-2003 by Secret Labs AB.\n# Copyright (c) 1995-1996 by Fredrik Lundh.\n#\n# See the README file for information on usage and redistribution.\n#\n\n__version__ = \"0.6\"\n\nimport array, struct\nfrom PIL import Image, ImageFile, _binary\nfrom PIL.JpegPresets import presets\nfrom PIL._util import isStringType\n\ni8 = _binary.i8\no8 = _binary.o8\ni16 = _binary.i16be\ni32 = _binary.i32be\n\n#\n# Parser\n\ndef Skip(self, marker):\n    n = i16(self.fp.read(2))-2\n    ImageFile._safe_read(self.fp, n)\n\ndef APP(self, marker):\n    #\n    # Application marker.  Store these in the APP dictionary.\n    # Also look for well-known application markers.\n\n    n = i16(self.fp.read(2))-2\n    s = ImageFile._safe_read(self.fp, n)\n\n    app = \"APP%d\" % (marker&15)\n\n    self.app[app] = s # compatibility\n    self.applist.append((app, s))\n\n    if marker == 0xFFE0 and s[:4] == b\"JFIF\":\n        # extract JFIF information\n        self.info[\"jfif\"] = version = i16(s, 5) # version\n        self.info[\"jfif_version\"] = divmod(version, 256)\n        # extract JFIF properties\n        try:\n            jfif_unit = i8(s[7])\n            jfif_density = i16(s, 8), i16(s, 10)\n        except:\n            pass\n        else:\n            if jfif_unit == 1:\n                self.info[\"dpi\"] = jfif_density\n            self.info[\"jfif_unit\"] = jfif_unit\n            self.info[\"jfif_density\"] = jfif_density\n    elif marker == 0xFFE1 and s[:5] == b\"Exif\\0\":\n        # extract Exif information (incomplete)\n        self.info[\"exif\"] = s # FIXME: value will change\n    elif marker == 0xFFE2 and s[:5] == b\"FPXR\\0\":\n        # extract FlashPix information (incomplete)\n        self.info[\"flashpix\"] = s # FIXME: value will change\n    elif marker == 0xFFE2 and s[:12] == b\"ICC_PROFILE\\0\":\n        # Since an ICC profile can be larger than the maximum size of\n        # a JPEG marker (64K), we need provisions to split it into\n        # multiple markers. The format defined by the ICC specifies\n        # one or more APP2 markers containing the following data:\n        #   Identifying string      ASCII \"ICC_PROFILE\\0\"  (12 bytes)\n        #   Marker sequence number  1, 2, etc (1 byte)\n        #   Number of markers       Total of APP2's used (1 byte)\n        #   Profile data            (remainder of APP2 data)\n        # Decoders should use the marker sequence numbers to\n        # reassemble the profile, rather than assuming that the APP2\n        # markers appear in the correct sequence.\n        self.icclist.append(s)\n    elif marker == 0xFFEE and s[:5] == b\"Adobe\":\n        self.info[\"adobe\"] = i16(s, 5)\n        # extract Adobe custom properties\n        try:\n            adobe_transform = i8(s[1])\n        except:\n            pass\n        else:\n            self.info[\"adobe_transform\"] = adobe_transform\n\ndef COM(self, marker):\n    #\n    # Comment marker.  Store these in the APP dictionary.\n\n    n = i16(self.fp.read(2))-2\n    s = ImageFile._safe_read(self.fp, n)\n\n    self.app[\"COM\"] = s # compatibility\n    self.applist.append((\"COM\", s))\n\ndef SOF(self, marker):\n    #\n    # Start of frame marker.  Defines the size and mode of the\n    # image.  JPEG is colour blind, so we use some simple\n    # heuristics to map the number of layers to an appropriate\n    # mode.  Note that this could be made a bit brighter, by\n    # looking for JFIF and Adobe APP markers.\n\n    n = i16(self.fp.read(2))-2\n    s = ImageFile._safe_read(self.fp, n)\n    self.size = i16(s[3:]), i16(s[1:])\n\n    self.bits = i8(s[0])\n    if self.bits != 8:\n        raise SyntaxError(\"cannot handle %d-bit layers\" % self.bits)\n\n    self.layers = i8(s[5])\n    if self.layers == 1:\n        self.mode = \"L\"\n    elif self.layers == 3:\n        self.mode = \"RGB\"\n    elif self.layers == 4:\n        self.mode = \"CMYK\"\n    else:\n        raise SyntaxError(\"cannot handle %d-layer images\" % self.layers)\n\n    if marker in [0xFFC2, 0xFFC6, 0xFFCA, 0xFFCE]:\n        self.info[\"progressive\"] = self.info[\"progression\"] = 1\n\n    if self.icclist:\n        # fixup icc profile\n        self.icclist.sort() # sort by sequence number\n        if i8(self.icclist[0][13]) == len(self.icclist):\n            profile = []\n            for p in self.icclist:\n                profile.append(p[14:])\n            icc_profile = b\"\".join(profile)\n        else:\n            icc_profile = None # wrong number of fragments\n        self.info[\"icc_profile\"] = icc_profile\n        self.icclist = None\n\n    for i in range(6, len(s), 3):\n        t = s[i:i+3]\n        # 4-tuples: id, vsamp, hsamp, qtable\n        self.layer.append((t[0], i8(t[1])//16, i8(t[1])&15, i8(t[2])))\n\ndef DQT(self, marker):\n    #\n    # Define quantization table.  Support baseline 8-bit tables\n    # only.  Note that there might be more than one table in\n    # each marker.\n\n    # FIXME: The quantization tables can be used to estimate the\n    # compression quality.\n\n    n = i16(self.fp.read(2))-2\n    s = ImageFile._safe_read(self.fp, n)\n    while len(s):\n        if len(s) < 65:\n            raise SyntaxError(\"bad quantization table marker\")\n        v = i8(s[0])\n        if v//16 == 0:\n            self.quantization[v&15] = array.array(\"b\", s[1:65])\n            s = s[65:]\n        else:\n            return # FIXME: add code to read 16-bit tables!\n            # raise SyntaxError, \"bad quantization table element size\"\n\n\n#\n# JPEG marker table\n\nMARKER = {\n    0xFFC0: (\"SOF0\", \"Baseline DCT\", SOF),\n    0xFFC1: (\"SOF1\", \"Extended Sequential DCT\", SOF),\n    0xFFC2: (\"SOF2\", \"Progressive DCT\", SOF),\n    0xFFC3: (\"SOF3\", \"Spatial lossless\", SOF),\n    0xFFC4: (\"DHT\", \"Define Huffman table\", Skip),\n    0xFFC5: (\"SOF5\", \"Differential sequential DCT\", SOF),\n    0xFFC6: (\"SOF6\", \"Differential progressive DCT\", SOF),\n    0xFFC7: (\"SOF7\", \"Differential spatial\", SOF),\n    0xFFC8: (\"JPG\", \"Extension\", None),\n    0xFFC9: (\"SOF9\", \"Extended sequential DCT (AC)\", SOF),\n    0xFFCA: (\"SOF10\", \"Progressive DCT (AC)\", SOF),\n    0xFFCB: (\"SOF11\", \"Spatial lossless DCT (AC)\", SOF),\n    0xFFCC: (\"DAC\", \"Define arithmetic coding conditioning\", Skip),\n    0xFFCD: (\"SOF13\", \"Differential sequential DCT (AC)\", SOF),\n    0xFFCE: (\"SOF14\", \"Differential progressive DCT (AC)\", SOF),\n    0xFFCF: (\"SOF15\", \"Differential spatial (AC)\", SOF),\n    0xFFD0: (\"RST0\", \"Restart 0\", None),\n    0xFFD1: (\"RST1\", \"Restart 1\", None),\n    0xFFD2: (\"RST2\", \"Restart 2\", None),\n    0xFFD3: (\"RST3\", \"Restart 3\", None),\n    0xFFD4: (\"RST4\", \"Restart 4\", None),\n    0xFFD5: (\"RST5\", \"Restart 5\", None),\n    0xFFD6: (\"RST6\", \"Restart 6\", None),\n    0xFFD7: (\"RST7\", \"Restart 7\", None),\n    0xFFD8: (\"SOI\", \"Start of image\", None),\n    0xFFD9: (\"EOI\", \"End of image\", None),\n    0xFFDA: (\"SOS\", \"Start of scan\", Skip),\n    0xFFDB: (\"DQT\", \"Define quantization table\", DQT),\n    0xFFDC: (\"DNL\", \"Define number of lines\", Skip),\n    0xFFDD: (\"DRI\", \"Define restart interval\", Skip),\n    0xFFDE: (\"DHP\", \"Define hierarchical progression\", SOF),\n    0xFFDF: (\"EXP\", \"Expand reference component\", Skip),\n    0xFFE0: (\"APP0\", \"Application segment 0\", APP),\n    0xFFE1: (\"APP1\", \"Application segment 1\", APP),\n    0xFFE2: (\"APP2\", \"Application segment 2\", APP),\n    0xFFE3: (\"APP3\", \"Application segment 3\", APP),\n    0xFFE4: (\"APP4\", \"Application segment 4\", APP),\n    0xFFE5: (\"APP5\", \"Application segment 5\", APP),\n    0xFFE6: (\"APP6\", \"Application segment 6\", APP),\n    0xFFE7: (\"APP7\", \"Application segment 7\", APP),\n    0xFFE8: (\"APP8\", \"Application segment 8\", APP),\n    0xFFE9: (\"APP9\", \"Application segment 9\", APP),\n    0xFFEA: (\"APP10\", \"Application segment 10\", APP),\n    0xFFEB: (\"APP11\", \"Application segment 11\", APP),\n    0xFFEC: (\"APP12\", \"Application segment 12\", APP),\n    0xFFED: (\"APP13\", \"Application segment 13\", APP),\n    0xFFEE: (\"APP14\", \"Application segment 14\", APP),\n    0xFFEF: (\"APP15\", \"Application segment 15\", APP),\n    0xFFF0: (\"JPG0\", \"Extension 0\", None),\n    0xFFF1: (\"JPG1\", \"Extension 1\", None),\n    0xFFF2: (\"JPG2\", \"Extension 2\", None),\n    0xFFF3: (\"JPG3\", \"Extension 3\", None),\n    0xFFF4: (\"JPG4\", \"Extension 4\", None),\n    0xFFF5: (\"JPG5\", \"Extension 5\", None),\n    0xFFF6: (\"JPG6\", \"Extension 6\", None),\n    0xFFF7: (\"JPG7\", \"Extension 7\", None),\n    0xFFF8: (\"JPG8\", \"Extension 8\", None),\n    0xFFF9: (\"JPG9\", \"Extension 9\", None),\n    0xFFFA: (\"JPG10\", \"Extension 10\", None),\n    0xFFFB: (\"JPG11\", \"Extension 11\", None),\n    0xFFFC: (\"JPG12\", \"Extension 12\", None),\n    0xFFFD: (\"JPG13\", \"Extension 13\", None),\n    0xFFFE: (\"COM\", \"Comment\", COM)\n}\n\n\ndef _accept(prefix):\n    return prefix[0:1] == b\"\\377\"\n\n##\n# Image plugin for JPEG and JFIF images.\n\nclass JpegImageFile(ImageFile.ImageFile):\n\n    format = \"JPEG\"\n    format_description = \"JPEG (ISO 10918)\"\n\n    def _open(self):\n\n        s = self.fp.read(1)\n\n        if i8(s[0]) != 255:\n            raise SyntaxError(\"not a JPEG file\")\n\n        # Create attributes\n        self.bits = self.layers = 0\n\n        # JPEG specifics (internal)\n        self.layer = []\n        self.huffman_dc = {}\n        self.huffman_ac = {}\n        self.quantization = {}\n        self.app = {} # compatibility\n        self.applist = []\n        self.icclist = []\n\n        while True:\n\n            s = s + self.fp.read(1)\n\n            i = i16(s)\n\n            if i in MARKER:\n                name, description, handler = MARKER[i]\n                # print hex(i), name, description\n                if handler is not None:\n                    handler(self, i)\n                if i == 0xFFDA: # start of scan\n                    rawmode = self.mode\n                    if self.mode == \"CMYK\":\n                        rawmode = \"CMYK;I\" # assume adobe conventions\n                    self.tile = [(\"jpeg\", (0,0) + self.size, 0, (rawmode, \"\"))]\n                    # self.__offset = self.fp.tell()\n                    break\n                s = self.fp.read(1)\n            elif i == 0 or i == 65535:\n                # padded marker or junk; move on\n                s = \"\\xff\"\n            else:\n                raise SyntaxError(\"no marker found\")\n\n    def draft(self, mode, size):\n\n        if len(self.tile) != 1:\n            return\n\n        d, e, o, a = self.tile[0]\n        scale = 0\n\n        if a[0] == \"RGB\" and mode in [\"L\", \"YCbCr\"]:\n            self.mode = mode\n            a = mode, \"\"\n\n        if size:\n            scale = max(self.size[0] // size[0], self.size[1] // size[1])\n            for s in [8, 4, 2, 1]:\n                if scale >= s:\n                    break\n            e = e[0], e[1], (e[2]-e[0]+s-1)//s+e[0], (e[3]-e[1]+s-1)//s+e[1]\n            self.size = ((self.size[0]+s-1)//s, (self.size[1]+s-1)//s)\n            scale = s\n\n        self.tile = [(d, e, o, a)]\n        self.decoderconfig = (scale, 1)\n\n        return self\n\n    def load_djpeg(self):\n\n        # ALTERNATIVE: handle JPEGs via the IJG command line utilities\n\n        import tempfile, os\n        f, path = tempfile.mkstemp()\n        os.close(f)\n        if os.path.exists(self.filename):\n            os.system(\"djpeg '%s' >'%s'\" % (self.filename, path))\n        else:\n            raise ValueError(\"Invalid Filename\")\n\n        try:\n            self.im = Image.core.open_ppm(path)\n        finally:\n            try: os.unlink(path)\n            except: pass\n\n        self.mode = self.im.mode\n        self.size = self.im.size\n\n        self.tile = []\n\n    def _getexif(self):\n        return _getexif(self)\n\n\ndef _getexif(self):\n    # Extract EXIF information.  This method is highly experimental,\n    # and is likely to be replaced with something better in a future\n    # version.\n    from PIL import TiffImagePlugin\n    import io\n    def fixup(value):\n        if len(value) == 1:\n            return value[0]\n        return value\n    # The EXIF record consists of a TIFF file embedded in a JPEG\n    # application marker (!).\n    try:\n        data = self.info[\"exif\"]\n    except KeyError:\n        return None\n    file = io.BytesIO(data[6:])\n    head = file.read(8)\n    exif = {}\n    # process dictionary\n    info = TiffImagePlugin.ImageFileDirectory(head)\n    info.load(file)\n    for key, value in info.items():\n        exif[key] = fixup(value)\n    # get exif extension\n    try:\n        file.seek(exif[0x8769])\n    except KeyError:\n        pass\n    else:\n        info = TiffImagePlugin.ImageFileDirectory(head)\n        info.load(file)\n        for key, value in info.items():\n            exif[key] = fixup(value)\n    # get gpsinfo extension\n    try:\n        file.seek(exif[0x8825])\n    except KeyError:\n        pass\n    else:\n        info = TiffImagePlugin.ImageFileDirectory(head)\n        info.load(file)\n        exif[0x8825] = gps = {}\n        for key, value in info.items():\n            gps[key] = fixup(value)\n    return exif\n\n# --------------------------------------------------------------------\n# stuff to save JPEG files\n\nRAWMODE = {\n    \"1\": \"L\",\n    \"L\": \"L\",\n    \"RGB\": \"RGB\",\n    \"RGBA\": \"RGB\",\n    \"RGBX\": \"RGB\",\n    \"CMYK\": \"CMYK;I\", # assume adobe conventions\n    \"YCbCr\": \"YCbCr\",\n}\n\nzigzag_index = ( 0,  1,  5,  6, 14, 15, 27, 28,\n                 2,  4,  7, 13, 16, 26, 29, 42,\n                 3,  8, 12, 17, 25, 30, 41, 43,\n                 9, 11, 18, 24, 31, 40, 44, 53,\n                10, 19, 23, 32, 39, 45, 52, 54,\n                20, 22, 33, 38, 46, 51, 55, 60,\n                21, 34, 37, 47, 50, 56, 59, 61,\n                35, 36, 48, 49, 57, 58, 62, 63)\n\nsamplings = {\n             (1, 1, 1, 1, 1, 1): 0,\n             (2, 1, 1, 1, 1, 1): 1,\n             (2, 2, 1, 1, 1, 1): 2,\n            }\n\ndef convert_dict_qtables(qtables):\n    qtables = [qtables[key] for key in xrange(len(qtables)) if qtables.has_key(key)]\n    for idx, table in enumerate(qtables):\n        qtables[idx] = [table[i] for i in zigzag_index]\n    return qtables\n\ndef get_sampling(im):\n    sampling = im.layer[0][1:3] + im.layer[1][1:3] + im.layer[2][1:3]\n    return samplings.get(sampling, -1)\n\ndef _save(im, fp, filename):\n\n    try:\n        rawmode = RAWMODE[im.mode]\n    except KeyError:\n        raise IOError(\"cannot write mode %s as JPEG\" % im.mode)\n\n    info = im.encoderinfo\n\n    dpi = info.get(\"dpi\", (0, 0))\n\n    quality = info.get(\"quality\", 0)\n    subsampling = info.get(\"subsampling\", -1)\n    qtables = info.get(\"qtables\")\n\n    if quality == \"keep\":\n        quality = 0\n        subsampling = \"keep\"\n        qtables = \"keep\"\n    elif quality in presets:\n        preset = presets[quality]\n        quality = 0\n        subsampling = preset.get('subsampling', -1)\n        qtables = preset.get('quantization')\n    elif not isinstance(quality, int):\n        raise ValueError(\"Invalid quality setting\")\n    else:\n        if subsampling in presets:\n            subsampling = presets[subsampling].get('subsampling', -1)\n        if qtables in presets:\n            qtables = presets[qtables].get('quantization')\n\n    if subsampling == \"4:4:4\":\n        subsampling = 0\n    elif subsampling == \"4:2:2\":\n        subsampling = 1\n    elif subsampling == \"4:1:1\":\n        subsampling = 2\n    elif subsampling == \"keep\":\n        if im.format != \"JPEG\":\n            raise ValueError(\"Cannot use 'keep' when original image is not a JPEG\")\n        subsampling = get_sampling(im)\n\n    def validate_qtables(qtables):\n        if qtables is None:\n            return qtables\n        if isStringType(qtables):\n            try:\n                lines = [int(num) for line in qtables.splitlines()\n                         for num in line.split('#', 1)[0].split()]\n            except ValueError:\n                raise ValueError(\"Invalid quantization table\")\n            else:\n                qtables = [lines[s:s+64] for s in xrange(0, len(lines), 64)]\n        if isinstance(qtables, (tuple, list, dict)):\n            if isinstance(qtables, dict):\n                qtables = convert_dict_qtables(qtables)\n            elif isinstance(qtables, tuple):\n                qtables = list(qtables)\n            if not (0 < len(qtables) < 5):\n                raise ValueError(\"None or too many quantization tables\")\n            for idx, table in enumerate(qtables):\n                try:\n                    if len(table) != 64:\n                        raise\n                    table = array.array('b', table)\n                except TypeError:\n                    raise ValueError(\"Invalid quantization table\")\n                else:\n                    qtables[idx] = list(table)\n            return qtables\n\n    if qtables == \"keep\":\n        if im.format != \"JPEG\":\n            raise ValueError(\"Cannot use 'keep' when original image is not a JPEG\")\n        qtables = getattr(im, \"quantization\", None)\n    qtables = validate_qtables(qtables)\n\n    extra = b\"\"\n\n    icc_profile = info.get(\"icc_profile\")\n    if icc_profile:\n        ICC_OVERHEAD_LEN = 14\n        MAX_BYTES_IN_MARKER = 65533\n        MAX_DATA_BYTES_IN_MARKER = MAX_BYTES_IN_MARKER - ICC_OVERHEAD_LEN\n        markers = []\n        while icc_profile:\n            markers.append(icc_profile[:MAX_DATA_BYTES_IN_MARKER])\n            icc_profile = icc_profile[MAX_DATA_BYTES_IN_MARKER:]\n        i = 1\n        for marker in markers:\n            size = struct.pack(\">H\", 2 + ICC_OVERHEAD_LEN + len(marker))\n            extra = extra + (b\"\\xFF\\xE2\" + size + b\"ICC_PROFILE\\0\" + o8(i) + o8(len(markers)) + marker)\n            i = i + 1\n\n    # get keyword arguments\n    im.encoderconfig = (\n        quality,\n        # \"progressive\" is the official name, but older documentation\n        # says \"progression\"\n        # FIXME: issue a warning if the wrong form is used (post-1.1.7)\n        \"progressive\" in info or \"progression\" in info,\n        info.get(\"smooth\", 0),\n        \"optimize\" in info,\n        info.get(\"streamtype\", 0),\n        dpi[0], dpi[1],\n        subsampling,\n        qtables,\n        extra,\n        info.get(\"exif\", b\"\")\n        )\n\n\n    # if we optimize, libjpeg needs a buffer big enough to hold the whole image in a shot.\n    # Guessing on the size, at im.size bytes. (raw pizel size is channels*size, this\n    # is a value that's been used in a django patch.\n    # https://github.com/jdriscoll/django-imagekit/issues/50\n    bufsize=0\n    if \"optimize\" in info or \"progressive\" in info or \"progression\" in info:\n        bufsize = im.size[0]*im.size[1]\n\n    # The exif info needs to be written as one block, + APP1, + one spare byte.\n    # Ensure that our buffer is big enough\n    bufsize = max(ImageFile.MAXBLOCK, bufsize, len(info.get(\"exif\",b\"\")) + 5 )\n\n    ImageFile._save(im, fp, [(\"jpeg\", (0,0)+im.size, 0, rawmode)], bufsize)\n\ndef _save_cjpeg(im, fp, filename):\n    # ALTERNATIVE: handle JPEGs via the IJG command line utilities.\n    import os\n    file = im._dump()\n    os.system(\"cjpeg %s >%s\" % (file, filename))\n    try: os.unlink(file)\n    except: pass\n\n# -------------------------------------------------------------------q-\n# Registry stuff\n\nImage.register_open(\"JPEG\", JpegImageFile, _accept)\nImage.register_save(\"JPEG\", _save)\n\nImage.register_extension(\"JPEG\", \".jfif\")\nImage.register_extension(\"JPEG\", \".jpe\")\nImage.register_extension(\"JPEG\", \".jpg\")\nImage.register_extension(\"JPEG\", \".jpeg\")\n\nImage.register_mime(\"JPEG\", \"image/jpeg\")\n", "target": 0}
{"idx": 920, "func": "# -*- coding: utf-8 -*-\n'''\nThe crypt module manages all of the cryptography functions for minions and\nmasters, encrypting and decrypting payloads, preparing messages, and\nauthenticating peers\n'''\n# Import python libs\nfrom __future__ import absolute_import, print_function\nimport os\nimport sys\nimport copy\nimport time\nimport hmac\nimport base64\nimport hashlib\nimport logging\nimport stat\nimport traceback\nimport binascii\nimport weakref\nimport getpass\n\n# Import third party libs\nimport salt.ext.six as six\nfrom salt.ext.six.moves import zip  # pylint: disable=import-error,redefined-builtin\ntry:\n    from Cryptodome.Cipher import AES, PKCS1_OAEP\n    from Cryptodome.Hash import SHA\n    from Cryptodome.PublicKey import RSA\n    from Cryptodome.Signature import PKCS1_v1_5\n    import Cryptodome.Random  # pylint: disable=W0611\n    CDOME = True\nexcept ImportError:\n    CDOME = False\nif not CDOME:\n    try:\n        from Crypto.Cipher import AES, PKCS1_OAEP\n        from Crypto.Hash import SHA\n        from Crypto.PublicKey import RSA\n        from Crypto.Signature import PKCS1_v1_5\n        # let this be imported, if possible\n        import Crypto.Random  # pylint: disable=W0611\n    except ImportError:\n        # No need for crypt in local mode\n        pass\n\n# Import salt libs\nimport salt.defaults.exitcodes\nimport salt.utils\nimport salt.utils.decorators\nimport salt.payload\nimport salt.transport.client\nimport salt.transport.frame\nimport salt.utils.rsax931\nimport salt.utils.verify\nimport salt.version\nfrom salt.exceptions import (\n    AuthenticationError, SaltClientError, SaltReqTimeoutError\n)\n\nimport tornado.gen\n\nlog = logging.getLogger(__name__)\n\n\ndef dropfile(cachedir, user=None):\n    '''\n    Set an AES dropfile to request the master update the publish session key\n    '''\n    dfn = os.path.join(cachedir, '.dfn')\n    # set a mask (to avoid a race condition on file creation) and store original.\n    mask = os.umask(191)\n    try:\n        log.info('Rotating AES key')\n        if os.path.isfile(dfn):\n            log.info('AES key rotation already requested')\n            return\n\n        if os.path.isfile(dfn) and not os.access(dfn, os.W_OK):\n            os.chmod(dfn, stat.S_IRUSR | stat.S_IWUSR)\n        with salt.utils.fopen(dfn, 'wb+') as fp_:\n            fp_.write(b'')\n        os.chmod(dfn, stat.S_IRUSR)\n        if user:\n            try:\n                import pwd\n                uid = pwd.getpwnam(user).pw_uid\n                os.chown(dfn, uid, -1)\n            except (KeyError, ImportError, OSError, IOError):\n                pass\n    finally:\n        os.umask(mask)  # restore original umask\n\n\ndef gen_keys(keydir, keyname, keysize, user=None):\n    '''\n    Generate a RSA public keypair for use with salt\n\n    :param str keydir: The directory to write the keypair to\n    :param str keyname: The type of salt server for whom this key should be written. (i.e. 'master' or 'minion')\n    :param int keysize: The number of bits in the key\n    :param str user: The user on the system who should own this keypair\n\n    :rtype: str\n    :return: Path on the filesystem to the RSA private key\n    '''\n    base = os.path.join(keydir, keyname)\n    priv = '{0}.pem'.format(base)\n    pub = '{0}.pub'.format(base)\n\n    salt.utils.reinit_crypto()\n    gen = RSA.generate(bits=keysize, e=65537)\n    if os.path.isfile(priv):\n        # Between first checking and the generation another process has made\n        # a key! Use the winner's key\n        return priv\n\n    # Do not try writing anything, if directory has no permissions.\n    if not os.access(keydir, os.W_OK):\n        raise IOError('Write access denied to \"{0}\" for user \"{1}\".'.format(os.path.abspath(keydir), getpass.getuser()))\n\n    cumask = os.umask(191)\n    with salt.utils.fopen(priv, 'wb+') as f:\n        f.write(gen.exportKey('PEM'))\n    os.umask(cumask)\n    with salt.utils.fopen(pub, 'wb+') as f:\n        f.write(gen.publickey().exportKey('PEM'))\n    os.chmod(priv, 256)\n    if user:\n        try:\n            import pwd\n            uid = pwd.getpwnam(user).pw_uid\n            os.chown(priv, uid, -1)\n            os.chown(pub, uid, -1)\n        except (KeyError, ImportError, OSError):\n            # The specified user was not found, allow the backup systems to\n            # report the error\n            pass\n    return priv\n\n\n@salt.utils.decorators.memoize\ndef _get_key_with_evict(path, timestamp):\n    '''\n    Load a key from disk.  `timestamp` above is intended to be the timestamp\n    of the file's last modification. This fn is memoized so if it is called with the\n    same path and timestamp (the file's last modified time) the second time\n    the result is returned from the memoiziation.  If the file gets modified\n    then the params are different and the key is loaded from disk.\n    '''\n    log.debug('salt.crypt._get_key_with_evict: Loading private key')\n    with salt.utils.fopen(path) as f:\n        key = RSA.importKey(f.read())\n    return key\n\n\ndef _get_rsa_key(path):\n    '''\n    Read a key off the disk.  Poor man's simple cache in effect here,\n    we memoize the result of calling _get_rsa_with_evict.  This means\n    the first time _get_key_with_evict is called with a path and a timestamp\n    the result is cached.  If the file (the private key) does not change\n    then its timestamp will not change and the next time the result is returned\n    from the cache.  If the key DOES change the next time _get_rsa_with_evict\n    is called it is called with different parameters and the fn is run fully to\n    retrieve the key from disk.\n    '''\n    log.debug('salt.crypt._get_rsa_key: Loading private key')\n    return _get_key_with_evict(path, str(os.path.getmtime(path)))\n\n\ndef sign_message(privkey_path, message):\n    '''\n    Use Crypto.Signature.PKCS1_v1_5 to sign a message. Returns the signature.\n    '''\n    key = _get_rsa_key(privkey_path)\n    log.debug('salt.crypt.sign_message: Signing message.')\n    signer = PKCS1_v1_5.new(key)\n    return signer.sign(SHA.new(message))\n\n\ndef verify_signature(pubkey_path, message, signature):\n    '''\n    Use Crypto.Signature.PKCS1_v1_5 to verify the signature on a message.\n    Returns True for valid signature.\n    '''\n    log.debug('salt.crypt.verify_signature: Loading public key')\n    with salt.utils.fopen(pubkey_path) as f:\n        pubkey = RSA.importKey(f.read())\n    log.debug('salt.crypt.verify_signature: Verifying signature')\n    verifier = PKCS1_v1_5.new(pubkey)\n    return verifier.verify(SHA.new(message), signature)\n\n\ndef gen_signature(priv_path, pub_path, sign_path):\n    '''\n    creates a signature for the given public-key with\n    the given private key and writes it to sign_path\n    '''\n\n    with salt.utils.fopen(pub_path) as fp_:\n        mpub_64 = fp_.read()\n\n    mpub_sig = sign_message(priv_path, mpub_64)\n    mpub_sig_64 = binascii.b2a_base64(mpub_sig)\n    if os.path.isfile(sign_path):\n        return False\n    log.trace('Calculating signature for {0} with {1}'\n              .format(os.path.basename(pub_path),\n                      os.path.basename(priv_path)))\n\n    if os.path.isfile(sign_path):\n        log.trace('Signature file {0} already exists, please '\n                  'remove it first and try again'.format(sign_path))\n    else:\n        with salt.utils.fopen(sign_path, 'wb+') as sig_f:\n            sig_f.write(salt.utils.to_bytes(mpub_sig_64))\n        log.trace('Wrote signature to {0}'.format(sign_path))\n    return True\n\n\ndef private_encrypt(key, message):\n    '''\n    Generate an M2Crypto-compatible signature\n\n    :param Crypto.PublicKey.RSA._RSAobj key: The RSA key object\n    :param str message: The message to sign\n    :rtype: str\n    :return: The signature, or an empty string if the signature operation failed\n    '''\n    signer = salt.utils.rsax931.RSAX931Signer(key.exportKey('PEM'))\n    return signer.sign(message)\n\n\ndef public_decrypt(pub, message):\n    '''\n    Verify an M2Crypto-compatible signature\n\n    :param Crypto.PublicKey.RSA._RSAobj key: The RSA public key object\n    :param str message: The signed message to verify\n    :rtype: str\n    :return: The message (or digest) recovered from the signature, or an\n        empty string if the verification failed\n    '''\n    verifier = salt.utils.rsax931.RSAX931Verifier(pub.exportKey('PEM'))\n    return verifier.verify(message)\n\n\nclass MasterKeys(dict):\n    '''\n    The Master Keys class is used to manage the RSA public key pair used for\n    authentication by the master.\n\n    It also generates a signing key-pair if enabled with master_sign_key_name.\n    '''\n    def __init__(self, opts):\n        super(MasterKeys, self).__init__()\n        self.opts = opts\n        self.pub_path = os.path.join(self.opts['pki_dir'], 'master.pub')\n        self.rsa_path = os.path.join(self.opts['pki_dir'], 'master.pem')\n\n        self.key = self.__get_keys()\n        self.pub_signature = None\n\n        # set names for the signing key-pairs\n        if opts['master_sign_pubkey']:\n\n            # if only the signature is available, use that\n            if opts['master_use_pubkey_signature']:\n                self.sig_path = os.path.join(self.opts['pki_dir'],\n                                             opts['master_pubkey_signature'])\n                if os.path.isfile(self.sig_path):\n                    with salt.utils.fopen(self.sig_path) as fp_:\n                        self.pub_signature = fp_.read()\n                    log.info('Read {0}\\'s signature from {1}'\n                             ''.format(os.path.basename(self.pub_path),\n                                       self.opts['master_pubkey_signature']))\n                else:\n                    log.error('Signing the master.pub key with a signature is enabled '\n                              'but no signature file found at the defined location '\n                              '{0}'.format(self.sig_path))\n                    log.error('The signature-file may be either named differently '\n                               'or has to be created with \\'salt-key --gen-signature\\'')\n                    sys.exit(1)\n\n            # create a new signing key-pair to sign the masters\n            # auth-replies when a minion tries to connect\n            else:\n                self.pub_sign_path = os.path.join(self.opts['pki_dir'],\n                                                  opts['master_sign_key_name'] + '.pub')\n                self.rsa_sign_path = os.path.join(self.opts['pki_dir'],\n                                                  opts['master_sign_key_name'] + '.pem')\n                self.sign_key = self.__get_keys(name=opts['master_sign_key_name'])\n\n    # We need __setstate__ and __getstate__ to avoid pickling errors since\n    # some of the member variables correspond to Cython objects which are\n    # not picklable.\n    # These methods are only used when pickling so will not be used on\n    # non-Windows platforms.\n    def __setstate__(self, state):\n        self.__init__(state['opts'])\n\n    def __getstate__(self):\n        return {'opts': self.opts}\n\n    def __get_keys(self, name='master'):\n        '''\n        Returns a key object for a key in the pki-dir\n        '''\n        path = os.path.join(self.opts['pki_dir'],\n                            name + '.pem')\n        if os.path.exists(path):\n            with salt.utils.fopen(path) as f:\n                key = RSA.importKey(f.read())\n            log.debug('Loaded {0} key: {1}'.format(name, path))\n        else:\n            log.info('Generating {0} keys: {1}'.format(name, self.opts['pki_dir']))\n            gen_keys(self.opts['pki_dir'],\n                     name,\n                     self.opts['keysize'],\n                     self.opts.get('user'))\n            with salt.utils.fopen(self.rsa_path) as f:\n                key = RSA.importKey(f.read())\n        return key\n\n    def get_pub_str(self, name='master'):\n        '''\n        Return the string representation of a public key\n        in the pki-directory\n        '''\n        path = os.path.join(self.opts['pki_dir'],\n                            name + '.pub')\n        if not os.path.isfile(path):\n            key = self.__get_keys()\n            with salt.utils.fopen(path, 'wb+') as wfh:\n                wfh.write(key.publickey().exportKey('PEM'))\n        with salt.utils.fopen(path) as rfh:\n            return rfh.read()\n\n    def get_mkey_paths(self):\n        return self.pub_path, self.rsa_path\n\n    def get_sign_paths(self):\n        return self.pub_sign_path, self.rsa_sign_path\n\n    def pubkey_signature(self):\n        '''\n        returns the base64 encoded signature from the signature file\n        or None if the master has its own signing keys\n        '''\n        return self.pub_signature\n\n\nclass AsyncAuth(object):\n    '''\n    Set up an Async object to maintain authentication with the salt master\n    '''\n    # This class is only a singleton per minion/master pair\n    # mapping of io_loop -> {key -> auth}\n    instance_map = weakref.WeakKeyDictionary()\n\n    # mapping of key -> creds\n    creds_map = {}\n\n    def __new__(cls, opts, io_loop=None):\n        '''\n        Only create one instance of AsyncAuth per __key()\n        '''\n        # do we have any mapping for this io_loop\n        io_loop = io_loop or tornado.ioloop.IOLoop.current()\n        if io_loop not in AsyncAuth.instance_map:\n            AsyncAuth.instance_map[io_loop] = weakref.WeakValueDictionary()\n        loop_instance_map = AsyncAuth.instance_map[io_loop]\n\n        key = cls.__key(opts)\n        auth = loop_instance_map.get(key)\n        if auth is None:\n            log.debug('Initializing new AsyncAuth for {0}'.format(key))\n            # we need to make a local variable for this, as we are going to store\n            # it in a WeakValueDictionary-- which will remove the item if no one\n            # references it-- this forces a reference while we return to the caller\n            auth = object.__new__(cls)\n            auth.__singleton_init__(opts, io_loop=io_loop)\n            loop_instance_map[key] = auth\n        else:\n            log.debug('Re-using AsyncAuth for {0}'.format(key))\n        return auth\n\n    @classmethod\n    def __key(cls, opts, io_loop=None):\n        return (opts['pki_dir'],     # where the keys are stored\n                opts['id'],          # minion ID\n                opts['master_uri'],  # master ID\n                )\n\n    # has to remain empty for singletons, since __init__ will *always* be called\n    def __init__(self, opts, io_loop=None):\n        pass\n\n    # an init for the singleton instance to call\n    def __singleton_init__(self, opts, io_loop=None):\n        '''\n        Init an Auth instance\n\n        :param dict opts: Options for this server\n        :return: Auth instance\n        :rtype: Auth\n        '''\n        self.opts = opts\n        if six.PY2:\n            self.token = Crypticle.generate_key_string()\n        else:\n            self.token = salt.utils.to_bytes(Crypticle.generate_key_string())\n        self.serial = salt.payload.Serial(self.opts)\n        self.pub_path = os.path.join(self.opts['pki_dir'], 'minion.pub')\n        self.rsa_path = os.path.join(self.opts['pki_dir'], 'minion.pem')\n        if self.opts['__role'] == 'syndic':\n            self.mpub = 'syndic_master.pub'\n        else:\n            self.mpub = 'minion_master.pub'\n        if not os.path.isfile(self.pub_path):\n            self.get_keys()\n\n        self.io_loop = io_loop or tornado.ioloop.IOLoop.current()\n\n        salt.utils.reinit_crypto()\n        key = self.__key(self.opts)\n        # TODO: if we already have creds for this key, lets just re-use\n        if key in AsyncAuth.creds_map:\n            creds = AsyncAuth.creds_map[key]\n            self._creds = creds\n            self._crypticle = Crypticle(self.opts, creds['aes'])\n            self._authenticate_future = tornado.concurrent.Future()\n            self._authenticate_future.set_result(True)\n        else:\n            self.authenticate()\n\n    def __deepcopy__(self, memo):\n        cls = self.__class__\n        result = cls.__new__(cls, copy.deepcopy(self.opts, memo), io_loop=None)\n        memo[id(self)] = result\n        for key in self.__dict__:\n            if key in ('io_loop',):\n                # The io_loop has a thread Lock which will fail to be deep\n                # copied. Skip it because it will just be recreated on the\n                # new copy.\n                continue\n            setattr(result, key, copy.deepcopy(self.__dict__[key], memo))\n        return result\n\n    @property\n    def creds(self):\n        return self._creds\n\n    @property\n    def crypticle(self):\n        return self._crypticle\n\n    @property\n    def authenticated(self):\n        return hasattr(self, '_authenticate_future') and \\\n               self._authenticate_future.done() and \\\n               self._authenticate_future.exception() is None\n\n    def invalidate(self):\n        if self.authenticated:\n            del self._authenticate_future\n            key = self.__key(self.opts)\n            if key in AsyncAuth.creds_map:\n                del AsyncAuth.creds_map[key]\n\n    def authenticate(self, callback=None):\n        '''\n        Ask for this client to reconnect to the origin\n\n        This function will de-dupe all calls here and return a *single* future\n        for the sign-in-- whis way callers can all assume there aren't others\n        '''\n        # if an auth is in flight-- and not done-- just pass that back as the future to wait on\n        if hasattr(self, '_authenticate_future') and not self._authenticate_future.done():\n            future = self._authenticate_future\n        else:\n            future = tornado.concurrent.Future()\n            self._authenticate_future = future\n            self.io_loop.add_callback(self._authenticate)\n\n        if callback is not None:\n            def handle_future(future):\n                response = future.result()\n                self.io_loop.add_callback(callback, response)\n            future.add_done_callback(handle_future)\n\n        return future\n\n    @tornado.gen.coroutine\n    def _authenticate(self):\n        '''\n        Authenticate with the master, this method breaks the functional\n        paradigm, it will update the master information from a fresh sign\n        in, signing in can occur as often as needed to keep up with the\n        revolving master AES key.\n\n        :rtype: Crypticle\n        :returns: A crypticle used for encryption operations\n        '''\n        acceptance_wait_time = self.opts['acceptance_wait_time']\n        acceptance_wait_time_max = self.opts['acceptance_wait_time_max']\n        if not acceptance_wait_time_max:\n            acceptance_wait_time_max = acceptance_wait_time\n        creds = None\n        channel = salt.transport.client.AsyncReqChannel.factory(self.opts,\n                                                                crypt='clear',\n                                                                io_loop=self.io_loop)\n        error = None\n        while True:\n            try:\n                creds = yield self.sign_in(channel=channel)\n            except SaltClientError as exc:\n                error = exc\n                break\n            if creds == 'retry':\n                if self.opts.get('detect_mode') is True:\n                    error = SaltClientError('Detect mode is on')\n                    break\n                if self.opts.get('caller'):\n                    print('Minion failed to authenticate with the master, '\n                          'has the minion key been accepted?')\n                    sys.exit(2)\n                if acceptance_wait_time:\n                    log.info('Waiting {0} seconds before retry.'.format(acceptance_wait_time))\n                    yield tornado.gen.sleep(acceptance_wait_time)\n                if acceptance_wait_time < acceptance_wait_time_max:\n                    acceptance_wait_time += acceptance_wait_time\n                    log.debug('Authentication wait time is {0}'.format(acceptance_wait_time))\n                continue\n            break\n        if not isinstance(creds, dict) or 'aes' not in creds:\n            if self.opts.get('detect_mode') is True:\n                error = SaltClientError('-|RETRY|-')\n            try:\n                del AsyncAuth.creds_map[self.__key(self.opts)]\n            except KeyError:\n                pass\n            if not error:\n                error = SaltClientError('Attempt to authenticate with the salt master failed')\n            self._authenticate_future.set_exception(error)\n        else:\n            key = self.__key(self.opts)\n            AsyncAuth.creds_map[key] = creds\n            self._creds = creds\n            self._crypticle = Crypticle(self.opts, creds['aes'])\n            self._authenticate_future.set_result(True)  # mark the sign-in as complete\n            # Notify the bus about creds change\n            event = salt.utils.event.get_event(self.opts.get('__role'), opts=self.opts, listen=False)\n            event.fire_event({'key': key, 'creds': creds}, salt.utils.event.tagify(prefix='auth', suffix='creds'))\n\n    @tornado.gen.coroutine\n    def sign_in(self, timeout=60, safe=True, tries=1, channel=None):\n        '''\n        Send a sign in request to the master, sets the key information and\n        returns a dict containing the master publish interface to bind to\n        and the decrypted aes key for transport decryption.\n\n        :param int timeout: Number of seconds to wait before timing out the sign-in request\n        :param bool safe: If True, do not raise an exception on timeout. Retry instead.\n        :param int tries: The number of times to try to authenticate before giving up.\n\n        :raises SaltReqTimeoutError: If the sign-in request has timed out and :param safe: is not set\n\n        :return: Return a string on failure indicating the reason for failure. On success, return a dictionary\n        with the publication port and the shared AES key.\n\n        '''\n        auth = {}\n\n        auth_timeout = self.opts.get('auth_timeout', None)\n        if auth_timeout is not None:\n            timeout = auth_timeout\n        auth_safemode = self.opts.get('auth_safemode', None)\n        if auth_safemode is not None:\n            safe = auth_safemode\n        auth_tries = self.opts.get('auth_tries', None)\n        if auth_tries is not None:\n            tries = auth_tries\n\n        m_pub_fn = os.path.join(self.opts['pki_dir'], self.mpub)\n\n        auth['master_uri'] = self.opts['master_uri']\n\n        if not channel:\n            channel = salt.transport.client.AsyncReqChannel.factory(self.opts,\n                                                                crypt='clear',\n                                                                io_loop=self.io_loop)\n\n        sign_in_payload = self.minion_sign_in_payload()\n        try:\n            payload = yield channel.send(\n                sign_in_payload,\n                tries=tries,\n                timeout=timeout\n            )\n        except SaltReqTimeoutError as e:\n            if safe:\n                log.warning('SaltReqTimeoutError: {0}'.format(e))\n                raise tornado.gen.Return('retry')\n            if self.opts.get('detect_mode') is True:\n                raise tornado.gen.Return('retry')\n            else:\n                raise SaltClientError('Attempt to authenticate with the salt master failed with timeout error')\n        if not isinstance(payload, dict):\n            log.error('Sign-in attempt failed: %s', payload)\n            raise tornado.gen.Return(False)\n        if 'load' in payload:\n            if 'ret' in payload['load']:\n                if not payload['load']['ret']:\n                    if self.opts['rejected_retry']:\n                        log.error(\n                            'The Salt Master has rejected this minion\\'s public '\n                            'key.\\nTo repair this issue, delete the public key '\n                            'for this minion on the Salt Master.\\nThe Salt '\n                            'Minion will attempt to to re-authenicate.'\n                        )\n                        raise tornado.gen.Return('retry')\n                    else:\n                        log.critical(\n                            'The Salt Master has rejected this minion\\'s public '\n                            'key!\\nTo repair this issue, delete the public key '\n                            'for this minion on the Salt Master and restart this '\n                            'minion.\\nOr restart the Salt Master in open mode to '\n                            'clean out the keys. The Salt Minion will now exit.'\n                        )\n                        sys.exit(salt.defaults.exitcodes.EX_OK)\n                # has the master returned that its maxed out with minions?\n                elif payload['load']['ret'] == 'full':\n                    raise tornado.gen.Return('full')\n                else:\n                    log.error(\n                        'The Salt Master has cached the public key for this '\n                        'node, this salt minion will wait for {0} seconds '\n                        'before attempting to re-authenticate'.format(\n                            self.opts['acceptance_wait_time']\n                        )\n                    )\n                    raise tornado.gen.Return('retry')\n        auth['aes'] = self.verify_master(payload, master_pub='token' in sign_in_payload)\n        if not auth['aes']:\n            log.critical(\n                'The Salt Master server\\'s public key did not authenticate!\\n'\n                'The master may need to be updated if it is a version of Salt '\n                'lower than {0}, or\\n'\n                'If you are confident that you are connecting to a valid Salt '\n                'Master, then remove the master public key and restart the '\n                'Salt Minion.\\nThe master public key can be found '\n                'at:\\n{1}'.format(salt.version.__version__, m_pub_fn)\n            )\n            raise SaltClientError('Invalid master key')\n        if self.opts.get('syndic_master', False):  # Is syndic\n            syndic_finger = self.opts.get('syndic_finger', self.opts.get('master_finger', False))\n            if syndic_finger:\n                if salt.utils.pem_finger(m_pub_fn, sum_type=self.opts['hash_type']) != syndic_finger:\n                    self._finger_fail(syndic_finger, m_pub_fn)\n        else:\n            if self.opts.get('master_finger', False):\n                if salt.utils.pem_finger(m_pub_fn, sum_type=self.opts['hash_type']) != self.opts['master_finger']:\n                    self._finger_fail(self.opts['master_finger'], m_pub_fn)\n        auth['publish_port'] = payload['publish_port']\n        raise tornado.gen.Return(auth)\n\n    def get_keys(self):\n        '''\n        Return keypair object for the minion.\n\n        :rtype: Crypto.PublicKey.RSA._RSAobj\n        :return: The RSA keypair\n        '''\n        # Make sure all key parent directories are accessible\n        user = self.opts.get('user', 'root')\n        salt.utils.verify.check_path_traversal(self.opts['pki_dir'], user)\n\n        if os.path.exists(self.rsa_path):\n            with salt.utils.fopen(self.rsa_path) as f:\n                key = RSA.importKey(f.read())\n            log.debug('Loaded minion key: {0}'.format(self.rsa_path))\n        else:\n            log.info('Generating keys: {0}'.format(self.opts['pki_dir']))\n            gen_keys(self.opts['pki_dir'],\n                     'minion',\n                     self.opts['keysize'],\n                     self.opts.get('user'))\n            with salt.utils.fopen(self.rsa_path) as f:\n                key = RSA.importKey(f.read())\n        return key\n\n    def gen_token(self, clear_tok):\n        '''\n        Encrypt a string with the minion private key to verify identity\n        with the master.\n\n        :param str clear_tok: A plaintext token to encrypt\n        :return: Encrypted token\n        :rtype: str\n        '''\n        return private_encrypt(self.get_keys(), clear_tok)\n\n    def minion_sign_in_payload(self):\n        '''\n        Generates the payload used to authenticate with the master\n        server. This payload consists of the passed in id_ and the ssh\n        public key to encrypt the AES key sent back from the master.\n\n        :return: Payload dictionary\n        :rtype: dict\n        '''\n        payload = {}\n        payload['cmd'] = '_auth'\n        payload['id'] = self.opts['id']\n        try:\n            pubkey_path = os.path.join(self.opts['pki_dir'], self.mpub)\n            with salt.utils.fopen(pubkey_path) as f:\n                pub = RSA.importKey(f.read())\n            cipher = PKCS1_OAEP.new(pub)\n            payload['token'] = cipher.encrypt(self.token)\n        except Exception:\n            pass\n        with salt.utils.fopen(self.pub_path) as f:\n            payload['pub'] = f.read()\n        return payload\n\n    def decrypt_aes(self, payload, master_pub=True):\n        '''\n        This function is used to decrypt the AES seed phrase returned from\n        the master server. The seed phrase is decrypted with the SSH RSA\n        host key.\n\n        Pass in the encrypted AES key.\n        Returns the decrypted AES seed key, a string\n\n        :param dict payload: The incoming payload. This is a dictionary which may have the following keys:\n            'aes': The shared AES key\n            'enc': The format of the message. ('clear', 'pub', etc)\n            'sig': The message signature\n            'publish_port': The TCP port which published the message\n            'token': The encrypted token used to verify the message.\n            'pub_key': The public key of the sender.\n\n        :rtype: str\n        :return: The decrypted token that was provided, with padding.\n\n        :rtype: str\n        :return: The decrypted AES seed key\n        '''\n        if self.opts.get('auth_trb', False):\n            log.warning(\n                    'Auth Called: {0}'.format(\n                        ''.join(traceback.format_stack())\n                        )\n                    )\n        else:\n            log.debug('Decrypting the current master AES key')\n        key = self.get_keys()\n        cipher = PKCS1_OAEP.new(key)\n        key_str = cipher.decrypt(payload['aes'])\n        if 'sig' in payload:\n            m_path = os.path.join(self.opts['pki_dir'], self.mpub)\n            if os.path.exists(m_path):\n                try:\n                    with salt.utils.fopen(m_path) as f:\n                        mkey = RSA.importKey(f.read())\n                except Exception:\n                    return '', ''\n                digest = hashlib.sha256(key_str).hexdigest()\n                if six.PY3:\n                    digest = salt.utils.to_bytes(digest)\n                m_digest = public_decrypt(mkey.publickey(), payload['sig'])\n                if m_digest != digest:\n                    return '', ''\n        else:\n            return '', ''\n\n        if six.PY3:\n            key_str = salt.utils.to_str(key_str)\n\n        if '_|-' in key_str:\n            return key_str.split('_|-')\n        else:\n            if 'token' in payload:\n                token = cipher.decrypt(payload['token'])\n                return key_str, token\n            elif not master_pub:\n                return key_str, ''\n        return '', ''\n\n    def verify_pubkey_sig(self, message, sig):\n        '''\n        Wraps the verify_signature method so we have\n        additional checks.\n\n        :rtype: bool\n        :return: Success or failure of public key verification\n        '''\n        if self.opts['master_sign_key_name']:\n            path = os.path.join(self.opts['pki_dir'],\n                                self.opts['master_sign_key_name'] + '.pub')\n\n            if os.path.isfile(path):\n                res = verify_signature(path,\n                                       message,\n                                       binascii.a2b_base64(sig))\n            else:\n                log.error('Verification public key {0} does not exist. You '\n                          'need to copy it from the master to the minions '\n                          'pki directory'.format(os.path.basename(path)))\n                return False\n            if res:\n                log.debug('Successfully verified signature of master '\n                          'public key with verification public key '\n                          '{0}'.format(self.opts['master_sign_key_name'] + '.pub'))\n                return True\n            else:\n                log.debug('Failed to verify signature of public key')\n                return False\n        else:\n            log.error('Failed to verify the signature of the message because '\n                      'the verification key-pairs name is not defined. Please '\n                      'make sure that master_sign_key_name is defined.')\n            return False\n\n    def verify_signing_master(self, payload):\n        try:\n            if self.verify_pubkey_sig(payload['pub_key'],\n                                      payload['pub_sig']):\n                log.info('Received signed and verified master pubkey '\n                         'from master {0}'.format(self.opts['master']))\n                m_pub_fn = os.path.join(self.opts['pki_dir'], self.mpub)\n                uid = salt.utils.get_uid(self.opts.get('user', None))\n                with salt.utils.fpopen(m_pub_fn, 'wb+', uid=uid) as wfh:\n                    wfh.write(salt.utils.to_bytes(payload['pub_key']))\n                return True\n            else:\n                log.error('Received signed public-key from master {0} '\n                          'but signature verification failed!'.format(self.opts['master']))\n                return False\n        except Exception as sign_exc:\n            log.error('There was an error while verifying the masters public-key signature')\n            raise Exception(sign_exc)\n\n    def check_auth_deps(self, payload):\n        '''\n        Checks if both master and minion either sign (master) and\n        verify (minion). If one side does not, it should fail.\n\n        :param dict payload: The incoming payload. This is a dictionary which may have the following keys:\n            'aes': The shared AES key\n            'enc': The format of the message. ('clear', 'pub', 'aes')\n            'publish_port': The TCP port which published the message\n            'token': The encrypted token used to verify the message.\n            'pub_key': The RSA public key of the sender.\n        '''\n        # master and minion sign and verify\n        if 'pub_sig' in payload and self.opts['verify_master_pubkey_sign']:\n            return True\n        # master and minion do NOT sign and do NOT verify\n        elif 'pub_sig' not in payload and not self.opts['verify_master_pubkey_sign']:\n            return True\n\n        # master signs, but minion does NOT verify\n        elif 'pub_sig' in payload and not self.opts['verify_master_pubkey_sign']:\n            log.error('The masters sent its public-key signature, but signature '\n                      'verification is not enabled on the minion. Either enable '\n                      'signature verification on the minion or disable signing '\n                      'the public key on the master!')\n            return False\n        # master does NOT sign but minion wants to verify\n        elif 'pub_sig' not in payload and self.opts['verify_master_pubkey_sign']:\n            log.error('The master did not send its public-key signature, but '\n                      'signature verification is enabled on the minion. Either '\n                      'disable signature verification on the minion or enable '\n                      'signing the public on the master!')\n            return False\n\n    def extract_aes(self, payload, master_pub=True):\n        '''\n        Return the AES key received from the master after the minion has been\n        successfully authenticated.\n\n        :param dict payload: The incoming payload. This is a dictionary which may have the following keys:\n            'aes': The shared AES key\n            'enc': The format of the message. ('clear', 'pub', etc)\n            'publish_port': The TCP port which published the message\n            'token': The encrypted token used to verify the message.\n            'pub_key': The RSA public key of the sender.\n\n        :rtype: str\n        :return: The shared AES key received from the master.\n        '''\n        if master_pub:\n            try:\n                aes, token = self.decrypt_aes(payload, master_pub)\n                if token != self.token:\n                    log.error(\n                        'The master failed to decrypt the random minion token'\n                    )\n                    return ''\n            except Exception:\n                log.error(\n                    'The master failed to decrypt the random minion token'\n                )\n                return ''\n            return aes\n        else:\n            aes, token = self.decrypt_aes(payload, master_pub)\n            return aes\n\n    def verify_master(self, payload, master_pub=True):\n        '''\n        Verify that the master is the same one that was previously accepted.\n\n        :param dict payload: The incoming payload. This is a dictionary which may have the following keys:\n            'aes': The shared AES key\n            'enc': The format of the message. ('clear', 'pub', etc)\n            'publish_port': The TCP port which published the message\n            'token': The encrypted token used to verify the message.\n            'pub_key': The RSA public key of the sender.\n        :param bool master_pub: Operate as if minion had no master pubkey when it sent auth request, i.e. don't verify\n        the minion signature\n\n        :rtype: str\n        :return: An empty string on verification failure. On success, the decrypted AES message in the payload.\n        '''\n        m_pub_fn = os.path.join(self.opts['pki_dir'], self.mpub)\n        m_pub_exists = os.path.isfile(m_pub_fn)\n        if m_pub_exists and master_pub and not self.opts['open_mode']:\n            with salt.utils.fopen(m_pub_fn) as fp_:\n                local_master_pub = fp_.read()\n\n            if payload['pub_key'].replace('\\n', '').replace('\\r', '') != \\\n                    local_master_pub.replace('\\n', '').replace('\\r', ''):\n                if not self.check_auth_deps(payload):\n                    return ''\n\n                if self.opts['verify_master_pubkey_sign']:\n                    if self.verify_signing_master(payload):\n                        return self.extract_aes(payload, master_pub=False)\n                    else:\n                        return ''\n                else:\n                    # This is not the last master we connected to\n                    log.error('The master key has changed, the salt master could '\n                              'have been subverted, verify salt master\\'s public '\n                              'key')\n                    return ''\n\n            else:\n                if not self.check_auth_deps(payload):\n                    return ''\n                # verify the signature of the pubkey even if it has\n                # not changed compared with the one we already have\n                if self.opts['always_verify_signature']:\n                    if self.verify_signing_master(payload):\n                        return self.extract_aes(payload)\n                    else:\n                        log.error('The masters public could not be verified. Is the '\n                                  'verification pubkey {0} up to date?'\n                                  ''.format(self.opts['master_sign_key_name'] + '.pub'))\n                        return ''\n\n                else:\n                    return self.extract_aes(payload)\n        else:\n            if not self.check_auth_deps(payload):\n                return ''\n\n            # verify the masters pubkey signature if the minion\n            # has not received any masters pubkey before\n            if self.opts['verify_master_pubkey_sign']:\n                if self.verify_signing_master(payload):\n                    return self.extract_aes(payload, master_pub=False)\n                else:\n                    return ''\n            else:\n                if not m_pub_exists:\n                    # the minion has not received any masters pubkey yet, write\n                    # the newly received pubkey to minion_master.pub\n                    with salt.utils.fopen(m_pub_fn, 'wb+') as fp_:\n                        fp_.write(salt.utils.to_bytes(payload['pub_key']))\n                return self.extract_aes(payload, master_pub=False)\n\n    def _finger_fail(self, finger, master_key):\n        log.critical(\n            'The specified fingerprint in the master configuration '\n            'file:\\n{0}\\nDoes not match the authenticating master\\'s '\n            'key:\\n{1}\\nVerify that the configured fingerprint '\n            'matches the fingerprint of the correct master and that '\n            'this minion is not subject to a man-in-the-middle attack.'\n            .format(\n                finger,\n                salt.utils.pem_finger(master_key, sum_type=self.opts['hash_type'])\n            )\n        )\n        sys.exit(42)\n\n\n# TODO: remove, we should just return a sync wrapper of AsyncAuth\nclass SAuth(AsyncAuth):\n    '''\n    Set up an object to maintain authentication with the salt master\n    '''\n    # This class is only a singleton per minion/master pair\n    instances = weakref.WeakValueDictionary()\n\n    def __new__(cls, opts, io_loop=None):\n        '''\n        Only create one instance of SAuth per __key()\n        '''\n        key = cls.__key(opts)\n        auth = SAuth.instances.get(key)\n        if auth is None:\n            log.debug('Initializing new SAuth for {0}'.format(key))\n            auth = object.__new__(cls)\n            auth.__singleton_init__(opts)\n            SAuth.instances[key] = auth\n        else:\n            log.debug('Re-using SAuth for {0}'.format(key))\n        return auth\n\n    @classmethod\n    def __key(cls, opts, io_loop=None):\n        return (opts['pki_dir'],     # where the keys are stored\n                opts['id'],          # minion ID\n                opts['master_uri'],  # master ID\n                )\n\n    # has to remain empty for singletons, since __init__ will *always* be called\n    def __init__(self, opts, io_loop=None):\n        super(SAuth, self).__init__(opts, io_loop=io_loop)\n\n    # an init for the singleton instance to call\n    def __singleton_init__(self, opts, io_loop=None):\n        '''\n        Init an Auth instance\n\n        :param dict opts: Options for this server\n        :return: Auth instance\n        :rtype: Auth\n        '''\n        self.opts = opts\n        if six.PY2:\n            self.token = Crypticle.generate_key_string()\n        else:\n            self.token = salt.utils.to_bytes(Crypticle.generate_key_string())\n        self.serial = salt.payload.Serial(self.opts)\n        self.pub_path = os.path.join(self.opts['pki_dir'], 'minion.pub')\n        self.rsa_path = os.path.join(self.opts['pki_dir'], 'minion.pem')\n        if 'syndic_master' in self.opts:\n            self.mpub = 'syndic_master.pub'\n        elif 'alert_master' in self.opts:\n            self.mpub = 'monitor_master.pub'\n        else:\n            self.mpub = 'minion_master.pub'\n        if not os.path.isfile(self.pub_path):\n            self.get_keys()\n\n    @property\n    def creds(self):\n        if not hasattr(self, '_creds'):\n            self.authenticate()\n        return self._creds\n\n    @property\n    def crypticle(self):\n        if not hasattr(self, '_crypticle'):\n            self.authenticate()\n        return self._crypticle\n\n    def authenticate(self, _=None):  # TODO: remove unused var\n        '''\n        Authenticate with the master, this method breaks the functional\n        paradigm, it will update the master information from a fresh sign\n        in, signing in can occur as often as needed to keep up with the\n        revolving master AES key.\n\n        :rtype: Crypticle\n        :returns: A crypticle used for encryption operations\n        '''\n        acceptance_wait_time = self.opts['acceptance_wait_time']\n        acceptance_wait_time_max = self.opts['acceptance_wait_time_max']\n        channel = salt.transport.client.ReqChannel.factory(self.opts, crypt='clear')\n        if not acceptance_wait_time_max:\n            acceptance_wait_time_max = acceptance_wait_time\n        while True:\n            creds = self.sign_in(channel=channel)\n            if creds == 'retry':\n                if self.opts.get('caller'):\n                    print('Minion failed to authenticate with the master, '\n                          'has the minion key been accepted?')\n                    sys.exit(2)\n                if acceptance_wait_time:\n                    log.info('Waiting {0} seconds before retry.'.format(acceptance_wait_time))\n                    time.sleep(acceptance_wait_time)\n                if acceptance_wait_time < acceptance_wait_time_max:\n                    acceptance_wait_time += acceptance_wait_time\n                    log.debug('Authentication wait time is {0}'.format(acceptance_wait_time))\n                continue\n            break\n        self._creds = creds\n        self._crypticle = Crypticle(self.opts, creds['aes'])\n\n    def sign_in(self, timeout=60, safe=True, tries=1, channel=None):\n        '''\n        Send a sign in request to the master, sets the key information and\n        returns a dict containing the master publish interface to bind to\n        and the decrypted aes key for transport decryption.\n\n        :param int timeout: Number of seconds to wait before timing out the sign-in request\n        :param bool safe: If True, do not raise an exception on timeout. Retry instead.\n        :param int tries: The number of times to try to authenticate before giving up.\n\n        :raises SaltReqTimeoutError: If the sign-in request has timed out and :param safe: is not set\n\n        :return: Return a string on failure indicating the reason for failure. On success, return a dictionary\n        with the publication port and the shared AES key.\n\n        '''\n        auth = {}\n\n        auth_timeout = self.opts.get('auth_timeout', None)\n        if auth_timeout is not None:\n            timeout = auth_timeout\n        auth_safemode = self.opts.get('auth_safemode', None)\n        if auth_safemode is not None:\n            safe = auth_safemode\n        auth_tries = self.opts.get('auth_tries', None)\n        if auth_tries is not None:\n            tries = auth_tries\n\n        m_pub_fn = os.path.join(self.opts['pki_dir'], self.mpub)\n\n        auth['master_uri'] = self.opts['master_uri']\n\n        if not channel:\n            channel = salt.transport.client.ReqChannel.factory(self.opts, crypt='clear')\n\n        sign_in_payload = self.minion_sign_in_payload()\n        try:\n            payload = channel.send(\n                sign_in_payload,\n                tries=tries,\n                timeout=timeout\n            )\n        except SaltReqTimeoutError as e:\n            if safe:\n                log.warning('SaltReqTimeoutError: {0}'.format(e))\n                return 'retry'\n            raise SaltClientError('Attempt to authenticate with the salt master failed with timeout error')\n\n        if 'load' in payload:\n            if 'ret' in payload['load']:\n                if not payload['load']['ret']:\n                    if self.opts['rejected_retry']:\n                        log.error(\n                            'The Salt Master has rejected this minion\\'s public '\n                            'key.\\nTo repair this issue, delete the public key '\n                            'for this minion on the Salt Master.\\nThe Salt '\n                            'Minion will attempt to to re-authenicate.'\n                        )\n                        return 'retry'\n                    else:\n                        log.critical(\n                            'The Salt Master has rejected this minion\\'s public '\n                            'key!\\nTo repair this issue, delete the public key '\n                            'for this minion on the Salt Master and restart this '\n                            'minion.\\nOr restart the Salt Master in open mode to '\n                            'clean out the keys. The Salt Minion will now exit.'\n                        )\n                        sys.exit(salt.defaults.exitcodes.EX_OK)\n                # has the master returned that its maxed out with minions?\n                elif payload['load']['ret'] == 'full':\n                    return 'full'\n                else:\n                    log.error(\n                        'The Salt Master has cached the public key for this '\n                        'node. If this is the first time connecting to this master '\n                        'then this key may need to be accepted using \\'salt-key -a {0}\\' on '\n                        'the salt master. This salt minion will wait for {1} seconds '\n                        'before attempting to re-authenticate.'.format(\n                            self.opts['id'],\n                            self.opts['acceptance_wait_time']\n                        )\n                    )\n                    return 'retry'\n        auth['aes'] = self.verify_master(payload, master_pub='token' in sign_in_payload)\n        if not auth['aes']:\n            log.critical(\n                'The Salt Master server\\'s public key did not authenticate!\\n'\n                'The master may need to be updated if it is a version of Salt '\n                'lower than {0}, or\\n'\n                'If you are confident that you are connecting to a valid Salt '\n                'Master, then remove the master public key and restart the '\n                'Salt Minion.\\nThe master public key can be found '\n                'at:\\n{1}'.format(salt.version.__version__, m_pub_fn)\n            )\n            sys.exit(42)\n        if self.opts.get('syndic_master', False):  # Is syndic\n            syndic_finger = self.opts.get('syndic_finger', self.opts.get('master_finger', False))\n            if syndic_finger:\n                if salt.utils.pem_finger(m_pub_fn, sum_type=self.opts['hash_type']) != syndic_finger:\n                    self._finger_fail(syndic_finger, m_pub_fn)\n        else:\n            if self.opts.get('master_finger', False):\n                if salt.utils.pem_finger(m_pub_fn, sum_type=self.opts['hash_type']) != self.opts['master_finger']:\n                    self._finger_fail(self.opts['master_finger'], m_pub_fn)\n        auth['publish_port'] = payload['publish_port']\n        return auth\n\n\nclass Crypticle(object):\n    '''\n    Authenticated encryption class\n\n    Encryption algorithm: AES-CBC\n    Signing algorithm: HMAC-SHA256\n    '''\n\n    PICKLE_PAD = b'pickle::'\n    AES_BLOCK_SIZE = 16\n    SIG_SIZE = hashlib.sha256().digest_size\n\n    def __init__(self, opts, key_string, key_size=192):\n        self.key_string = key_string\n        self.keys = self.extract_keys(self.key_string, key_size)\n        self.key_size = key_size\n        self.serial = salt.payload.Serial(opts)\n\n    @classmethod\n    def generate_key_string(cls, key_size=192):\n        key = os.urandom(key_size // 8 + cls.SIG_SIZE)\n        b64key = base64.b64encode(key)\n        if six.PY3:\n            b64key = b64key.decode('utf-8')\n        return b64key.replace('\\n', '')\n\n    @classmethod\n    def extract_keys(cls, key_string, key_size):\n        if six.PY2:\n            key = key_string.decode('base64')\n        else:\n            key = salt.utils.to_bytes(base64.b64decode(key_string))\n        assert len(key) == key_size / 8 + cls.SIG_SIZE, 'invalid key'\n        return key[:-cls.SIG_SIZE], key[-cls.SIG_SIZE:]\n\n    def encrypt(self, data):\n        '''\n        encrypt data with AES-CBC and sign it with HMAC-SHA256\n        '''\n        aes_key, hmac_key = self.keys\n        pad = self.AES_BLOCK_SIZE - len(data) % self.AES_BLOCK_SIZE\n        if six.PY2:\n            data = data + pad * chr(pad)\n        else:\n            data = data + salt.utils.to_bytes(pad * chr(pad))\n        iv_bytes = os.urandom(self.AES_BLOCK_SIZE)\n        cypher = AES.new(aes_key, AES.MODE_CBC, iv_bytes)\n        data = iv_bytes + cypher.encrypt(data)\n        sig = hmac.new(hmac_key, data, hashlib.sha256).digest()\n        return data + sig\n\n    def decrypt(self, data):\n        '''\n        verify HMAC-SHA256 signature and decrypt data with AES-CBC\n        '''\n        aes_key, hmac_key = self.keys\n        sig = data[-self.SIG_SIZE:]\n        data = data[:-self.SIG_SIZE]\n        if six.PY3 and not isinstance(data, bytes):\n            data = salt.utils.to_bytes(data)\n        mac_bytes = hmac.new(hmac_key, data, hashlib.sha256).digest()\n        if len(mac_bytes) != len(sig):\n            log.debug('Failed to authenticate message')\n            raise AuthenticationError('message authentication failed')\n        result = 0\n\n        if six.PY2:\n            for zipped_x, zipped_y in zip(mac_bytes, sig):\n                result |= ord(zipped_x) ^ ord(zipped_y)\n        else:\n            for zipped_x, zipped_y in zip(mac_bytes, sig):\n                result |= zipped_x ^ zipped_y\n        if result != 0:\n            log.debug('Failed to authenticate message')\n            raise AuthenticationError('message authentication failed')\n        iv_bytes = data[:self.AES_BLOCK_SIZE]\n        data = data[self.AES_BLOCK_SIZE:]\n        cypher = AES.new(aes_key, AES.MODE_CBC, iv_bytes)\n        data = cypher.decrypt(data)\n        if six.PY2:\n            return data[:-ord(data[-1])]\n        else:\n            return data[:-data[-1]]\n\n    def dumps(self, obj):\n        '''\n        Serialize and encrypt a python object\n        '''\n        return self.encrypt(self.PICKLE_PAD + self.serial.dumps(obj))\n\n    def loads(self, data, raw=False):\n        '''\n        Decrypt and un-serialize a python object\n        '''\n        data = self.decrypt(data)\n        # simple integrity check to verify that we got meaningful data\n        if not data.startswith(self.PICKLE_PAD):\n            return {}\n        load = self.serial.loads(data[len(self.PICKLE_PAD):], raw=raw)\n        return load\n", "target": 0}
{"idx": 921, "func": "import qrcode\nimport qrcode.image.svg\nfrom django.conf import settings\nfrom django.contrib.auth import REDIRECT_FIELD_NAME\nfrom django.contrib.auth.views import SuccessURLAllowedHostsMixin\nfrom django.http import HttpResponse\nfrom django.shortcuts import resolve_url\nfrom django.urls import reverse\nfrom django.utils.decorators import method_decorator\nfrom django.utils.functional import cached_property\nfrom django.utils.http import is_safe_url\nfrom django.views.decorators.cache import never_cache\nfrom django.views.decorators.debug import sensitive_post_parameters\nfrom django.views.generic import (\n    DeleteView, FormView, ListView, UpdateView, View)\nfrom django_otp import login as otp_login\nfrom django_otp.plugins.otp_totp.models import TOTPDevice\n\nfrom wagtail_2fa import forms, utils\nfrom wagtail_2fa.mixins import OtpRequiredMixin\n\n\nclass LoginView(SuccessURLAllowedHostsMixin, FormView):\n    template_name = \"wagtail_2fa/otp_form.html\"\n    form_class = forms.TokenForm\n    redirect_field_name = REDIRECT_FIELD_NAME\n\n    @method_decorator(sensitive_post_parameters())\n    @method_decorator(never_cache)\n    def dispatch(self, *args, **kwargs):\n        return super().dispatch(*args, **kwargs)\n\n    def get_form_kwargs(self):\n        kwargs = super().get_form_kwargs()\n        kwargs[\"user\"] = self.request.user\n        return kwargs\n\n    def get_context_data(self, *args, **kwargs):\n        context = super().get_context_data(*args, **kwargs)\n        context[self.redirect_field_name] = self.get_redirect_url()\n        return context\n\n    def form_valid(self, form):\n        otp_login(self.request, self.request.user.otp_device)\n        return super().form_valid(form)\n\n    def get_redirect_url(self):\n        \"\"\"Return the user-originating redirect URL if it's safe.\"\"\"\n        redirect_to = self.request.POST.get(\n            self.redirect_field_name, self.request.GET.get(self.redirect_field_name, \"\")\n        )\n        url_is_safe = is_safe_url(\n            url=redirect_to,\n            allowed_hosts=self.get_success_url_allowed_hosts(),\n            require_https=self.request.is_secure(),\n        )\n        return redirect_to if url_is_safe else \"\"\n\n    def get_success_url(self):\n        url = self.get_redirect_url()\n        return url or resolve_url(settings.LOGIN_REDIRECT_URL)\n\n\nclass DeviceListView(OtpRequiredMixin, ListView):\n    template_name = \"wagtail_2fa/device_list.html\"\n\n    # require OTP if configured\n    if_configured = True\n\n    def get_queryset(self):\n        return TOTPDevice.objects.devices_for_user(self.kwargs['user_id'], confirmed=True)\n\n    def get_context_data(self, **kwargs):\n        context = super().get_context_data(**kwargs)\n        context['user_id'] = int(self.kwargs['user_id'])\n        return context\n\n\nclass DeviceCreateView(OtpRequiredMixin, FormView):\n    form_class = forms.DeviceForm\n    template_name = \"wagtail_2fa/device_form.html\"\n\n    # require OTP if configured\n    if_configured = True\n\n    def get_form_kwargs(self):\n        kwargs = super().get_form_kwargs()\n        kwargs[\"request\"] = self.request\n        kwargs[\"instance\"] = self.device\n        return kwargs\n\n    def form_valid(self, form):\n        form.save()\n        utils.delete_unconfirmed_devices(self.request.user)\n\n        if not self.request.user.is_verified():\n            otp_login(self.request, form.instance)\n        return super().form_valid(form)\n\n    def get_success_url(self):\n        return reverse('wagtail_2fa_device_list', kwargs={'user_id': self.request.user.id})\n\n    @cached_property\n    def device(self):\n        if self.request.method.lower() == \"get\":\n            return utils.new_unconfirmed_device(self.request.user)\n        else:\n            return utils.get_unconfirmed_device(self.request.user)\n\n\nclass DeviceUpdateView(OtpRequiredMixin, UpdateView):\n    form_class = forms.DeviceForm\n    template_name = \"wagtail_2fa/device_form.html\"\n\n    def get_queryset(self):\n        return TOTPDevice.objects.devices_for_user(self.request.user, confirmed=True)\n\n    def get_form_kwargs(self):\n        kwargs = super().get_form_kwargs()\n        kwargs[\"request\"] = self.request\n        return kwargs\n\n    def get_success_url(self):\n        return reverse('wagtail_2fa_device_list', kwargs={'user_id': self.request.user.id})\n\n\nclass DeviceDeleteView(OtpRequiredMixin, DeleteView):\n    template_name = \"wagtail_2fa/device_confirm_delete.html\"\n\n    def get_queryset(self):\n        device = TOTPDevice.objects.get(**self.kwargs)\n        return TOTPDevice.objects.devices_for_user(device.user, confirmed=True)\n\n    def get_success_url(self):\n        return reverse('wagtail_2fa_device_list', kwargs={'user_id': self.request.POST.get('user_id')})\n\n\nclass DeviceQRCodeView(OtpRequiredMixin, View):\n    # require OTP if configured\n    if_configured = True\n\n    def get(self, request):\n        device = utils.get_unconfirmed_device(self.request.user)\n        img = qrcode.make(device.config_url, image_factory=qrcode.image.svg.SvgImage)\n        response = HttpResponse(content_type=\"image/svg+xml\")\n        img.save(response)\n\n        return response\n", "target": 1}
{"idx": 922, "func": "from __future__ import absolute_import\n\nimport datetime\nimport os\nimport re\nimport sys\nimport time\nimport warnings\n\nfrom pprint import pformat\nfrom urllib import urlencode, quote\nfrom urlparse import urljoin, urlparse\ntry:\n    from cStringIO import StringIO\nexcept ImportError:\n    from StringIO import StringIO\ntry:\n    # The mod_python version is more efficient, so try importing it first.\n    from mod_python.util import parse_qsl\nexcept ImportError:\n    try:\n        # Python 2.6 and greater\n        from urlparse import parse_qsl\n    except ImportError:\n        # Python 2.5. Works on Python 2.6 but raises PendingDeprecationWarning\n        from cgi import parse_qsl\n\nimport Cookie\n# httponly support exists in Python 2.6's Cookie library,\n# but not in Python 2.5.\n_morsel_supports_httponly = 'httponly' in Cookie.Morsel._reserved\n# Some versions of Python 2.7 and later won't need this encoding bug fix:\n_cookie_encodes_correctly = Cookie.SimpleCookie().value_encode(';') == (';', '\"\\\\073\"')\n# See ticket #13007, http://bugs.python.org/issue2193 and http://trac.edgewall.org/ticket/2256\n_tc = Cookie.SimpleCookie()\ntry:\n    _tc.load('foo:bar=1')\n    _cookie_allows_colon_in_names = True\nexcept Cookie.CookieError:\n    _cookie_allows_colon_in_names = False\n\nif _morsel_supports_httponly and _cookie_encodes_correctly and _cookie_allows_colon_in_names:\n    SimpleCookie = Cookie.SimpleCookie\nelse:\n    if not _morsel_supports_httponly:\n        class Morsel(Cookie.Morsel):\n            def __setitem__(self, K, V):\n                K = K.lower()\n                if K == \"httponly\":\n                    if V:\n                        # The superclass rejects httponly as a key,\n                        # so we jump to the grandparent.\n                        super(Cookie.Morsel, self).__setitem__(K, V)\n                else:\n                    super(Morsel, self).__setitem__(K, V)\n\n            def OutputString(self, attrs=None):\n                output = super(Morsel, self).OutputString(attrs)\n                if \"httponly\" in self:\n                    output += \"; httponly\"\n                return output\n    else:\n        Morsel = Cookie.Morsel\n\n    class SimpleCookie(Cookie.SimpleCookie):\n        if not _cookie_encodes_correctly:\n            def value_encode(self, val):\n                # Some browsers do not support quoted-string from RFC 2109,\n                # including some versions of Safari and Internet Explorer.\n                # These browsers split on ';', and some versions of Safari\n                # are known to split on ', '. Therefore, we encode ';' and ','\n\n                # SimpleCookie already does the hard work of encoding and decoding.\n                # It uses octal sequences like '\\\\012' for newline etc.\n                # and non-ASCII chars. We just make use of this mechanism, to\n                # avoid introducing two encoding schemes which would be confusing\n                # and especially awkward for javascript.\n\n                # NB, contrary to Python docs, value_encode returns a tuple containing\n                # (real val, encoded_val)\n                val, encoded = super(SimpleCookie, self).value_encode(val)\n\n                encoded = encoded.replace(\";\", \"\\\\073\").replace(\",\",\"\\\\054\")\n                # If encoded now contains any quoted chars, we need double quotes\n                # around the whole string.\n                if \"\\\\\" in encoded and not encoded.startswith('\"'):\n                    encoded = '\"' + encoded + '\"'\n\n                return val, encoded\n\n        if not _cookie_allows_colon_in_names or not _morsel_supports_httponly:\n            def load(self, rawdata):\n                self.bad_cookies = set()\n                super(SimpleCookie, self).load(rawdata)\n                for key in self.bad_cookies:\n                    del self[key]\n\n            # override private __set() method:\n            # (needed for using our Morsel, and for laxness with CookieError\n            def _BaseCookie__set(self, key, real_value, coded_value):\n                try:\n                    M = self.get(key, Morsel())\n                    M.set(key, real_value, coded_value)\n                    dict.__setitem__(self, key, M)\n                except Cookie.CookieError:\n                    self.bad_cookies.add(key)\n                    dict.__setitem__(self, key, Cookie.Morsel())\n\n\nclass CompatCookie(SimpleCookie):\n    def __init__(self, *args, **kwargs):\n        super(CompatCookie, self).__init__(*args, **kwargs)\n        warnings.warn(\"CompatCookie is deprecated. Use django.http.SimpleCookie instead.\", DeprecationWarning)\n\nfrom django.conf import settings\nfrom django.core import signing\nfrom django.core.exceptions import ImproperlyConfigured, SuspiciousOperation\nfrom django.core.files import uploadhandler\nfrom django.http.multipartparser import MultiPartParser\nfrom django.http.utils import *\nfrom django.utils.datastructures import MultiValueDict, ImmutableList\nfrom django.utils.encoding import smart_str, iri_to_uri, force_unicode\nfrom django.utils.http import cookie_date\nfrom django.utils import timezone\n\nRESERVED_CHARS=\"!*'();:@&=+$,/?%#[]\"\n\nabsolute_http_url_re = re.compile(r\"^https?://\", re.I)\n\nclass Http404(Exception):\n    pass\n\nRAISE_ERROR = object()\n\n\ndef build_request_repr(request, path_override=None, GET_override=None,\n                       POST_override=None, COOKIES_override=None,\n                       META_override=None):\n    \"\"\"\n    Builds and returns the request's representation string. The request's\n    attributes may be overridden by pre-processed values.\n    \"\"\"\n    # Since this is called as part of error handling, we need to be very\n    # robust against potentially malformed input.\n    try:\n        get = (pformat(GET_override)\n               if GET_override is not None\n               else pformat(request.GET))\n    except:\n        get = '<could not parse>'\n    if request._post_parse_error:\n        post = '<could not parse>'\n    else:\n        try:\n            post = (pformat(POST_override)\n                    if POST_override is not None\n                    else pformat(request.POST))\n        except:\n            post = '<could not parse>'\n    try:\n        cookies = (pformat(COOKIES_override)\n                   if COOKIES_override is not None\n                   else pformat(request.COOKIES))\n    except:\n        cookies = '<could not parse>'\n    try:\n        meta = (pformat(META_override)\n                if META_override is not None\n                else pformat(request.META))\n    except:\n        meta = '<could not parse>'\n    path = path_override if path_override is not None else request.path\n    return smart_str(u'<%s\\npath:%s,\\nGET:%s,\\nPOST:%s,\\nCOOKIES:%s,\\nMETA:%s>' %\n                     (request.__class__.__name__,\n                      path,\n                      unicode(get),\n                      unicode(post),\n                      unicode(cookies),\n                      unicode(meta)))\n\nclass UnreadablePostError(IOError):\n    pass\n\nclass HttpRequest(object):\n    \"\"\"A basic HTTP request.\"\"\"\n\n    # The encoding used in GET/POST dicts. None means use default setting.\n    _encoding = None\n    _upload_handlers = []\n\n    def __init__(self):\n        self.GET, self.POST, self.COOKIES, self.META, self.FILES = {}, {}, {}, {}, {}\n        self.path = ''\n        self.path_info = ''\n        self.method = None\n        self._post_parse_error = False\n\n    def __repr__(self):\n        return build_request_repr(self)\n\n    def get_host(self):\n        \"\"\"Returns the HTTP host using the environment or request headers.\"\"\"\n        # We try three options, in order of decreasing preference.\n        if settings.USE_X_FORWARDED_HOST and (\n            'HTTP_X_FORWARDED_HOST' in self.META):\n            host = self.META['HTTP_X_FORWARDED_HOST']\n        elif 'HTTP_HOST' in self.META:\n            host = self.META['HTTP_HOST']\n        else:\n            # Reconstruct the host using the algorithm from PEP 333.\n            host = self.META['SERVER_NAME']\n            server_port = str(self.META['SERVER_PORT'])\n            if server_port != (self.is_secure() and '443' or '80'):\n                host = '%s:%s' % (host, server_port)\n        return host\n\n    def get_full_path(self):\n        # RFC 3986 requires query string arguments to be in the ASCII range.\n        # Rather than crash if this doesn't happen, we encode defensively.\n        return '%s%s' % (self.path, self.META.get('QUERY_STRING', '') and ('?' + iri_to_uri(self.META.get('QUERY_STRING', ''))) or '')\n\n    def get_signed_cookie(self, key, default=RAISE_ERROR, salt='', max_age=None):\n        \"\"\"\n        Attempts to return a signed cookie. If the signature fails or the\n        cookie has expired, raises an exception... unless you provide the\n        default argument in which case that value will be returned instead.\n        \"\"\"\n        try:\n            cookie_value = self.COOKIES[key].encode('utf-8')\n        except KeyError:\n            if default is not RAISE_ERROR:\n                return default\n            else:\n                raise\n        try:\n            value = signing.get_cookie_signer(salt=key + salt).unsign(\n                cookie_value, max_age=max_age)\n        except signing.BadSignature:\n            if default is not RAISE_ERROR:\n                return default\n            else:\n                raise\n        return value\n\n    def build_absolute_uri(self, location=None):\n        \"\"\"\n        Builds an absolute URI from the location and the variables available in\n        this request. If no location is specified, the absolute URI is built on\n        ``request.get_full_path()``.\n        \"\"\"\n        if not location:\n            location = self.get_full_path()\n        if not absolute_http_url_re.match(location):\n            current_uri = '%s://%s%s' % (self.is_secure() and 'https' or 'http',\n                                         self.get_host(), self.path)\n            location = urljoin(current_uri, location)\n        return iri_to_uri(location)\n\n    def _is_secure(self):\n        return os.environ.get(\"HTTPS\") == \"on\"\n\n    def is_secure(self):\n        # First, check the SECURE_PROXY_SSL_HEADER setting.\n        if settings.SECURE_PROXY_SSL_HEADER:\n            try:\n                header, value = settings.SECURE_PROXY_SSL_HEADER\n            except ValueError:\n                raise ImproperlyConfigured('The SECURE_PROXY_SSL_HEADER setting must be a tuple containing two values.')\n            if self.META.get(header, None) == value:\n                return True\n\n        # Failing that, fall back to _is_secure(), which is a hook for\n        # subclasses to implement.\n        return self._is_secure()\n\n    def is_ajax(self):\n        return self.META.get('HTTP_X_REQUESTED_WITH') == 'XMLHttpRequest'\n\n    def _set_encoding(self, val):\n        \"\"\"\n        Sets the encoding used for GET/POST accesses. If the GET or POST\n        dictionary has already been created, it is removed and recreated on the\n        next access (so that it is decoded correctly).\n        \"\"\"\n        self._encoding = val\n        if hasattr(self, '_get'):\n            del self._get\n        if hasattr(self, '_post'):\n            del self._post\n\n    def _get_encoding(self):\n        return self._encoding\n\n    encoding = property(_get_encoding, _set_encoding)\n\n    def _initialize_handlers(self):\n        self._upload_handlers = [uploadhandler.load_handler(handler, self)\n                                 for handler in settings.FILE_UPLOAD_HANDLERS]\n\n    def _set_upload_handlers(self, upload_handlers):\n        if hasattr(self, '_files'):\n            raise AttributeError(\"You cannot set the upload handlers after the upload has been processed.\")\n        self._upload_handlers = upload_handlers\n\n    def _get_upload_handlers(self):\n        if not self._upload_handlers:\n            # If there are no upload handlers defined, initialize them from settings.\n            self._initialize_handlers()\n        return self._upload_handlers\n\n    upload_handlers = property(_get_upload_handlers, _set_upload_handlers)\n\n    def parse_file_upload(self, META, post_data):\n        \"\"\"Returns a tuple of (POST QueryDict, FILES MultiValueDict).\"\"\"\n        self.upload_handlers = ImmutableList(\n            self.upload_handlers,\n            warning = \"You cannot alter upload handlers after the upload has been processed.\"\n        )\n        parser = MultiPartParser(META, post_data, self.upload_handlers, self.encoding)\n        return parser.parse()\n\n    @property\n    def body(self):\n        if not hasattr(self, '_body'):\n            if self._read_started:\n                raise Exception(\"You cannot access body after reading from request's data stream\")\n            try:\n                self._body = self.read()\n            except IOError, e:\n                raise UnreadablePostError, e, sys.exc_traceback\n            self._stream = StringIO(self._body)\n        return self._body\n\n    @property\n    def raw_post_data(self):\n        warnings.warn('HttpRequest.raw_post_data has been deprecated. Use HttpRequest.body instead.', PendingDeprecationWarning)\n        return self.body\n\n    def _mark_post_parse_error(self):\n        self._post = QueryDict('')\n        self._files = MultiValueDict()\n        self._post_parse_error = True\n\n    def _load_post_and_files(self):\n        # Populates self._post and self._files\n        if self.method != 'POST':\n            self._post, self._files = QueryDict('', encoding=self._encoding), MultiValueDict()\n            return\n        if self._read_started and not hasattr(self, '_body'):\n            self._mark_post_parse_error()\n            return\n\n        if self.META.get('CONTENT_TYPE', '').startswith('multipart'):\n            if hasattr(self, '_body'):\n                # Use already read data\n                data = StringIO(self._body)\n            else:\n                data = self\n            try:\n                self._post, self._files = self.parse_file_upload(self.META, data)\n            except:\n                # An error occured while parsing POST data. Since when\n                # formatting the error the request handler might access\n                # self.POST, set self._post and self._file to prevent\n                # attempts to parse POST data again.\n                # Mark that an error occured. This allows self.__repr__ to\n                # be explicit about it instead of simply representing an\n                # empty POST\n                self._mark_post_parse_error()\n                raise\n        else:\n            self._post, self._files = QueryDict(self.body, encoding=self._encoding), MultiValueDict()\n\n    ## File-like and iterator interface.\n    ##\n    ## Expects self._stream to be set to an appropriate source of bytes by\n    ## a corresponding request subclass (WSGIRequest or ModPythonRequest).\n    ## Also when request data has already been read by request.POST or\n    ## request.body, self._stream points to a StringIO instance\n    ## containing that data.\n\n    def read(self, *args, **kwargs):\n        self._read_started = True\n        return self._stream.read(*args, **kwargs)\n\n    def readline(self, *args, **kwargs):\n        self._read_started = True\n        return self._stream.readline(*args, **kwargs)\n\n    def xreadlines(self):\n        while True:\n            buf = self.readline()\n            if not buf:\n                break\n            yield buf\n    __iter__ = xreadlines\n\n    def readlines(self):\n        return list(iter(self))\n\nclass QueryDict(MultiValueDict):\n    \"\"\"\n    A specialized MultiValueDict that takes a query string when initialized.\n    This is immutable unless you create a copy of it.\n\n    Values retrieved from this class are converted from the given encoding\n    (DEFAULT_CHARSET by default) to unicode.\n    \"\"\"\n    # These are both reset in __init__, but is specified here at the class\n    # level so that unpickling will have valid values\n    _mutable = True\n    _encoding = None\n\n    def __init__(self, query_string, mutable=False, encoding=None):\n        MultiValueDict.__init__(self)\n        if not encoding:\n            encoding = settings.DEFAULT_CHARSET\n        self.encoding = encoding\n        for key, value in parse_qsl((query_string or ''), True): # keep_blank_values=True\n            self.appendlist(force_unicode(key, encoding, errors='replace'),\n                            force_unicode(value, encoding, errors='replace'))\n        self._mutable = mutable\n\n    def _get_encoding(self):\n        if self._encoding is None:\n            self._encoding = settings.DEFAULT_CHARSET\n        return self._encoding\n\n    def _set_encoding(self, value):\n        self._encoding = value\n\n    encoding = property(_get_encoding, _set_encoding)\n\n    def _assert_mutable(self):\n        if not self._mutable:\n            raise AttributeError(\"This QueryDict instance is immutable\")\n\n    def __setitem__(self, key, value):\n        self._assert_mutable()\n        key = str_to_unicode(key, self.encoding)\n        value = str_to_unicode(value, self.encoding)\n        MultiValueDict.__setitem__(self, key, value)\n\n    def __delitem__(self, key):\n        self._assert_mutable()\n        super(QueryDict, self).__delitem__(key)\n\n    def __copy__(self):\n        result = self.__class__('', mutable=True, encoding=self.encoding)\n        for key, value in dict.items(self):\n            dict.__setitem__(result, key, value)\n        return result\n\n    def __deepcopy__(self, memo):\n        import copy\n        result = self.__class__('', mutable=True, encoding=self.encoding)\n        memo[id(self)] = result\n        for key, value in dict.items(self):\n            dict.__setitem__(result, copy.deepcopy(key, memo), copy.deepcopy(value, memo))\n        return result\n\n    def setlist(self, key, list_):\n        self._assert_mutable()\n        key = str_to_unicode(key, self.encoding)\n        list_ = [str_to_unicode(elt, self.encoding) for elt in list_]\n        MultiValueDict.setlist(self, key, list_)\n\n    def setlistdefault(self, key, default_list=()):\n        self._assert_mutable()\n        if key not in self:\n            self.setlist(key, default_list)\n        return MultiValueDict.getlist(self, key)\n\n    def appendlist(self, key, value):\n        self._assert_mutable()\n        key = str_to_unicode(key, self.encoding)\n        value = str_to_unicode(value, self.encoding)\n        MultiValueDict.appendlist(self, key, value)\n\n    def update(self, other_dict):\n        self._assert_mutable()\n        f = lambda s: str_to_unicode(s, self.encoding)\n        if hasattr(other_dict, 'lists'):\n            for key, valuelist in other_dict.lists():\n                for value in valuelist:\n                    MultiValueDict.update(self, {f(key): f(value)})\n        else:\n            d = dict([(f(k), f(v)) for k, v in other_dict.items()])\n            MultiValueDict.update(self, d)\n\n    def pop(self, key, *args):\n        self._assert_mutable()\n        return MultiValueDict.pop(self, key, *args)\n\n    def popitem(self):\n        self._assert_mutable()\n        return MultiValueDict.popitem(self)\n\n    def clear(self):\n        self._assert_mutable()\n        MultiValueDict.clear(self)\n\n    def setdefault(self, key, default=None):\n        self._assert_mutable()\n        key = str_to_unicode(key, self.encoding)\n        default = str_to_unicode(default, self.encoding)\n        return MultiValueDict.setdefault(self, key, default)\n\n    def copy(self):\n        \"\"\"Returns a mutable copy of this object.\"\"\"\n        return self.__deepcopy__({})\n\n    def urlencode(self, safe=None):\n        \"\"\"\n        Returns an encoded string of all query string arguments.\n\n        :arg safe: Used to specify characters which do not require quoting, for\n            example::\n\n                >>> q = QueryDict('', mutable=True)\n                >>> q['next'] = '/a&b/'\n                >>> q.urlencode()\n                'next=%2Fa%26b%2F'\n                >>> q.urlencode(safe='/')\n                'next=/a%26b/'\n\n        \"\"\"\n        output = []\n        if safe:\n            encode = lambda k, v: '%s=%s' % ((quote(k, safe), quote(v, safe)))\n        else:\n            encode = lambda k, v: urlencode({k: v})\n        for k, list_ in self.lists():\n            k = smart_str(k, self.encoding)\n            output.extend([encode(k, smart_str(v, self.encoding))\n                           for v in list_])\n        return '&'.join(output)\n\ndef parse_cookie(cookie):\n    if cookie == '':\n        return {}\n    if not isinstance(cookie, Cookie.BaseCookie):\n        try:\n            c = SimpleCookie()\n            c.load(cookie)\n        except Cookie.CookieError:\n            # Invalid cookie\n            return {}\n    else:\n        c = cookie\n    cookiedict = {}\n    for key in c.keys():\n        cookiedict[key] = c.get(key).value\n    return cookiedict\n\nclass BadHeaderError(ValueError):\n    pass\n\nclass HttpResponse(object):\n    \"\"\"A basic HTTP response, with content and dictionary-accessed headers.\"\"\"\n\n    status_code = 200\n\n    def __init__(self, content='', mimetype=None, status=None,\n            content_type=None):\n        # _headers is a mapping of the lower-case name to the original case of\n        # the header (required for working with legacy systems) and the header\n        # value. Both the name of the header and its value are ASCII strings.\n        self._headers = {}\n        self._charset = settings.DEFAULT_CHARSET\n        if mimetype: # For backwards compatibility.\n            content_type = mimetype\n        if not content_type:\n            content_type = \"%s; charset=%s\" % (settings.DEFAULT_CONTENT_TYPE,\n                    self._charset)\n        self.content = content\n        self.cookies = SimpleCookie()\n        if status:\n            self.status_code = status\n\n        self['Content-Type'] = content_type\n\n    def __str__(self):\n        \"\"\"Full HTTP message, including headers.\"\"\"\n        return '\\n'.join(['%s: %s' % (key, value)\n            for key, value in self._headers.values()]) \\\n            + '\\n\\n' + self.content\n\n    def _convert_to_ascii(self, *values):\n        \"\"\"Converts all values to ascii strings.\"\"\"\n        for value in values:\n            if isinstance(value, unicode):\n                try:\n                    value = value.encode('us-ascii')\n                except UnicodeError, e:\n                    e.reason += ', HTTP response headers must be in US-ASCII format'\n                    raise\n            else:\n                value = str(value)\n            if '\\n' in value or '\\r' in value:\n                raise BadHeaderError(\"Header values can't contain newlines (got %r)\" % (value))\n            yield value\n\n    def __setitem__(self, header, value):\n        header, value = self._convert_to_ascii(header, value)\n        self._headers[header.lower()] = (header, value)\n\n    def __delitem__(self, header):\n        try:\n            del self._headers[header.lower()]\n        except KeyError:\n            pass\n\n    def __getitem__(self, header):\n        return self._headers[header.lower()][1]\n\n    def __getstate__(self):\n        # SimpleCookie is not pickeable with pickle.HIGHEST_PROTOCOL, so we\n        # serialise to a string instead\n        state = self.__dict__.copy()\n        state['cookies'] = str(state['cookies'])\n        return state\n\n    def __setstate__(self, state):\n        self.__dict__.update(state)\n        self.cookies = SimpleCookie(self.cookies)\n\n    def has_header(self, header):\n        \"\"\"Case-insensitive check for a header.\"\"\"\n        return header.lower() in self._headers\n\n    __contains__ = has_header\n\n    def items(self):\n        return self._headers.values()\n\n    def get(self, header, alternate=None):\n        return self._headers.get(header.lower(), (None, alternate))[1]\n\n    def set_cookie(self, key, value='', max_age=None, expires=None, path='/',\n                   domain=None, secure=False, httponly=False):\n        \"\"\"\n        Sets a cookie.\n\n        ``expires`` can be:\n        - a string in the correct format,\n        - a naive ``datetime.datetime`` object in UTC,\n        - an aware ``datetime.datetime`` object in any time zone.\n        If it is a ``datetime.datetime`` object then ``max_age`` will be calculated.\n\n        \"\"\"\n        self.cookies[key] = value\n        if expires is not None:\n            if isinstance(expires, datetime.datetime):\n                if timezone.is_aware(expires):\n                    expires = timezone.make_naive(expires, timezone.utc)\n                delta = expires - expires.utcnow()\n                # Add one second so the date matches exactly (a fraction of\n                # time gets lost between converting to a timedelta and\n                # then the date string).\n                delta = delta + datetime.timedelta(seconds=1)\n                # Just set max_age - the max_age logic will set expires.\n                expires = None\n                max_age = max(0, delta.days * 86400 + delta.seconds)\n            else:\n                self.cookies[key]['expires'] = expires\n        if max_age is not None:\n            self.cookies[key]['max-age'] = max_age\n            # IE requires expires, so set it if hasn't been already.\n            if not expires:\n                self.cookies[key]['expires'] = cookie_date(time.time() +\n                                                           max_age)\n        if path is not None:\n            self.cookies[key]['path'] = path\n        if domain is not None:\n            self.cookies[key]['domain'] = domain\n        if secure:\n            self.cookies[key]['secure'] = True\n        if httponly:\n            self.cookies[key]['httponly'] = True\n\n    def set_signed_cookie(self, key, value, salt='', **kwargs):\n        value = signing.get_cookie_signer(salt=key + salt).sign(value)\n        return self.set_cookie(key, value, **kwargs)\n\n    def delete_cookie(self, key, path='/', domain=None):\n        self.set_cookie(key, max_age=0, path=path, domain=domain,\n                        expires='Thu, 01-Jan-1970 00:00:00 GMT')\n\n    def _get_content(self):\n        if self.has_header('Content-Encoding'):\n            return ''.join([str(e) for e in self._container])\n        return ''.join([smart_str(e, self._charset) for e in self._container])\n\n    def _set_content(self, value):\n        if hasattr(value, '__iter__'):\n            self._container = value\n            self._base_content_is_iter = True\n        else:\n            self._container = [value]\n            self._base_content_is_iter = False\n\n    content = property(_get_content, _set_content)\n\n    def __iter__(self):\n        self._iterator = iter(self._container)\n        return self\n\n    def next(self):\n        chunk = self._iterator.next()\n        if isinstance(chunk, unicode):\n            chunk = chunk.encode(self._charset)\n        return str(chunk)\n\n    def close(self):\n        if hasattr(self._container, 'close'):\n            self._container.close()\n\n    # The remaining methods partially implement the file-like object interface.\n    # See http://docs.python.org/lib/bltin-file-objects.html\n    def write(self, content):\n        if self._base_content_is_iter:\n            raise Exception(\"This %s instance is not writable\" % self.__class__)\n        self._container.append(content)\n\n    def flush(self):\n        pass\n\n    def tell(self):\n        if self._base_content_is_iter:\n            raise Exception(\"This %s instance cannot tell its position\" % self.__class__)\n        return sum([len(str(chunk)) for chunk in self._container])\n\nclass HttpResponseRedirectBase(HttpResponse):\n    allowed_schemes = ['http', 'https', 'ftp']\n\n    def __init__(self, redirect_to):\n        super(HttpResponseRedirectBase, self).__init__()\n        parsed = urlparse(redirect_to)\n        if parsed.scheme and parsed.scheme not in self.allowed_schemes:\n            raise SuspiciousOperation(\"Unsafe redirect to URL with scheme '%s'\" % parsed.scheme)\n        self['Location'] = iri_to_uri(redirect_to)\n\nclass HttpResponseRedirect(HttpResponseRedirectBase):\n    status_code = 302\n\nclass HttpResponsePermanentRedirect(HttpResponseRedirectBase):\n    status_code = 301\n\nclass HttpResponseNotModified(HttpResponse):\n    status_code = 304\n\nclass HttpResponseBadRequest(HttpResponse):\n    status_code = 400\n\nclass HttpResponseNotFound(HttpResponse):\n    status_code = 404\n\nclass HttpResponseForbidden(HttpResponse):\n    status_code = 403\n\nclass HttpResponseNotAllowed(HttpResponse):\n    status_code = 405\n\n    def __init__(self, permitted_methods):\n        super(HttpResponseNotAllowed, self).__init__()\n        self['Allow'] = ', '.join(permitted_methods)\n\nclass HttpResponseGone(HttpResponse):\n    status_code = 410\n\nclass HttpResponseServerError(HttpResponse):\n    status_code = 500\n\n# A backwards compatible alias for HttpRequest.get_host.\ndef get_host(request):\n    return request.get_host()\n\n# It's neither necessary nor appropriate to use\n# django.utils.encoding.smart_unicode for parsing URLs and form inputs. Thus,\n# this slightly more restricted function.\ndef str_to_unicode(s, encoding):\n    \"\"\"\n    Converts basestring objects to unicode, using the given encoding. Illegally\n    encoded input characters are replaced with Unicode \"unknown\" codepoint\n    (\\ufffd).\n\n    Returns any non-basestring objects without change.\n    \"\"\"\n    if isinstance(s, str):\n        return unicode(s, encoding, 'replace')\n    else:\n        return s\n\n", "target": 1}
{"idx": 923, "func": "from __future__ import unicode_literals\n\nimport re\nimport sys\nimport types\n\nfrom django.conf import settings\nfrom django.core.urlresolvers import Resolver404, resolve\nfrom django.http import HttpResponse, HttpResponseNotFound\nfrom django.template import Context, Engine, TemplateDoesNotExist\nfrom django.template.defaultfilters import force_escape, pprint\nfrom django.utils import lru_cache, six, timezone\nfrom django.utils.datastructures import MultiValueDict\nfrom django.utils.encoding import force_bytes, smart_text\nfrom django.utils.module_loading import import_string\nfrom django.utils.translation import ugettext as _\n\n# Minimal Django templates engine to render the error templates\n# regardless of the project's TEMPLATES setting.\nDEBUG_ENGINE = Engine(debug=True)\n\nHIDDEN_SETTINGS = re.compile('API|TOKEN|KEY|SECRET|PASS|SIGNATURE')\n\nCLEANSED_SUBSTITUTE = '********************'\n\n\nclass CallableSettingWrapper(object):\n    \"\"\" Object to wrap callable appearing in settings\n\n    * Not to call in the debug page (#21345).\n    * Not to break the debug page if the callable forbidding to set attributes (#23070).\n    \"\"\"\n    def __init__(self, callable_setting):\n        self._wrapped = callable_setting\n\n    def __repr__(self):\n        return repr(self._wrapped)\n\n\ndef cleanse_setting(key, value):\n    \"\"\"Cleanse an individual setting key/value of sensitive content.\n\n    If the value is a dictionary, recursively cleanse the keys in\n    that dictionary.\n    \"\"\"\n    try:\n        if HIDDEN_SETTINGS.search(key):\n            cleansed = CLEANSED_SUBSTITUTE\n        else:\n            if isinstance(value, dict):\n                cleansed = {k: cleanse_setting(k, v) for k, v in value.items()}\n            else:\n                cleansed = value\n    except TypeError:\n        # If the key isn't regex-able, just return as-is.\n        cleansed = value\n\n    if callable(cleansed):\n        # For fixing #21345 and #23070\n        cleansed = CallableSettingWrapper(cleansed)\n\n    return cleansed\n\n\ndef get_safe_settings():\n    \"Returns a dictionary of the settings module, with sensitive settings blurred out.\"\n    settings_dict = {}\n    for k in dir(settings):\n        if k.isupper():\n            settings_dict[k] = cleanse_setting(k, getattr(settings, k))\n    return settings_dict\n\n\ndef technical_500_response(request, exc_type, exc_value, tb, status_code=500):\n    \"\"\"\n    Create a technical server error response. The last three arguments are\n    the values returned from sys.exc_info() and friends.\n    \"\"\"\n    reporter = ExceptionReporter(request, exc_type, exc_value, tb)\n    if request.is_ajax():\n        text = reporter.get_traceback_text()\n        return HttpResponse(text, status=status_code, content_type='text/plain')\n    else:\n        html = reporter.get_traceback_html()\n        return HttpResponse(html, status=status_code, content_type='text/html')\n\n\n@lru_cache.lru_cache()\ndef get_default_exception_reporter_filter():\n    # Instantiate the default filter for the first time and cache it.\n    return import_string(settings.DEFAULT_EXCEPTION_REPORTER_FILTER)()\n\n\ndef get_exception_reporter_filter(request):\n    default_filter = get_default_exception_reporter_filter()\n    return getattr(request, 'exception_reporter_filter', default_filter)\n\n\nclass ExceptionReporterFilter(object):\n    \"\"\"\n    Base for all exception reporter filter classes. All overridable hooks\n    contain lenient default behaviors.\n    \"\"\"\n\n    def get_post_parameters(self, request):\n        if request is None:\n            return {}\n        else:\n            return request.POST\n\n    def get_traceback_frame_variables(self, request, tb_frame):\n        return list(tb_frame.f_locals.items())\n\n\nclass SafeExceptionReporterFilter(ExceptionReporterFilter):\n    \"\"\"\n    Use annotations made by the sensitive_post_parameters and\n    sensitive_variables decorators to filter out sensitive information.\n    \"\"\"\n\n    def is_active(self, request):\n        \"\"\"\n        This filter is to add safety in production environments (i.e. DEBUG\n        is False). If DEBUG is True then your site is not safe anyway.\n        This hook is provided as a convenience to easily activate or\n        deactivate the filter on a per request basis.\n        \"\"\"\n        return settings.DEBUG is False\n\n    def get_cleansed_multivaluedict(self, request, multivaluedict):\n        \"\"\"\n        Replaces the keys in a MultiValueDict marked as sensitive with stars.\n        This mitigates leaking sensitive POST parameters if something like\n        request.POST['nonexistent_key'] throws an exception (#21098).\n        \"\"\"\n        sensitive_post_parameters = getattr(request, 'sensitive_post_parameters', [])\n        if self.is_active(request) and sensitive_post_parameters:\n            multivaluedict = multivaluedict.copy()\n            for param in sensitive_post_parameters:\n                if param in multivaluedict:\n                    multivaluedict[param] = CLEANSED_SUBSTITUTE\n        return multivaluedict\n\n    def get_post_parameters(self, request):\n        \"\"\"\n        Replaces the values of POST parameters marked as sensitive with\n        stars (*********).\n        \"\"\"\n        if request is None:\n            return {}\n        else:\n            sensitive_post_parameters = getattr(request, 'sensitive_post_parameters', [])\n            if self.is_active(request) and sensitive_post_parameters:\n                cleansed = request.POST.copy()\n                if sensitive_post_parameters == '__ALL__':\n                    # Cleanse all parameters.\n                    for k, v in cleansed.items():\n                        cleansed[k] = CLEANSED_SUBSTITUTE\n                    return cleansed\n                else:\n                    # Cleanse only the specified parameters.\n                    for param in sensitive_post_parameters:\n                        if param in cleansed:\n                            cleansed[param] = CLEANSED_SUBSTITUTE\n                    return cleansed\n            else:\n                return request.POST\n\n    def cleanse_special_types(self, request, value):\n        try:\n            # If value is lazy or a complex object of another kind, this check\n            # might raise an exception. isinstance checks that lazy\n            # MultiValueDicts will have a return value.\n            is_multivalue_dict = isinstance(value, MultiValueDict)\n        except Exception as e:\n            return '{!r} while evaluating {!r}'.format(e, value)\n\n        if is_multivalue_dict:\n            # Cleanse MultiValueDicts (request.POST is the one we usually care about)\n            value = self.get_cleansed_multivaluedict(request, value)\n        return value\n\n    def get_traceback_frame_variables(self, request, tb_frame):\n        \"\"\"\n        Replaces the values of variables marked as sensitive with\n        stars (*********).\n        \"\"\"\n        # Loop through the frame's callers to see if the sensitive_variables\n        # decorator was used.\n        current_frame = tb_frame.f_back\n        sensitive_variables = None\n        while current_frame is not None:\n            if (current_frame.f_code.co_name == 'sensitive_variables_wrapper'\n                    and 'sensitive_variables_wrapper' in current_frame.f_locals):\n                # The sensitive_variables decorator was used, so we take note\n                # of the sensitive variables' names.\n                wrapper = current_frame.f_locals['sensitive_variables_wrapper']\n                sensitive_variables = getattr(wrapper, 'sensitive_variables', None)\n                break\n            current_frame = current_frame.f_back\n\n        cleansed = {}\n        if self.is_active(request) and sensitive_variables:\n            if sensitive_variables == '__ALL__':\n                # Cleanse all variables\n                for name, value in tb_frame.f_locals.items():\n                    cleansed[name] = CLEANSED_SUBSTITUTE\n            else:\n                # Cleanse specified variables\n                for name, value in tb_frame.f_locals.items():\n                    if name in sensitive_variables:\n                        value = CLEANSED_SUBSTITUTE\n                    else:\n                        value = self.cleanse_special_types(request, value)\n                    cleansed[name] = value\n        else:\n            # Potentially cleanse the request and any MultiValueDicts if they\n            # are one of the frame variables.\n            for name, value in tb_frame.f_locals.items():\n                cleansed[name] = self.cleanse_special_types(request, value)\n\n        if (tb_frame.f_code.co_name == 'sensitive_variables_wrapper'\n                and 'sensitive_variables_wrapper' in tb_frame.f_locals):\n            # For good measure, obfuscate the decorated function's arguments in\n            # the sensitive_variables decorator's frame, in case the variables\n            # associated with those arguments were meant to be obfuscated from\n            # the decorated function's frame.\n            cleansed['func_args'] = CLEANSED_SUBSTITUTE\n            cleansed['func_kwargs'] = CLEANSED_SUBSTITUTE\n\n        return cleansed.items()\n\n\nclass ExceptionReporter(object):\n    \"\"\"\n    A class to organize and coordinate reporting on exceptions.\n    \"\"\"\n    def __init__(self, request, exc_type, exc_value, tb, is_email=False):\n        self.request = request\n        self.filter = get_exception_reporter_filter(self.request)\n        self.exc_type = exc_type\n        self.exc_value = exc_value\n        self.tb = tb\n        self.is_email = is_email\n\n        self.template_info = getattr(self.exc_value, 'template_debug', None)\n        self.template_does_not_exist = False\n        self.postmortem = None\n\n        # Handle deprecated string exceptions\n        if isinstance(self.exc_type, six.string_types):\n            self.exc_value = Exception('Deprecated String Exception: %r' % self.exc_type)\n            self.exc_type = type(self.exc_value)\n\n    def get_traceback_data(self):\n        \"\"\"Return a dictionary containing traceback information.\"\"\"\n        if self.exc_type and issubclass(self.exc_type, TemplateDoesNotExist):\n            self.template_does_not_exist = True\n            self.postmortem = self.exc_value.chain or [self.exc_value]\n\n        frames = self.get_traceback_frames()\n        for i, frame in enumerate(frames):\n            if 'vars' in frame:\n                frame_vars = []\n                for k, v in frame['vars']:\n                    v = pprint(v)\n                    # The force_escape filter assume unicode, make sure that works\n                    if isinstance(v, six.binary_type):\n                        v = v.decode('utf-8', 'replace')  # don't choke on non-utf-8 input\n                    # Trim large blobs of data\n                    if len(v) > 4096:\n                        v = '%s... <trimmed %d bytes string>' % (v[0:4096], len(v))\n                    frame_vars.append((k, force_escape(v)))\n                frame['vars'] = frame_vars\n            frames[i] = frame\n\n        unicode_hint = ''\n        if self.exc_type and issubclass(self.exc_type, UnicodeError):\n            start = getattr(self.exc_value, 'start', None)\n            end = getattr(self.exc_value, 'end', None)\n            if start is not None and end is not None:\n                unicode_str = self.exc_value.args[1]\n                unicode_hint = smart_text(\n                    unicode_str[max(start - 5, 0):min(end + 5, len(unicode_str))],\n                    'ascii', errors='replace'\n                )\n        from django import get_version\n        c = {\n            'is_email': self.is_email,\n            'unicode_hint': unicode_hint,\n            'frames': frames,\n            'request': self.request,\n            'filtered_POST': self.filter.get_post_parameters(self.request),\n            'settings': get_safe_settings(),\n            'sys_executable': sys.executable,\n            'sys_version_info': '%d.%d.%d' % sys.version_info[0:3],\n            'server_time': timezone.now(),\n            'django_version_info': get_version(),\n            'sys_path': sys.path,\n            'template_info': self.template_info,\n            'template_does_not_exist': self.template_does_not_exist,\n            'postmortem': self.postmortem,\n        }\n        # Check whether exception info is available\n        if self.exc_type:\n            c['exception_type'] = self.exc_type.__name__\n        if self.exc_value:\n            c['exception_value'] = smart_text(self.exc_value, errors='replace')\n        if frames:\n            c['lastframe'] = frames[-1]\n        return c\n\n    def get_traceback_html(self):\n        \"Return HTML version of debug 500 HTTP error page.\"\n        t = DEBUG_ENGINE.from_string(TECHNICAL_500_TEMPLATE)\n        c = Context(self.get_traceback_data(), use_l10n=False)\n        return t.render(c)\n\n    def get_traceback_text(self):\n        \"Return plain text version of debug 500 HTTP error page.\"\n        t = DEBUG_ENGINE.from_string(TECHNICAL_500_TEXT_TEMPLATE)\n        c = Context(self.get_traceback_data(), autoescape=False, use_l10n=False)\n        return t.render(c)\n\n    def _get_lines_from_file(self, filename, lineno, context_lines, loader=None, module_name=None):\n        \"\"\"\n        Returns context_lines before and after lineno from file.\n        Returns (pre_context_lineno, pre_context, context_line, post_context).\n        \"\"\"\n        source = None\n        if loader is not None and hasattr(loader, \"get_source\"):\n            try:\n                source = loader.get_source(module_name)\n            except ImportError:\n                pass\n            if source is not None:\n                source = source.splitlines()\n        if source is None:\n            try:\n                with open(filename, 'rb') as fp:\n                    source = fp.read().splitlines()\n            except (OSError, IOError):\n                pass\n        if source is None:\n            return None, [], None, []\n\n        # If we just read the source from a file, or if the loader did not\n        # apply tokenize.detect_encoding to decode the source into a Unicode\n        # string, then we should do that ourselves.\n        if isinstance(source[0], six.binary_type):\n            encoding = 'ascii'\n            for line in source[:2]:\n                # File coding may be specified. Match pattern from PEP-263\n                # (http://www.python.org/dev/peps/pep-0263/)\n                match = re.search(br'coding[:=]\\s*([-\\w.]+)', line)\n                if match:\n                    encoding = match.group(1).decode('ascii')\n                    break\n            source = [six.text_type(sline, encoding, 'replace') for sline in source]\n\n        lower_bound = max(0, lineno - context_lines)\n        upper_bound = lineno + context_lines\n\n        pre_context = source[lower_bound:lineno]\n        context_line = source[lineno]\n        post_context = source[lineno + 1:upper_bound]\n\n        return lower_bound, pre_context, context_line, post_context\n\n    def get_traceback_frames(self):\n        def explicit_or_implicit_cause(exc_value):\n            explicit = getattr(exc_value, '__cause__', None)\n            implicit = getattr(exc_value, '__context__', None)\n            return explicit or implicit\n\n        # Get the exception and all its causes\n        exceptions = []\n        exc_value = self.exc_value\n        while exc_value:\n            exceptions.append(exc_value)\n            exc_value = explicit_or_implicit_cause(exc_value)\n\n        frames = []\n        # No exceptions were supplied to ExceptionReporter\n        if not exceptions:\n            return frames\n\n        # In case there's just one exception (always in Python 2,\n        # sometimes in Python 3), take the traceback from self.tb (Python 2\n        # doesn't have a __traceback__ attribute on Exception)\n        exc_value = exceptions.pop()\n        tb = self.tb if six.PY2 or not exceptions else exc_value.__traceback__\n\n        while tb is not None:\n            # Support for __traceback_hide__ which is used by a few libraries\n            # to hide internal frames.\n            if tb.tb_frame.f_locals.get('__traceback_hide__'):\n                tb = tb.tb_next\n                continue\n            filename = tb.tb_frame.f_code.co_filename\n            function = tb.tb_frame.f_code.co_name\n            lineno = tb.tb_lineno - 1\n            loader = tb.tb_frame.f_globals.get('__loader__')\n            module_name = tb.tb_frame.f_globals.get('__name__') or ''\n            pre_context_lineno, pre_context, context_line, post_context = self._get_lines_from_file(\n                filename, lineno, 7, loader, module_name,\n            )\n            if pre_context_lineno is not None:\n                frames.append({\n                    'exc_cause': explicit_or_implicit_cause(exc_value),\n                    'exc_cause_explicit': getattr(exc_value, '__cause__', True),\n                    'tb': tb,\n                    'type': 'django' if module_name.startswith('django.') else 'user',\n                    'filename': filename,\n                    'function': function,\n                    'lineno': lineno + 1,\n                    'vars': self.filter.get_traceback_frame_variables(self.request, tb.tb_frame),\n                    'id': id(tb),\n                    'pre_context': pre_context,\n                    'context_line': context_line,\n                    'post_context': post_context,\n                    'pre_context_lineno': pre_context_lineno + 1,\n                })\n\n            # If the traceback for current exception is consumed, try the\n            # other exception.\n            if six.PY2:\n                tb = tb.tb_next\n            elif not tb.tb_next and exceptions:\n                exc_value = exceptions.pop()\n                tb = exc_value.__traceback__\n            else:\n                tb = tb.tb_next\n\n        return frames\n\n    def format_exception(self):\n        \"\"\"\n        Return the same data as from traceback.format_exception.\n        \"\"\"\n        import traceback\n        frames = self.get_traceback_frames()\n        tb = [(f['filename'], f['lineno'], f['function'], f['context_line']) for f in frames]\n        list = ['Traceback (most recent call last):\\n']\n        list += traceback.format_list(tb)\n        list += traceback.format_exception_only(self.exc_type, self.exc_value)\n        return list\n\n\ndef technical_404_response(request, exception):\n    \"Create a technical 404 error response. The exception should be the Http404.\"\n    try:\n        error_url = exception.args[0]['path']\n    except (IndexError, TypeError, KeyError):\n        error_url = request.path_info[1:]  # Trim leading slash\n\n    try:\n        tried = exception.args[0]['tried']\n    except (IndexError, TypeError, KeyError):\n        tried = []\n    else:\n        if (not tried                           # empty URLconf\n            or (request.path == '/'\n                and len(tried) == 1             # default URLconf\n                and len(tried[0]) == 1\n                and getattr(tried[0][0], 'app_name', '') == getattr(tried[0][0], 'namespace', '') == 'admin')):\n            return default_urlconf(request)\n\n    urlconf = getattr(request, 'urlconf', settings.ROOT_URLCONF)\n    if isinstance(urlconf, types.ModuleType):\n        urlconf = urlconf.__name__\n\n    caller = ''\n    try:\n        resolver_match = resolve(request.path)\n    except Resolver404:\n        pass\n    else:\n        obj = resolver_match.func\n\n        if hasattr(obj, '__name__'):\n            caller = obj.__name__\n        elif hasattr(obj, '__class__') and hasattr(obj.__class__, '__name__'):\n            caller = obj.__class__.__name__\n\n        if hasattr(obj, '__module__'):\n            module = obj.__module__\n            caller = '%s.%s' % (module, caller)\n\n    t = DEBUG_ENGINE.from_string(TECHNICAL_404_TEMPLATE)\n    c = Context({\n        'urlconf': urlconf,\n        'root_urlconf': settings.ROOT_URLCONF,\n        'request_path': error_url,\n        'urlpatterns': tried,\n        'reason': force_bytes(exception, errors='replace'),\n        'request': request,\n        'settings': get_safe_settings(),\n        'raising_view_name': caller,\n    })\n    return HttpResponseNotFound(t.render(c), content_type='text/html')\n\n\ndef default_urlconf(request):\n    \"Create an empty URLconf 404 error response.\"\n    t = DEBUG_ENGINE.from_string(DEFAULT_URLCONF_TEMPLATE)\n    c = Context({\n        \"title\": _(\"Welcome to Django\"),\n        \"heading\": _(\"It worked!\"),\n        \"subheading\": _(\"Congratulations on your first Django-powered page.\"),\n        \"instructions\": _(\"Of course, you haven't actually done any work yet. \"\n            \"Next, start your first app by running <code>python manage.py startapp [app_label]</code>.\"),\n        \"explanation\": _(\"You're seeing this message because you have <code>DEBUG = True</code> in your \"\n            \"Django settings file and you haven't configured any URLs. Get to work!\"),\n    })\n\n    return HttpResponse(t.render(c), content_type='text/html')\n\n#\n# Templates are embedded in the file so that we know the error handler will\n# always work even if the template loader is broken.\n#\n\nTECHNICAL_500_TEMPLATE = (\"\"\"\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n  <meta http-equiv=\"content-type\" content=\"text/html; charset=utf-8\">\n  <meta name=\"robots\" content=\"NONE,NOARCHIVE\">\n  <title>{% if exception_type %}{{ exception_type }}{% else %}Report{% endif %}\"\"\"\n\"\"\"{% if request %} at {{ request.path_info|escape }}{% endif %}</title>\n  <style type=\"text/css\">\n    html * { padding:0; margin:0; }\n    body * { padding:10px 20px; }\n    body * * { padding:0; }\n    body { font:small sans-serif; }\n    body>div { border-bottom:1px solid #ddd; }\n    h1 { font-weight:normal; }\n    h2 { margin-bottom:.8em; }\n    h2 span { font-size:80%; color:#666; font-weight:normal; }\n    h3 { margin:1em 0 .5em 0; }\n    h4 { margin:0 0 .5em 0; font-weight: normal; }\n    code, pre { font-size: 100%; white-space: pre-wrap; }\n    table { border:1px solid #ccc; border-collapse: collapse; width:100%; background:white; }\n    tbody td, tbody th { vertical-align:top; padding:2px 3px; }\n    thead th {\n      padding:1px 6px 1px 3px; background:#fefefe; text-align:left;\n      font-weight:normal; font-size:11px; border:1px solid #ddd;\n    }\n    tbody th { width:12em; text-align:right; color:#666; padding-right:.5em; }\n    table.vars { margin:5px 0 2px 40px; }\n    table.vars td, table.req td { font-family:monospace; }\n    table td.code { width:100%; }\n    table td.code pre { overflow:hidden; }\n    table.source th { color:#666; }\n    table.source td { font-family:monospace; white-space:pre; border-bottom:1px solid #eee; }\n    ul.traceback { list-style-type:none; color: #222; }\n    ul.traceback li.frame { padding-bottom:1em; color:#666; }\n    ul.traceback li.user { background-color:#e0e0e0; color:#000 }\n    div.context { padding:10px 0; overflow:hidden; }\n    div.context ol { padding-left:30px; margin:0 10px; list-style-position: inside; }\n    div.context ol li { font-family:monospace; white-space:pre; color:#777; cursor:pointer; padding-left: 2px; }\n    div.context ol li pre { display:inline; }\n    div.context ol.context-line li { color:#505050; background-color:#dfdfdf; padding: 3px 2px; }\n    div.context ol.context-line li span { position:absolute; right:32px; }\n    .user div.context ol.context-line li { background-color:#bbb; color:#000; }\n    .user div.context ol li { color:#666; }\n    div.commands { margin-left: 40px; }\n    div.commands a { color:#555; text-decoration:none; }\n    .user div.commands a { color: black; }\n    #summary { background: #ffc; }\n    #summary h2 { font-weight: normal; color: #666; }\n    #explanation { background:#eee; }\n    #template, #template-not-exist { background:#f6f6f6; }\n    #template-not-exist ul { margin: 0 0 10px 20px; }\n    #template-not-exist .postmortem-section { margin-bottom: 3px; }\n    #unicode-hint { background:#eee; }\n    #traceback { background:#eee; }\n    #requestinfo { background:#f6f6f6; padding-left:120px; }\n    #summary table { border:none; background:transparent; }\n    #requestinfo h2, #requestinfo h3 { position:relative; margin-left:-100px; }\n    #requestinfo h3 { margin-bottom:-1em; }\n    .error { background: #ffc; }\n    .specific { color:#cc3300; font-weight:bold; }\n    h2 span.commands { font-size:.7em;}\n    span.commands a:link {color:#5E5694;}\n    pre.exception_value { font-family: sans-serif; color: #666; font-size: 1.5em; margin: 10px 0 10px 0; }\n    .append-bottom { margin-bottom: 10px; }\n  </style>\n  {% if not is_email %}\n  <script type=\"text/javascript\">\n  //<!--\n    function getElementsByClassName(oElm, strTagName, strClassName){\n        // Written by Jonathan Snook, http://www.snook.ca/jon; Add-ons by Robert Nyman, http://www.robertnyman.com\n        var arrElements = (strTagName == \"*\" && document.all)? document.all :\n        oElm.getElementsByTagName(strTagName);\n        var arrReturnElements = new Array();\n        strClassName = strClassName.replace(/\\-/g, \"\\\\-\");\n        var oRegExp = new RegExp(\"(^|\\\\s)\" + strClassName + \"(\\\\s|$)\");\n        var oElement;\n        for(var i=0; i<arrElements.length; i++){\n            oElement = arrElements[i];\n            if(oRegExp.test(oElement.className)){\n                arrReturnElements.push(oElement);\n            }\n        }\n        return (arrReturnElements)\n    }\n    function hideAll(elems) {\n      for (var e = 0; e < elems.length; e++) {\n        elems[e].style.display = 'none';\n      }\n    }\n    window.onload = function() {\n      hideAll(getElementsByClassName(document, 'table', 'vars'));\n      hideAll(getElementsByClassName(document, 'ol', 'pre-context'));\n      hideAll(getElementsByClassName(document, 'ol', 'post-context'));\n      hideAll(getElementsByClassName(document, 'div', 'pastebin'));\n    }\n    function toggle() {\n      for (var i = 0; i < arguments.length; i++) {\n        var e = document.getElementById(arguments[i]);\n        if (e) {\n          e.style.display = e.style.display == 'none' ? 'block': 'none';\n        }\n      }\n      return false;\n    }\n    function varToggle(link, id) {\n      toggle('v' + id);\n      var s = link.getElementsByTagName('span')[0];\n      var uarr = String.fromCharCode(0x25b6);\n      var darr = String.fromCharCode(0x25bc);\n      s.innerHTML = s.innerHTML == uarr ? darr : uarr;\n      return false;\n    }\n    function switchPastebinFriendly(link) {\n      s1 = \"Switch to copy-and-paste view\";\n      s2 = \"Switch back to interactive view\";\n      link.innerHTML = link.innerHTML.trim() == s1 ? s2: s1;\n      toggle('browserTraceback', 'pastebinTraceback');\n      return false;\n    }\n    //-->\n  </script>\n  {% endif %}\n</head>\n<body>\n<div id=\"summary\">\n  <h1>{% if exception_type %}{{ exception_type }}{% else %}Report{% endif %}\"\"\"\n  \"\"\"{% if request %} at {{ request.path_info|escape }}{% endif %}</h1>\n  <pre class=\"exception_value\">\"\"\"\n \"\"\"{% if exception_value %}{{ exception_value|force_escape }}{% else %}No exception message supplied{% endif %}\"\"\"\n\"\"\"</pre>\n  <table class=\"meta\">\n{% if request %}\n    <tr>\n      <th>Request Method:</th>\n      <td>{{ request.META.REQUEST_METHOD }}</td>\n    </tr>\n    <tr>\n      <th>Request URL:</th>\n      <td>{{ request.get_raw_uri|escape }}</td>\n    </tr>\n{% endif %}\n    <tr>\n      <th>Django Version:</th>\n      <td>{{ django_version_info }}</td>\n    </tr>\n{% if exception_type %}\n    <tr>\n      <th>Exception Type:</th>\n      <td>{{ exception_type }}</td>\n    </tr>\n{% endif %}\n{% if exception_type and exception_value %}\n    <tr>\n      <th>Exception Value:</th>\n      <td><pre>{{ exception_value|force_escape }}</pre></td>\n    </tr>\n{% endif %}\n{% if lastframe %}\n    <tr>\n      <th>Exception Location:</th>\n      <td>{{ lastframe.filename|escape }} in {{ lastframe.function|escape }}, line {{ lastframe.lineno }}</td>\n    </tr>\n{% endif %}\n    <tr>\n      <th>Python Executable:</th>\n      <td>{{ sys_executable|escape }}</td>\n    </tr>\n    <tr>\n      <th>Python Version:</th>\n      <td>{{ sys_version_info }}</td>\n    </tr>\n    <tr>\n      <th>Python Path:</th>\n      <td><pre>{{ sys_path|pprint }}</pre></td>\n    </tr>\n    <tr>\n      <th>Server time:</th>\n      <td>{{server_time|date:\"r\"}}</td>\n    </tr>\n  </table>\n</div>\n{% if unicode_hint %}\n<div id=\"unicode-hint\">\n    <h2>Unicode error hint</h2>\n    <p>The string that could not be encoded/decoded was: <strong>{{ unicode_hint|force_escape }}</strong></p>\n</div>\n{% endif %}\n{% if template_does_not_exist %}\n<div id=\"template-not-exist\">\n    <h2>Template-loader postmortem</h2>\n    {% if postmortem %}\n        <p class=\"append-bottom\">Django tried loading these templates, in this order:</p>\n        {% for entry in postmortem %}\n            <p class=\"postmortem-section\">Using engine <code>{{ entry.backend.name }}</code>:</p>\n            <ul>\n                {% if entry.tried %}\n                    {% for attempt in entry.tried %}\n                        <li><code>{{ attempt.0.loader_name }}</code>: {{ attempt.0.name }} ({{ attempt.1 }})</li>\n                    {% endfor %}\n                    </ul>\n                {% else %}\n                    <li>This engine did not provide a list of tried templates.</li>\n                {% endif %}\n            </ul>\n        {% endfor %}\n    {% else %}\n        <p>No templates were found because your 'TEMPLATES' setting is not configured.</p>\n    {% endif %}\n</div>\n{% endif %}\n{% if template_info %}\n<div id=\"template\">\n   <h2>Error during template rendering</h2>\n   <p>In template <code>{{ template_info.name }}</code>, error at line <strong>{{ template_info.line }}</strong></p>\n   <h3>{{ template_info.message }}</h3>\n   <table class=\"source{% if template_info.top %} cut-top{% endif %}\n      {% if template_info.bottom != template_info.total %} cut-bottom{% endif %}\">\n   {% for source_line in template_info.source_lines %}\n   {% if source_line.0 == template_info.line %}\n   <tr class=\"error\"><th>{{ source_line.0 }}</th>\n     <td>{{ template_info.before }}\"\"\"\n      \"\"\"<span class=\"specific\">{{ template_info.during }}</span>\"\"\"\n      \"\"\"{{ template_info.after }}</td>\n   </tr>\n   {% else %}\n      <tr><th>{{ source_line.0 }}</th>\n      <td>{{ source_line.1 }}</td></tr>\n   {% endif %}\n   {% endfor %}\n   </table>\n</div>\n{% endif %}\n{% if frames %}\n<div id=\"traceback\">\n  <h2>Traceback <span class=\"commands\">{% if not is_email %}<a href=\"#\" onclick=\"return switchPastebinFriendly(this);\">\n    Switch to copy-and-paste view</a></span>{% endif %}\n  </h2>\n  {% autoescape off %}\n  <div id=\"browserTraceback\">\n    <ul class=\"traceback\">\n      {% for frame in frames %}\n        {% ifchanged frame.exc_cause %}{% if frame.exc_cause %}\n          <li><h3>\n          {% if frame.exc_cause_explicit %}\n            The above exception ({{ frame.exc_cause }}) was the direct cause of the following exception:\n          {% else %}\n            During handling of the above exception ({{ frame.exc_cause }}), another exception occurred:\n          {% endif %}\n        </h3></li>\n        {% endif %}{% endifchanged %}\n        <li class=\"frame {{ frame.type }}\">\n          <code>{{ frame.filename|escape }}</code> in <code>{{ frame.function|escape }}</code>\n\n          {% if frame.context_line %}\n            <div class=\"context\" id=\"c{{ frame.id }}\">\n              {% if frame.pre_context and not is_email %}\n                <ol start=\"{{ frame.pre_context_lineno }}\" class=\"pre-context\" id=\"pre{{ frame.id }}\">\n                {% for line in frame.pre_context %}\n                  <li onclick=\"toggle('pre{{ frame.id }}', 'post{{ frame.id }}')\"><pre>{{ line|escape }}</pre></li>\n                {% endfor %}\n                </ol>\n              {% endif %}\n              <ol start=\"{{ frame.lineno }}\" class=\"context-line\">\n                <li onclick=\"toggle('pre{{ frame.id }}', 'post{{ frame.id }}')\"><pre>\n\"\"\"            \"\"\"{{ frame.context_line|escape }}</pre>{% if not is_email %} <span>...</span>{% endif %}</li></ol>\n              {% if frame.post_context and not is_email  %}\n                <ol start='{{ frame.lineno|add:\"1\" }}' class=\"post-context\" id=\"post{{ frame.id }}\">\n                  {% for line in frame.post_context %}\n                  <li onclick=\"toggle('pre{{ frame.id }}', 'post{{ frame.id }}')\"><pre>{{ line|escape }}</pre></li>\n                  {% endfor %}\n              </ol>\n              {% endif %}\n            </div>\n          {% endif %}\n\n          {% if frame.vars %}\n            <div class=\"commands\">\n                {% if is_email %}\n                    <h2>Local Vars</h2>\n                {% else %}\n                    <a href=\"#\" onclick=\"return varToggle(this, '{{ frame.id }}')\"><span>&#x25b6;</span> Local vars</a>\n                {% endif %}\n            </div>\n            <table class=\"vars\" id=\"v{{ frame.id }}\">\n              <thead>\n                <tr>\n                  <th>Variable</th>\n                  <th>Value</th>\n                </tr>\n              </thead>\n              <tbody>\n                {% for var in frame.vars|dictsort:\"0\" %}\n                  <tr>\n                    <td>{{ var.0|force_escape }}</td>\n                    <td class=\"code\"><pre>{{ var.1 }}</pre></td>\n                  </tr>\n                {% endfor %}\n              </tbody>\n            </table>\n          {% endif %}\n        </li>\n      {% endfor %}\n    </ul>\n  </div>\n  {% endautoescape %}\n  <form action=\"http://dpaste.com/\" name=\"pasteform\" id=\"pasteform\" method=\"post\">\n{% if not is_email %}\n  <div id=\"pastebinTraceback\" class=\"pastebin\">\n    <input type=\"hidden\" name=\"language\" value=\"PythonConsole\">\n    <input type=\"hidden\" name=\"title\"\n      value=\"{{ exception_type|escape }}{% if request %} at {{ request.path_info|escape }}{% endif %}\">\n    <input type=\"hidden\" name=\"source\" value=\"Django Dpaste Agent\">\n    <input type=\"hidden\" name=\"poster\" value=\"Django\">\n    <textarea name=\"content\" id=\"traceback_area\" cols=\"140\" rows=\"25\">\nEnvironment:\n\n{% if request %}\nRequest Method: {{ request.META.REQUEST_METHOD }}\nRequest URL: {{ request.get_raw_uri|escape }}\n{% endif %}\nDjango Version: {{ django_version_info }}\nPython Version: {{ sys_version_info }}\nInstalled Applications:\n{{ settings.INSTALLED_APPS|pprint }}\nInstalled Middleware:\n{{ settings.MIDDLEWARE_CLASSES|pprint }}\n\n{% if template_does_not_exist %}Template loader postmortem\n{% if postmortem %}Django tried loading these templates, in this order:\n{% for entry in postmortem %}\nUsing engine {{ entry.backend.name }}:\n{% if entry.tried %}{% for attempt in entry.tried %}\"\"\"\n\"\"\"    * {{ attempt.0.loader_name }}: {{ attempt.0.name }} ({{ attempt.1 }})\n{% endfor %}{% else %}    This engine did not provide a list of tried templates.\n{% endif %}{% endfor %}\n{% else %}No templates were found because your 'TEMPLATES' setting is not configured.\n{% endif %}{% endif %}{% if template_info %}\nTemplate error:\nIn template {{ template_info.name }}, error at line {{ template_info.line }}\n   {{ template_info.message }}\"\"\"\n\"{% for source_line in template_info.source_lines %}\"\n\"{% if source_line.0 == template_info.line %}\"\n\"   {{ source_line.0 }} : {{ template_info.before }} {{ template_info.during }} {{ template_info.after }}\"\n\"{% else %}\"\n\"   {{ source_line.0 }} : {{ source_line.1 }}\"\n\"\"\"{% endif %}{% endfor %}{% endif %}\n\nTraceback:{% for frame in frames %}\n{% ifchanged frame.exc_cause %}{% if frame.exc_cause %}{% if frame.exc_cause_explicit %}\nThe above exception ({{ frame.exc_cause }}) was the direct cause of the following exception:\n{% else %}\nDuring handling of the above exception ({{ frame.exc_cause }}), another exception occurred:\n{% endif %}{% endif %}{% endifchanged %}\nFile \"{{ frame.filename|escape }}\" in {{ frame.function|escape }}\n{% if frame.context_line %}  {{ frame.lineno }}. {{ frame.context_line|escape }}{% endif %}{% endfor %}\n\nException Type: {{ exception_type|escape }}{% if request %} at {{ request.path_info|escape }}{% endif %}\nException Value: {{ exception_value|force_escape }}\n</textarea>\n  <br><br>\n  <input type=\"submit\" value=\"Share this traceback on a public website\">\n  </div>\n</form>\n</div>\n{% endif %}\n{% endif %}\n\n<div id=\"requestinfo\">\n  <h2>Request information</h2>\n\n{% if request %}\n  <h3 id=\"get-info\">GET</h3>\n  {% if request.GET %}\n    <table class=\"req\">\n      <thead>\n        <tr>\n          <th>Variable</th>\n          <th>Value</th>\n        </tr>\n      </thead>\n      <tbody>\n        {% for var in request.GET.items %}\n          <tr>\n            <td>{{ var.0 }}</td>\n            <td class=\"code\"><pre>{{ var.1|pprint }}</pre></td>\n          </tr>\n        {% endfor %}\n      </tbody>\n    </table>\n  {% else %}\n    <p>No GET data</p>\n  {% endif %}\n\n  <h3 id=\"post-info\">POST</h3>\n  {% if filtered_POST %}\n    <table class=\"req\">\n      <thead>\n        <tr>\n          <th>Variable</th>\n          <th>Value</th>\n        </tr>\n      </thead>\n      <tbody>\n        {% for var in filtered_POST.items %}\n          <tr>\n            <td>{{ var.0 }}</td>\n            <td class=\"code\"><pre>{{ var.1|pprint }}</pre></td>\n          </tr>\n        {% endfor %}\n      </tbody>\n    </table>\n  {% else %}\n    <p>No POST data</p>\n  {% endif %}\n  <h3 id=\"files-info\">FILES</h3>\n  {% if request.FILES %}\n    <table class=\"req\">\n        <thead>\n            <tr>\n                <th>Variable</th>\n                <th>Value</th>\n            </tr>\n        </thead>\n        <tbody>\n            {% for var in request.FILES.items %}\n                <tr>\n                    <td>{{ var.0 }}</td>\n                    <td class=\"code\"><pre>{{ var.1|pprint }}</pre></td>\n                </tr>\n            {% endfor %}\n        </tbody>\n    </table>\n  {% else %}\n    <p>No FILES data</p>\n  {% endif %}\n\n\n  <h3 id=\"cookie-info\">COOKIES</h3>\n  {% if request.COOKIES %}\n    <table class=\"req\">\n      <thead>\n        <tr>\n          <th>Variable</th>\n          <th>Value</th>\n        </tr>\n      </thead>\n      <tbody>\n        {% for var in request.COOKIES.items %}\n          <tr>\n            <td>{{ var.0 }}</td>\n            <td class=\"code\"><pre>{{ var.1|pprint }}</pre></td>\n          </tr>\n        {% endfor %}\n      </tbody>\n    </table>\n  {% else %}\n    <p>No cookie data</p>\n  {% endif %}\n\n  <h3 id=\"meta-info\">META</h3>\n  <table class=\"req\">\n    <thead>\n      <tr>\n        <th>Variable</th>\n        <th>Value</th>\n      </tr>\n    </thead>\n    <tbody>\n      {% for var in request.META.items|dictsort:\"0\" %}\n        <tr>\n          <td>{{ var.0 }}</td>\n          <td class=\"code\"><pre>{{ var.1|pprint }}</pre></td>\n        </tr>\n      {% endfor %}\n    </tbody>\n  </table>\n{% else %}\n  <p>Request data not supplied</p>\n{% endif %}\n\n  <h3 id=\"settings-info\">Settings</h3>\n  <h4>Using settings module <code>{{ settings.SETTINGS_MODULE }}</code></h4>\n  <table class=\"req\">\n    <thead>\n      <tr>\n        <th>Setting</th>\n        <th>Value</th>\n      </tr>\n    </thead>\n    <tbody>\n      {% for var in settings.items|dictsort:\"0\" %}\n        <tr>\n          <td>{{ var.0 }}</td>\n          <td class=\"code\"><pre>{{ var.1|pprint }}</pre></td>\n        </tr>\n      {% endfor %}\n    </tbody>\n  </table>\n\n</div>\n{% if not is_email %}\n  <div id=\"explanation\">\n    <p>\n      You're seeing this error because you have <code>DEBUG = True</code> in your\n      Django settings file. Change that to <code>False</code>, and Django will\n      display a standard page generated by the handler for this status code.\n    </p>\n  </div>\n{% endif %}\n</body>\n</html>\n\"\"\")\n\nTECHNICAL_500_TEXT_TEMPLATE = (\"\"\"\"\"\"\n\"\"\"{% firstof exception_type 'Report' %}{% if request %} at {{ request.path_info }}{% endif %}\n{% firstof exception_value 'No exception message supplied' %}\n{% if request %}\nRequest Method: {{ request.META.REQUEST_METHOD }}\nRequest URL: {{ request.get_raw_uri }}{% endif %}\nDjango Version: {{ django_version_info }}\nPython Executable: {{ sys_executable }}\nPython Version: {{ sys_version_info }}\nPython Path: {{ sys_path }}\nServer time: {{server_time|date:\"r\"}}\nInstalled Applications:\n{{ settings.INSTALLED_APPS|pprint }}\nInstalled Middleware:\n{{ settings.MIDDLEWARE_CLASSES|pprint }}\n{% if template_does_not_exist %}Template loader postmortem\n{% if postmortem %}Django tried loading these templates, in this order:\n{% for entry in postmortem %}\nUsing engine {{ entry.backend.name }}:\n{% if entry.tried %}{% for attempt in entry.tried %}\"\"\"\n\"\"\"    * {{ attempt.0.loader_name }}: {{ attempt.0.name }} ({{ attempt.1 }})\n{% endfor %}{% else %}    This engine did not provide a list of tried templates.\n{% endif %}{% endfor %}\n{% else %}No templates were found because your 'TEMPLATES' setting is not configured.\n{% endif %}\n{% endif %}{% if template_info %}\nTemplate error:\nIn template {{ template_info.name }}, error at line {{ template_info.line }}\n   {{ template_info.message }}\n{% for source_line in template_info.source_lines %}\"\"\"\n\"{% if source_line.0 == template_info.line %}\"\n\"   {{ source_line.0 }} : {{ template_info.before }} {{ template_info.during }} {{ template_info.after }}\"\n\"{% else %}\"\n\"   {{ source_line.0 }} : {{ source_line.1 }}\"\n\"\"\"{% endif %}{% endfor %}{% endif %}{% if frames %}\n\nTraceback:\"\"\"\n\"{% for frame in frames %}\"\n\"{% ifchanged frame.exc_cause %}\"\n\"  {% if frame.exc_cause %}\" \"\"\"\n    {% if frame.exc_cause_explicit %}\n      The above exception ({{ frame.exc_cause }}) was the direct cause of the following exception:\n    {% else %}\n      During handling of the above exception ({{ frame.exc_cause }}), another exception occurred:\n    {% endif %}\n  {% endif %}\n{% endifchanged %}\nFile \"{{ frame.filename }}\" in {{ frame.function }}\n{% if frame.context_line %}  {{ frame.lineno }}. {{ frame.context_line }}{% endif %}\n{% endfor %}\n{% if exception_type %}Exception Type: {{ exception_type }}{% if request %} at {{ request.path_info }}{% endif %}\n{% if exception_value %}Exception Value: {{ exception_value }}{% endif %}{% endif %}{% endif %}\n{% if request %}Request information:\nGET:{% for k, v in request.GET.items %}\n{{ k }} = {{ v|stringformat:\"r\" }}{% empty %} No GET data{% endfor %}\n\nPOST:{% for k, v in filtered_POST.items %}\n{{ k }} = {{ v|stringformat:\"r\" }}{% empty %} No POST data{% endfor %}\n\nFILES:{% for k, v in request.FILES.items %}\n{{ k }} = {{ v|stringformat:\"r\" }}{% empty %} No FILES data{% endfor %}\n\nCOOKIES:{% for k, v in request.COOKIES.items %}\n{{ k }} = {{ v|stringformat:\"r\" }}{% empty %} No cookie data{% endfor %}\n\nMETA:{% for k, v in request.META.items|dictsort:\"0\" %}\n{{ k }} = {{ v|stringformat:\"r\" }}{% endfor %}\n{% else %}Request data not supplied\n{% endif %}\nSettings:\nUsing settings module {{ settings.SETTINGS_MODULE }}{% for k, v in settings.items|dictsort:\"0\" %}\n{{ k }} = {{ v|stringformat:\"r\" }}{% endfor %}\n\n{% if not is_email %}\nYou're seeing this error because you have DEBUG = True in your\nDjango settings file. Change that to False, and Django will\ndisplay a standard page generated by the handler for this status code.\n{% endif %}\n\"\"\")\n\nTECHNICAL_404_TEMPLATE = \"\"\"\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n  <meta http-equiv=\"content-type\" content=\"text/html; charset=utf-8\">\n  <title>Page not found at {{ request.path_info|escape }}</title>\n  <meta name=\"robots\" content=\"NONE,NOARCHIVE\">\n  <style type=\"text/css\">\n    html * { padding:0; margin:0; }\n    body * { padding:10px 20px; }\n    body * * { padding:0; }\n    body { font:small sans-serif; background:#eee; }\n    body>div { border-bottom:1px solid #ddd; }\n    h1 { font-weight:normal; margin-bottom:.4em; }\n    h1 span { font-size:60%; color:#666; font-weight:normal; }\n    table { border:none; border-collapse: collapse; width:100%; }\n    td, th { vertical-align:top; padding:2px 3px; }\n    th { width:12em; text-align:right; color:#666; padding-right:.5em; }\n    #info { background:#f6f6f6; }\n    #info ol { margin: 0.5em 4em; }\n    #info ol li { font-family: monospace; }\n    #summary { background: #ffc; }\n    #explanation { background:#eee; border-bottom: 0px none; }\n  </style>\n</head>\n<body>\n  <div id=\"summary\">\n    <h1>Page not found <span>(404)</span></h1>\n    <table class=\"meta\">\n      <tr>\n        <th>Request Method:</th>\n        <td>{{ request.META.REQUEST_METHOD }}</td>\n      </tr>\n      <tr>\n        <th>Request URL:</th>\n        <td>{{ request.build_absolute_uri|escape }}</td>\n      </tr>\n      {% if raising_view_name %}\n      <tr>\n        <th>Raised by:</th>\n        <td>{{ raising_view_name }}</td>\n      </tr>\n      {% endif %}\n    </table>\n  </div>\n  <div id=\"info\">\n    {% if urlpatterns %}\n      <p>\n      Using the URLconf defined in <code>{{ urlconf }}</code>,\n      Django tried these URL patterns, in this order:\n      </p>\n      <ol>\n        {% for pattern in urlpatterns %}\n          <li>\n            {% for pat in pattern %}\n                {{ pat.regex.pattern }}\n                {% if forloop.last and pat.name %}[name='{{ pat.name }}']{% endif %}\n            {% endfor %}\n          </li>\n        {% endfor %}\n      </ol>\n      <p>The current URL, <code>{{ request_path|escape }}</code>, didn't match any of these.</p>\n    {% else %}\n      <p>{{ reason }}</p>\n    {% endif %}\n  </div>\n\n  <div id=\"explanation\">\n    <p>\n      You're seeing this error because you have <code>DEBUG = True</code> in\n      your Django settings file. Change that to <code>False</code>, and Django\n      will display a standard 404 page.\n    </p>\n  </div>\n</body>\n</html>\n\"\"\"\n\nDEFAULT_URLCONF_TEMPLATE = \"\"\"\n<!DOCTYPE html>\n<html lang=\"en\"><head>\n  <meta http-equiv=\"content-type\" content=\"text/html; charset=utf-8\">\n  <meta name=\"robots\" content=\"NONE,NOARCHIVE\"><title>{{ title }}</title>\n  <style type=\"text/css\">\n    html * { padding:0; margin:0; }\n    body * { padding:10px 20px; }\n    body * * { padding:0; }\n    body { font:small sans-serif; }\n    body>div { border-bottom:1px solid #ddd; }\n    h1 { font-weight:normal; }\n    h2 { margin-bottom:.8em; }\n    h2 span { font-size:80%; color:#666; font-weight:normal; }\n    h3 { margin:1em 0 .5em 0; }\n    h4 { margin:0 0 .5em 0; font-weight: normal; }\n    table { border:1px solid #ccc; border-collapse: collapse; width:100%; background:white; }\n    tbody td, tbody th { vertical-align:top; padding:2px 3px; }\n    thead th {\n      padding:1px 6px 1px 3px; background:#fefefe; text-align:left;\n      font-weight:normal; font-size:11px; border:1px solid #ddd;\n    }\n    tbody th { width:12em; text-align:right; color:#666; padding-right:.5em; }\n    #summary { background: #e0ebff; }\n    #summary h2 { font-weight: normal; color: #666; }\n    #explanation { background:#eee; }\n    #instructions { background:#f6f6f6; }\n    #summary table { border:none; background:transparent; }\n  </style>\n</head>\n\n<body>\n<div id=\"summary\">\n  <h1>{{ heading }}</h1>\n  <h2>{{ subheading }}</h2>\n</div>\n\n<div id=\"instructions\">\n  <p>\n    {{ instructions|safe }}\n  </p>\n</div>\n\n<div id=\"explanation\">\n  <p>\n    {{ explanation|safe }}\n  </p>\n</div>\n</body></html>\n\"\"\"\n", "target": 1}
{"idx": 924, "func": "# vim: tabstop=4 shiftwidth=4 softtabstop=4\n\n# Copyright 2010 United States Government as represented by the\n# Administrator of the National Aeronautics and Space Administration.\n#\n# Copyright 2011, Piston Cloud Computing, Inc.\n#\n# All Rights Reserved.\n#\n#    Licensed under the Apache License, Version 2.0 (the \"License\"); you may\n#    not use this file except in compliance with the License. You may obtain\n#    a copy of the License at\n#\n#         http://www.apache.org/licenses/LICENSE-2.0\n#\n#    Unless required by applicable law or agreed to in writing, software\n#    distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n#    License for the specific language governing permissions and limitations\n#    under the License.\n\"\"\"\nUtility methods to resize, repartition, and modify disk images.\n\nIncludes injection of SSH PGP keys into authorized_keys file.\n\n\"\"\"\n\nimport crypt\nimport json\nimport os\nimport random\nimport re\nimport tempfile\n\nfrom nova import exception\nfrom nova import flags\nfrom nova import log as logging\nfrom nova.openstack.common import cfg\nfrom nova import utils\nfrom nova.virt.disk import guestfs\nfrom nova.virt.disk import loop\nfrom nova.virt.disk import nbd\n\n\nLOG = logging.getLogger(__name__)\n\ndisk_opts = [\n    cfg.StrOpt('injected_network_template',\n               default='$pybasedir/nova/virt/interfaces.template',\n               help='Template file for injected network'),\n    cfg.ListOpt('img_handlers',\n                default=['loop', 'nbd', 'guestfs'],\n                help='Order of methods used to mount disk images'),\n\n    # NOTE(yamahata): ListOpt won't work because the command may include a\n    #                 comma. For example:\n    #\n    #                 mkfs.ext3 -O dir_index,extent -E stride=8,stripe-width=16\n    #                           --label %(fs_label)s %(target)s\n    #\n    #                 list arguments are comma separated and there is no way to\n    #                 escape such commas.\n    #\n    cfg.MultiStrOpt('virt_mkfs',\n                    default=[\n                      'default=mkfs.ext3 -L %(fs_label)s -F %(target)s',\n                      'linux=mkfs.ext3 -L %(fs_label)s -F %(target)s',\n                      'windows=mkfs.ntfs'\n                      ' --force --fast --label %(fs_label)s %(target)s',\n                      # NOTE(yamahata): vfat case\n                      #'windows=mkfs.vfat -n %(fs_label)s %(target)s',\n                      ],\n                    help='mkfs commands for ephemeral device. '\n                         'The format is <os_type>=<mkfs command>'),\n    ]\n\nFLAGS = flags.FLAGS\nFLAGS.register_opts(disk_opts)\n\n_MKFS_COMMAND = {}\n_DEFAULT_MKFS_COMMAND = None\n\n\nfor s in FLAGS.virt_mkfs:\n    # NOTE(yamahata): mkfs command may includes '=' for its options.\n    #                 So item.partition('=') doesn't work here\n    os_type, mkfs_command = s.split('=', 1)\n    if os_type:\n        _MKFS_COMMAND[os_type] = mkfs_command\n    if os_type == 'default':\n        _DEFAULT_MKFS_COMMAND = mkfs_command\n\n\n_QEMU_VIRT_SIZE_REGEX = re.compile('^virtual size: (.*) \\(([0-9]+) bytes\\)',\n                                   re.MULTILINE)\n\n\ndef mkfs(os_type, fs_label, target):\n    mkfs_command = (_MKFS_COMMAND.get(os_type, _DEFAULT_MKFS_COMMAND) or\n                    '') % locals()\n    if mkfs_command:\n        utils.execute(*mkfs_command.split())\n\n\ndef get_image_virtual_size(image):\n    out, _err = utils.execute('qemu-img', 'info', image)\n    m = _QEMU_VIRT_SIZE_REGEX.search(out)\n    return int(m.group(2))\n\n\ndef extend(image, size):\n    \"\"\"Increase image to size\"\"\"\n    # NOTE(MotoKen): check image virtual size before resize\n    virt_size = get_image_virtual_size(image)\n    if virt_size >= size:\n        return\n    utils.execute('qemu-img', 'resize', image, size)\n    # NOTE(vish): attempts to resize filesystem\n    utils.execute('e2fsck', '-fp', image, check_exit_code=False)\n    utils.execute('resize2fs', image, check_exit_code=False)\n\n\ndef bind(src, target, instance_name):\n    \"\"\"Bind device to a filesytem\"\"\"\n    if src:\n        utils.execute('touch', target, run_as_root=True)\n        utils.execute('mount', '-o', 'bind', src, target,\n                run_as_root=True)\n        s = os.stat(src)\n        cgroup_info = \"b %s:%s rwm\\n\" % (os.major(s.st_rdev),\n                                         os.minor(s.st_rdev))\n        cgroups_path = \\\n            \"/sys/fs/cgroup/devices/libvirt/lxc/%s/devices.allow\" \\\n            % instance_name\n        utils.execute('tee', cgroups_path,\n                      process_input=cgroup_info, run_as_root=True)\n\n\ndef unbind(target):\n    if target:\n        utils.execute('umount', target, run_as_root=True)\n\n\nclass _DiskImage(object):\n    \"\"\"Provide operations on a disk image file.\"\"\"\n\n    def __init__(self, image, partition=None, use_cow=False, mount_dir=None):\n        # These passed to each mounter\n        self.image = image\n        self.partition = partition\n        self.mount_dir = mount_dir\n\n        # Internal\n        self._mkdir = False\n        self._mounter = None\n        self._errors = []\n\n        # As a performance tweak, don't bother trying to\n        # directly loopback mount a cow image.\n        self.handlers = FLAGS.img_handlers[:]\n        if use_cow and 'loop' in self.handlers:\n            self.handlers.remove('loop')\n\n        if not self.handlers:\n            raise exception.Error(_('no capable image handler configured'))\n\n    @property\n    def errors(self):\n        \"\"\"Return the collated errors from all operations.\"\"\"\n        return '\\n--\\n'.join([''] + self._errors)\n\n    @staticmethod\n    def _handler_class(mode):\n        \"\"\"Look up the appropriate class to use based on MODE.\"\"\"\n        for cls in (loop.Mount, nbd.Mount, guestfs.Mount):\n            if cls.mode == mode:\n                return cls\n        raise exception.Error(_(\"unknown disk image handler: %s\") % mode)\n\n    def mount(self):\n        \"\"\"Mount a disk image, using the object attributes.\n\n        The first supported means provided by the mount classes is used.\n\n        True, or False is returned and the 'errors' attribute\n        contains any diagnostics.\n        \"\"\"\n        if self._mounter:\n            raise exception.Error(_('image already mounted'))\n\n        if not self.mount_dir:\n            self.mount_dir = tempfile.mkdtemp()\n            self._mkdir = True\n\n        try:\n            for h in self.handlers:\n                mounter_cls = self._handler_class(h)\n                mounter = mounter_cls(image=self.image,\n                                      partition=self.partition,\n                                      mount_dir=self.mount_dir)\n                if mounter.do_mount():\n                    self._mounter = mounter\n                    break\n                else:\n                    LOG.debug(mounter.error)\n                    self._errors.append(mounter.error)\n        finally:\n            if not self._mounter:\n                self.umount()  # rmdir\n\n        return bool(self._mounter)\n\n    def umount(self):\n        \"\"\"Unmount a disk image from the file system.\"\"\"\n        try:\n            if self._mounter:\n                self._mounter.do_umount()\n        finally:\n            if self._mkdir:\n                os.rmdir(self.mount_dir)\n\n\n# Public module functions\n\ndef inject_data(image,\n                key=None, net=None, metadata=None, admin_password=None,\n                partition=None, use_cow=False):\n    \"\"\"Injects a ssh key and optionally net data into a disk image.\n\n    it will mount the image as a fully partitioned disk and attempt to inject\n    into the specified partition number.\n\n    If partition is not specified it mounts the image as a single partition.\n\n    \"\"\"\n    img = _DiskImage(image=image, partition=partition, use_cow=use_cow)\n    if img.mount():\n        try:\n            inject_data_into_fs(img.mount_dir,\n                                key, net, metadata, admin_password,\n                                utils.execute)\n        finally:\n            img.umount()\n    else:\n        raise exception.Error(img.errors)\n\n\ndef inject_files(image, files, partition=None, use_cow=False):\n    \"\"\"Injects arbitrary files into a disk image\"\"\"\n    img = _DiskImage(image=image, partition=partition, use_cow=use_cow)\n    if img.mount():\n        try:\n            for (path, contents) in files:\n                _inject_file_into_fs(img.mount_dir, path, contents)\n        finally:\n            img.umount()\n    else:\n        raise exception.Error(img.errors)\n\n\ndef setup_container(image, container_dir=None, use_cow=False):\n    \"\"\"Setup the LXC container.\n\n    It will mount the loopback image to the container directory in order\n    to create the root filesystem for the container.\n\n    LXC does not support qcow2 images yet.\n    \"\"\"\n    try:\n        img = _DiskImage(image=image, use_cow=use_cow, mount_dir=container_dir)\n        if img.mount():\n            return img\n        else:\n            raise exception.Error(img.errors)\n    except Exception, exn:\n        LOG.exception(_('Failed to mount filesystem: %s'), exn)\n\n\ndef destroy_container(img):\n    \"\"\"Destroy the container once it terminates.\n\n    It will umount the container that is mounted,\n    and delete any  linked devices.\n\n    LXC does not support qcow2 images yet.\n    \"\"\"\n    try:\n        if img:\n            img.umount()\n    except Exception, exn:\n        LOG.exception(_('Failed to remove container: %s'), exn)\n\n\ndef inject_data_into_fs(fs, key, net, metadata, admin_password, execute):\n    \"\"\"Injects data into a filesystem already mounted by the caller.\n    Virt connections can call this directly if they mount their fs\n    in a different way to inject_data\n    \"\"\"\n    if key:\n        _inject_key_into_fs(key, fs, execute=execute)\n    if net:\n        _inject_net_into_fs(net, fs, execute=execute)\n    if metadata:\n        _inject_metadata_into_fs(metadata, fs, execute=execute)\n    if admin_password:\n        _inject_admin_password_into_fs(admin_password, fs, execute=execute)\n\n\ndef _inject_file_into_fs(fs, path, contents):\n    absolute_path = os.path.join(fs, path.lstrip('/'))\n    parent_dir = os.path.dirname(absolute_path)\n    utils.execute('mkdir', '-p', parent_dir, run_as_root=True)\n    utils.execute('tee', absolute_path, process_input=contents,\n          run_as_root=True)\n\n\ndef _inject_metadata_into_fs(metadata, fs, execute=None):\n    metadata_path = os.path.join(fs, \"meta.js\")\n    metadata = dict([(m.key, m.value) for m in metadata])\n\n    utils.execute('tee', metadata_path,\n                  process_input=json.dumps(metadata), run_as_root=True)\n\n\ndef _inject_key_into_fs(key, fs, execute=None):\n    \"\"\"Add the given public ssh key to root's authorized_keys.\n\n    key is an ssh key string.\n    fs is the path to the base of the filesystem into which to inject the key.\n    \"\"\"\n    sshdir = os.path.join(fs, 'root', '.ssh')\n    utils.execute('mkdir', '-p', sshdir, run_as_root=True)\n    utils.execute('chown', 'root', sshdir, run_as_root=True)\n    utils.execute('chmod', '700', sshdir, run_as_root=True)\n    keyfile = os.path.join(sshdir, 'authorized_keys')\n    key_data = [\n        '\\n',\n        '# The following ssh key was injected by Nova',\n        '\\n',\n        key.strip(),\n        '\\n',\n    ]\n    utils.execute('tee', '-a', keyfile,\n                  process_input=''.join(key_data), run_as_root=True)\n\n\ndef _inject_net_into_fs(net, fs, execute=None):\n    \"\"\"Inject /etc/network/interfaces into the filesystem rooted at fs.\n\n    net is the contents of /etc/network/interfaces.\n    \"\"\"\n    netdir = os.path.join(os.path.join(fs, 'etc'), 'network')\n    utils.execute('mkdir', '-p', netdir, run_as_root=True)\n    utils.execute('chown', 'root:root', netdir, run_as_root=True)\n    utils.execute('chmod', 755, netdir, run_as_root=True)\n    netfile = os.path.join(netdir, 'interfaces')\n    utils.execute('tee', netfile, process_input=net, run_as_root=True)\n\n\ndef _inject_admin_password_into_fs(admin_passwd, fs, execute=None):\n    \"\"\"Set the root password to admin_passwd\n\n    admin_password is a root password\n    fs is the path to the base of the filesystem into which to inject\n    the key.\n\n    This method modifies the instance filesystem directly,\n    and does not require a guest agent running in the instance.\n\n    \"\"\"\n    # The approach used here is to copy the password and shadow\n    # files from the instance filesystem to local files, make any\n    # necessary changes, and then copy them back.\n\n    admin_user = 'root'\n\n    fd, tmp_passwd = tempfile.mkstemp()\n    os.close(fd)\n    fd, tmp_shadow = tempfile.mkstemp()\n    os.close(fd)\n\n    utils.execute('cp', os.path.join(fs, 'etc', 'passwd'), tmp_passwd,\n                  run_as_root=True)\n    utils.execute('cp', os.path.join(fs, 'etc', 'shadow'), tmp_shadow,\n                  run_as_root=True)\n    _set_passwd(admin_user, admin_passwd, tmp_passwd, tmp_shadow)\n    utils.execute('cp', tmp_passwd, os.path.join(fs, 'etc', 'passwd'),\n                  run_as_root=True)\n    os.unlink(tmp_passwd)\n    utils.execute('cp', tmp_shadow, os.path.join(fs, 'etc', 'shadow'),\n                  run_as_root=True)\n    os.unlink(tmp_shadow)\n\n\ndef _set_passwd(username, admin_passwd, passwd_file, shadow_file):\n    \"\"\"set the password for username to admin_passwd\n\n    The passwd_file is not modified.  The shadow_file is updated.\n    if the username is not found in both files, an exception is raised.\n\n    :param username: the username\n    :param encrypted_passwd: the  encrypted password\n    :param passwd_file: path to the passwd file\n    :param shadow_file: path to the shadow password file\n    :returns: nothing\n    :raises: exception.Error(), IOError()\n\n    \"\"\"\n    salt_set = ('abcdefghijklmnopqrstuvwxyz'\n                'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n                '0123456789./')\n    # encryption algo - id pairs for crypt()\n    algos = {'SHA-512': '$6$', 'SHA-256': '$5$', 'MD5': '$1$', 'DES': ''}\n\n    salt = 16 * ' '\n    salt = ''.join([random.choice(salt_set) for c in salt])\n\n    # crypt() depends on the underlying libc, and may not support all\n    # forms of hash. We try md5 first. If we get only 13 characters back,\n    # then the underlying crypt() didn't understand the '$n$salt' magic,\n    # so we fall back to DES.\n    # md5 is the default because it's widely supported. Although the\n    # local crypt() might support stronger SHA, the target instance\n    # might not.\n    encrypted_passwd = crypt.crypt(admin_passwd, algos['MD5'] + salt)\n    if len(encrypted_passwd) == 13:\n        encrypted_passwd = crypt.crypt(admin_passwd, algos['DES'] + salt)\n\n    try:\n        p_file = open(passwd_file, 'rb')\n        s_file = open(shadow_file, 'rb')\n\n        # username MUST exist in passwd file or it's an error\n        found = False\n        for entry in p_file:\n            split_entry = entry.split(':')\n            if split_entry[0] == username:\n                found = True\n                break\n        if not found:\n            msg = _('User %(username)s not found in password file.')\n            raise exception.Error(msg % username)\n\n        # update password in the shadow file.It's an error if the\n        # the user doesn't exist.\n        new_shadow = list()\n        found = False\n        for entry in s_file:\n            split_entry = entry.split(':')\n            if split_entry[0] == username:\n                split_entry[1] = encrypted_passwd\n                found = True\n            new_entry = ':'.join(split_entry)\n            new_shadow.append(new_entry)\n        s_file.close()\n        if not found:\n            msg = _('User %(username)s not found in shadow file.')\n            raise exception.Error(msg % username)\n        s_file = open(shadow_file, 'wb')\n        for entry in new_shadow:\n            s_file.write(entry)\n    finally:\n        p_file.close()\n        s_file.close()\n", "target": 1}
{"idx": 925, "func": "# (c) 2012-2014, Michael DeHaan <michael.dehaan@gmail.com>\n#\n# This file is part of Ansible\n#\n# Ansible is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# Ansible is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.\n\nimport os\nimport pwd\nimport sys\nimport ConfigParser\nfrom string import ascii_letters, digits\n\n# copied from utils, avoid circular reference fun :)\ndef mk_boolean(value):\n    if value is None:\n        return False\n    val = str(value)\n    if val.lower() in [ \"true\", \"t\", \"y\", \"1\", \"yes\" ]:\n        return True\n    else:\n        return False\n\ndef get_config(p, section, key, env_var, default, boolean=False, integer=False, floating=False, islist=False):\n    ''' return a configuration variable with casting '''\n    value = _get_config(p, section, key, env_var, default)\n    if boolean:\n        return mk_boolean(value)\n    if value and integer:\n        return int(value)\n    if value and floating:\n        return float(value)\n    if value and islist:\n        return [x.strip() for x in value.split(',')]\n    return value\n\ndef _get_config(p, section, key, env_var, default):\n    ''' helper function for get_config '''\n    if env_var is not None:\n        value = os.environ.get(env_var, None)\n        if value is not None:\n            return value\n    if p is not None:\n        try:\n            return p.get(section, key, raw=True)\n        except:\n            return default\n    return default\n\ndef load_config_file():\n    ''' Load Config File order(first found is used): ENV, CWD, HOME, /etc/ansible '''\n\n    p = ConfigParser.ConfigParser()\n\n    path0 = os.getenv(\"ANSIBLE_CONFIG\", None)\n    if path0 is not None:\n        path0 = os.path.expanduser(path0)\n    path1 = os.getcwd() + \"/ansible.cfg\"\n    path2 = os.path.expanduser(\"~/.ansible.cfg\")\n    path3 = \"/etc/ansible/ansible.cfg\"\n\n    for path in [path0, path1, path2, path3]:\n        if path is not None and os.path.exists(path):\n            p.read(path)\n            return p\n    return None\n\ndef shell_expand_path(path):\n    ''' shell_expand_path is needed as os.path.expanduser does not work\n        when path is None, which is the default for ANSIBLE_PRIVATE_KEY_FILE '''\n    if path:\n        path = os.path.expanduser(path)\n    return path\n\np = load_config_file()\n\nactive_user   = pwd.getpwuid(os.geteuid())[0]\n\n# Needed so the RPM can call setup.py and have modules land in the\n# correct location. See #1277 for discussion\nif getattr(sys, \"real_prefix\", None):\n    # in a virtualenv\n    DIST_MODULE_PATH = os.path.join(sys.prefix, 'share/ansible/')\nelse:\n    DIST_MODULE_PATH = '/usr/share/ansible/'\n\n# check all of these extensions when looking for yaml files for things like\n# group variables -- really anything we can load\nYAML_FILENAME_EXTENSIONS = [ \"\", \".yml\", \".yaml\", \".json\" ]\n\n# sections in config file\nDEFAULTS='defaults'\n\n# configurable things\nDEFAULT_HOST_LIST         = shell_expand_path(get_config(p, DEFAULTS, 'hostfile', 'ANSIBLE_HOSTS', '/etc/ansible/hosts'))\nDEFAULT_MODULE_PATH       = get_config(p, DEFAULTS, 'library',          'ANSIBLE_LIBRARY',          DIST_MODULE_PATH)\nDEFAULT_ROLES_PATH        = shell_expand_path(get_config(p, DEFAULTS, 'roles_path',       'ANSIBLE_ROLES_PATH',       '/etc/ansible/roles'))\nDEFAULT_REMOTE_TMP        = shell_expand_path(get_config(p, DEFAULTS, 'remote_tmp',       'ANSIBLE_REMOTE_TEMP',      '$HOME/.ansible/tmp'))\nDEFAULT_MODULE_NAME       = get_config(p, DEFAULTS, 'module_name',      None,                       'command')\nDEFAULT_PATTERN           = get_config(p, DEFAULTS, 'pattern',          None,                       '*')\nDEFAULT_FORKS             = get_config(p, DEFAULTS, 'forks',            'ANSIBLE_FORKS',            5, integer=True)\nDEFAULT_MODULE_ARGS       = get_config(p, DEFAULTS, 'module_args',      'ANSIBLE_MODULE_ARGS',      '')\nDEFAULT_MODULE_LANG       = get_config(p, DEFAULTS, 'module_lang',      'ANSIBLE_MODULE_LANG',      'en_US.UTF-8')\nDEFAULT_TIMEOUT           = get_config(p, DEFAULTS, 'timeout',          'ANSIBLE_TIMEOUT',          10, integer=True)\nDEFAULT_POLL_INTERVAL     = get_config(p, DEFAULTS, 'poll_interval',    'ANSIBLE_POLL_INTERVAL',    15, integer=True)\nDEFAULT_REMOTE_USER       = get_config(p, DEFAULTS, 'remote_user',      'ANSIBLE_REMOTE_USER',      active_user)\nDEFAULT_ASK_PASS          = get_config(p, DEFAULTS, 'ask_pass',  'ANSIBLE_ASK_PASS',    False, boolean=True)\nDEFAULT_PRIVATE_KEY_FILE  = shell_expand_path(get_config(p, DEFAULTS, 'private_key_file', 'ANSIBLE_PRIVATE_KEY_FILE', None))\nDEFAULT_SUDO_USER         = get_config(p, DEFAULTS, 'sudo_user',        'ANSIBLE_SUDO_USER',        'root')\nDEFAULT_ASK_SUDO_PASS     = get_config(p, DEFAULTS, 'ask_sudo_pass',    'ANSIBLE_ASK_SUDO_PASS',    False, boolean=True)\nDEFAULT_REMOTE_PORT       = get_config(p, DEFAULTS, 'remote_port',      'ANSIBLE_REMOTE_PORT',      None, integer=True)\nDEFAULT_ASK_VAULT_PASS    = get_config(p, DEFAULTS, 'ask_vault_pass',    'ANSIBLE_ASK_VAULT_PASS',    False, boolean=True)\nDEFAULT_TRANSPORT         = get_config(p, DEFAULTS, 'transport',        'ANSIBLE_TRANSPORT',        'smart')\nDEFAULT_SCP_IF_SSH        = get_config(p, 'ssh_connection', 'scp_if_ssh',       'ANSIBLE_SCP_IF_SSH',       False, boolean=True)\nDEFAULT_MANAGED_STR       = get_config(p, DEFAULTS, 'ansible_managed',  None,           'Ansible managed: {file} modified on %Y-%m-%d %H:%M:%S by {uid} on {host}')\nDEFAULT_SYSLOG_FACILITY   = get_config(p, DEFAULTS, 'syslog_facility',  'ANSIBLE_SYSLOG_FACILITY', 'LOG_USER')\nDEFAULT_KEEP_REMOTE_FILES = get_config(p, DEFAULTS, 'keep_remote_files', 'ANSIBLE_KEEP_REMOTE_FILES', False, boolean=True)\nDEFAULT_SUDO              = get_config(p, DEFAULTS, 'sudo', 'ANSIBLE_SUDO', False, boolean=True)\nDEFAULT_SUDO_EXE          = get_config(p, DEFAULTS, 'sudo_exe', 'ANSIBLE_SUDO_EXE', 'sudo')\nDEFAULT_SUDO_FLAGS        = get_config(p, DEFAULTS, 'sudo_flags', 'ANSIBLE_SUDO_FLAGS', '-H')\nDEFAULT_HASH_BEHAVIOUR    = get_config(p, DEFAULTS, 'hash_behaviour', 'ANSIBLE_HASH_BEHAVIOUR', 'replace')\nDEFAULT_JINJA2_EXTENSIONS = get_config(p, DEFAULTS, 'jinja2_extensions', 'ANSIBLE_JINJA2_EXTENSIONS', None)\nDEFAULT_EXECUTABLE        = get_config(p, DEFAULTS, 'executable', 'ANSIBLE_EXECUTABLE', '/bin/sh')\nDEFAULT_SU_EXE            = get_config(p, DEFAULTS, 'su_exe', 'ANSIBLE_SU_EXE', 'su')\nDEFAULT_SU                = get_config(p, DEFAULTS, 'su', 'ANSIBLE_SU', False, boolean=True)\nDEFAULT_SU_FLAGS          = get_config(p, DEFAULTS, 'su_flags', 'ANSIBLE_SU_FLAGS', '')\nDEFAULT_SU_USER           = get_config(p, DEFAULTS, 'su_user', 'ANSIBLE_SU_USER', 'root')\nDEFAULT_ASK_SU_PASS       = get_config(p, DEFAULTS, 'ask_su_pass', 'ANSIBLE_ASK_SU_PASS', False, boolean=True)\nDEFAULT_GATHERING         = get_config(p, DEFAULTS, 'gathering', 'ANSIBLE_GATHERING', 'implicit').lower()\n\nDEFAULT_ACTION_PLUGIN_PATH     = get_config(p, DEFAULTS, 'action_plugins',     'ANSIBLE_ACTION_PLUGINS', '/usr/share/ansible_plugins/action_plugins')\nDEFAULT_CALLBACK_PLUGIN_PATH   = get_config(p, DEFAULTS, 'callback_plugins',   'ANSIBLE_CALLBACK_PLUGINS', '/usr/share/ansible_plugins/callback_plugins')\nDEFAULT_CONNECTION_PLUGIN_PATH = get_config(p, DEFAULTS, 'connection_plugins', 'ANSIBLE_CONNECTION_PLUGINS', '/usr/share/ansible_plugins/connection_plugins')\nDEFAULT_LOOKUP_PLUGIN_PATH     = get_config(p, DEFAULTS, 'lookup_plugins',     'ANSIBLE_LOOKUP_PLUGINS', '/usr/share/ansible_plugins/lookup_plugins')\nDEFAULT_VARS_PLUGIN_PATH       = get_config(p, DEFAULTS, 'vars_plugins',       'ANSIBLE_VARS_PLUGINS', '/usr/share/ansible_plugins/vars_plugins')\nDEFAULT_FILTER_PLUGIN_PATH     = get_config(p, DEFAULTS, 'filter_plugins',     'ANSIBLE_FILTER_PLUGINS', '/usr/share/ansible_plugins/filter_plugins')\nDEFAULT_LOG_PATH               = shell_expand_path(get_config(p, DEFAULTS, 'log_path',           'ANSIBLE_LOG_PATH', ''))\n\nANSIBLE_FORCE_COLOR            = get_config(p, DEFAULTS, 'force_color', 'ANSIBLE_FORCE_COLOR', None, boolean=True)\nANSIBLE_NOCOLOR                = get_config(p, DEFAULTS, 'nocolor', 'ANSIBLE_NOCOLOR', None, boolean=True)\nANSIBLE_NOCOWS                 = get_config(p, DEFAULTS, 'nocows', 'ANSIBLE_NOCOWS', None, boolean=True)\nDISPLAY_SKIPPED_HOSTS          = get_config(p, DEFAULTS, 'display_skipped_hosts', 'DISPLAY_SKIPPED_HOSTS', True, boolean=True)\nDEFAULT_UNDEFINED_VAR_BEHAVIOR = get_config(p, DEFAULTS, 'error_on_undefined_vars', 'ANSIBLE_ERROR_ON_UNDEFINED_VARS', True, boolean=True)\nHOST_KEY_CHECKING              = get_config(p, DEFAULTS, 'host_key_checking',  'ANSIBLE_HOST_KEY_CHECKING',    True, boolean=True)\nSYSTEM_WARNINGS                = get_config(p, DEFAULTS, 'system_warnings', 'ANSIBLE_SYSTEM_WARNINGS', True, boolean=True)\nDEPRECATION_WARNINGS           = get_config(p, DEFAULTS, 'deprecation_warnings', 'ANSIBLE_DEPRECATION_WARNINGS', True, boolean=True)\nDEFAULT_CALLABLE_WHITELIST     = get_config(p, DEFAULTS, 'callable_whitelist', 'ANSIBLE_CALLABLE_WHITELIST', [], islist=True)\n\n# CONNECTION RELATED\nANSIBLE_SSH_ARGS               = get_config(p, 'ssh_connection', 'ssh_args', 'ANSIBLE_SSH_ARGS', None)\nANSIBLE_SSH_CONTROL_PATH       = get_config(p, 'ssh_connection', 'control_path', 'ANSIBLE_SSH_CONTROL_PATH', \"%(directory)s/ansible-ssh-%%h-%%p-%%r\")\nANSIBLE_SSH_PIPELINING         = get_config(p, 'ssh_connection', 'pipelining', 'ANSIBLE_SSH_PIPELINING', False, boolean=True)\nPARAMIKO_RECORD_HOST_KEYS      = get_config(p, 'paramiko_connection', 'record_host_keys', 'ANSIBLE_PARAMIKO_RECORD_HOST_KEYS', True, boolean=True)\n# obsolete -- will be formally removed in 1.6\nZEROMQ_PORT                    = get_config(p, 'fireball_connection', 'zeromq_port', 'ANSIBLE_ZEROMQ_PORT', 5099, integer=True)\nACCELERATE_PORT                = get_config(p, 'accelerate', 'accelerate_port', 'ACCELERATE_PORT', 5099, integer=True)\nACCELERATE_TIMEOUT             = get_config(p, 'accelerate', 'accelerate_timeout', 'ACCELERATE_TIMEOUT', 30, integer=True)\nACCELERATE_CONNECT_TIMEOUT     = get_config(p, 'accelerate', 'accelerate_connect_timeout', 'ACCELERATE_CONNECT_TIMEOUT', 1.0, floating=True)\nACCELERATE_DAEMON_TIMEOUT      = get_config(p, 'accelerate', 'accelerate_daemon_timeout', 'ACCELERATE_DAEMON_TIMEOUT', 30, integer=True)\nACCELERATE_KEYS_DIR            = get_config(p, 'accelerate', 'accelerate_keys_dir', 'ACCELERATE_KEYS_DIR', '~/.fireball.keys')\nACCELERATE_KEYS_DIR_PERMS      = get_config(p, 'accelerate', 'accelerate_keys_dir_perms', 'ACCELERATE_KEYS_DIR_PERMS', '700')\nACCELERATE_KEYS_FILE_PERMS     = get_config(p, 'accelerate', 'accelerate_keys_file_perms', 'ACCELERATE_KEYS_FILE_PERMS', '600')\nACCELERATE_MULTI_KEY           = get_config(p, 'accelerate', 'accelerate_multi_key', 'ACCELERATE_MULTI_KEY', False, boolean=True)\nPARAMIKO_PTY                   = get_config(p, 'paramiko_connection', 'pty', 'ANSIBLE_PARAMIKO_PTY', True, boolean=True)\n\n# characters included in auto-generated passwords\nDEFAULT_PASSWORD_CHARS = ascii_letters + digits + \".,:-_\"\n\n# non-configurable things\nDEFAULT_SUDO_PASS         = None\nDEFAULT_REMOTE_PASS       = None\nDEFAULT_SUBSET            = None\nDEFAULT_SU_PASS           = None\nVAULT_VERSION_MIN         = 1.0\nVAULT_VERSION_MAX         = 1.0\n", "target": 0}
{"idx": 926, "func": "# This file is dual licensed under the terms of the Apache License, Version\n# 2.0, and the BSD License. See the LICENSE file in the root of this repository\n# for complete details.\n\nfrom __future__ import absolute_import, division, print_function\n\nimport six\n\nfrom cryptography import utils\nfrom cryptography.exceptions import (\n    AlreadyFinalized, InvalidKey, UnsupportedAlgorithm, _Reasons\n)\nfrom cryptography.hazmat.backends.interfaces import HMACBackend\nfrom cryptography.hazmat.primitives import constant_time, hmac\nfrom cryptography.hazmat.primitives.kdf import KeyDerivationFunction\n\n\n@utils.register_interface(KeyDerivationFunction)\nclass HKDF(object):\n    def __init__(self, algorithm, length, salt, info, backend):\n        if not isinstance(backend, HMACBackend):\n            raise UnsupportedAlgorithm(\n                \"Backend object does not implement HMACBackend.\",\n                _Reasons.BACKEND_MISSING_INTERFACE\n            )\n\n        self._algorithm = algorithm\n\n        if not (salt is None or isinstance(salt, bytes)):\n            raise TypeError(\"salt must be bytes.\")\n\n        if salt is None:\n            salt = b\"\\x00\" * (self._algorithm.digest_size // 8)\n\n        self._salt = salt\n\n        self._backend = backend\n\n        self._hkdf_expand = HKDFExpand(self._algorithm, length, info, backend)\n\n    def _extract(self, key_material):\n        h = hmac.HMAC(self._salt, self._algorithm, backend=self._backend)\n        h.update(key_material)\n        return h.finalize()\n\n    def derive(self, key_material):\n        if not isinstance(key_material, bytes):\n            raise TypeError(\"key_material must be bytes.\")\n\n        return self._hkdf_expand.derive(self._extract(key_material))\n\n    def verify(self, key_material, expected_key):\n        if not constant_time.bytes_eq(self.derive(key_material), expected_key):\n            raise InvalidKey\n\n\n@utils.register_interface(KeyDerivationFunction)\nclass HKDFExpand(object):\n    def __init__(self, algorithm, length, info, backend):\n        if not isinstance(backend, HMACBackend):\n            raise UnsupportedAlgorithm(\n                \"Backend object does not implement HMACBackend.\",\n                _Reasons.BACKEND_MISSING_INTERFACE\n            )\n\n        self._algorithm = algorithm\n\n        self._backend = backend\n\n        max_length = 255 * (algorithm.digest_size // 8)\n\n        if length > max_length:\n            raise ValueError(\n                \"Can not derive keys larger than {0} octets.\".format(\n                    max_length\n                ))\n\n        self._length = length\n\n        if not (info is None or isinstance(info, bytes)):\n            raise TypeError(\"info must be bytes.\")\n\n        if info is None:\n            info = b\"\"\n\n        self._info = info\n\n        self._used = False\n\n    def _expand(self, key_material):\n        output = [b\"\"]\n        counter = 1\n\n        while (self._algorithm.digest_size // 8) * len(output) < self._length:\n            h = hmac.HMAC(key_material, self._algorithm, backend=self._backend)\n            h.update(output[-1])\n            h.update(self._info)\n            h.update(six.int2byte(counter))\n            output.append(h.finalize())\n            counter += 1\n\n        return b\"\".join(output)[:self._length]\n\n    def derive(self, key_material):\n        if not isinstance(key_material, bytes):\n            raise TypeError(\"key_material must be bytes.\")\n\n        if self._used:\n            raise AlreadyFinalized\n\n        self._used = True\n        return self._expand(key_material)\n\n    def verify(self, key_material, expected_key):\n        if not constant_time.bytes_eq(self.derive(key_material), expected_key):\n            raise InvalidKey\n", "target": 1}
{"idx": 927, "func": "# coding: UTF-8\n'''Mock D-BUS objects for test suites.'''\n\n# This program is free software; you can redistribute it and/or modify it under\n# the terms of the GNU Lesser General Public License as published by the Free\n# Software Foundation; either version 3 of the License, or (at your option) any\n# later version.  See http://www.gnu.org/copyleft/lgpl.html for the full text\n# of the license.\n\n__author__ = 'Martin Pitt'\n__email__ = 'martin.pitt@ubuntu.com'\n__copyright__ = '(c) 2012 Canonical Ltd.'\n__license__ = 'LGPL 3+'\n\nimport copy\nimport time\nimport sys\nimport types\nimport importlib\nfrom xml.etree import ElementTree\n\n# we do not use this ourselves, but mock methods often want to use this\nimport os\nos  # pyflakes\n\nimport dbus\nimport dbus.service\n\n# global path -> DBusMockObject mapping\nobjects = {}\n\nMOCK_IFACE = 'org.freedesktop.DBus.Mock'\nOBJECT_MANAGER_IFACE = 'org.freedesktop.DBus.ObjectManager'\n\n# stubs to keep code compatible with Python 2 and 3\nif sys.version_info[0] >= 3:\n    long = int\n    unicode = str\n\n\ndef load_module(name):\n    if os.path.exists(name) and os.path.splitext(name)[1] == '.py':\n        sys.path.insert(0, os.path.dirname(os.path.abspath(name)))\n        try:\n            m = os.path.splitext(os.path.basename(name))[0]\n            module = importlib.import_module(m)\n        finally:\n            sys.path.pop(0)\n\n        return module\n\n    return importlib.import_module('dbusmock.templates.' + name)\n\n\nclass DBusMockObject(dbus.service.Object):\n    '''Mock D-Bus object\n\n    This can be configured to have arbitrary methods (including code execution)\n    and properties via methods on the org.freedesktop.DBus.Mock interface, so\n    that you can control the mock from any programming language.\n    '''\n\n    def __init__(self, bus_name, path, interface, props, logfile=None,\n                 is_object_manager=False):\n        '''Create a new DBusMockObject\n\n        bus_name: A dbus.service.BusName instance where the object will be put on\n        path: D-Bus object path\n        interface: Primary D-Bus interface name of this object (where\n                   properties and methods will be put on)\n        props: A property_name (string) \u2192 property (Variant) map with initial\n               properties on \"interface\"\n        logfile: When given, method calls will be logged into that file name;\n                 if None, logging will be written to stdout. Note that you can\n                 also query the called methods over D-BUS with GetCalls() and\n                 GetMethodCalls().\n        is_object_manager: If True, the GetManagedObjects method will\n                           automatically be implemented on the object, returning\n                           all objects which have this one\u2019s path as a prefix of\n                           theirs. Note that the InterfacesAdded and\n                           InterfacesRemoved signals will not be automatically\n                           emitted.\n        '''\n        dbus.service.Object.__init__(self, bus_name, path)\n\n        self.bus_name = bus_name\n        self.path = path\n        self.interface = interface\n        self.is_object_manager = is_object_manager\n\n        self._template = None\n        self._template_parameters = None\n\n        if logfile:\n            self.logfile = open(logfile, 'w')\n        else:\n            self.logfile = None\n        self.is_logfile_owner = True\n        self.call_log = []\n\n        if props is None:\n            props = {}\n\n        self._reset(props)\n\n    def __del__(self):\n        if self.logfile and self.is_logfile_owner:\n            self.logfile.close()\n\n    def _set_up_object_manager(self):\n        '''Set up this mock object as a D-Bus ObjectManager.'''\n        if self.path == '/':\n            cond = 'k != \\'/\\''\n        else:\n            cond = 'k.startswith(\\'%s/\\')' % self.path\n\n        self.AddMethod(OBJECT_MANAGER_IFACE,\n                       'GetManagedObjects', '', 'a{oa{sa{sv}}}',\n                       'ret = {dbus.ObjectPath(k): objects[k].props ' +\n                       '  for k in objects.keys() if ' + cond + '}')\n\n    def _reset(self, props):\n        # interface -> name -> value\n        self.props = {self.interface: props}\n\n        # interface -> name -> (in_signature, out_signature, code, dbus_wrapper_fn)\n        self.methods = {self.interface: {}}\n\n        if self.is_object_manager:\n            self._set_up_object_manager()\n\n    @dbus.service.method(dbus.PROPERTIES_IFACE,\n                         in_signature='ss', out_signature='v')\n    def Get(self, interface_name, property_name):\n        '''Standard D-Bus API for getting a property value'''\n\n        self.log('Get %s.%s' % (interface_name, property_name))\n\n        if not interface_name:\n            interface_name = self.interface\n        try:\n            return self.GetAll(interface_name)[property_name]\n        except KeyError:\n            raise dbus.exceptions.DBusException(\n                'no such property ' + property_name,\n                name=self.interface + '.UnknownProperty')\n\n    @dbus.service.method(dbus.PROPERTIES_IFACE,\n                         in_signature='s', out_signature='a{sv}')\n    def GetAll(self, interface_name, *args, **kwargs):\n        '''Standard D-Bus API for getting all property values'''\n\n        self.log('GetAll ' + interface_name)\n\n        if not interface_name:\n            interface_name = self.interface\n        try:\n            return self.props[interface_name]\n        except KeyError:\n            raise dbus.exceptions.DBusException(\n                'no such interface ' + interface_name,\n                name=self.interface + '.UnknownInterface')\n\n    @dbus.service.method(dbus.PROPERTIES_IFACE,\n                         in_signature='ssv', out_signature='')\n    def Set(self, interface_name, property_name, value, *args, **kwargs):\n        '''Standard D-Bus API for setting a property value'''\n\n        self.log('Set %s.%s%s' % (interface_name,\n                                  property_name,\n                                  self.format_args((value,))))\n\n        try:\n            iface_props = self.props[interface_name]\n        except KeyError:\n            raise dbus.exceptions.DBusException(\n                'no such interface ' + interface_name,\n                name=self.interface + '.UnknownInterface')\n\n        if property_name not in iface_props:\n            raise dbus.exceptions.DBusException(\n                'no such property ' + property_name,\n                name=self.interface + '.UnknownProperty')\n\n        iface_props[property_name] = value\n\n        self.EmitSignal('org.freedesktop.DBus.Properties',\n                        'PropertiesChanged',\n                        'sa{sv}as',\n                        [interface_name,\n                         dbus.Dictionary({property_name: value}, signature='sv'),\n                         dbus.Array([], signature='s')\n                        ])\n\n    @dbus.service.method(MOCK_IFACE,\n                         in_signature='ssa{sv}a(ssss)',\n                         out_signature='')\n    def AddObject(self, path, interface, properties, methods):\n        '''Add a new D-Bus object to the mock\n\n        path: D-Bus object path\n        interface: Primary D-Bus interface name of this object (where\n                   properties and methods will be put on)\n        properties: A property_name (string) \u2192 value map with initial\n                    properties on \"interface\"\n        methods: An array of 4-tuples (name, in_sig, out_sig, code) describing\n                 methods to add to \"interface\"; see AddMethod() for details of\n                 the tuple values\n\n        If this is a D-Bus ObjectManager instance, the InterfacesAdded signal\n        will *not* be emitted for the object automatically; it must be emitted\n        manually if desired. This is because AddInterface may be called after\n        AddObject, but before the InterfacesAdded signal should be emitted.\n\n        Example:\n        dbus_proxy.AddObject('/com/example/Foo/Manager',\n                             'com.example.Foo.Control',\n                             {\n                                 'state': dbus.String('online', variant_level=1),\n                             },\n                             [\n                                 ('Start', '', '', ''),\n                                 ('EchoInt', 'i', 'i', 'ret = args[0]'),\n                                 ('GetClients', '', 'ao', 'ret = [\"/com/example/Foo/Client1\"]'),\n                             ])\n        '''\n        if path in objects:\n            raise dbus.exceptions.DBusException(\n                'object %s already exists' % path,\n                name='org.freedesktop.DBus.Mock.NameError')\n\n        obj = DBusMockObject(self.bus_name,\n                             path,\n                             interface,\n                             properties)\n        # make sure created objects inherit the log file stream\n        obj.logfile = self.logfile\n        obj.is_logfile_owner = False\n        obj.AddMethods(interface, methods)\n\n        objects[path] = obj\n\n    @dbus.service.method(MOCK_IFACE,\n                         in_signature='s',\n                         out_signature='')\n    def RemoveObject(self, path):\n        '''Remove a D-Bus object from the mock\n\n        As with AddObject, this will *not* emit the InterfacesRemoved signal if\n        it\u2019s an ObjectManager instance.\n        '''\n        try:\n            objects[path].remove_from_connection()\n            del objects[path]\n        except KeyError:\n            raise dbus.exceptions.DBusException(\n                'object %s does not exist' % path,\n                name='org.freedesktop.DBus.Mock.NameError')\n\n    @dbus.service.method(MOCK_IFACE,\n                         in_signature='', out_signature='')\n    def Reset(self):\n        '''Reset the mock object state.\n\n        Remove all mock objects from the bus and tidy up so the state is as if\n        python-dbusmock had just been restarted. If the mock object was\n        originally created with a template (from the command line, the Python\n        API or by calling AddTemplate over D-Bus), it will be\n        re-instantiated with that template.\n        '''\n        # Clear other existing objects.\n        for obj_name, obj in objects.items():\n            if obj_name != self.path:\n                obj.remove_from_connection()\n        objects.clear()\n\n        # Reinitialise our state. Carefully remove new methods from our dict;\n        # they don't not actually exist if they are a statically defined\n        # template function\n        for method_name in self.methods[self.interface]:\n            try:\n                delattr(self.__class__, method_name)\n            except AttributeError:\n                pass\n\n        self._reset({})\n\n        if self._template is not None:\n            self.AddTemplate(self._template, self._template_parameters)\n\n        objects[self.path] = self\n\n    @dbus.service.method(MOCK_IFACE,\n                         in_signature='sssss',\n                         out_signature='')\n    def AddMethod(self, interface, name, in_sig, out_sig, code):\n        '''Add a method to this object\n\n        interface: D-Bus interface to add this to. For convenience you can\n                   specify '' here to add the method to the object's main\n                   interface (as specified on construction).\n        name: Name of the method\n        in_sig: Signature of input arguments; for example \"ias\" for a method\n                that takes an int32 and a string array as arguments; see\n                http://dbus.freedesktop.org/doc/dbus-specification.html#message-protocol-signatures\n        out_sig: Signature of output arguments; for example \"s\" for a method\n                 that returns a string; use '' for methods that do not return\n                 anything.\n        code: Python 3 code to run in the method call; you have access to the\n              arguments through the \"args\" list, and can set the return value\n              by assigning a value to the \"ret\" variable. You can also read the\n              global \"objects\" variable, which is a dictionary mapping object\n              paths to DBusMockObject instances.\n\n              For keeping state across method calls, you are free to use normal\n              Python members of the \"self\" object, which will be persistant for\n              the whole mock's life time. E. g. you can have a method with\n              \"self.my_state = True\", and another method that returns it with\n              \"ret = self.my_state\".\n\n              When specifying '', the method will not do anything (except\n              logging) and return None.\n        '''\n        if not interface:\n            interface = self.interface\n        n_args = len(dbus.Signature(in_sig))\n\n        # we need to have separate methods for dbus-python, so clone\n        # mock_method(); using message_keyword with this dynamic approach fails\n        # because inspect cannot handle those, so pass on interface and method\n        # name as first positional arguments\n        method = lambda self, *args, **kwargs: DBusMockObject.mock_method(\n            self, interface, name, in_sig, *args, **kwargs)\n\n        # we cannot specify in_signature here, as that trips over a consistency\n        # check in dbus-python; we need to set it manually instead\n        dbus_method = dbus.service.method(interface,\n                                          out_signature=out_sig)(method)\n        dbus_method.__name__ = str(name)\n        dbus_method._dbus_in_signature = in_sig\n        dbus_method._dbus_args = ['arg%i' % i for i in range(1, n_args + 1)]\n\n        # for convenience, add mocked methods on the primary interface as\n        # callable methods\n        if interface == self.interface:\n            setattr(self.__class__, name, dbus_method)\n\n        self.methods.setdefault(interface, {})[str(name)] = (in_sig, out_sig, code, dbus_method)\n\n    @dbus.service.method(MOCK_IFACE,\n                         in_signature='sa(ssss)',\n                         out_signature='')\n    def AddMethods(self, interface, methods):\n        '''Add several methods to this object\n\n        interface: D-Bus interface to add this to. For convenience you can\n                   specify '' here to add the method to the object's main\n                   interface (as specified on construction).\n        methods: list of 4-tuples (name, in_sig, out_sig, code) describing one\n                 method each. See AddMethod() for details of the tuple values.\n        '''\n        for method in methods:\n            self.AddMethod(interface, *method)\n\n    @dbus.service.method(MOCK_IFACE,\n                         in_signature='ssv',\n                         out_signature='')\n    def AddProperty(self, interface, name, value):\n        '''Add property to this object\n\n        interface: D-Bus interface to add this to. For convenience you can\n                   specify '' here to add the property to the object's main\n                   interface (as specified on construction).\n        name: Property name.\n        value: Property value.\n        '''\n        if not interface:\n            interface = self.interface\n        try:\n            self.props[interface][name]\n            raise dbus.exceptions.DBusException(\n                'property %s already exists' % name,\n                name=self.interface + '.PropertyExists')\n        except KeyError:\n            # this is what we expect\n            pass\n\n        # copy.copy removes one level of variant-ness, which means that the\n        # types get exported in introspection data correctly, but we can't do\n        # this for container types.\n        if not (isinstance(value, dbus.Dictionary) or isinstance(value, dbus.Array)):\n            value = copy.copy(value)\n\n        self.props.setdefault(interface, {})[name] = value\n\n    @dbus.service.method(MOCK_IFACE,\n                         in_signature='sa{sv}',\n                         out_signature='')\n    def AddProperties(self, interface, properties):\n        '''Add several properties to this object\n\n        interface: D-Bus interface to add this to. For convenience you can\n                   specify '' here to add the property to the object's main\n                   interface (as specified on construction).\n        properties: A property_name (string) \u2192 value map\n        '''\n        for k, v in properties.items():\n            self.AddProperty(interface, k, v)\n\n    @dbus.service.method(MOCK_IFACE,\n                         in_signature='sa{sv}',\n                         out_signature='')\n    def AddTemplate(self, template, parameters):\n        '''Load a template into the mock.\n\n        python-dbusmock ships a set of standard mocks for common system\n        services such as UPower and NetworkManager. With these the actual tests\n        become a lot simpler, as they only have to set up the particular\n        properties for the tests, and not the skeleton of common properties,\n        interfaces, and methods.\n\n        template: Name of the template to load or the full path to a *.py file\n                  for custom templates. See \"pydoc dbusmock.templates\" for a\n                  list of available templates from python-dbusmock package, and\n                  \"pydoc dbusmock.templates.NAME\" for documentation about\n                  template NAME.\n        parameters: A parameter (string) \u2192 value (variant) map, for\n                    parameterizing templates. Each template can define their\n                    own, see documentation of that particular template for\n                    details.\n        '''\n        try:\n            module = load_module(template)\n        except ImportError as e:\n            raise dbus.exceptions.DBusException('Cannot add template %s: %s' % (template, str(e)),\n                                                name='org.freedesktop.DBus.Mock.TemplateError')\n\n        # If the template specifies this is an ObjectManager, set that up\n        if hasattr(module, 'IS_OBJECT_MANAGER') and module.IS_OBJECT_MANAGER:\n            self._set_up_object_manager()\n\n        # pick out all D-BUS service methods and add them to our interface\n        for symbol in dir(module):\n            fn = getattr(module, symbol)\n            if ('_dbus_interface' in dir(fn) and\n                    ('_dbus_is_signal' not in dir(fn) or not fn._dbus_is_signal)):\n                # for dbus-python compatibility, add methods as callables\n                setattr(self.__class__, symbol, fn)\n                self.methods.setdefault(fn._dbus_interface, {})[str(symbol)] = (\n                    fn._dbus_in_signature,\n                    fn._dbus_out_signature, '', fn\n                )\n\n        if parameters is None:\n            parameters = {}\n\n        module.load(self, parameters)\n        # save the given template and parameters for re-instantiation on\n        # Reset()\n        self._template = template\n        self._template_parameters = parameters\n\n    @dbus.service.method(MOCK_IFACE,\n                         in_signature='sssav',\n                         out_signature='')\n    def EmitSignal(self, interface, name, signature, args):\n        '''Emit a signal from the object.\n\n        interface: D-Bus interface to send the signal from. For convenience you\n                   can specify '' here to add the method to the object's main\n                   interface (as specified on construction).\n        name: Name of the signal\n        signature: Signature of input arguments; for example \"ias\" for a signal\n                that takes an int32 and a string array as arguments; see\n                http://dbus.freedesktop.org/doc/dbus-specification.html#message-protocol-signatures\n        args: variant array with signal arguments; must match order and type in\n              \"signature\"\n        '''\n        if not interface:\n            interface = self.interface\n\n        # convert types of arguments according to signature, using\n        # MethodCallMessage.append(); this will also provide type/length\n        # checks, except for the case of an empty signature\n        if signature == '' and len(args) > 0:\n            raise TypeError('Fewer items found in D-Bus signature than in Python arguments')\n        m = dbus.connection.MethodCallMessage('a.b', '/a', 'a.b', 'a')\n        m.append(signature=signature, *args)\n        args = m.get_args_list()\n\n        fn = lambda self, *args: self.log('emit %s.%s%s' % (interface, name, self.format_args(args)))\n        fn.__name__ = str(name)\n        dbus_fn = dbus.service.signal(interface)(fn)\n        dbus_fn._dbus_signature = signature\n        dbus_fn._dbus_args = ['arg%i' % i for i in range(1, len(args) + 1)]\n\n        dbus_fn(self, *args)\n\n    @dbus.service.method(MOCK_IFACE,\n                         in_signature='',\n                         out_signature='a(tsav)')\n    def GetCalls(self):\n        '''List all the logged calls since the last call to ClearCalls().\n\n        Return a list of (timestamp, method_name, args_list) tuples.\n        '''\n        return self.call_log\n\n    @dbus.service.method(MOCK_IFACE,\n                         in_signature='s',\n                         out_signature='a(tav)')\n    def GetMethodCalls(self, method):\n        '''List all the logged calls of a particular method.\n\n        Return a list of (timestamp, args_list) tuples.\n        '''\n        return [(row[0], row[2]) for row in self.call_log if row[1] == method]\n\n    @dbus.service.method(MOCK_IFACE,\n                         in_signature='',\n                         out_signature='')\n    def ClearCalls(self):\n        '''Empty the log of mock call signatures.'''\n\n        self.call_log = []\n\n    @dbus.service.signal(MOCK_IFACE, signature='sav')\n    def MethodCalled(self, name, args):\n        '''Signal emitted for every called mock method.\n\n        This is emitted for all mock method calls.  This can be used to confirm\n        that a particular method was called with particular arguments, as an\n        alternative to reading the mock's log or GetCalls().\n        '''\n        pass\n\n    def mock_method(self, interface, dbus_method, in_signature, *args, **kwargs):\n        '''Master mock method.\n\n        This gets \"instantiated\" in AddMethod(). Execute the code snippet of\n        the method and return the \"ret\" variable if it was set.\n        '''\n        # print('mock_method', dbus_method, self, in_signature, args, kwargs, file=sys.stderr)\n\n        # convert types of arguments according to signature, using\n        # MethodCallMessage.append(); this will also provide type/length\n        # checks, except for the case of an empty signature\n        if in_signature == '' and len(args) > 0:\n            raise TypeError('Fewer items found in D-Bus signature than in Python arguments')\n        m = dbus.connection.MethodCallMessage('a.b', '/a', 'a.b', 'a')\n        m.append(signature=in_signature, *args)\n        args = m.get_args_list()\n\n        self.log(dbus_method + self.format_args(args))\n        self.call_log.append((int(time.time()), str(dbus_method), args))\n        self.MethodCalled(dbus_method, args)\n\n        # The code may be a Python 3 string to interpret, or may be a function\n        # object (if AddMethod was called from within Python itself, rather than\n        # over D-Bus).\n        code = self.methods[interface][dbus_method][2]\n        if code and isinstance(code, types.FunctionType):\n            return code(self, *args)\n        elif code:\n            loc = locals().copy()\n            exec(code, globals(), loc)\n            if 'ret' in loc:\n                return loc['ret']\n\n    def format_args(self, args):\n        '''Format a D-BUS argument tuple into an appropriate logging string.'''\n\n        def format_arg(a):\n            if isinstance(a, dbus.Boolean):\n                return str(bool(a))\n            if isinstance(a, dbus.Byte):\n                return str(int(a))\n            if isinstance(a, int) or isinstance(a, long):\n                return str(a)\n            if isinstance(a, str) or isinstance(a, unicode):\n                return '\"' + str(a) + '\"'\n            if isinstance(a, list):\n                return '[' + ', '.join([format_arg(x) for x in a]) + ']'\n            if isinstance(a, dict):\n                fmta = '{'\n                first = True\n                for k, v in a.items():\n                    if first:\n                        first = False\n                    else:\n                        fmta += ', '\n                    fmta += format_arg(k) + ': ' + format_arg(v)\n                return fmta + '}'\n\n            # fallback\n            return repr(a)\n\n        s = ''\n        for a in args:\n            if s:\n                s += ' '\n            s += format_arg(a)\n        if s:\n            s = ' ' + s\n        return s\n\n    def log(self, msg):\n        '''Log a message, prefixed with a timestamp.\n\n        If a log file was specified in the constructor, it is written there,\n        otherwise it goes to stdout.\n        '''\n        if self.logfile:\n            fd = self.logfile\n        else:\n            fd = sys.stdout\n\n        fd.write('%.3f %s\\n' % (time.time(), msg))\n        fd.flush()\n\n    @dbus.service.method(dbus.INTROSPECTABLE_IFACE,\n                         in_signature='',\n                         out_signature='s',\n                         path_keyword='object_path',\n                         connection_keyword='connection')\n    def Introspect(self, object_path, connection):\n        '''Return XML description of this object's interfaces, methods and signals.\n\n        This wraps dbus-python's Introspect() method to include the dynamic\n        methods and properties.\n        '''\n        # temporarily add our dynamic methods\n        cls = self.__class__.__module__ + '.' + self.__class__.__name__\n        orig_interfaces = self._dbus_class_table[cls]\n\n        mock_interfaces = orig_interfaces.copy()\n        for interface, methods in self.methods.items():\n            for method in methods:\n                mock_interfaces.setdefault(interface, {})[method] = self.methods[interface][method][3]\n        self._dbus_class_table[cls] = mock_interfaces\n\n        xml = dbus.service.Object.Introspect(self, object_path, connection)\n\n        tree = ElementTree.fromstring(xml)\n\n        for name in self.props:\n            # We might have properties for new interfaces we don't know about\n            # yet. Try to find an existing <interface> node named after our\n            # interface to append to, and create one if we can't.\n            interface = tree.find(\".//interface[@name='%s']\" % name)\n            if interface is None:\n                interface = ElementTree.Element(\"interface\", {\"name\": name})\n                tree.append(interface)\n\n            for prop, val in self.props[name].items():\n                if val is None:\n                    # can't guess type from None, skip\n                    continue\n                elem = ElementTree.Element(\"property\", {\n                    \"name\": prop,\n                    # We don't store the signature anywhere, so guess it.\n                    \"type\": dbus.lowlevel.Message.guess_signature(val),\n                    \"access\": \"readwrite\"})\n\n                interface.append(elem)\n\n        xml = ElementTree.tostring(tree, encoding='utf8', method='xml').decode('utf8')\n\n        # restore original class table\n        self._dbus_class_table[cls] = orig_interfaces\n\n        return xml\n\n\n# Overwrite dbus-python's _method_lookup(), as that offers no way to have the\n# same method name on different interfaces\norig_method_lookup = dbus.service._method_lookup\n\n\ndef _dbusmock_method_lookup(obj, method_name, dbus_interface):\n    try:\n        m = obj.methods[dbus_interface or obj.interface][method_name]\n        return (m[3], m[3])\n    except KeyError:\n        return orig_method_lookup(obj, method_name, dbus_interface)\n\ndbus.service._method_lookup = _dbusmock_method_lookup\n\n\n#\n# Helper API for templates\n#\n\n\ndef get_objects():\n    '''Return all existing object paths'''\n\n    return objects.keys()\n\n\ndef get_object(path):\n    '''Return object for a given object path'''\n\n    return objects[path]\n", "target": 1}
{"idx": 928, "func": "# -*- coding: utf-8 -*-\n\n\"\"\"\nrequests.session\n~~~~~~~~~~~~~~~~\n\nThis module provides a Session object to manage and persist settings across\nrequests (cookies, auth, proxies).\n\"\"\"\nimport os\nimport sys\nimport time\nfrom datetime import timedelta\n\nfrom .auth import _basic_auth_str\nfrom .compat import cookielib, is_py3, OrderedDict, urljoin, urlparse, Mapping\nfrom .cookies import (\n    cookiejar_from_dict, extract_cookies_to_jar, RequestsCookieJar, merge_cookies)\nfrom .models import Request, PreparedRequest, DEFAULT_REDIRECT_LIMIT\nfrom .hooks import default_hooks, dispatch_hook\nfrom ._internal_utils import to_native_string\nfrom .utils import to_key_val_list, default_headers\nfrom .exceptions import (\n    TooManyRedirects, InvalidSchema, ChunkedEncodingError, ContentDecodingError)\n\nfrom .structures import CaseInsensitiveDict\nfrom .adapters import HTTPAdapter\n\nfrom .utils import (\n    requote_uri, get_environ_proxies, get_netrc_auth, should_bypass_proxies,\n    get_auth_from_url, rewind_body\n)\n\nfrom .status_codes import codes\n\n# formerly defined here, reexposed here for backward compatibility\nfrom .models import REDIRECT_STATI\n\n# Preferred clock, based on which one is more accurate on a given system.\nif sys.platform == 'win32':\n    try:  # Python 3.4+\n        preferred_clock = time.perf_counter\n    except AttributeError:  # Earlier than Python 3.\n        preferred_clock = time.clock\nelse:\n    preferred_clock = time.time\n\n\ndef merge_setting(request_setting, session_setting, dict_class=OrderedDict):\n    \"\"\"Determines appropriate setting for a given request, taking into account\n    the explicit setting on that request, and the setting in the session. If a\n    setting is a dictionary, they will be merged together using `dict_class`\n    \"\"\"\n\n    if session_setting is None:\n        return request_setting\n\n    if request_setting is None:\n        return session_setting\n\n    # Bypass if not a dictionary (e.g. verify)\n    if not (\n            isinstance(session_setting, Mapping) and\n            isinstance(request_setting, Mapping)\n    ):\n        return request_setting\n\n    merged_setting = dict_class(to_key_val_list(session_setting))\n    merged_setting.update(to_key_val_list(request_setting))\n\n    # Remove keys that are set to None. Extract keys first to avoid altering\n    # the dictionary during iteration.\n    none_keys = [k for (k, v) in merged_setting.items() if v is None]\n    for key in none_keys:\n        del merged_setting[key]\n\n    return merged_setting\n\n\ndef merge_hooks(request_hooks, session_hooks, dict_class=OrderedDict):\n    \"\"\"Properly merges both requests and session hooks.\n\n    This is necessary because when request_hooks == {'response': []}, the\n    merge breaks Session hooks entirely.\n    \"\"\"\n    if session_hooks is None or session_hooks.get('response') == []:\n        return request_hooks\n\n    if request_hooks is None or request_hooks.get('response') == []:\n        return session_hooks\n\n    return merge_setting(request_hooks, session_hooks, dict_class)\n\n\nclass SessionRedirectMixin(object):\n\n    def get_redirect_target(self, resp):\n        \"\"\"Receives a Response. Returns a redirect URI or ``None``\"\"\"\n        # Due to the nature of how requests processes redirects this method will\n        # be called at least once upon the original response and at least twice\n        # on each subsequent redirect response (if any).\n        # If a custom mixin is used to handle this logic, it may be advantageous\n        # to cache the redirect location onto the response object as a private\n        # attribute.\n        if resp.is_redirect:\n            location = resp.headers['location']\n            # Currently the underlying http module on py3 decode headers\n            # in latin1, but empirical evidence suggests that latin1 is very\n            # rarely used with non-ASCII characters in HTTP headers.\n            # It is more likely to get UTF8 header rather than latin1.\n            # This causes incorrect handling of UTF8 encoded location headers.\n            # To solve this, we re-encode the location in latin1.\n            if is_py3:\n                location = location.encode('latin1')\n            return to_native_string(location, 'utf8')\n        return None\n\n    def resolve_redirects(self, resp, req, stream=False, timeout=None,\n                          verify=True, cert=None, proxies=None, yield_requests=False, **adapter_kwargs):\n        \"\"\"Receives a Response. Returns a generator of Responses or Requests.\"\"\"\n\n        hist = []  # keep track of history\n\n        url = self.get_redirect_target(resp)\n        previous_fragment = urlparse(req.url).fragment\n        while url:\n            prepared_request = req.copy()\n\n            # Update history and keep track of redirects.\n            # resp.history must ignore the original request in this loop\n            hist.append(resp)\n            resp.history = hist[1:]\n\n            try:\n                resp.content  # Consume socket so it can be released\n            except (ChunkedEncodingError, ContentDecodingError, RuntimeError):\n                resp.raw.read(decode_content=False)\n\n            if len(resp.history) >= self.max_redirects:\n                raise TooManyRedirects('Exceeded %s redirects.' % self.max_redirects, response=resp)\n\n            # Release the connection back into the pool.\n            resp.close()\n\n            # Handle redirection without scheme (see: RFC 1808 Section 4)\n            if url.startswith('//'):\n                parsed_rurl = urlparse(resp.url)\n                url = '%s:%s' % (to_native_string(parsed_rurl.scheme), url)\n\n            # Normalize url case and attach previous fragment if needed (RFC 7231 7.1.2)\n            parsed = urlparse(url)\n            if parsed.fragment == '' and previous_fragment:\n                parsed = parsed._replace(fragment=previous_fragment)\n            elif parsed.fragment:\n                previous_fragment = parsed.fragment\n            url = parsed.geturl()\n\n            # Facilitate relative 'location' headers, as allowed by RFC 7231.\n            # (e.g. '/path/to/resource' instead of 'http://domain.tld/path/to/resource')\n            # Compliant with RFC3986, we percent encode the url.\n            if not parsed.netloc:\n                url = urljoin(resp.url, requote_uri(url))\n            else:\n                url = requote_uri(url)\n\n            prepared_request.url = to_native_string(url)\n\n            self.rebuild_method(prepared_request, resp)\n\n            # https://github.com/requests/requests/issues/1084\n            if resp.status_code not in (codes.temporary_redirect, codes.permanent_redirect):\n                # https://github.com/requests/requests/issues/3490\n                purged_headers = ('Content-Length', 'Content-Type', 'Transfer-Encoding')\n                for header in purged_headers:\n                    prepared_request.headers.pop(header, None)\n                prepared_request.body = None\n\n            headers = prepared_request.headers\n            try:\n                del headers['Cookie']\n            except KeyError:\n                pass\n\n            # Extract any cookies sent on the response to the cookiejar\n            # in the new request. Because we've mutated our copied prepared\n            # request, use the old one that we haven't yet touched.\n            extract_cookies_to_jar(prepared_request._cookies, req, resp.raw)\n            merge_cookies(prepared_request._cookies, self.cookies)\n            prepared_request.prepare_cookies(prepared_request._cookies)\n\n            # Rebuild auth and proxy information.\n            proxies = self.rebuild_proxies(prepared_request, proxies)\n            self.rebuild_auth(prepared_request, resp)\n\n            # A failed tell() sets `_body_position` to `object()`. This non-None\n            # value ensures `rewindable` will be True, allowing us to raise an\n            # UnrewindableBodyError, instead of hanging the connection.\n            rewindable = (\n                prepared_request._body_position is not None and\n                ('Content-Length' in headers or 'Transfer-Encoding' in headers)\n            )\n\n            # Attempt to rewind consumed file-like object.\n            if rewindable:\n                rewind_body(prepared_request)\n\n            # Override the original request.\n            req = prepared_request\n\n            if yield_requests:\n                yield req\n            else:\n\n                resp = self.send(\n                    req,\n                    stream=stream,\n                    timeout=timeout,\n                    verify=verify,\n                    cert=cert,\n                    proxies=proxies,\n                    allow_redirects=False,\n                    **adapter_kwargs\n                )\n\n                extract_cookies_to_jar(self.cookies, prepared_request, resp.raw)\n\n                # extract redirect url, if any, for the next loop\n                url = self.get_redirect_target(resp)\n                yield resp\n\n    def rebuild_auth(self, prepared_request, response):\n        \"\"\"When being redirected we may want to strip authentication from the\n        request to avoid leaking credentials. This method intelligently removes\n        and reapplies authentication where possible to avoid credential loss.\n        \"\"\"\n        headers = prepared_request.headers\n        url = prepared_request.url\n\n        if 'Authorization' in headers:\n            # If we get redirected to a new host, we should strip out any\n            # authentication headers.\n            original_parsed = urlparse(response.request.url)\n            redirect_parsed = urlparse(url)\n\n            if (original_parsed.hostname != redirect_parsed.hostname):\n                del headers['Authorization']\n\n        # .netrc might have more auth for us on our new host.\n        new_auth = get_netrc_auth(url) if self.trust_env else None\n        if new_auth is not None:\n            prepared_request.prepare_auth(new_auth)\n\n        return\n\n    def rebuild_proxies(self, prepared_request, proxies):\n        \"\"\"This method re-evaluates the proxy configuration by considering the\n        environment variables. If we are redirected to a URL covered by\n        NO_PROXY, we strip the proxy configuration. Otherwise, we set missing\n        proxy keys for this URL (in case they were stripped by a previous\n        redirect).\n\n        This method also replaces the Proxy-Authorization header where\n        necessary.\n\n        :rtype: dict\n        \"\"\"\n        proxies = proxies if proxies is not None else {}\n        headers = prepared_request.headers\n        url = prepared_request.url\n        scheme = urlparse(url).scheme\n        new_proxies = proxies.copy()\n        no_proxy = proxies.get('no_proxy')\n\n        bypass_proxy = should_bypass_proxies(url, no_proxy=no_proxy)\n        if self.trust_env and not bypass_proxy:\n            environ_proxies = get_environ_proxies(url, no_proxy=no_proxy)\n\n            proxy = environ_proxies.get(scheme, environ_proxies.get('all'))\n\n            if proxy:\n                new_proxies.setdefault(scheme, proxy)\n\n        if 'Proxy-Authorization' in headers:\n            del headers['Proxy-Authorization']\n\n        try:\n            username, password = get_auth_from_url(new_proxies[scheme])\n        except KeyError:\n            username, password = None, None\n\n        if username and password:\n            headers['Proxy-Authorization'] = _basic_auth_str(username, password)\n\n        return new_proxies\n\n    def rebuild_method(self, prepared_request, response):\n        \"\"\"When being redirected we may want to change the method of the request\n        based on certain specs or browser behavior.\n        \"\"\"\n        method = prepared_request.method\n\n        # http://tools.ietf.org/html/rfc7231#section-6.4.4\n        if response.status_code == codes.see_other and method != 'HEAD':\n            method = 'GET'\n\n        # Do what the browsers do, despite standards...\n        # First, turn 302s into GETs.\n        if response.status_code == codes.found and method != 'HEAD':\n            method = 'GET'\n\n        # Second, if a POST is responded to with a 301, turn it into a GET.\n        # This bizarre behaviour is explained in Issue 1704.\n        if response.status_code == codes.moved and method == 'POST':\n            method = 'GET'\n\n        prepared_request.method = method\n\n\nclass Session(SessionRedirectMixin):\n    \"\"\"A Requests session.\n\n    Provides cookie persistence, connection-pooling, and configuration.\n\n    Basic Usage::\n\n      >>> import requests\n      >>> s = requests.Session()\n      >>> s.get('http://httpbin.org/get')\n      <Response [200]>\n\n    Or as a context manager::\n\n      >>> with requests.Session() as s:\n      >>>     s.get('http://httpbin.org/get')\n      <Response [200]>\n    \"\"\"\n\n    __attrs__ = [\n        'headers', 'cookies', 'auth', 'proxies', 'hooks', 'params', 'verify',\n        'cert', 'prefetch', 'adapters', 'stream', 'trust_env',\n        'max_redirects',\n    ]\n\n    def __init__(self):\n\n        #: A case-insensitive dictionary of headers to be sent on each\n        #: :class:`Request <Request>` sent from this\n        #: :class:`Session <Session>`.\n        self.headers = default_headers()\n\n        #: Default Authentication tuple or object to attach to\n        #: :class:`Request <Request>`.\n        self.auth = None\n\n        #: Dictionary mapping protocol or protocol and host to the URL of the proxy\n        #: (e.g. {'http': 'foo.bar:3128', 'http://host.name': 'foo.bar:4012'}) to\n        #: be used on each :class:`Request <Request>`.\n        self.proxies = {}\n\n        #: Event-handling hooks.\n        self.hooks = default_hooks()\n\n        #: Dictionary of querystring data to attach to each\n        #: :class:`Request <Request>`. The dictionary values may be lists for\n        #: representing multivalued query parameters.\n        self.params = {}\n\n        #: Stream response content default.\n        self.stream = False\n\n        #: SSL Verification default.\n        self.verify = True\n\n        #: SSL client certificate default, if String, path to ssl client\n        #: cert file (.pem). If Tuple, ('cert', 'key') pair.\n        self.cert = None\n\n        #: Maximum number of redirects allowed. If the request exceeds this\n        #: limit, a :class:`TooManyRedirects` exception is raised.\n        #: This defaults to requests.models.DEFAULT_REDIRECT_LIMIT, which is\n        #: 30.\n        self.max_redirects = DEFAULT_REDIRECT_LIMIT\n\n        #: Trust environment settings for proxy configuration, default\n        #: authentication and similar.\n        self.trust_env = True\n\n        #: A CookieJar containing all currently outstanding cookies set on this\n        #: session. By default it is a\n        #: :class:`RequestsCookieJar <requests.cookies.RequestsCookieJar>`, but\n        #: may be any other ``cookielib.CookieJar`` compatible object.\n        self.cookies = cookiejar_from_dict({})\n\n        # Default connection adapters.\n        self.adapters = OrderedDict()\n        self.mount('https://', HTTPAdapter())\n        self.mount('http://', HTTPAdapter())\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, *args):\n        self.close()\n\n    def prepare_request(self, request):\n        \"\"\"Constructs a :class:`PreparedRequest <PreparedRequest>` for\n        transmission and returns it. The :class:`PreparedRequest` has settings\n        merged from the :class:`Request <Request>` instance and those of the\n        :class:`Session`.\n\n        :param request: :class:`Request` instance to prepare with this\n            session's settings.\n        :rtype: requests.PreparedRequest\n        \"\"\"\n        cookies = request.cookies or {}\n\n        # Bootstrap CookieJar.\n        if not isinstance(cookies, cookielib.CookieJar):\n            cookies = cookiejar_from_dict(cookies)\n\n        # Merge with session cookies\n        merged_cookies = merge_cookies(\n            merge_cookies(RequestsCookieJar(), self.cookies), cookies)\n\n        # Set environment's basic authentication if not explicitly set.\n        auth = request.auth\n        if self.trust_env and not auth and not self.auth:\n            auth = get_netrc_auth(request.url)\n\n        p = PreparedRequest()\n        p.prepare(\n            method=request.method.upper(),\n            url=request.url,\n            files=request.files,\n            data=request.data,\n            json=request.json,\n            headers=merge_setting(request.headers, self.headers, dict_class=CaseInsensitiveDict),\n            params=merge_setting(request.params, self.params),\n            auth=merge_setting(auth, self.auth),\n            cookies=merged_cookies,\n            hooks=merge_hooks(request.hooks, self.hooks),\n        )\n        return p\n\n    def request(self, method, url,\n            params=None, data=None, headers=None, cookies=None, files=None,\n            auth=None, timeout=None, allow_redirects=True, proxies=None,\n            hooks=None, stream=None, verify=None, cert=None, json=None):\n        \"\"\"Constructs a :class:`Request <Request>`, prepares it and sends it.\n        Returns :class:`Response <Response>` object.\n\n        :param method: method for the new :class:`Request` object.\n        :param url: URL for the new :class:`Request` object.\n        :param params: (optional) Dictionary or bytes to be sent in the query\n            string for the :class:`Request`.\n        :param data: (optional) Dictionary, list of tuples, bytes, or file-like\n            object to send in the body of the :class:`Request`.\n        :param json: (optional) json to send in the body of the\n            :class:`Request`.\n        :param headers: (optional) Dictionary of HTTP Headers to send with the\n            :class:`Request`.\n        :param cookies: (optional) Dict or CookieJar object to send with the\n            :class:`Request`.\n        :param files: (optional) Dictionary of ``'filename': file-like-objects``\n            for multipart encoding upload.\n        :param auth: (optional) Auth tuple or callable to enable\n            Basic/Digest/Custom HTTP Auth.\n        :param timeout: (optional) How long to wait for the server to send\n            data before giving up, as a float, or a :ref:`(connect timeout,\n            read timeout) <timeouts>` tuple.\n        :type timeout: float or tuple\n        :param allow_redirects: (optional) Set to True by default.\n        :type allow_redirects: bool\n        :param proxies: (optional) Dictionary mapping protocol or protocol and\n            hostname to the URL of the proxy.\n        :param stream: (optional) whether to immediately download the response\n            content. Defaults to ``False``.\n        :param verify: (optional) Either a boolean, in which case it controls whether we verify\n            the server's TLS certificate, or a string, in which case it must be a path\n            to a CA bundle to use. Defaults to ``True``.\n        :param cert: (optional) if String, path to ssl client cert file (.pem).\n            If Tuple, ('cert', 'key') pair.\n        :rtype: requests.Response\n        \"\"\"\n        # Create the Request.\n        req = Request(\n            method=method.upper(),\n            url=url,\n            headers=headers,\n            files=files,\n            data=data or {},\n            json=json,\n            params=params or {},\n            auth=auth,\n            cookies=cookies,\n            hooks=hooks,\n        )\n        prep = self.prepare_request(req)\n\n        proxies = proxies or {}\n\n        settings = self.merge_environment_settings(\n            prep.url, proxies, stream, verify, cert\n        )\n\n        # Send the request.\n        send_kwargs = {\n            'timeout': timeout,\n            'allow_redirects': allow_redirects,\n        }\n        send_kwargs.update(settings)\n        resp = self.send(prep, **send_kwargs)\n\n        return resp\n\n    def get(self, url, **kwargs):\n        r\"\"\"Sends a GET request. Returns :class:`Response` object.\n\n        :param url: URL for the new :class:`Request` object.\n        :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n        :rtype: requests.Response\n        \"\"\"\n\n        kwargs.setdefault('allow_redirects', True)\n        return self.request('GET', url, **kwargs)\n\n    def options(self, url, **kwargs):\n        r\"\"\"Sends a OPTIONS request. Returns :class:`Response` object.\n\n        :param url: URL for the new :class:`Request` object.\n        :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n        :rtype: requests.Response\n        \"\"\"\n\n        kwargs.setdefault('allow_redirects', True)\n        return self.request('OPTIONS', url, **kwargs)\n\n    def head(self, url, **kwargs):\n        r\"\"\"Sends a HEAD request. Returns :class:`Response` object.\n\n        :param url: URL for the new :class:`Request` object.\n        :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n        :rtype: requests.Response\n        \"\"\"\n\n        kwargs.setdefault('allow_redirects', False)\n        return self.request('HEAD', url, **kwargs)\n\n    def post(self, url, data=None, json=None, **kwargs):\n        r\"\"\"Sends a POST request. Returns :class:`Response` object.\n\n        :param url: URL for the new :class:`Request` object.\n        :param data: (optional) Dictionary, list of tuples, bytes, or file-like\n            object to send in the body of the :class:`Request`.\n        :param json: (optional) json to send in the body of the :class:`Request`.\n        :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n        :rtype: requests.Response\n        \"\"\"\n\n        return self.request('POST', url, data=data, json=json, **kwargs)\n\n    def put(self, url, data=None, **kwargs):\n        r\"\"\"Sends a PUT request. Returns :class:`Response` object.\n\n        :param url: URL for the new :class:`Request` object.\n        :param data: (optional) Dictionary, list of tuples, bytes, or file-like\n            object to send in the body of the :class:`Request`.\n        :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n        :rtype: requests.Response\n        \"\"\"\n\n        return self.request('PUT', url, data=data, **kwargs)\n\n    def patch(self, url, data=None, **kwargs):\n        r\"\"\"Sends a PATCH request. Returns :class:`Response` object.\n\n        :param url: URL for the new :class:`Request` object.\n        :param data: (optional) Dictionary, list of tuples, bytes, or file-like\n            object to send in the body of the :class:`Request`.\n        :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n        :rtype: requests.Response\n        \"\"\"\n\n        return self.request('PATCH', url, data=data, **kwargs)\n\n    def delete(self, url, **kwargs):\n        r\"\"\"Sends a DELETE request. Returns :class:`Response` object.\n\n        :param url: URL for the new :class:`Request` object.\n        :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n        :rtype: requests.Response\n        \"\"\"\n\n        return self.request('DELETE', url, **kwargs)\n\n    def send(self, request, **kwargs):\n        \"\"\"Send a given PreparedRequest.\n\n        :rtype: requests.Response\n        \"\"\"\n        # Set defaults that the hooks can utilize to ensure they always have\n        # the correct parameters to reproduce the previous request.\n        kwargs.setdefault('stream', self.stream)\n        kwargs.setdefault('verify', self.verify)\n        kwargs.setdefault('cert', self.cert)\n        kwargs.setdefault('proxies', self.proxies)\n\n        # It's possible that users might accidentally send a Request object.\n        # Guard against that specific failure case.\n        if isinstance(request, Request):\n            raise ValueError('You can only send PreparedRequests.')\n\n        # Set up variables needed for resolve_redirects and dispatching of hooks\n        allow_redirects = kwargs.pop('allow_redirects', True)\n        stream = kwargs.get('stream')\n        hooks = request.hooks\n\n        # Get the appropriate adapter to use\n        adapter = self.get_adapter(url=request.url)\n\n        # Start time (approximately) of the request\n        start = preferred_clock()\n\n        # Send the request\n        r = adapter.send(request, **kwargs)\n\n        # Total elapsed time of the request (approximately)\n        elapsed = preferred_clock() - start\n        r.elapsed = timedelta(seconds=elapsed)\n\n        # Response manipulation hooks\n        r = dispatch_hook('response', hooks, r, **kwargs)\n\n        # Persist cookies\n        if r.history:\n\n            # If the hooks create history then we want those cookies too\n            for resp in r.history:\n                extract_cookies_to_jar(self.cookies, resp.request, resp.raw)\n\n        extract_cookies_to_jar(self.cookies, request, r.raw)\n\n        # Redirect resolving generator.\n        gen = self.resolve_redirects(r, request, **kwargs)\n\n        # Resolve redirects if allowed.\n        history = [resp for resp in gen] if allow_redirects else []\n\n        # Shuffle things around if there's history.\n        if history:\n            # Insert the first (original) request at the start\n            history.insert(0, r)\n            # Get the last request made\n            r = history.pop()\n            r.history = history\n\n        # If redirects aren't being followed, store the response on the Request for Response.next().\n        if not allow_redirects:\n            try:\n                r._next = next(self.resolve_redirects(r, request, yield_requests=True, **kwargs))\n            except StopIteration:\n                pass\n\n        if not stream:\n            r.content\n\n        return r\n\n    def merge_environment_settings(self, url, proxies, stream, verify, cert):\n        \"\"\"\n        Check the environment and merge it with some settings.\n\n        :rtype: dict\n        \"\"\"\n        # Gather clues from the surrounding environment.\n        if self.trust_env:\n            # Set environment's proxies.\n            no_proxy = proxies.get('no_proxy') if proxies is not None else None\n            env_proxies = get_environ_proxies(url, no_proxy=no_proxy)\n            for (k, v) in env_proxies.items():\n                proxies.setdefault(k, v)\n\n            # Look for requests environment configuration and be compatible\n            # with cURL.\n            if verify is True or verify is None:\n                verify = (os.environ.get('REQUESTS_CA_BUNDLE') or\n                          os.environ.get('CURL_CA_BUNDLE'))\n\n        # Merge all the kwargs.\n        proxies = merge_setting(proxies, self.proxies)\n        stream = merge_setting(stream, self.stream)\n        verify = merge_setting(verify, self.verify)\n        cert = merge_setting(cert, self.cert)\n\n        return {'verify': verify, 'proxies': proxies, 'stream': stream,\n                'cert': cert}\n\n    def get_adapter(self, url):\n        \"\"\"\n        Returns the appropriate connection adapter for the given URL.\n\n        :rtype: requests.adapters.BaseAdapter\n        \"\"\"\n        for (prefix, adapter) in self.adapters.items():\n\n            if url.lower().startswith(prefix.lower()):\n                return adapter\n\n        # Nothing matches :-/\n        raise InvalidSchema(\"No connection adapters were found for '%s'\" % url)\n\n    def close(self):\n        \"\"\"Closes all adapters and as such the session\"\"\"\n        for v in self.adapters.values():\n            v.close()\n\n    def mount(self, prefix, adapter):\n        \"\"\"Registers a connection adapter to a prefix.\n\n        Adapters are sorted in descending order by prefix length.\n        \"\"\"\n        self.adapters[prefix] = adapter\n        keys_to_move = [k for k in self.adapters if len(k) < len(prefix)]\n\n        for key in keys_to_move:\n            self.adapters[key] = self.adapters.pop(key)\n\n    def __getstate__(self):\n        state = dict((attr, getattr(self, attr, None)) for attr in self.__attrs__)\n        return state\n\n    def __setstate__(self, state):\n        for attr, value in state.items():\n            setattr(self, attr, value)\n\n\ndef session():\n    \"\"\"\n    Returns a :class:`Session` for context-management.\n\n    .. deprecated:: 1.0.0\n\n        This method has been deprecated since version 1.0.0 and is only kept for\n        backwards compatibility. New code should use :class:`~requests.sessions.Session`\n        to create a session. This may be removed at a future date.\n\n    :rtype: Session\n    \"\"\"\n    return Session()\n", "target": 1}
{"idx": 929, "func": "\"\"\"Base Tornado handlers for the Jupyter server.\"\"\"\n\n# Copyright (c) Jupyter Development Team.\n# Distributed under the terms of the Modified BSD License.\n\nimport datetime\nimport functools\nimport ipaddress\nimport json\nimport mimetypes\nimport os\nimport re\nimport sys\nimport traceback\nimport types\nimport warnings\nfrom http.client import responses\nfrom http.cookies import Morsel\nfrom urllib.parse import urlparse\nfrom jinja2 import TemplateNotFound\nfrom tornado import web, gen, escape, httputil\nfrom tornado.log import app_log\nimport prometheus_client\n\nfrom jupyter_server._sysinfo import get_sys_info\n\nfrom traitlets.config import Application\nfrom ipython_genutils.path import filefind\nfrom ipython_genutils.py3compat import string_types\n\nimport jupyter_server\nfrom jupyter_server._tz import utcnow\nfrom jupyter_server.i18n import combine_translations\nfrom jupyter_server.utils import is_hidden, url_path_join, url_is_absolute, url_escape\nfrom jupyter_server.services.security import csp_report_uri\n\n#-----------------------------------------------------------------------------\n# Top-level handlers\n#-----------------------------------------------------------------------------\nnon_alphanum = re.compile(r'[^A-Za-z0-9]')\n\n_sys_info_cache = None\ndef json_sys_info():\n    global _sys_info_cache\n    if _sys_info_cache is None:\n        _sys_info_cache = json.dumps(get_sys_info())\n    return _sys_info_cache\n\ndef log():\n    if Application.initialized():\n        return Application.instance().log\n    else:\n        return app_log\n\nclass AuthenticatedHandler(web.RequestHandler):\n    \"\"\"A RequestHandler with an authenticated user.\"\"\"\n\n    @property\n    def content_security_policy(self):\n        \"\"\"The default Content-Security-Policy header\n\n        Can be overridden by defining Content-Security-Policy in settings['headers']\n        \"\"\"\n        if 'Content-Security-Policy' in self.settings.get('headers', {}):\n            # user-specified, don't override\n            return self.settings['headers']['Content-Security-Policy']\n\n        return '; '.join([\n            \"frame-ancestors 'self'\",\n            # Make sure the report-uri is relative to the base_url\n            \"report-uri \" + self.settings.get('csp_report_uri', url_path_join(self.base_url, csp_report_uri)),\n        ])\n\n    def set_default_headers(self):\n        headers = {}\n        headers.update(self.settings.get('headers', {}))\n\n        headers[\"Content-Security-Policy\"] = self.content_security_policy\n\n        # Allow for overriding headers\n        for header_name, value in headers.items():\n            try:\n                self.set_header(header_name, value)\n            except Exception as e:\n                # tornado raise Exception (not a subclass)\n                # if method is unsupported (websocket and Access-Control-Allow-Origin\n                # for example, so just ignore)\n                self.log.debug(e)\n\n    def force_clear_cookie(self, name, path=\"/\", domain=None):\n        \"\"\"Deletes the cookie with the given name.\n\n        Tornado's cookie handling currently (Jan 2018) stores cookies in a dict\n        keyed by name, so it can only modify one cookie with a given name per\n        response. The browser can store multiple cookies with the same name\n        but different domains and/or paths. This method lets us clear multiple\n        cookies with the same name.\n\n        Due to limitations of the cookie protocol, you must pass the same\n        path and domain to clear a cookie as were used when that cookie\n        was set (but there is no way to find out on the server side\n        which values were used for a given cookie).\n        \"\"\"\n        name = escape.native_str(name)\n        expires = datetime.datetime.utcnow() - datetime.timedelta(days=365)\n\n        morsel = Morsel()\n        morsel.set(name, '', '\"\"')\n        morsel['expires'] = httputil.format_timestamp(expires)\n        morsel['path'] = path\n        if domain:\n            morsel['domain'] = domain\n        self.add_header(\"Set-Cookie\", morsel.OutputString())\n\n    def clear_login_cookie(self):\n        cookie_options = self.settings.get('cookie_options', {})\n        path = cookie_options.setdefault('path', self.base_url)\n        self.clear_cookie(self.cookie_name, path=path)\n        if path and path != '/':\n            # also clear cookie on / to ensure old cookies are cleared\n            # after the change in path behavior.\n            # N.B. This bypasses the normal cookie handling, which can't update\n            # two cookies with the same name. See the method above.\n            self.force_clear_cookie(self.cookie_name)\n\n    def get_current_user(self):\n        if self.login_handler is None:\n            return 'anonymous'\n        return self.login_handler.get_user(self)\n\n    def skip_check_origin(self):\n        \"\"\"Ask my login_handler if I should skip the origin_check\n\n        For example: in the default LoginHandler, if a request is token-authenticated,\n        origin checking should be skipped.\n        \"\"\"\n        if self.request.method == 'OPTIONS':\n            # no origin-check on options requests, which are used to check origins!\n            return True\n        if self.login_handler is None or not hasattr(self.login_handler, 'should_check_origin'):\n            return False\n        return not self.login_handler.should_check_origin(self)\n\n    @property\n    def token_authenticated(self):\n        \"\"\"Have I been authenticated with a token?\"\"\"\n        if self.login_handler is None or not hasattr(self.login_handler, 'is_token_authenticated'):\n            return False\n        return self.login_handler.is_token_authenticated(self)\n\n    @property\n    def cookie_name(self):\n        default_cookie_name = non_alphanum.sub('-', 'username-{}'.format(\n            self.request.host\n        ))\n        return self.settings.get('cookie_name', default_cookie_name)\n\n    @property\n    def logged_in(self):\n        \"\"\"Is a user currently logged in?\"\"\"\n        user = self.get_current_user()\n        return (user and not user == 'anonymous')\n\n    @property\n    def login_handler(self):\n        \"\"\"Return the login handler for this application, if any.\"\"\"\n        return self.settings.get('login_handler_class', None)\n\n    @property\n    def token(self):\n        \"\"\"Return the login token for this application, if any.\"\"\"\n        return self.settings.get('token', None)\n\n    @property\n    def login_available(self):\n        \"\"\"May a user proceed to log in?\n\n        This returns True if login capability is available, irrespective of\n        whether the user is already logged in or not.\n\n        \"\"\"\n        if self.login_handler is None:\n            return False\n        return bool(self.login_handler.get_login_available(self.settings))\n\n\nclass JupyterHandler(AuthenticatedHandler):\n    \"\"\"Jupyter-specific extensions to authenticated handling\n\n    Mostly property shortcuts to Jupyter-specific settings.\n    \"\"\"\n\n    @property\n    def config(self):\n        return self.settings.get('config', None)\n\n    @property\n    def log(self):\n        \"\"\"use the Jupyter log by default, falling back on tornado's logger\"\"\"\n        return log()\n\n    @property\n    def jinja_template_vars(self):\n        \"\"\"User-supplied values to supply to jinja templates.\"\"\"\n        return self.settings.get('jinja_template_vars', {})\n\n    #---------------------------------------------------------------\n    # URLs\n    #---------------------------------------------------------------\n\n    @property\n    def version_hash(self):\n        \"\"\"The version hash to use for cache hints for static files\"\"\"\n        return self.settings.get('version_hash', '')\n\n    @property\n    def mathjax_url(self):\n        url = self.settings.get('mathjax_url', '')\n        if not url or url_is_absolute(url):\n            return url\n        return url_path_join(self.base_url, url)\n\n    @property\n    def mathjax_config(self):\n        return self.settings.get('mathjax_config', 'TeX-AMS-MML_HTMLorMML-full,Safe')\n\n    @property\n    def base_url(self):\n        return self.settings.get('base_url', '/')\n\n    @property\n    def default_url(self):\n        return self.settings.get('default_url', '')\n\n    @property\n    def ws_url(self):\n        return self.settings.get('websocket_url', '')\n\n    @property\n    def contents_js_source(self):\n        self.log.debug(\"Using contents: %s\", self.settings.get('contents_js_source',\n            'services/contents'))\n        return self.settings.get('contents_js_source', 'services/contents')\n\n    #---------------------------------------------------------------\n    # Manager objects\n    #---------------------------------------------------------------\n\n    @property\n    def kernel_manager(self):\n        return self.settings['kernel_manager']\n\n    @property\n    def contents_manager(self):\n        return self.settings['contents_manager']\n\n    @property\n    def session_manager(self):\n        return self.settings['session_manager']\n\n    @property\n    def terminal_manager(self):\n        return self.settings['terminal_manager']\n\n    @property\n    def kernel_spec_manager(self):\n        return self.settings['kernel_spec_manager']\n\n    @property\n    def config_manager(self):\n        return self.settings['config_manager']\n\n    #---------------------------------------------------------------\n    # CORS\n    #---------------------------------------------------------------\n\n    @property\n    def allow_origin(self):\n        \"\"\"Normal Access-Control-Allow-Origin\"\"\"\n        return self.settings.get('allow_origin', '')\n\n    @property\n    def allow_origin_pat(self):\n        \"\"\"Regular expression version of allow_origin\"\"\"\n        return self.settings.get('allow_origin_pat', None)\n\n    @property\n    def allow_credentials(self):\n        \"\"\"Whether to set Access-Control-Allow-Credentials\"\"\"\n        return self.settings.get('allow_credentials', False)\n\n    def set_default_headers(self):\n        \"\"\"Add CORS headers, if defined\"\"\"\n        super(JupyterHandler, self).set_default_headers()\n        if self.allow_origin:\n            self.set_header(\"Access-Control-Allow-Origin\", self.allow_origin)\n        elif self.allow_origin_pat:\n            origin = self.get_origin()\n            if origin and self.allow_origin_pat.match(origin):\n                self.set_header(\"Access-Control-Allow-Origin\", origin)\n        elif (\n            self.token_authenticated\n            and \"Access-Control-Allow-Origin\" not in\n                self.settings.get('headers', {})\n        ):\n            # allow token-authenticated requests cross-origin by default.\n            # only apply this exception if allow-origin has not been specified.\n            self.set_header('Access-Control-Allow-Origin',\n                self.request.headers.get('Origin', ''))\n\n        if self.allow_credentials:\n            self.set_header(\"Access-Control-Allow-Credentials\", 'true')\n\n    def set_attachment_header(self, filename):\n        \"\"\"Set Content-Disposition: attachment header\n\n        As a method to ensure handling of filename encoding\n        \"\"\"\n        escaped_filename = url_escape(filename)\n        self.set_header('Content-Disposition',\n            'attachment;'\n            \" filename*=utf-8''{utf8}\"\n            .format(\n                utf8=escaped_filename,\n            )\n        )\n\n    def get_origin(self):\n        # Handle WebSocket Origin naming convention differences\n        # The difference between version 8 and 13 is that in 8 the\n        # client sends a \"Sec-Websocket-Origin\" header and in 13 it's\n        # simply \"Origin\".\n        if \"Origin\" in self.request.headers:\n            origin = self.request.headers.get(\"Origin\")\n        else:\n            origin = self.request.headers.get(\"Sec-Websocket-Origin\", None)\n        return origin\n\n    # origin_to_satisfy_tornado is present because tornado requires\n    # check_origin to take an origin argument, but we don't use it\n    def check_origin(self, origin_to_satisfy_tornado=\"\"):\n        \"\"\"Check Origin for cross-site API requests, including websockets\n\n        Copied from WebSocket with changes:\n\n        - allow unspecified host/origin (e.g. scripts)\n        - allow token-authenticated requests\n        \"\"\"\n        if self.allow_origin == '*' or self.skip_check_origin():\n            return True\n\n        host = self.request.headers.get(\"Host\")\n        origin = self.request.headers.get(\"Origin\")\n\n        # If no header is provided, let the request through.\n        # Origin can be None for:\n        # - same-origin (IE, Firefox)\n        # - Cross-site POST form (IE, Firefox)\n        # - Scripts\n        # The cross-site POST (XSRF) case is handled by tornado's xsrf_token\n        if origin is None or host is None:\n            return True\n\n        origin = origin.lower()\n        origin_host = urlparse(origin).netloc\n\n        # OK if origin matches host\n        if origin_host == host:\n            return True\n\n        # Check CORS headers\n        if self.allow_origin:\n            allow = self.allow_origin == origin\n        elif self.allow_origin_pat:\n            allow = bool(self.allow_origin_pat.match(origin))\n        else:\n            # No CORS headers deny the request\n            allow = False\n        if not allow:\n            self.log.warning(\"Blocking Cross Origin API request for %s.  Origin: %s, Host: %s\",\n                self.request.path, origin, host,\n            )\n        return allow\n\n    def check_xsrf_cookie(self):\n        \"\"\"Bypass xsrf cookie checks when token-authenticated\"\"\"\n        if self.token_authenticated or self.settings.get('disable_check_xsrf', False):\n            # Token-authenticated requests do not need additional XSRF-check\n            # Servers without authentication are vulnerable to XSRF\n            return\n        return super(JupyterHandler, self).check_xsrf_cookie()\n\n    def check_host(self):\n        \"\"\"Check the host header if remote access disallowed.\n\n        Returns True if the request should continue, False otherwise.\n        \"\"\"\n        if self.settings.get('allow_remote_access', False):\n            return True\n\n        # Remove port (e.g. ':8888') from host\n        host = re.match(r'^(.*?)(:\\d+)?$', self.request.host).group(1)\n\n        # Browsers format IPv6 addresses like [::1]; we need to remove the []\n        if host.startswith('[') and host.endswith(']'):\n            host = host[1:-1]\n\n        try:\n            addr = ipaddress.ip_address(host)\n        except ValueError:\n            # Not an IP address: check against hostnames\n            allow = host in self.settings.get('local_hostnames', ['localhost'])\n        else:\n            allow = addr.is_loopback\n\n        if not allow:\n            self.log.warning(\n                (\"Blocking request with non-local 'Host' %s (%s). \"\n                 \"If the server should be accessible at that name, \"\n                 \"set ServerApp.allow_remote_access to disable the check.\"),\n                host, self.request.host\n            )\n        return allow\n\n    def prepare(self):\n        if not self.check_host():\n            raise web.HTTPError(403)\n        return super(JupyterHandler, self).prepare()\n\n    #---------------------------------------------------------------\n    # template rendering\n    #---------------------------------------------------------------\n\n    def get_template(self, name):\n        \"\"\"Return the jinja template object for a given name\"\"\"\n        return self.settings['jinja2_env'].get_template(name)\n\n    def render_template(self, name, **ns):\n        ns.update(self.template_namespace)\n        template = self.get_template(name)\n        return template.render(**ns)\n\n    @property\n    def template_namespace(self):\n        return dict(\n            base_url=self.base_url,\n            default_url=self.default_url,\n            ws_url=self.ws_url,\n            logged_in=self.logged_in,\n            allow_password_change=self.settings.get('allow_password_change'),\n            login_available=self.login_available,\n            token_available=bool(self.token),\n            static_url=self.static_url,\n            sys_info=json_sys_info(),\n            contents_js_source=self.contents_js_source,\n            version_hash=self.version_hash,\n            xsrf_form_html=self.xsrf_form_html,\n            token=self.token,\n            xsrf_token=self.xsrf_token.decode('utf8'),\n            nbjs_translations=json.dumps(combine_translations(\n                self.request.headers.get('Accept-Language', ''))),\n            **self.jinja_template_vars\n        )\n\n    def get_json_body(self):\n        \"\"\"Return the body of the request as JSON data.\"\"\"\n        if not self.request.body:\n            return None\n        # Do we need to call body.decode('utf-8') here?\n        body = self.request.body.strip().decode(u'utf-8')\n        try:\n            model = json.loads(body)\n        except Exception as e:\n            self.log.debug(\"Bad JSON: %r\", body)\n            self.log.error(\"Couldn't parse JSON\", exc_info=True)\n            raise web.HTTPError(400, u'Invalid JSON in body of request') from e\n        return model\n\n    def write_error(self, status_code, **kwargs):\n        \"\"\"render custom error pages\"\"\"\n        exc_info = kwargs.get('exc_info')\n        message = ''\n        status_message = responses.get(status_code, 'Unknown HTTP Error')\n        exception = '(unknown)'\n        if exc_info:\n            exception = exc_info[1]\n            # get the custom message, if defined\n            try:\n                message = exception.log_message % exception.args\n            except Exception:\n                pass\n\n            # construct the custom reason, if defined\n            reason = getattr(exception, 'reason', '')\n            if reason:\n                status_message = reason\n\n        # build template namespace\n        ns = dict(\n            status_code=status_code,\n            status_message=status_message,\n            message=message,\n            exception=exception,\n        )\n\n        self.set_header('Content-Type', 'text/html')\n        # render the template\n        try:\n            html = self.render_template('%s.html' % status_code, **ns)\n        except TemplateNotFound:\n            html = self.render_template('error.html', **ns)\n\n        self.write(html)\n\n\nclass APIHandler(JupyterHandler):\n    \"\"\"Base class for API handlers\"\"\"\n\n    def prepare(self):\n        if not self.check_origin():\n            raise web.HTTPError(404)\n        return super(APIHandler, self).prepare()\n\n    def write_error(self, status_code, **kwargs):\n        \"\"\"APIHandler errors are JSON, not human pages\"\"\"\n        self.set_header('Content-Type', 'application/json')\n        message = responses.get(status_code, 'Unknown HTTP Error')\n        reply = {\n            'message': message,\n        }\n        exc_info = kwargs.get('exc_info')\n        if exc_info:\n            e = exc_info[1]\n            if isinstance(e, HTTPError):\n                reply['message'] = e.log_message or message\n                reply['reason'] = e.reason\n            else:\n                reply['message'] = 'Unhandled error'\n                reply['reason'] = None\n                reply['traceback'] = ''.join(traceback.format_exception(*exc_info))\n        self.log.warning(reply['message'])\n        self.finish(json.dumps(reply))\n\n    def get_current_user(self):\n        \"\"\"Raise 403 on API handlers instead of redirecting to human login page\"\"\"\n        # preserve _user_cache so we don't raise more than once\n        if hasattr(self, '_user_cache'):\n            return self._user_cache\n        self._user_cache = user = super(APIHandler, self).get_current_user()\n        return user\n\n    def get_login_url(self):\n        # if get_login_url is invoked in an API handler,\n        # that means @web.authenticated is trying to trigger a redirect.\n        # instead of redirecting, raise 403 instead.\n        if not self.current_user:\n            raise web.HTTPError(403)\n        return super(APIHandler, self).get_login_url()\n\n    @property\n    def content_security_policy(self):\n        csp = '; '.join([\n                super(APIHandler, self).content_security_policy,\n                \"default-src 'none'\",\n            ])\n        return csp\n\n    # set _track_activity = False on API handlers that shouldn't track activity\n    _track_activity = True\n\n    def update_api_activity(self):\n        \"\"\"Update last_activity of API requests\"\"\"\n        # record activity of authenticated requests\n        if (\n            self._track_activity\n            and getattr(self, '_user_cache', None)\n            and self.get_argument('no_track_activity', None) is None\n        ):\n            self.settings['api_last_activity'] = utcnow()\n\n    def finish(self, *args, **kwargs):\n        self.update_api_activity()\n        self.set_header('Content-Type', 'application/json')\n        return super(APIHandler, self).finish(*args, **kwargs)\n\n    def options(self, *args, **kwargs):\n        if 'Access-Control-Allow-Headers' in self.settings.get('headers', {}):\n            self.set_header('Access-Control-Allow-Headers', self.settings['headers']['Access-Control-Allow-Headers'])\n        else:\n            self.set_header('Access-Control-Allow-Headers',\n                            'accept, content-type, authorization, x-xsrftoken')\n        self.set_header('Access-Control-Allow-Methods',\n                        'GET, PUT, POST, PATCH, DELETE, OPTIONS')\n\n        # if authorization header is requested,\n        # that means the request is token-authenticated.\n        # avoid browser-side rejection of the preflight request.\n        # only allow this exception if allow_origin has not been specified\n        # and Jupyter server authentication is enabled.\n        # If the token is not valid, the 'real' request will still be rejected.\n        requested_headers = self.request.headers.get('Access-Control-Request-Headers', '').split(',')\n        if requested_headers and any(\n            h.strip().lower() == 'authorization'\n            for h in requested_headers\n        ) and (\n            # FIXME: it would be even better to check specifically for token-auth,\n            # but there is currently no API for this.\n            self.login_available\n        ) and (\n            self.allow_origin\n            or self.allow_origin_pat\n            or 'Access-Control-Allow-Origin' in self.settings.get('headers', {})\n        ):\n            self.set_header('Access-Control-Allow-Origin',\n                self.request.headers.get('Origin', ''))\n\n\nclass Template404(JupyterHandler):\n    \"\"\"Render our 404 template\"\"\"\n    def prepare(self):\n        raise web.HTTPError(404)\n\n\nclass AuthenticatedFileHandler(JupyterHandler, web.StaticFileHandler):\n    \"\"\"static files should only be accessible when logged in\"\"\"\n\n    @property\n    def content_security_policy(self):\n        # In case we're serving HTML/SVG, confine any Javascript to a unique\n        # origin so it can't interact with the Jupyter server.\n        return super(AuthenticatedFileHandler, self).content_security_policy + \\\n                \"; sandbox allow-scripts\"\n\n    @web.authenticated\n    def get(self, path):\n        if os.path.splitext(path)[1] == '.ipynb' or self.get_argument(\"download\", False):\n            name = path.rsplit('/', 1)[-1]\n            self.set_attachment_header(name)\n\n        return web.StaticFileHandler.get(self, path)\n\n    def get_content_type(self):\n        path = self.absolute_path.strip('/')\n        if '/' in path:\n            _, name = path.rsplit('/', 1)\n        else:\n            name = path\n        if name.endswith('.ipynb'):\n            return 'application/x-ipynb+json'\n        else:\n            cur_mime = mimetypes.guess_type(name)[0]\n            if cur_mime == 'text/plain':\n                return 'text/plain; charset=UTF-8'\n            else:\n                return super(AuthenticatedFileHandler, self).get_content_type()\n\n    def set_headers(self):\n        super(AuthenticatedFileHandler, self).set_headers()\n        # disable browser caching, rely on 304 replies for savings\n        if \"v\" not in self.request.arguments:\n            self.add_header(\"Cache-Control\", \"no-cache\")\n\n    def compute_etag(self):\n        return None\n\n    def validate_absolute_path(self, root, absolute_path):\n        \"\"\"Validate and return the absolute path.\n\n        Requires tornado 3.1\n\n        Adding to tornado's own handling, forbids the serving of hidden files.\n        \"\"\"\n        abs_path = super(AuthenticatedFileHandler, self).validate_absolute_path(root, absolute_path)\n        abs_root = os.path.abspath(root)\n        if is_hidden(abs_path, abs_root) and not self.contents_manager.allow_hidden:\n            self.log.info(\"Refusing to serve hidden file, via 404 Error, use flag 'ContentsManager.allow_hidden' to enable\")\n            raise web.HTTPError(404)\n        return abs_path\n\ndef json_errors(method):\n    \"\"\"Decorate methods with this to return GitHub style JSON errors.\n\n    This should be used on any JSON API on any handler method that can raise HTTPErrors.\n\n    This will grab the latest HTTPError exception using sys.exc_info\n    and then:\n\n    1. Set the HTTP status code based on the HTTPError\n    2. Create and return a JSON body with a message field describing\n       the error in a human readable form.\n    \"\"\"\n    warnings.warn('@json_errors is deprecated in notebook 5.2.0. Subclass APIHandler instead.',\n        DeprecationWarning,\n        stacklevel=2,\n    )\n    @functools.wraps(method)\n    def wrapper(self, *args, **kwargs):\n        self.write_error = types.MethodType(APIHandler.write_error, self)\n        return method(self, *args, **kwargs)\n    return wrapper\n\n#-----------------------------------------------------------------------------\n# File handler\n#-----------------------------------------------------------------------------\n\n# to minimize subclass changes:\nHTTPError = web.HTTPError\n\nclass FileFindHandler(JupyterHandler, web.StaticFileHandler):\n    \"\"\"subclass of StaticFileHandler for serving files from a search path\"\"\"\n\n    # cache search results, don't search for files more than once\n    _static_paths = {}\n\n    def set_headers(self):\n        super(FileFindHandler, self).set_headers()\n        # disable browser caching, rely on 304 replies for savings\n        if \"v\" not in self.request.arguments or \\\n                any(self.request.path.startswith(path) for path in self.no_cache_paths):\n            self.set_header(\"Cache-Control\", \"no-cache\")\n\n    def initialize(self, path, default_filename=None, no_cache_paths=None):\n        self.no_cache_paths = no_cache_paths or []\n\n        if isinstance(path, string_types):\n            path = [path]\n\n        self.root = tuple(\n            os.path.abspath(os.path.expanduser(p)) + os.sep for p in path\n        )\n        self.default_filename = default_filename\n\n    def compute_etag(self):\n        return None\n\n    @classmethod\n    def get_absolute_path(cls, roots, path):\n        \"\"\"locate a file to serve on our static file search path\"\"\"\n        with cls._lock:\n            if path in cls._static_paths:\n                return cls._static_paths[path]\n            try:\n                abspath = os.path.abspath(filefind(path, roots))\n            except IOError:\n                # IOError means not found\n                return ''\n\n            cls._static_paths[path] = abspath\n\n            log().debug(\"Path %s served from %s\"%(path, abspath))\n            return abspath\n\n    def validate_absolute_path(self, root, absolute_path):\n        \"\"\"check if the file should be served (raises 404, 403, etc.)\"\"\"\n        if absolute_path == '':\n            raise web.HTTPError(404)\n\n        for root in self.root:\n            if (absolute_path + os.sep).startswith(root):\n                break\n\n        return super(FileFindHandler, self).validate_absolute_path(root, absolute_path)\n\n\nclass APIVersionHandler(APIHandler):\n\n    def get(self):\n        # not authenticated, so give as few info as possible\n        self.finish(json.dumps({\"version\": jupyter_server.__version__}))\n\n\nclass TrailingSlashHandler(web.RequestHandler):\n    \"\"\"Simple redirect handler that strips trailing slashes\n\n    This should be the first, highest priority handler.\n    \"\"\"\n\n    def get(self):\n        uri = self.request.path.rstrip(\"/\")\n        if uri:\n            self.redirect('?'.join((uri, self.request.query)))\n\n    post = put = get\n\n\nclass MainHandler(JupyterHandler):\n    \"\"\"Simple handler for base_url.\"\"\"\n\n    def get(self):\n        html = self.render_template(\"main.html\")\n        self.write(html)\n\n    post = put = get\n\n\nclass FilesRedirectHandler(JupyterHandler):\n    \"\"\"Handler for redirecting relative URLs to the /files/ handler\"\"\"\n\n    @staticmethod\n    def redirect_to_files(self, path):\n        \"\"\"make redirect logic a reusable static method\n\n        so it can be called from other handlers.\n        \"\"\"\n        cm = self.contents_manager\n        if cm.dir_exists(path):\n            # it's a *directory*, redirect to /tree\n            url = url_path_join(self.base_url, 'tree', url_escape(path))\n        else:\n            orig_path = path\n            # otherwise, redirect to /files\n            parts = path.split('/')\n\n            if not cm.file_exists(path=path) and 'files' in parts:\n                # redirect without files/ iff it would 404\n                # this preserves pre-2.0-style 'files/' links\n                self.log.warning(\"Deprecated files/ URL: %s\", orig_path)\n                parts.remove('files')\n                path = '/'.join(parts)\n\n            if not cm.file_exists(path=path):\n                raise web.HTTPError(404)\n\n            url = url_path_join(self.base_url, 'files', url_escape(path))\n        self.log.debug(\"Redirecting %s to %s\", self.request.path, url)\n        self.redirect(url)\n\n    def get(self, path=''):\n        return self.redirect_to_files(self, path)\n\n\nclass RedirectWithParams(web.RequestHandler):\n    \"\"\"Sam as web.RedirectHandler, but preserves URL parameters\"\"\"\n    def initialize(self, url, permanent=True):\n        self._url = url\n        self._permanent = permanent\n\n    def get(self):\n        sep = '&' if '?' in self._url else '?'\n        url = sep.join([self._url, self.request.query])\n        self.redirect(url, permanent=self._permanent)\n\nclass PrometheusMetricsHandler(JupyterHandler):\n    \"\"\"\n    Return prometheus metrics for this Jupyter server\n    \"\"\"\n    @web.authenticated\n    def get(self):\n        self.set_header('Content-Type', prometheus_client.CONTENT_TYPE_LATEST)\n        self.write(prometheus_client.generate_latest(prometheus_client.REGISTRY))\n\n\n#-----------------------------------------------------------------------------\n# URL pattern fragments for re-use\n#-----------------------------------------------------------------------------\n\n# path matches any number of `/foo[/bar...]` or just `/` or ''\npath_regex = r\"(?P<path>(?:(?:/[^/]+)+|/?))\"\n\n#-----------------------------------------------------------------------------\n# URL to handler mappings\n#-----------------------------------------------------------------------------\n\n\ndefault_handlers = [\n    (r\".*/\", TrailingSlashHandler),\n    (r\"api\", APIVersionHandler),\n    (r'/(robots\\.txt|favicon\\.ico)', web.StaticFileHandler),\n    (r'/metrics', PrometheusMetricsHandler)\n]\n", "target": 1}
{"idx": 930, "func": "# vim: tabstop=4 shiftwidth=4 softtabstop=4\n\n# Copyright 2012 OpenStack LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"); you may\n# not use this file except in compliance with the License. You may obtain\n# a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n# License for the specific language governing permissions and limitations\n# under the License.\n\nimport uuid\n\nimport routes\n\nfrom keystone import catalog\nfrom keystone import exception\nfrom keystone import identity\nfrom keystone import policy\nfrom keystone import token\nfrom keystone.common import logging\nfrom keystone.common import utils\nfrom keystone.common import wsgi\n\n\nLOG = logging.getLogger(__name__)\n\n\nclass AdminRouter(wsgi.ComposingRouter):\n    def __init__(self):\n        mapper = routes.Mapper()\n\n        version_controller = VersionController('admin')\n        mapper.connect('/',\n                       controller=version_controller,\n                       action='get_version')\n\n        # Token Operations\n        auth_controller = TokenController()\n        mapper.connect('/tokens',\n                       controller=auth_controller,\n                       action='authenticate',\n                       conditions=dict(method=['POST']))\n        mapper.connect('/tokens/{token_id}',\n                       controller=auth_controller,\n                       action='validate_token',\n                       conditions=dict(method=['GET']))\n        mapper.connect('/tokens/{token_id}',\n                       controller=auth_controller,\n                       action='validate_token_head',\n                       conditions=dict(method=['HEAD']))\n        mapper.connect('/tokens/{token_id}',\n                       controller=auth_controller,\n                       action='delete_token',\n                       conditions=dict(method=['DELETE']))\n        mapper.connect('/tokens/{token_id}/endpoints',\n                       controller=auth_controller,\n                       action='endpoints',\n                       conditions=dict(method=['GET']))\n\n        # Miscellaneous Operations\n        extensions_controller = AdminExtensionsController()\n        mapper.connect('/extensions',\n                       controller=extensions_controller,\n                       action='get_extensions_info',\n                       conditions=dict(method=['GET']))\n        mapper.connect('/extensions/{extension_alias}',\n                       controller=extensions_controller,\n                       action='get_extension_info',\n                       conditions=dict(method=['GET']))\n        identity_router = identity.AdminRouter()\n        routers = [identity_router]\n        super(AdminRouter, self).__init__(mapper, routers)\n\n\nclass PublicRouter(wsgi.ComposingRouter):\n    def __init__(self):\n        mapper = routes.Mapper()\n\n        version_controller = VersionController('public')\n        mapper.connect('/',\n                       controller=version_controller,\n                       action='get_version')\n\n        # Token Operations\n        auth_controller = TokenController()\n        mapper.connect('/tokens',\n                       controller=auth_controller,\n                       action='authenticate',\n                       conditions=dict(method=['POST']))\n\n        # Miscellaneous\n        extensions_controller = PublicExtensionsController()\n        mapper.connect('/extensions',\n                       controller=extensions_controller,\n                       action='get_extensions_info',\n                       conditions=dict(method=['GET']))\n        mapper.connect('/extensions/{extension_alias}',\n                       controller=extensions_controller,\n                       action='get_extension_info',\n                       conditions=dict(method=['GET']))\n\n        identity_router = identity.PublicRouter()\n        routers = [identity_router]\n\n        super(PublicRouter, self).__init__(mapper, routers)\n\n\nclass PublicVersionRouter(wsgi.ComposingRouter):\n    def __init__(self):\n        mapper = routes.Mapper()\n        version_controller = VersionController('public')\n        mapper.connect('/',\n                       controller=version_controller,\n                       action='get_versions')\n        routers = []\n        super(PublicVersionRouter, self).__init__(mapper, routers)\n\n\nclass AdminVersionRouter(wsgi.ComposingRouter):\n    def __init__(self):\n        mapper = routes.Mapper()\n        version_controller = VersionController('admin')\n        mapper.connect('/',\n                       controller=version_controller,\n                       action='get_versions')\n        routers = []\n        super(AdminVersionRouter, self).__init__(mapper, routers)\n\n\nclass VersionController(wsgi.Application):\n    def __init__(self, version_type):\n        self.catalog_api = catalog.Manager()\n        self.url_key = \"%sURL\" % version_type\n\n        super(VersionController, self).__init__()\n\n    def _get_identity_url(self, context):\n        catalog_ref = self.catalog_api.get_catalog(\n                context=context,\n                user_id=None,\n                tenant_id=None)\n        for region, region_ref in catalog_ref.iteritems():\n            for service, service_ref in region_ref.iteritems():\n                if service == 'identity':\n                    return service_ref[self.url_key]\n\n        raise exception.NotImplemented()\n\n    def _get_versions_list(self, context):\n        \"\"\"The list of versions is dependent on the context.\"\"\"\n        identity_url = self._get_identity_url(context)\n        if not identity_url.endswith('/'):\n            identity_url = identity_url + '/'\n\n        versions = {}\n        versions['v2.0'] = {\n            \"id\": \"v2.0\",\n            \"status\": \"beta\",\n            \"updated\": \"2011-11-19T00:00:00Z\",\n            \"links\": [\n                {\n                    \"rel\": \"self\",\n                    \"href\": identity_url,\n                }, {\n                    \"rel\": \"describedby\",\n                    \"type\": \"text/html\",\n                    \"href\": \"http://docs.openstack.org/api/openstack-\"\n                                \"identity-service/2.0/content/\"\n                }, {\n                    \"rel\": \"describedby\",\n                    \"type\": \"application/pdf\",\n                    \"href\": \"http://docs.openstack.org/api/openstack-\"\n                                \"identity-service/2.0/identity-dev-guide-\"\n                                \"2.0.pdf\"\n                }\n            ],\n            \"media-types\": [\n                {\n                    \"base\": \"application/json\",\n                    \"type\": \"application/vnd.openstack.identity-v2.0\"\n                                \"+json\"\n                }, {\n                    \"base\": \"application/xml\",\n                    \"type\": \"application/vnd.openstack.identity-v2.0\"\n                                \"+xml\"\n                }\n            ]\n        }\n\n        return versions\n\n    def get_versions(self, context):\n        versions = self._get_versions_list(context)\n        return wsgi.render_response(status=(300, 'Multiple Choices'), body={\n            \"versions\": {\n                \"values\": versions.values()\n            }\n        })\n\n    def get_version(self, context):\n        versions = self._get_versions_list(context)\n        return wsgi.render_response(body={\n            \"version\": versions['v2.0']\n        })\n\n\nclass NoopController(wsgi.Application):\n    def __init__(self):\n        super(NoopController, self).__init__()\n\n    def noop(self, context):\n        return {}\n\n\nclass TokenController(wsgi.Application):\n    def __init__(self):\n        self.catalog_api = catalog.Manager()\n        self.identity_api = identity.Manager()\n        self.token_api = token.Manager()\n        self.policy_api = policy.Manager()\n        super(TokenController, self).__init__()\n\n    def authenticate(self, context, auth=None):\n        \"\"\"Authenticate credentials and return a token.\n\n        Accept auth as a dict that looks like::\n\n            {\n                \"auth\":{\n                    \"passwordCredentials\":{\n                        \"username\":\"test_user\",\n                        \"password\":\"mypass\"\n                    },\n                    \"tenantName\":\"customer-x\"\n                }\n            }\n\n        In this case, tenant is optional, if not provided the token will be\n        considered \"unscoped\" and can later be used to get a scoped token.\n\n        Alternatively, this call accepts auth with only a token and tenant\n        that will return a token that is scoped to that tenant.\n        \"\"\"\n\n        token_id = uuid.uuid4().hex\n        if 'passwordCredentials' in auth:\n            username = auth['passwordCredentials'].get('username', '')\n            password = auth['passwordCredentials'].get('password', '')\n            tenant_name = auth.get('tenantName', None)\n\n            user_id = auth['passwordCredentials'].get('userId', None)\n            if username:\n                user_ref = self.identity_api.get_user_by_name(\n                        context=context, user_name=username)\n                if user_ref:\n                    user_id = user_ref['id']\n\n            # more compat\n            tenant_id = auth.get('tenantId', None)\n            if tenant_name:\n                tenant_ref = self.identity_api.get_tenant_by_name(\n                        context=context, tenant_name=tenant_name)\n                if tenant_ref:\n                    tenant_id = tenant_ref['id']\n\n            try:\n                auth_info = self.identity_api.authenticate(context=context,\n                                                           user_id=user_id,\n                                                           password=password,\n                                                           tenant_id=tenant_id)\n                (user_ref, tenant_ref, metadata_ref) = auth_info\n\n                # If the user is disabled don't allow them to authenticate\n                if not user_ref.get('enabled', True):\n                    LOG.warning('User %s is disabled' % user_id)\n                    raise exception.Unauthorized()\n            except AssertionError as e:\n                raise exception.Unauthorized(e.message)\n\n            token_ref = self.token_api.create_token(\n                    context, token_id, dict(id=token_id,\n                                            user=user_ref,\n                                            tenant=tenant_ref,\n                                            metadata=metadata_ref))\n            if tenant_ref:\n                catalog_ref = self.catalog_api.get_catalog(\n                        context=context,\n                        user_id=user_ref['id'],\n                        tenant_id=tenant_ref['id'],\n                        metadata=metadata_ref)\n            else:\n                catalog_ref = {}\n\n        elif 'token' in auth:\n            token = auth['token'].get('id', None)\n\n            tenant_name = auth.get('tenantName')\n\n            # more compat\n            if tenant_name:\n                tenant_ref = self.identity_api.get_tenant_by_name(\n                        context=context, tenant_name=tenant_name)\n                tenant_id = tenant_ref['id']\n            else:\n                tenant_id = auth.get('tenantId', None)\n\n            try:\n                old_token_ref = self.token_api.get_token(context=context,\n                                                         token_id=token)\n            except exception.NotFound:\n                raise exception.Unauthorized()\n\n            user_ref = old_token_ref['user']\n\n            # If the user is disabled don't allow them to authenticate\n            current_user_ref = self.identity_api.get_user(\n                                                    context=context,\n                                                    user_id=user_ref['id'])\n            if not current_user_ref.get('enabled', True):\n                LOG.warning('User %s is disabled' % user_ref['id'])\n                raise exception.Unauthorized()\n\n            tenants = self.identity_api.get_tenants_for_user(context,\n                                                             user_ref['id'])\n            if tenant_id:\n                assert tenant_id in tenants\n\n            tenant_ref = self.identity_api.get_tenant(context=context,\n                                                      tenant_id=tenant_id)\n            if tenant_ref:\n                metadata_ref = self.identity_api.get_metadata(\n                        context=context,\n                        user_id=user_ref['id'],\n                        tenant_id=tenant_ref['id'])\n                catalog_ref = self.catalog_api.get_catalog(\n                        context=context,\n                        user_id=user_ref['id'],\n                        tenant_id=tenant_ref['id'],\n                        metadata=metadata_ref)\n            else:\n                metadata_ref = {}\n                catalog_ref = {}\n\n            token_ref = self.token_api.create_token(\n                    context, token_id, dict(id=token_id,\n                                            user=user_ref,\n                                            tenant=tenant_ref,\n                                            metadata=metadata_ref))\n\n        # TODO(termie): optimize this call at some point and put it into the\n        #               the return for metadata\n        # fill out the roles in the metadata\n        roles_ref = []\n        for role_id in metadata_ref.get('roles', []):\n            roles_ref.append(self.identity_api.get_role(context, role_id))\n        logging.debug('TOKEN_REF %s', token_ref)\n        return self._format_authenticate(token_ref, roles_ref, catalog_ref)\n\n    def _get_token_ref(self, context, token_id, belongs_to=None):\n        \"\"\"Returns a token if a valid one exists.\n\n        Optionally, limited to a token owned by a specific tenant.\n\n        \"\"\"\n        # TODO(termie): this stuff should probably be moved to middleware\n        self.assert_admin(context)\n\n        token_ref = self.token_api.get_token(context=context,\n                                             token_id=token_id)\n\n        if belongs_to:\n            assert token_ref['tenant']['id'] == belongs_to\n\n        return token_ref\n\n    # admin only\n    def validate_token_head(self, context, token_id):\n        \"\"\"Check that a token is valid.\n\n        Optionally, also ensure that it is owned by a specific tenant.\n\n        Identical to ``validate_token``, except does not return a response.\n\n        \"\"\"\n        belongs_to = context['query_string'].get(\"belongsTo\")\n        assert self._get_token_ref(context, token_id, belongs_to)\n\n    # admin only\n    def validate_token(self, context, token_id):\n        \"\"\"Check that a token is valid.\n\n        Optionally, also ensure that it is owned by a specific tenant.\n\n        Returns metadata about the token along any associated roles.\n\n        \"\"\"\n        belongs_to = context['query_string'].get(\"belongsTo\")\n        token_ref = self._get_token_ref(context, token_id, belongs_to)\n\n        # TODO(termie): optimize this call at some point and put it into the\n        #               the return for metadata\n        # fill out the roles in the metadata\n        metadata_ref = token_ref['metadata']\n        roles_ref = []\n        for role_id in metadata_ref.get('roles', []):\n            roles_ref.append(self.identity_api.get_role(context, role_id))\n\n        # Get a service catalog if belongs_to is not none\n        # This is needed for on-behalf-of requests\n        catalog_ref = None\n        if belongs_to is not None:\n            catalog_ref = self.catalog_api.get_catalog(\n                context=context,\n                user_id=token_ref['user']['id'],\n                tenant_id=token_ref['tenant']['id'],\n                metadata=metadata_ref)\n        return self._format_token(token_ref, roles_ref, catalog_ref)\n\n    def delete_token(self, context, token_id):\n        \"\"\"Delete a token, effectively invalidating it for authz.\"\"\"\n        # TODO(termie): this stuff should probably be moved to middleware\n        self.assert_admin(context)\n\n        self.token_api.delete_token(context=context, token_id=token_id)\n\n    def endpoints(self, context, token_id):\n        \"\"\"Return a list of endpoints available to the token.\"\"\"\n        raise exception.NotImplemented()\n\n    def _format_authenticate(self, token_ref, roles_ref, catalog_ref):\n        o = self._format_token(token_ref, roles_ref)\n        o['access']['serviceCatalog'] = self._format_catalog(catalog_ref)\n        return o\n\n    def _format_token(self, token_ref, roles_ref, catalog_ref=None):\n        user_ref = token_ref['user']\n        metadata_ref = token_ref['metadata']\n        expires = token_ref['expires']\n        if expires is not None:\n            expires = utils.isotime(expires)\n        o = {'access': {'token': {'id': token_ref['id'],\n                                  'expires': expires,\n                                  },\n                        'user': {'id': user_ref['id'],\n                                 'name': user_ref['name'],\n                                 'username': user_ref['name'],\n                                 'roles': roles_ref,\n                                 'roles_links': metadata_ref.get('roles_links',\n                                                               [])\n                                 }\n                        }\n             }\n        if 'tenant' in token_ref and token_ref['tenant']:\n            token_ref['tenant']['enabled'] = True\n            o['access']['token']['tenant'] = token_ref['tenant']\n        if catalog_ref is not None:\n            o['access']['serviceCatalog'] = self._format_catalog(catalog_ref)\n        return o\n\n    def _format_catalog(self, catalog_ref):\n        \"\"\"Munge catalogs from internal to output format\n        Internal catalogs look like:\n\n        {$REGION: {\n            {$SERVICE: {\n                $key1: $value1,\n                ...\n                }\n            }\n        }\n\n        The legacy api wants them to look like\n\n        [{'name': $SERVICE[name],\n          'type': $SERVICE,\n          'endpoints': [{\n              'tenantId': $tenant_id,\n              ...\n              'region': $REGION,\n              }],\n          'endpoints_links': [],\n         }]\n\n        \"\"\"\n        if not catalog_ref:\n            return {}\n\n        services = {}\n        for region, region_ref in catalog_ref.iteritems():\n            for service, service_ref in region_ref.iteritems():\n                new_service_ref = services.get(service, {})\n                new_service_ref['name'] = service_ref.pop('name')\n                new_service_ref['type'] = service\n                new_service_ref['endpoints_links'] = []\n                service_ref['region'] = region\n\n                endpoints_ref = new_service_ref.get('endpoints', [])\n                endpoints_ref.append(service_ref)\n\n                new_service_ref['endpoints'] = endpoints_ref\n                services[service] = new_service_ref\n\n        return services.values()\n\n\nclass ExtensionsController(wsgi.Application):\n    \"\"\"Base extensions controller to be extended by public and admin API's.\"\"\"\n\n    def __init__(self, extensions=None):\n        super(ExtensionsController, self).__init__()\n\n        self.extensions = extensions or {}\n\n    def get_extensions_info(self, context):\n        return {'extensions': {'values': self.extensions.values()}}\n\n    def get_extension_info(self, context, extension_alias):\n        try:\n            return {'extension': self.extensions[extension_alias]}\n        except KeyError:\n            raise exception.NotFound(target=extension_alias)\n\n\nclass PublicExtensionsController(ExtensionsController):\n    pass\n\n\nclass AdminExtensionsController(ExtensionsController):\n    def __init__(self, *args, **kwargs):\n        super(AdminExtensionsController, self).__init__(*args, **kwargs)\n\n        # TODO(dolph): Extensions should obviously provide this information\n        #               themselves, but hardcoding it here allows us to match\n        #               the API spec in the short term with minimal complexity.\n        self.extensions['OS-KSADM'] = {\n            'name': 'Openstack Keystone Admin',\n            'namespace': 'http://docs.openstack.org/identity/api/ext/'\n                         'OS-KSADM/v1.0',\n            'alias': 'OS-KSADM',\n            'updated': '2011-08-19T13:25:27-06:00',\n            'description': 'Openstack extensions to Keystone v2.0 API '\n                           'enabling Admin Operations.',\n            'links': [\n                {\n                    'rel': 'describedby',\n                    # TODO(dolph): link needs to be revised after\n                    #              bug 928059 merges\n                    'type': 'text/html',\n                    'href': ('https://github.com/openstack/'\n                        'identity-api'),\n                }\n            ]\n        }\n\n\n@logging.fail_gracefully\ndef public_app_factory(global_conf, **local_conf):\n    conf = global_conf.copy()\n    conf.update(local_conf)\n    return PublicRouter()\n\n\n@logging.fail_gracefully\ndef admin_app_factory(global_conf, **local_conf):\n    conf = global_conf.copy()\n    conf.update(local_conf)\n    return AdminRouter()\n\n\n@logging.fail_gracefully\ndef public_version_app_factory(global_conf, **local_conf):\n    conf = global_conf.copy()\n    conf.update(local_conf)\n    return PublicVersionRouter()\n\n\n@logging.fail_gracefully\ndef admin_version_app_factory(global_conf, **local_conf):\n    conf = global_conf.copy()\n    conf.update(local_conf)\n    return AdminVersionRouter()\n", "target": 0}
{"idx": 931, "func": "import json\nimport os\nimport re\nimport tempfile\n\nimport anchore_engine.configuration.localconfig\nfrom anchore_engine.utils import run_command, run_command_list, manifest_to_digest, AnchoreException\nfrom anchore_engine.subsys import logger\nfrom anchore_engine.common.errors import AnchoreError\n\ndef manifest_to_digest_shellout(rawmanifest):\n    ret = None\n    tmpmanifest = None\n    try:\n        fd,tmpmanifest = tempfile.mkstemp()\n        os.write(fd, rawmanifest.encode('utf-8'))\n        os.close(fd)\n\n        localconfig = anchore_engine.configuration.localconfig.get_config()\n        global_timeout = localconfig.get('skopeo_global_timeout', 0)\n        try:\n            global_timeout = int(global_timeout)\n            if global_timeout < 0:\n                global_timeout = 0\n        except:\n            global_timeout = 0\n\n        if global_timeout:\n            global_timeout_str = \"--command-timeout {}s\".format(global_timeout)\n        else:\n            global_timeout_str = \"\"\n\n        cmd = \"skopeo {} manifest-digest {}\".format(global_timeout_str, tmpmanifest)\n        rc, sout, serr = run_command(cmd)\n        if rc == 0 and re.match(\"^sha256:.*\", str(sout, 'utf-8')):\n            ret = sout.strip()\n        else:\n            logger.warn(\"failed to calculate digest from schema v1 manifest: cmd={} rc={} sout={} serr={}\".format(cmd, rc, sout, serr))\n            raise SkopeoError(cmd=cmd, rc=rc, err=serr, out=sout, msg='Failed to calculate digest from schema v1 manifest', )\n    except Exception as err:\n        raise err\n    finally:\n        if tmpmanifest:\n            os.remove(tmpmanifest)\n\n    return(ret)\n\ndef copy_image_from_docker_archive(source_archive, dest_dir):\n    cmdstr = \"skopeo copy docker-archive:{} oci:{}:image\".format(source_archive, dest_dir)\n    cmd = cmdstr.split()\n    try:\n        rc, sout, serr = run_command_list(cmd)\n        if rc != 0:\n            raise SkopeoError(cmd=cmd, rc=rc, out=sout, err=serr)\n        else:\n            logger.debug(\"command succeeded: cmd=\"+str(cmdstr)+\" stdout=\"+str(sout).strip()+\" stderr=\"+str(serr).strip())\n\n    except Exception as err:\n        logger.error(\"command failed with exception - \" + str(err))\n        raise err\n\ndef download_image(fulltag, copydir, user=None, pw=None, verify=True, manifest=None, parent_manifest=None, use_cache_dir=None, dest_type='oci'):\n    try:\n        proc_env = os.environ.copy()\n        if user and pw:\n            proc_env['SKOPUSER'] = user\n            proc_env['SKOPPASS'] = pw\n            credstr = '--src-creds \\\"${SKOPUSER}\\\":\\\"${SKOPPASS}\\\"'\n        else:\n            credstr = \"\"\n\n        if verify:\n            tlsverifystr = \"--src-tls-verify=true\"\n        else:\n            tlsverifystr = \"--src-tls-verify=false\"\n\n        if use_cache_dir and os.path.exists(use_cache_dir):\n            cachestr = \"--dest-shared-blob-dir \" + use_cache_dir\n        else:\n            cachestr = \"\"\n\n        localconfig = anchore_engine.configuration.localconfig.get_config()\n        global_timeout = localconfig.get('skopeo_global_timeout', 0)\n        try:\n            global_timeout = int(global_timeout)\n            if global_timeout < 0:\n                global_timeout = 0\n        except:\n            global_timeout = 0\n\n        if global_timeout:\n            global_timeout_str = \"--command-timeout {}s\".format(global_timeout)\n        else:\n            global_timeout_str = \"\"\n\n        os_overrides = [\"\"]\n        if manifest:\n            manifest_data = json.loads(manifest)\n\n            # skopeo doesn't support references in manifests for copy/download operations, with oci dest type - if found, override with dir dest_type\n            for l in manifest_data.get('layers', []):\n                if 'foreign.diff' in l.get('mediaType', \"\"):\n                    dest_type = 'dir'\n\n            if parent_manifest:\n                parent_manifest_data = json.loads(parent_manifest)\n            else:\n                parent_manifest_data = {}\n\n            if parent_manifest_data:\n                for mlist in parent_manifest_data.get('manifests', []):\n                    imageos = mlist.get('platform', {}).get('os', \"\")\n                    if imageos not in [\"\", 'linux']:\n                        # add a windows os override to the list of override attempts, to complete the options that are supported by skopeo\n                        dest_type = 'dir'\n                        os_overrides.insert(0, \"windows\")\n                        break\n\n        for os_override in os_overrides:\n            success = False\n            if os_override not in [\"\", 'linux']:\n                dest_type = 'dir'\n                os_override_str = \"--override-os {}\".format(os_override)\n            else:\n                os_override_str = \"\"\n                \n            if dest_type == 'oci':\n                if manifest:\n                    with open(os.path.join(copydir, \"manifest.json\"), 'w') as OFH:\n                        OFH.write(manifest)\n\n                if parent_manifest:\n                    with open(os.path.join(copydir, \"parent_manifest.json\"), 'w') as OFH:\n                        OFH.write(parent_manifest)\n                        \n                cmd = [\"/bin/sh\", \"-c\", \"skopeo {} {} copy {} {} {} docker://{} oci:{}:image\".format(os_override_str, global_timeout_str, tlsverifystr, credstr, cachestr, fulltag, copydir)]\n            else:\n                cmd = [\"/bin/sh\", \"-c\", \"skopeo {} {} copy {} {} docker://{} dir:{}\".format(os_override_str, global_timeout_str, tlsverifystr, credstr, fulltag, copydir)]\n\n            cmdstr = ' '.join(cmd)\n            try:\n                rc, sout, serr = run_command_list(cmd, env=proc_env)\n                if rc != 0:\n                    skopeo_error = SkopeoError(cmd=cmd, rc=rc, out=sout, err=serr)\n                    if skopeo_error.error_code != AnchoreError.OSARCH_MISMATCH.name:\n                        raise SkopeoError(cmd=cmd, rc=rc, out=sout, err=serr)                    \n                else:\n                    logger.debug(\"command succeeded: cmd=\"+str(cmdstr)+\" stdout=\"+str(sout).strip()+\" stderr=\"+str(serr).strip())\n                    success = True                    \n\n            except Exception as err:\n                logger.error(\"command failed with exception - \" + str(err))\n                raise err\n\n            if success:\n                break\n        if not success:\n            logger.error(\"could not download image\")\n            raise Exception(\"could not download image\")\n    except Exception as err:\n        raise err\n\n    return(True)\n\ndef get_repo_tags_skopeo(url, registry, repo, user=None, pw=None, verify=None, lookuptag=None):\n    try:\n        proc_env = os.environ.copy()\n        if user and pw:\n            proc_env['SKOPUSER'] = user\n            proc_env['SKOPPASS'] = pw\n            credstr = '--creds \\\"${SKOPUSER}\\\":\\\"${SKOPPASS}\\\"'\n        else:\n            credstr = \"\"\n\n        if verify:\n            tlsverifystr = \"--tls-verify=true\"\n        else:\n            tlsverifystr = \"--tls-verify=false\"\n            \n        localconfig = anchore_engine.configuration.localconfig.get_config()\n        global_timeout = localconfig.get('skopeo_global_timeout', 0)\n        try:\n            global_timeout = int(global_timeout)\n            if global_timeout < 0:\n                global_timeout = 0\n        except:\n            global_timeout = 0\n\n        if global_timeout:\n            global_timeout_str = \"--command-timeout {}s\".format(global_timeout)\n        else:\n            global_timeout_str = \"\"\n\n        pullstring = registry + \"/\" + repo\n        if lookuptag:\n            pullstring = pullstring + \":\" + lookuptag\n\n        repotags = []\n\n        cmd = [\"/bin/sh\", \"-c\", \"skopeo {} inspect {} {} docker://{}\".format(global_timeout_str, tlsverifystr, credstr, pullstring)]\n        cmdstr = ' '.join(cmd)\n        try:\n            rc, sout, serr = run_command_list(cmd, env=proc_env)\n            sout = str(sout, 'utf-8') if sout else None\n            if rc != 0:\n                raise SkopeoError(cmd=cmd, rc=rc, out=sout, err=serr)\n            else:\n                logger.debug(\"command succeeded: cmd=\"+str(cmdstr)+\" stdout=\"+str(sout).strip()+\" stderr=\"+str(serr).strip())\n        except Exception as err:\n            logger.error(\"command failed with exception - \" + str(err))\n            raise err\n\n        data = json.loads(sout)\n        repotags = data.get('RepoTags', [])\n    except Exception as err:\n        raise err\n\n    if not repotags:\n        raise Exception(\"no tags found for input repo from skopeo\")\n\n    return(repotags)\n\ndef get_image_manifest_skopeo_raw(pullstring, user=None, pw=None, verify=True):\n    ret = None\n    try:\n        proc_env = os.environ.copy()\n        if user and pw:\n            proc_env['SKOPUSER'] = user\n            proc_env['SKOPPASS'] = pw\n            credstr = '--creds \\\"${SKOPUSER}\\\":\\\"${SKOPPASS}\\\"'\n        else:\n            credstr = \"\"\n\n        if verify:\n            tlsverifystr = \"--tls-verify=true\"\n        else:\n            tlsverifystr = \"--tls-verify=false\"\n\n        localconfig = anchore_engine.configuration.localconfig.get_config()\n        global_timeout = localconfig.get('skopeo_global_timeout', 0)            \n        try:\n            global_timeout = int(global_timeout)\n            if global_timeout < 0:\n                global_timeout = 0\n        except:\n            global_timeout = 0\n\n        if global_timeout:\n            global_timeout_str = \"--command-timeout {}s\".format(global_timeout)\n        else:\n            global_timeout_str = \"\"\n\n        os_override_strs = [\"\", \"--override-os windows\"]\n        try:\n            success = False\n            for os_override_str in os_override_strs:\n                cmd = [\"/bin/sh\", \"-c\", \"skopeo {} {} inspect --raw {} {} docker://{}\".format(global_timeout_str, os_override_str, tlsverifystr, credstr, pullstring)]\n                cmdstr = ' '.join(cmd)\n                try:\n                    rc, sout, serr = run_command_list(cmd, env=proc_env)\n                    if rc != 0:\n                        skopeo_error = SkopeoError(cmd=cmd, rc=rc, out=sout, err=serr)\n                        if skopeo_error.error_code != AnchoreError.OSARCH_MISMATCH.name:\n                            raise SkopeoError(cmd=cmd, rc=rc, out=sout, err=serr)\n                    else:\n                        logger.debug(\"command succeeded: cmd=\"+str(cmdstr)+\" stdout=\"+str(sout).strip()+\" stderr=\"+str(serr).strip())\n                        success = True\n                except Exception as err:\n                    logger.error(\"command failed with exception - \" + str(err))\n                    raise err\n\n                if success:\n                    sout = str(sout, 'utf-8') if sout else None    \n                    ret = sout\n                    break\n\n            if not success:\n                logger.error(\"could not retrieve manifest\")\n                raise Exception(\"could not retrieve manifest\")\n            \n        except Exception as err:\n            raise err\n    except Exception as err:\n        raise err\n\n    return(ret)\n\ndef get_image_manifest_skopeo(url, registry, repo, intag=None, indigest=None, topdigest=None, user=None, pw=None, verify=True, topmanifest=None):\n    manifest = {}\n    digest = None\n    testDigest = None\n\n    if indigest:\n        pullstring = registry + \"/\" + repo + \"@\" + indigest\n    elif intag:\n        pullstring = registry + \"/\" + repo + \":\" + intag\n    else:\n        raise Exception(\"invalid input - must supply either an intag or indigest\")\n\n    try:\n        try:\n            rawmanifest = get_image_manifest_skopeo_raw(pullstring, user=user, pw=pw, verify=verify)\n            digest = manifest_to_digest(rawmanifest)\n            manifest = json.loads(rawmanifest)\n            if topmanifest is None:\n                topmanifest = json.loads(rawmanifest)\n            if not topdigest:\n                topdigest = digest\n\n            if manifest.get('schemaVersion') == 2 and manifest.get('mediaType') == 'application/vnd.docker.distribution.manifest.list.v2+json':\n                # Get the arch-specific version for amd64 and linux\n                new_digest = None\n                for entry in manifest.get('manifests'):\n                    platform = entry.get('platform')\n                    if platform and platform.get('architecture') in ['amd64'] and platform.get('os') in ['linux', 'windows']:\n                        new_digest = entry.get('digest')\n                        break\n\n                return get_image_manifest_skopeo(url=url, registry=registry, repo=repo, intag=None, indigest=new_digest, user=user, pw=pw, verify=verify, topdigest=topdigest, topmanifest=topmanifest)\n        except Exception as err:\n            logger.warn(\"CMD failed - exception: \" + str(err))\n            raise err\n\n    except Exception as err:\n        import traceback\n        traceback.print_exc()\n        raise err\n\n    if not manifest or not digest:\n        raise SkopeoError(msg=\"No digest/manifest from skopeo\")\n\n    return(manifest, digest, topdigest, topmanifest)\n\nclass SkopeoError(AnchoreException):\n\n    def __init__(self, cmd=None, rc=None, err=None, out=None, msg='Error encountered in skopeo operation'):\n        from anchore_engine.common.errors import AnchoreError\n\n        self.cmd = ' '.join(cmd) if isinstance(cmd, list) else cmd\n        self.exitcode = rc\n        self.stderr = str(err).replace('\\r', ' ').replace('\\n', ' ').strip() if err else None\n        self.stdout = str(out).replace('\\r', ' ').replace('\\n', ' ').strip() if out else None\n        self.msg = msg\n        try:\n            if \"unauthorized\" in self.stderr:\n                self.error_code = AnchoreError.REGISTRY_PERMISSION_DENIED.name\n            elif \"manifest unknown\" in self.stderr:\n                self.error_code = AnchoreError.REGISTRY_IMAGE_NOT_FOUND.name\n            elif \"connection refused\" in self.stderr or \"no route to host\" in self.stderr:\n                self.error_code = AnchoreError.REGISTRY_NOT_ACCESSIBLE.name\n            elif \"error pinging registry\" in self.stderr:\n                self.error_code = AnchoreError.REGISTRY_NOT_SUPPORTED.name\n            elif \"no image found in manifest list for architecture amd64, OS linux\" in self.stderr:\n                self.error_code = AnchoreError.OSARCH_MISMATCH.name\n            else:\n                self.error_code = AnchoreError.SKOPEO_UNKNOWN_ERROR.name\n        except:\n            self.error_code = AnchoreError.UNKNOWN.name\n        \n\n    def __repr__(self):\n        return '{}. cmd={}, rc={}, stdout={}, stderr={}, error_code={}'.format(self.msg, self.cmd, self.exitcode, self.stdout, self.stderr, self.error_code)\n\n    def __str__(self):\n        return '{}. cmd={}, rc={}, stdout={}, stderr={}, error_code={}'.format(self.msg, self.cmd, self.exitcode, self.stdout, self.stderr, self.error_code)\n", "target": 0}
{"idx": 932, "func": "# -*- coding: utf-8 -*-\nfrom __future__ import with_statement\nimport json\nimport datetime\nfrom cms.utils.urlutils import admin_reverse\n\nfrom djangocms_text_ckeditor.cms_plugins import TextPlugin\nfrom djangocms_text_ckeditor.models import Text\nfrom django.contrib import admin\nfrom django.contrib.admin.models import LogEntry\nfrom django.contrib.admin.sites import site\nfrom django.contrib.auth.models import Permission, AnonymousUser\nfrom django.contrib.sites.models import Site\nfrom django.core.urlresolvers import reverse\nfrom django.http import (Http404, HttpResponseBadRequest, HttpResponseForbidden, HttpResponse,\n                         QueryDict, HttpResponseNotFound)\nfrom django.utils.datastructures import MultiValueDictKeyError\nfrom django.utils.encoding import smart_str\nfrom django.utils import timezone\nfrom django.utils.six.moves.urllib.parse import urlparse\n\nfrom cms.admin.change_list import CMSChangeList\nfrom cms.admin.forms import PageForm, AdvancedSettingsForm\nfrom cms.admin.pageadmin import PageAdmin\nfrom cms.admin.permissionadmin import PagePermissionInlineAdmin\nfrom cms.api import create_page, create_title, add_plugin, assign_user_to_page, publish_page\nfrom cms.constants import PLUGIN_MOVE_ACTION\nfrom cms.models import UserSettings, StaticPlaceholder\nfrom cms.models.pagemodel import Page\nfrom cms.models.permissionmodels import GlobalPagePermission, PagePermission\nfrom cms.models.placeholdermodel import Placeholder\nfrom cms.models.pluginmodel import CMSPlugin\nfrom cms.models.titlemodels import Title\nfrom cms.test_utils import testcases as base\nfrom cms.test_utils.testcases import CMSTestCase, URL_CMS_PAGE_DELETE, URL_CMS_PAGE, URL_CMS_TRANSLATION_DELETE\nfrom cms.test_utils.util.context_managers import SettingsOverride\nfrom cms.test_utils.util.fuzzy_int import FuzzyInt\nfrom cms.utils import get_cms_setting\nfrom cms.utils.compat import DJANGO_1_4, DJANGO_1_6\nfrom cms.utils.compat.dj import get_user_model, force_unicode\n\n\nclass AdminTestsBase(CMSTestCase):\n    @property\n    def admin_class(self):\n        return site._registry[Page]\n\n    def _get_guys(self, admin_only=False, use_global_permissions=True):\n        admiN_user = self.get_superuser()\n        if admin_only:\n            return admiN_user\n        USERNAME = 'test'\n\n        if get_user_model().USERNAME_FIELD == 'email':\n            normal_guy = get_user_model().objects.create_user(USERNAME, 'test@test.com', 'test@test.com')\n        else:\n            normal_guy = get_user_model().objects.create_user(USERNAME, 'test@test.com', USERNAME)\n\n        normal_guy.is_staff = True\n        normal_guy.is_active = True\n        normal_guy.save()\n        normal_guy.user_permissions = Permission.objects.filter(\n            codename__in=['change_page', 'change_title', 'add_page', 'add_title', 'delete_page', 'delete_title']\n        )\n        if use_global_permissions:\n            gpp = GlobalPagePermission.objects.create(\n                user=normal_guy,\n                can_change=True,\n                can_delete=True,\n                can_change_advanced_settings=False,\n                can_publish=True,\n                can_change_permissions=False,\n                can_move_page=True,\n            )\n            gpp.sites = Site.objects.all()\n        return admiN_user, normal_guy\n\n\nclass AdminTestCase(AdminTestsBase):\n\n    def test_extension_not_in_admin(self):\n        admin_user, staff = self._get_guys()\n        with self.login_user_context(admin_user):\n            request = self.get_request('/admin/cms/page/1/', 'en',)\n            response = site.index(request)\n            self.assertNotContains(response, '/mytitleextension/')\n            self.assertNotContains(response, '/mypageextension/')\n\n    def test_permissioned_page_list(self):\n        \"\"\"\n        Makes sure that a user with restricted page permissions can view\n        the page list.\n        \"\"\"\n        admin_user, normal_guy = self._get_guys(use_global_permissions=False)\n\n        current_site = Site.objects.get(pk=1)\n        page = create_page(\"Test page\", \"nav_playground.html\", \"en\",\n                           site=current_site, created_by=admin_user)\n\n        PagePermission.objects.create(page=page, user=normal_guy)\n\n        with self.login_user_context(normal_guy):\n            resp = self.client.get(URL_CMS_PAGE)\n            self.assertEqual(resp.status_code, 200)\n\n    def test_edit_does_not_reset_page_adv_fields(self):\n        \"\"\"\n        Makes sure that if a non-superuser with no rights to edit advanced page\n        fields edits a page, those advanced fields are not touched.\n        \"\"\"\n        OLD_PAGE_NAME = 'Test Page'\n        NEW_PAGE_NAME = 'Test page 2'\n        REVERSE_ID = 'Test'\n        OVERRIDE_URL = 'my/override/url'\n\n        admin_user, normal_guy = self._get_guys()\n\n        current_site = Site.objects.get(pk=1)\n\n        # The admin creates the page\n        page = create_page(OLD_PAGE_NAME, \"nav_playground.html\", \"en\",\n                           site=current_site, created_by=admin_user)\n        page.reverse_id = REVERSE_ID\n        page.save()\n        title = page.get_title_obj()\n        title.has_url_overwrite = True\n        title.path = OVERRIDE_URL\n        title.save()\n\n        self.assertEqual(page.get_title(), OLD_PAGE_NAME)\n        self.assertEqual(page.reverse_id, REVERSE_ID)\n        self.assertEqual(title.overwrite_url, OVERRIDE_URL)\n\n        # The user edits the page (change the page name for ex.)\n        page_data = {\n            'title': NEW_PAGE_NAME,\n            'slug': page.get_slug(),\n            'language': title.language,\n            'site': page.site.pk,\n            'template': page.template,\n            'pagepermission_set-TOTAL_FORMS': 0,\n            'pagepermission_set-INITIAL_FORMS': 0,\n            'pagepermission_set-MAX_NUM_FORMS': 0,\n            'pagepermission_set-2-TOTAL_FORMS': 0,\n            'pagepermission_set-2-INITIAL_FORMS': 0,\n            'pagepermission_set-2-MAX_NUM_FORMS': 0\n        }\n        # required only if user haves can_change_permission\n        with self.login_user_context(normal_guy):\n            resp = self.client.post(base.URL_CMS_PAGE_CHANGE % page.pk, page_data,\n                                    follow=True)\n            self.assertEqual(resp.status_code, 200)\n            self.assertTemplateNotUsed(resp, 'admin/login.html')\n            page = Page.objects.get(pk=page.pk)\n\n            self.assertEqual(page.get_title(), NEW_PAGE_NAME)\n            self.assertEqual(page.reverse_id, REVERSE_ID)\n            title = page.get_title_obj()\n            self.assertEqual(title.overwrite_url, OVERRIDE_URL)\n\n        # The admin edits the page (change the page name for ex.)\n        page_data = {\n            'title': OLD_PAGE_NAME,\n            'slug': page.get_slug(),\n            'language': title.language,\n            'site': page.site.pk,\n            'template': page.template,\n            'reverse_id': page.reverse_id,\n            'pagepermission_set-TOTAL_FORMS': 0,  # required only if user haves can_change_permission\n            'pagepermission_set-INITIAL_FORMS': 0,\n            'pagepermission_set-MAX_NUM_FORMS': 0,\n            'pagepermission_set-2-TOTAL_FORMS': 0,\n            'pagepermission_set-2-INITIAL_FORMS': 0,\n            'pagepermission_set-2-MAX_NUM_FORMS': 0\n        }\n        with self.login_user_context(admin_user):\n            resp = self.client.post(base.URL_CMS_PAGE_CHANGE % page.pk, page_data,\n                                    follow=True)\n            self.assertEqual(resp.status_code, 200)\n            self.assertTemplateNotUsed(resp, 'admin/login.html')\n            page = Page.objects.get(pk=page.pk)\n\n            self.assertEqual(page.get_title(), OLD_PAGE_NAME)\n            self.assertEqual(page.reverse_id, REVERSE_ID)\n            title = page.get_title_obj()\n            self.assertEqual(title.overwrite_url, OVERRIDE_URL)\n\n    def test_edit_does_not_reset_apphook(self):\n        \"\"\"\n        Makes sure that if a non-superuser with no rights to edit advanced page\n        fields edits a page, those advanced fields are not touched.\n        \"\"\"\n        OLD_PAGE_NAME = 'Test Page'\n        NEW_PAGE_NAME = 'Test page 2'\n        REVERSE_ID = 'Test'\n        APPLICATION_URLS = 'project.sampleapp.urls'\n\n        admin_user, normal_guy = self._get_guys()\n\n        current_site = Site.objects.get(pk=1)\n\n        # The admin creates the page\n        page = create_page(OLD_PAGE_NAME, \"nav_playground.html\", \"en\",\n                           site=current_site, created_by=admin_user)\n        page.reverse_id = REVERSE_ID\n        page.save()\n        title = page.get_title_obj()\n        title.has_url_overwrite = True\n\n        title.save()\n        page.application_urls = APPLICATION_URLS\n        page.save()\n        self.assertEqual(page.get_title(), OLD_PAGE_NAME)\n        self.assertEqual(page.reverse_id, REVERSE_ID)\n        self.assertEqual(page.application_urls, APPLICATION_URLS)\n\n        # The user edits the page (change the page name for ex.)\n        page_data = {\n            'title': NEW_PAGE_NAME,\n            'slug': page.get_slug(),\n            'language': title.language,\n            'site': page.site.pk,\n            'template': page.template,\n            'pagepermission_set-TOTAL_FORMS': 0,\n            'pagepermission_set-INITIAL_FORMS': 0,\n            'pagepermission_set-MAX_NUM_FORMS': 0,\n            'pagepermission_set-2-TOTAL_FORMS': 0,\n            'pagepermission_set-2-INITIAL_FORMS': 0,\n            'pagepermission_set-2-MAX_NUM_FORMS': 0,\n        }\n\n        with self.login_user_context(normal_guy):\n            resp = self.client.post(base.URL_CMS_PAGE_CHANGE % page.pk, page_data,\n                                    follow=True)\n            self.assertEqual(resp.status_code, 200)\n            self.assertTemplateNotUsed(resp, 'admin/login.html')\n            page = Page.objects.get(pk=page.pk)\n            self.assertEqual(page.get_title(), NEW_PAGE_NAME)\n            self.assertEqual(page.reverse_id, REVERSE_ID)\n            self.assertEqual(page.application_urls, APPLICATION_URLS)\n            title = page.get_title_obj()\n            # The admin edits the page (change the page name for ex.)\n            page_data = {\n                'title': OLD_PAGE_NAME,\n                'slug': page.get_slug(),\n                'language': title.language,\n                'site': page.site.pk,\n                'template': page.template,\n                'reverse_id': page.reverse_id,\n            }\n\n        with self.login_user_context(admin_user):\n            resp = self.client.post(base.URL_CMS_PAGE_ADVANCED_CHANGE % page.pk, page_data,\n                                    follow=True)\n            self.assertEqual(resp.status_code, 200)\n            self.assertTemplateNotUsed(resp, 'admin/login.html')\n            resp = self.client.post(base.URL_CMS_PAGE_CHANGE % page.pk, page_data,\n                                    follow=True)\n            self.assertEqual(resp.status_code, 200)\n            self.assertTemplateNotUsed(resp, 'admin/login.html')\n            page = Page.objects.get(pk=page.pk)\n\n            self.assertEqual(page.get_title(), OLD_PAGE_NAME)\n            self.assertEqual(page.reverse_id, REVERSE_ID)\n            self.assertEqual(page.application_urls, '')\n\n    def test_2apphooks_with_same_namespace(self):\n        PAGE1 = 'Test Page'\n        PAGE2 = 'Test page 2'\n        APPLICATION_URLS = 'project.sampleapp.urls'\n\n        admin_user, normal_guy = self._get_guys()\n\n        current_site = Site.objects.get(pk=1)\n\n        # The admin creates the page\n        page = create_page(PAGE1, \"nav_playground.html\", \"en\",\n                           site=current_site, created_by=admin_user)\n        page2 = create_page(PAGE2, \"nav_playground.html\", \"en\",\n                            site=current_site, created_by=admin_user)\n\n        page.application_urls = APPLICATION_URLS\n        page.application_namespace = \"space1\"\n        page.save()\n        page2.application_urls = APPLICATION_URLS\n        page2.save()\n\n        # The admin edits the page (change the page name for ex.)\n        page_data = {\n            'title': PAGE2,\n            'slug': page2.get_slug(),\n            'language': 'en',\n            'site': page.site.pk,\n            'template': page2.template,\n            'application_urls': 'SampleApp',\n            'application_namespace': 'space1',\n        }\n\n        with self.login_user_context(admin_user):\n            resp = self.client.post(base.URL_CMS_PAGE_ADVANCED_CHANGE % page.pk, page_data)\n            self.assertEqual(resp.status_code, 302)\n            self.assertEqual(Page.objects.filter(application_namespace=\"space1\").count(), 1)\n            resp = self.client.post(base.URL_CMS_PAGE_ADVANCED_CHANGE % page2.pk, page_data)\n            self.assertEqual(resp.status_code, 200)\n            page_data['application_namespace'] = 'space2'\n            resp = self.client.post(base.URL_CMS_PAGE_ADVANCED_CHANGE % page2.pk, page_data)\n            self.assertEqual(resp.status_code, 302)\n\n    def test_delete(self):\n        admin_user = self.get_superuser()\n        create_page(\"home\", \"nav_playground.html\", \"en\",\n                           created_by=admin_user, published=True)\n        page = create_page(\"delete-page\", \"nav_playground.html\", \"en\",\n                           created_by=admin_user, published=True)\n        create_page('child-page', \"nav_playground.html\", \"en\",\n                    created_by=admin_user, published=True, parent=page)\n        body = page.placeholders.get(slot='body')\n        add_plugin(body, 'TextPlugin', 'en', body='text')\n        page.publish('en')\n        with self.login_user_context(admin_user):\n            data = {'post': 'yes'}\n            with self.assertNumQueries(FuzzyInt(300, 407)):\n                response = self.client.post(URL_CMS_PAGE_DELETE % page.pk, data)\n            self.assertRedirects(response, URL_CMS_PAGE)\n\n    def test_delete_diff_language(self):\n        admin_user = self.get_superuser()\n        create_page(\"home\", \"nav_playground.html\", \"en\",\n                           created_by=admin_user, published=True)\n        page = create_page(\"delete-page\", \"nav_playground.html\", \"en\",\n                           created_by=admin_user, published=True)\n        create_page('child-page', \"nav_playground.html\", \"de\",\n                    created_by=admin_user, published=True, parent=page)\n        body = page.placeholders.get(slot='body')\n        add_plugin(body, 'TextPlugin', 'en', body='text')\n        page.publish('en')\n        with self.login_user_context(admin_user):\n            data = {'post': 'yes'}\n            with self.assertNumQueries(FuzzyInt(300, 394)):\n                response = self.client.post(URL_CMS_PAGE_DELETE % page.pk, data)\n            self.assertRedirects(response, URL_CMS_PAGE)\n\n    def test_search_fields(self):\n        superuser = self.get_superuser()\n        from django.contrib.admin import site\n\n        with self.login_user_context(superuser):\n            for model, admin_instance in site._registry.items():\n                if model._meta.app_label != 'cms':\n                    continue\n                if not admin_instance.search_fields:\n                    continue\n                url = admin_reverse('cms_%s_changelist' % model._meta.module_name)\n                response = self.client.get('%s?q=1' % url)\n                errmsg = response.content\n                self.assertEqual(response.status_code, 200, errmsg)\n\n    def test_delete_translation(self):\n        admin_user = self.get_superuser()\n        page = create_page(\"delete-page-translation\", \"nav_playground.html\", \"en\",\n                           created_by=admin_user, published=True)\n        create_title(\"de\", \"delete-page-translation-2\", page, slug=\"delete-page-translation-2\")\n        create_title(\"es-mx\", \"delete-page-translation-es\", page, slug=\"delete-page-translation-es\")\n        with self.login_user_context(admin_user):\n            response = self.client.get(URL_CMS_TRANSLATION_DELETE % page.pk, {'language': 'de'})\n            self.assertEqual(response.status_code, 200)\n            response = self.client.post(URL_CMS_TRANSLATION_DELETE % page.pk, {'language': 'de'})\n            self.assertRedirects(response, URL_CMS_PAGE)\n            response = self.client.get(URL_CMS_TRANSLATION_DELETE % page.pk, {'language': 'es-mx'})\n            self.assertEqual(response.status_code, 200)\n            response = self.client.post(URL_CMS_TRANSLATION_DELETE % page.pk, {'language': 'es-mx'})\n            self.assertRedirects(response, URL_CMS_PAGE)\n\n    def test_change_dates(self):\n        admin_user, staff = self._get_guys()\n        page = create_page('test-page', 'nav_playground.html', 'en')\n        page.publish('en')\n        draft = page.get_draft_object()\n\n        with self.settings(USE_TZ=False):\n            original_date = draft.publication_date\n            original_end_date = draft.publication_end_date\n            new_date = timezone.now() - datetime.timedelta(days=1)\n            new_end_date = timezone.now() + datetime.timedelta(days=1)\n            url = admin_reverse('cms_page_dates', args=(draft.pk,))\n            with self.login_user_context(admin_user):\n                response = self.client.post(url, {\n                    'language': 'en',\n                    'site': draft.site.pk,\n                    'publication_date_0': new_date.date(),\n                    'publication_date_1': new_date.strftime(\"%H:%M:%S\"),\n                    'publication_end_date_0': new_end_date.date(),\n                    'publication_end_date_1': new_end_date.strftime(\"%H:%M:%S\"),\n                })\n                self.assertEqual(response.status_code, 302)\n                draft = Page.objects.get(pk=draft.pk)\n                self.assertNotEqual(draft.publication_date.timetuple(), original_date.timetuple())\n                self.assertEqual(draft.publication_date.timetuple(), new_date.timetuple())\n                self.assertEqual(draft.publication_end_date.timetuple(), new_end_date.timetuple())\n                if original_end_date:\n                    self.assertNotEqual(draft.publication_end_date.timetuple(), original_end_date.timetuple())\n\n        with self.settings(USE_TZ=True):\n            original_date = draft.publication_date\n            original_end_date = draft.publication_end_date\n            new_date = timezone.localtime(timezone.now()) - datetime.timedelta(days=1)\n            new_end_date = timezone.localtime(timezone.now()) + datetime.timedelta(days=1)\n            url = admin_reverse('cms_page_dates', args=(draft.pk,))\n            with self.login_user_context(admin_user):\n                response = self.client.post(url, {\n                    'language': 'en',\n                    'site': draft.site.pk,\n                    'publication_date_0': new_date.date(),\n                    'publication_date_1': new_date.strftime(\"%H:%M:%S\"),\n                    'publication_end_date_0': new_end_date.date(),\n                    'publication_end_date_1': new_end_date.strftime(\"%H:%M:%S\"),\n                })\n                self.assertEqual(response.status_code, 302)\n                draft = Page.objects.get(pk=draft.pk)\n                self.assertNotEqual(draft.publication_date.timetuple(), original_date.timetuple())\n                self.assertEqual(timezone.localtime(draft.publication_date).timetuple(), new_date.timetuple())\n                self.assertEqual(timezone.localtime(draft.publication_end_date).timetuple(), new_end_date.timetuple())\n                if original_end_date:\n                    self.assertNotEqual(draft.publication_end_date.timetuple(), original_end_date.timetuple())\n\n    def test_change_template(self):\n        admin_user, staff = self._get_guys()\n        request = self.get_request('/admin/cms/page/1/', 'en')\n        request.method = \"POST\"\n        pageadmin = site._registry[Page]\n        with self.login_user_context(staff):\n            self.assertRaises(Http404, pageadmin.change_template, request, 1)\n            page = create_page('test-page', 'nav_playground.html', 'en')\n            response = pageadmin.change_template(request, page.pk)\n            self.assertEqual(response.status_code, 403)\n        url = admin_reverse('cms_page_change_template', args=(page.pk,))\n        with self.login_user_context(admin_user):\n            response = self.client.post(url, {'template': 'doesntexist'})\n            self.assertEqual(response.status_code, 400)\n            response = self.client.post(url, {'template': get_cms_setting('TEMPLATES')[0][0]})\n            self.assertEqual(response.status_code, 200)\n\n    def test_get_permissions(self):\n        page = create_page('test-page', 'nav_playground.html', 'en')\n        url = admin_reverse('cms_page_get_permissions', args=(page.pk,))\n        response = self.client.get(url)\n        if DJANGO_1_6:\n            self.assertEqual(response.status_code, 200)\n            self.assertTemplateUsed(response, 'admin/login.html')\n        else:\n            self.assertEqual(response.status_code, 302)\n            self.assertRedirects(response, '/en/admin/login/?next=/en/admin/cms/page/%s/permissions/' % page.pk)\n        admin_user = self.get_superuser()\n        with self.login_user_context(admin_user):\n            response = self.client.get(url)\n            self.assertEqual(response.status_code, 200)\n            self.assertTemplateNotUsed(response, 'admin/login.html')\n\n    def test_changelist_items(self):\n        admin_user = self.get_superuser()\n        first_level_page = create_page('level1', 'nav_playground.html', 'en')\n        second_level_page_top = create_page('level21', \"nav_playground.html\", \"en\",\n                                            created_by=admin_user, published=True, parent=first_level_page)\n        second_level_page_bottom = create_page('level22', \"nav_playground.html\", \"en\",\n                                               created_by=admin_user, published=True,\n                                               parent=self.reload(first_level_page))\n        third_level_page = create_page('level3', \"nav_playground.html\", \"en\",\n                                       created_by=admin_user, published=True, parent=second_level_page_top)\n        self.assertEqual(Page.objects.all().count(), 4)\n\n        url = admin_reverse('cms_%s_changelist' % Page._meta.module_name)\n        request = self.get_request(url)\n\n        request.session = {}\n        request.user = admin_user\n\n        page_admin = site._registry[Page]\n\n        cl_params = [request, page_admin.model, page_admin.list_display,\n            page_admin.list_display_links, page_admin.list_filter,\n            page_admin.date_hierarchy, page_admin.search_fields,\n            page_admin.list_select_related, page_admin.list_per_page]\n        if hasattr(page_admin, 'list_max_show_all'):  # django 1.4\n            cl_params.append(page_admin.list_max_show_all)\n        cl_params.extend([page_admin.list_editable, page_admin])\n        cl = CMSChangeList(*tuple(cl_params))\n\n        cl.set_items(request)\n\n        root_page = cl.get_items()[0]\n\n        self.assertEqual(root_page, first_level_page)\n        self.assertEqual(root_page.get_children()[0], second_level_page_top)\n        self.assertEqual(root_page.get_children()[1], second_level_page_bottom)\n        self.assertEqual(root_page.get_children()[0].get_children()[0], third_level_page)\n\n    def test_changelist_get_results(self):\n        admin_user = self.get_superuser()\n        first_level_page = create_page('level1', 'nav_playground.html', 'en', published=True)\n        second_level_page_top = create_page('level21', \"nav_playground.html\", \"en\",\n                                            created_by=admin_user, published=True,\n                                            parent=first_level_page)\n        second_level_page_bottom = create_page('level22', \"nav_playground.html\", \"en\", # nopyflakes\n                                               created_by=admin_user, published=True,\n                                               parent=self.reload(first_level_page))\n        third_level_page = create_page('level3', \"nav_playground.html\", \"en\", # nopyflakes\n                                       created_by=admin_user, published=True,\n                                       parent=second_level_page_top)\n        fourth_level_page = create_page('level23', \"nav_playground.html\", \"en\", # nopyflakes\n                                        created_by=admin_user,\n                                        parent=self.reload(first_level_page))\n        self.assertEqual(Page.objects.all().count(), 9)\n\n        url = admin_reverse('cms_%s_changelist' % Page._meta.module_name)\n\n        request = self.get_request(url)\n        request.session = {}\n        request.user = admin_user\n\n        page_admin = site._registry[Page]\n\n        # full blown page list. only draft pages are taken into account\n        cl_params = [request, page_admin.model, page_admin.list_display,\n            page_admin.list_display_links, page_admin.list_filter,\n            page_admin.date_hierarchy, page_admin.search_fields,\n            page_admin.list_select_related, page_admin.list_per_page]\n        if hasattr(page_admin, 'list_max_show_all'):  # django 1.4\n            cl_params.append(page_admin.list_max_show_all)\n        cl_params.extend([page_admin.list_editable, page_admin])\n        cl = CMSChangeList(*tuple(cl_params))\n        cl.get_results(request)\n        self.assertEqual(cl.full_result_count, 5)\n        self.assertEqual(cl.result_count, 5)\n\n        # only one unpublished page is returned\n        request = self.get_request(url+'?q=level23')\n        request.session = {}\n        request.user = admin_user\n        cl_params[0] = request\n        cl = CMSChangeList(*tuple(cl_params))\n        cl.get_results(request)\n        self.assertEqual(cl.full_result_count, 5)\n        self.assertEqual(cl.result_count, 1)\n\n        # a number of pages matches the query\n        request = self.get_request(url+'?q=level2')\n        request.session = {}\n        request.user = admin_user\n        cl_params[0] = request\n        cl = CMSChangeList(*tuple(cl_params))\n        cl.get_results(request)\n        self.assertEqual(cl.full_result_count, 5)\n        self.assertEqual(cl.result_count, 3)\n\n    def test_changelist_tree(self):\n        \"\"\" This test checks for proper jstree cookie unquoting.\n\n        It should be converted to a selenium test to actually test the jstree behaviour.\n        Cookie set below is just a forged example (from live session)\n        \"\"\"\n        admin_user = self.get_superuser()\n        first_level_page = create_page('level1', 'nav_playground.html', 'en')\n        second_level_page_top = create_page('level21', \"nav_playground.html\", \"en\",\n                                            created_by=admin_user, published=True, parent=first_level_page)\n        second_level_page_bottom = create_page('level22', \"nav_playground.html\", \"en\",\n                                               created_by=admin_user, published=True,\n                                               parent=self.reload(first_level_page))\n        third_level_page = create_page('level3', \"nav_playground.html\", \"en\",\n                                       created_by=admin_user, published=True, parent=second_level_page_top)\n\n        url = admin_reverse('cms_%s_changelist' % Page._meta.module_name)\n\n        if get_user_model().USERNAME_FIELD == 'email':\n            self.client.login(username='admin@django-cms.org', password='admin@django-cms.org')\n        else:\n            self.client.login(username='admin', password='admin')\n\n        self.client.cookies['djangocms_nodes_open'] = 'page_1%2Cpage_2'\n        response = self.client.get(url)\n        self.assertEqual(response.status_code, 200)\n        self.assertEqual(response.context[\"open_menu_trees\"], [1, 2])\n        # tests descendants method for the lazy load ajax call\n        url = \"%s%d/en/descendants/\" % (url, first_level_page.pk)\n        response = self.client.get(url)\n        self.assertEqual(response.status_code, 200)\n        # should include both direct descendant pages\n        self.assertContains(response, 'id=\"page_%s\"' % second_level_page_top.pk)\n        self.assertContains(response, 'id=\"page_%s\"' % second_level_page_bottom.pk)\n        # but not any further down the tree\n        self.assertNotContains(response, 'id=\"page_%s\"' % third_level_page.pk)\n        self.assertNotContains(response, 'None')\n\n    def test_unihandecode_doesnt_break_404_in_admin(self):\n        self.get_superuser()\n\n        if get_user_model().USERNAME_FIELD == 'email':\n            self.client.login(username='admin@django-cms.org', password='admin@django-cms.org')\n        else:\n            self.client.login(username='admin', password='admin')\n\n        response = self.client.get('/en/admin/cms/page/1/?language=en')\n        self.assertEqual(response.status_code, 404)\n\n    def test_tree_displays_in_correct_language(self):\n        '''\n        Test to prove and protect that the page titles in the tree are\n        displayed in the currently set language.\n        '''\n        admin_guy, normal_guy = self._get_guys(use_global_permissions=False)\n        site = Site.objects.get(pk=1)\n\n        en_title = \"EN Page\"\n        es_title = \"ES Pagina\"\n\n        # Create a page in en\n        page = create_page(en_title, \"nav_playground.html\", \"en\", site=site, created_by=admin)\n        # Add a es-mx translation for this page\n        create_title(\"es-mx\", es_title, page, slug=\"es_pagina\")\n\n        url = admin_reverse('cms_%s_changelist' % Page._meta.module_name)\n        url_pat = '<a href=\"{0}/{1}/preview/\"[^>]*>{2}</a>'\n\n        with self.login_user_context(admin_guy):\n            # Check the EN version of the tree...\n            response = self.client.get(url, {'language': 'en'})\n            self.assertRegexpMatches(str(response.content), url_pat.format(page.pk, 'en', en_title, ))\n\n            # Check the ES version of the tree...\n            response = self.client.get(url, {'language': 'es-mx'})\n            self.assertRegexpMatches(str(response.content), url_pat.format(page.pk, 'es-mx', es_title, ))\n\n    def test_empty_placeholder_in_correct_language(self):\n        \"\"\"\n        Test that Cleaning a placeholder only affect current language contents\n        \"\"\"\n        # create some objects\n        page_en = create_page(\"EmptyPlaceholderTestPage (EN)\", \"nav_playground.html\", \"en\")\n        ph = page_en.placeholders.get(slot=\"body\")\n\n        # add the text plugin to the en version of the page\n        add_plugin(ph, \"TextPlugin\", \"en\", body=\"Hello World EN 1\")\n        add_plugin(ph, \"TextPlugin\", \"en\", body=\"Hello World EN 2\")\n\n        # creating a de title of the page and adding plugins to it\n        create_title(\"de\", page_en.get_title(), page_en, slug=page_en.get_slug())\n        add_plugin(ph, \"TextPlugin\", \"de\", body=\"Hello World DE\")\n        add_plugin(ph, \"TextPlugin\", \"de\", body=\"Hello World DE 2\")\n        add_plugin(ph, \"TextPlugin\", \"de\", body=\"Hello World DE 3\")\n\n        # before cleaning the de placeholder\n        self.assertEqual(ph.get_plugins('en').count(), 2)\n        self.assertEqual(ph.get_plugins('de').count(), 3)\n\n        admin_user, staff = self._get_guys()\n        with self.login_user_context(admin_user):\n            url = '%s?language=de' % admin_reverse('cms_page_clear_placeholder', args=[ph.pk])\n            response = self.client.post(url, {'test': 0})\n\n        self.assertEqual(response.status_code, 302)\n\n        # After cleaning the de placeholder, en placeholder must still have all the plugins\n        self.assertEqual(ph.get_plugins('en').count(), 2)\n        self.assertEqual(ph.get_plugins('de').count(), 0)\n\n\nclass AdminTests(AdminTestsBase):\n    # TODO: needs tests for actual permissions, not only superuser/normaluser\n\n    def setUp(self):\n        self.page = create_page(\"testpage\", \"nav_playground.html\", \"en\")\n\n    def get_admin(self):\n        User = get_user_model()\n\n        fields = dict(email=\"admin@django-cms.org\", is_staff=True, is_superuser=True)\n\n        if (User.USERNAME_FIELD != 'email'):\n            fields[User.USERNAME_FIELD] = \"admin\"\n\n        usr = User(**fields)\n        usr.set_password(getattr(usr, User.USERNAME_FIELD))\n        usr.save()\n        return usr\n\n    def get_permless(self):\n        User = get_user_model()\n\n        fields = dict(email=\"permless@django-cms.org\", is_staff=True)\n\n        if (User.USERNAME_FIELD != 'email'):\n            fields[User.USERNAME_FIELD] = \"permless\"\n\n        usr = User(**fields)\n        usr.set_password(getattr(usr, User.USERNAME_FIELD))\n        usr.save()\n        return usr\n\n    def get_page(self):\n        return self.page\n\n    def test_change_publish_unpublish(self):\n        page = self.get_page()\n        permless = self.get_permless()\n        with self.login_user_context(permless):\n            request = self.get_request()\n            response = self.admin_class.publish_page(request, page.pk, \"en\")\n            self.assertEqual(response.status_code, 403)\n            page = self.reload(page)\n            self.assertFalse(page.is_published('en'))\n\n            request = self.get_request(post_data={'no': 'data'})\n            response = self.admin_class.publish_page(request, page.pk, \"en\")\n            # Forbidden\n            self.assertEqual(response.status_code, 403)\n            self.assertFalse(page.is_published('en'))\n\n        admin_user = self.get_admin()\n        with self.login_user_context(admin_user):\n            request = self.get_request(post_data={'no': 'data'})\n            response = self.admin_class.publish_page(request, page.pk, \"en\")\n            self.assertEqual(response.status_code, 302)\n\n            page = self.reload(page)\n            self.assertTrue(page.is_published('en'))\n\n            response = self.admin_class.unpublish(request, page.pk, \"en\")\n            self.assertEqual(response.status_code, 302)\n\n            page = self.reload(page)\n            self.assertFalse(page.is_published('en'))\n\n    def test_change_status_adds_log_entry(self):\n        page = self.get_page()\n        admin_user = self.get_admin()\n        with self.login_user_context(admin_user):\n            request = self.get_request(post_data={'no': 'data'})\n            self.assertFalse(LogEntry.objects.count())\n            response = self.admin_class.publish_page(request, page.pk, \"en\")\n            self.assertEqual(response.status_code, 302)\n            self.assertEqual(1, LogEntry.objects.count())\n            self.assertEqual(page.pk, int(LogEntry.objects.all()[0].object_id))\n\n    def test_change_innavigation(self):\n        page = self.get_page()\n        permless = self.get_permless()\n        admin_user = self.get_admin()\n        with self.login_user_context(permless):\n            request = self.get_request()\n            response = self.admin_class.change_innavigation(request, page.pk)\n            self.assertEqual(response.status_code, 403)\n        with self.login_user_context(permless):\n            request = self.get_request(post_data={'no': 'data'})\n            self.assertRaises(Http404, self.admin_class.change_innavigation,\n                              request, page.pk + 100)\n        with self.login_user_context(permless):\n            request = self.get_request(post_data={'no': 'data'})\n            response = self.admin_class.change_innavigation(request, page.pk)\n            self.assertEqual(response.status_code, 403)\n        with self.login_user_context(admin_user):\n            request = self.get_request(post_data={'no': 'data'})\n            old = page.in_navigation\n            response = self.admin_class.change_innavigation(request, page.pk)\n            # These asserts are for #3589\n            self.assertContains(response, 'lang=\"en\"')\n            self.assertContains(response, './%s/en/preview/' % page.pk)\n            self.assertEqual(response.status_code, 200)\n            page = self.reload(page)\n            self.assertEqual(old, not page.in_navigation)\n\n    def test_publish_page_requires_perms(self):\n        permless = self.get_permless()\n        with self.login_user_context(permless):\n            request = self.get_request()\n            request.method = \"POST\"\n            response = self.admin_class.publish_page(request, Page.objects.all()[0].pk, \"en\")\n            self.assertEqual(response.status_code, 403)\n\n    def test_revert_page(self):\n        self.page.publish('en')\n        title = self.page.title_set.get(language='en')\n        title.title = 'new'\n        title.save()\n        self.assertEqual(Title.objects.all().count(), 2)\n        self.assertEqual(Page.objects.all().count(), 2)\n        with self.login_user_context(self.get_superuser()):\n            request = self.get_request()\n            request.method = \"POST\"\n            response = self.admin_class.revert_page(request, Page.objects.all()[0].pk, \"en\")\n            self.assertEqual(response.status_code, 302)\n        self.assertEqual(Title.objects.all().count(), 2)\n        self.assertEqual(Page.objects.all().count(), 2)\n        new_title = Title.objects.get(pk=title.pk)\n        self.assertNotEqual(title.title, new_title.title)\n        self.assertTrue(title.publisher_is_draft)\n        self.assertTrue(new_title.publisher_is_draft)\n\n    def test_revert_page_requires_perms(self):\n        permless = self.get_permless()\n        with self.login_user_context(permless):\n            request = self.get_request()\n            request.method = \"POST\"\n            response = self.admin_class.revert_page(request, Page.objects.all()[0].pk, 'en')\n            self.assertEqual(response.status_code, 403)\n\n    def test_revert_page_redirects(self):\n        admin_user = self.get_admin()\n        self.page.publish(\"en\")  # Ensure public copy exists before reverting\n        with self.login_user_context(admin_user):\n            response = self.client.get(admin_reverse('cms_page_revert_page', args=(self.page.pk, 'en')))\n            self.assertEqual(response.status_code, 302)\n            url = response['Location']\n            self.assertTrue(url.endswith('?%s' % get_cms_setting('CMS_TOOLBAR_URL__EDIT_OFF')))\n\n    def test_remove_plugin_requires_post(self):\n        ph = Placeholder.objects.create(slot='test')\n        plugin = add_plugin(ph, 'TextPlugin', 'en', body='test')\n        admin_user = self.get_admin()\n        with self.login_user_context(admin_user):\n            request = self.get_request()\n            response = self.admin_class.delete_plugin(request, plugin.pk)\n            self.assertEqual(response.status_code, 200)\n\n    def test_move_plugin(self):\n        ph = Placeholder.objects.create(slot='test')\n        plugin = add_plugin(ph, 'TextPlugin', 'en', body='test')\n        page = self.get_page()\n        source, target = list(page.placeholders.all())[:2]\n        pageplugin = add_plugin(source, 'TextPlugin', 'en', body='test')\n        plugin_class = pageplugin.get_plugin_class_instance()\n        expected = {'reload': plugin_class.requires_reload(PLUGIN_MOVE_ACTION)}\n        placeholder = Placeholder.objects.all()[0]\n        permless = self.get_permless()\n        admin_user = self.get_admin()\n        with self.login_user_context(permless):\n            request = self.get_request()\n            response = self.admin_class.move_plugin(request)\n            self.assertEqual(response.status_code, 405)\n            request = self.get_request(post_data={'not_usable': '1'})\n            self.assertRaises(MultiValueDictKeyError, self.admin_class.move_plugin, request)\n        with self.login_user_context(admin_user):\n            request = self.get_request(post_data={'ids': plugin.pk})\n            self.assertRaises(MultiValueDictKeyError, self.admin_class.move_plugin, request)\n        with self.login_user_context(admin_user):\n            request = self.get_request(post_data={'plugin_id': pageplugin.pk,\n                'placeholder_id': 'invalid-placeholder', 'plugin_language': 'en'})\n            self.assertRaises(ValueError, self.admin_class.move_plugin, request)\n        with self.login_user_context(permless):\n            request = self.get_request(post_data={'plugin_id': pageplugin.pk,\n                'placeholder_id': placeholder.pk, 'plugin_parent': '', 'plugin_language': 'en'})\n            self.assertEqual(self.admin_class.move_plugin(request).status_code, HttpResponseForbidden.status_code)\n        with self.login_user_context(admin_user):\n            request = self.get_request(post_data={'plugin_id': pageplugin.pk,\n                'placeholder_id': placeholder.pk, 'plugin_parent': '', 'plugin_language': 'en'})\n            response = self.admin_class.move_plugin(request)\n            self.assertEqual(response.status_code, 200)\n            self.assertEqual(json.loads(response.content.decode('utf8')), expected)\n        with self.login_user_context(permless):\n            request = self.get_request(post_data={'plugin_id': pageplugin.pk,\n                'placeholder_id': placeholder.id, 'plugin_parent': '', 'plugin_language': 'en'})\n            self.assertEqual(self.admin_class.move_plugin(request).status_code, HttpResponseForbidden.status_code)\n        with self.login_user_context(admin_user):\n            request = self.get_request(post_data={'plugin_id': pageplugin.pk,\n                'placeholder_id': placeholder.id, 'plugin_parent': '', 'plugin_language': 'en'})\n            response = self.admin_class.move_plugin(request)\n            self.assertEqual(response.status_code, 200)\n            self.assertEqual(json.loads(response.content.decode('utf8')), expected)\n\n    def test_move_language(self):\n        page = self.get_page()\n        source, target = list(page.placeholders.all())[:2]\n        col = add_plugin(source, 'MultiColumnPlugin', 'en')\n        sub_col = add_plugin(source, 'ColumnPlugin', 'en', target=col)\n        col2 = add_plugin(source, 'MultiColumnPlugin', 'de')\n\n        admin_user = self.get_admin()\n        with self.login_user_context(admin_user):\n            request = self.get_request(post_data={'plugin_id': sub_col.pk,\n                'placeholder_id': source.id, 'plugin_parent': col2.pk, 'plugin_language': 'de'})\n            response = self.admin_class.move_plugin(request)\n            self.assertEqual(response.status_code, 200)\n        sub_col = CMSPlugin.objects.get(pk=sub_col.pk)\n        self.assertEqual(sub_col.language, \"de\")\n        self.assertEqual(sub_col.parent_id, col2.pk)\n\n    def test_preview_page(self):\n        permless = self.get_permless()\n        with self.login_user_context(permless):\n            request = self.get_request()\n            self.assertRaises(Http404, self.admin_class.preview_page, request, 404, \"en\")\n        page = self.get_page()\n        page.publish(\"en\")\n        base_url = page.get_absolute_url()\n        with self.login_user_context(permless):\n            request = self.get_request('/?public=true')\n            response = self.admin_class.preview_page(request, page.pk, 'en')\n            self.assertEqual(response.status_code, 302)\n            self.assertEqual(response['Location'], '%s?%s&language=en' % (base_url, get_cms_setting('CMS_TOOLBAR_URL__EDIT_ON')))\n            request = self.get_request()\n            response = self.admin_class.preview_page(request, page.pk, 'en')\n            self.assertEqual(response.status_code, 302)\n            self.assertEqual(response['Location'], '%s?%s&language=en' % (base_url, get_cms_setting('CMS_TOOLBAR_URL__EDIT_ON')))\n            current_site = Site.objects.create(domain='django-cms.org', name='django-cms')\n            page.site = current_site\n            page.save()\n            page.publish(\"en\")\n            self.assertTrue(page.is_home)\n            response = self.admin_class.preview_page(request, page.pk, 'en')\n            self.assertEqual(response.status_code, 302)\n            self.assertEqual(response['Location'],\n                             'http://django-cms.org%s?%s&language=en' % (base_url, get_cms_setting('CMS_TOOLBAR_URL__EDIT_ON')))\n\n    def test_too_many_plugins_global(self):\n        conf = {\n            'body': {\n                'limits': {\n                    'global': 1,\n                },\n            },\n        }\n        admin_user = self.get_admin()\n        url = admin_reverse('cms_page_add_plugin')\n        with SettingsOverride(CMS_PERMISSION=False,\n                              CMS_PLACEHOLDER_CONF=conf):\n            page = create_page('somepage', 'nav_playground.html', 'en')\n            body = page.placeholders.get(slot='body')\n            add_plugin(body, 'TextPlugin', 'en', body='text')\n            with self.login_user_context(admin_user):\n                data = {\n                    'plugin_type': 'TextPlugin',\n                    'placeholder_id': body.pk,\n                    'plugin_language': 'en',\n                }\n                response = self.client.post(url, data)\n                self.assertEqual(response.status_code, HttpResponseBadRequest.status_code)\n\n    def test_too_many_plugins_type(self):\n        conf = {\n            'body': {\n                'limits': {\n                    'TextPlugin': 1,\n                },\n            },\n        }\n        admin_user = self.get_admin()\n        url = admin_reverse('cms_page_add_plugin')\n        with SettingsOverride(CMS_PERMISSION=False,\n                              CMS_PLACEHOLDER_CONF=conf):\n            page = create_page('somepage', 'nav_playground.html', 'en')\n            body = page.placeholders.get(slot='body')\n            add_plugin(body, 'TextPlugin', 'en', body='text')\n            with self.login_user_context(admin_user):\n                data = {\n                    'plugin_type': 'TextPlugin',\n                    'placeholder_id': body.pk,\n                    'plugin_language': 'en',\n                    'plugin_parent': '',\n                }\n                response = self.client.post(url, data)\n                self.assertEqual(response.status_code, HttpResponseBadRequest.status_code)\n\n    def test_edit_title_dirty_bit(self):\n        language = \"en\"\n        admin_user = self.get_admin()\n        page = create_page('A', 'nav_playground.html', language)\n        page_admin = PageAdmin(Page, None)\n        page_admin._current_page = page\n        page.publish(\"en\")\n        draft_page = page.get_draft_object()\n        admin_url = reverse(\"admin:cms_page_edit_title_fields\", args=(\n            draft_page.pk, language\n        ))\n\n        post_data = {\n            'title': \"A Title\"\n        }\n        with self.login_user_context(admin_user):\n            self.client.post(admin_url, post_data)\n            draft_page = Page.objects.get(pk=page.pk).get_draft_object()\n            self.assertTrue(draft_page.is_dirty('en'))\n\n    def test_edit_title_languages(self):\n        language = \"en\"\n        admin_user = self.get_admin()\n        page = create_page('A', 'nav_playground.html', language)\n        page_admin = PageAdmin(Page, None)\n        page_admin._current_page = page\n        page.publish(\"en\")\n        draft_page = page.get_draft_object()\n        admin_url = reverse(\"admin:cms_page_edit_title_fields\", args=(\n            draft_page.pk, language\n        ))\n\n        post_data = {\n            'title': \"A Title\"\n        }\n        with self.login_user_context(admin_user):\n            self.client.post(admin_url, post_data)\n            draft_page = Page.objects.get(pk=page.pk).get_draft_object()\n            self.assertTrue(draft_page.is_dirty('en'))\n\n    def test_page_form_leak(self):\n        language = \"en\"\n        admin_user = self.get_admin()\n        request = self.get_request('/', 'en')\n        request.user = admin_user\n        page = create_page('A', 'nav_playground.html', language, menu_title='menu title')\n        page_admin = PageAdmin(Page, site)\n        page_admin._current_page = page\n\n        edit_form = page_admin.get_form(request, page)\n        add_form = page_admin.get_form(request, None)\n\n        self.assertEqual(edit_form.base_fields['menu_title'].initial, 'menu title')\n        self.assertEqual(add_form.base_fields['menu_title'].initial, None)\n\n\nclass NoDBAdminTests(CMSTestCase):\n    @property\n    def admin_class(self):\n        return site._registry[Page]\n\n    def test_lookup_allowed_site__exact(self):\n        self.assertTrue(self.admin_class.lookup_allowed('site__exact', '1'))\n\n    def test_lookup_allowed_published(self):\n        self.assertTrue(self.admin_class.lookup_allowed('published', value='1'))\n\n\nclass PluginPermissionTests(AdminTestsBase):\n    def setUp(self):\n        self._page = create_page('test page', 'nav_playground.html', 'en')\n        self._placeholder = self._page.placeholders.all()[0]\n\n    def _get_admin(self):\n        User = get_user_model()\n\n        fields = dict(email=\"admin@django-cms.org\", is_staff=True, is_active=True)\n\n        if (User.USERNAME_FIELD != 'email'):\n            fields[User.USERNAME_FIELD] = \"admin\"\n\n        admin_user = User(**fields)\n\n        admin_user.set_password('admin')\n        admin_user.save()\n        return admin_user\n\n    def _get_page_admin(self):\n        return admin.site._registry[Page]\n\n    def _give_permission(self, user, model, permission_type, save=True):\n        codename = '%s_%s' % (permission_type, model._meta.object_name.lower())\n        user.user_permissions.add(Permission.objects.get(codename=codename))\n\n    def _give_page_permission_rights(self, user):\n        self._give_permission(user, PagePermission, 'add')\n        self._give_permission(user, PagePermission, 'change')\n        self._give_permission(user, PagePermission, 'delete')\n\n    def _get_change_page_request(self, user, page):\n        return type('Request', (object,), {\n            'user': user,\n            'path': base.URL_CMS_PAGE_CHANGE % page.pk\n        })\n\n    def _give_cms_permissions(self, user, save=True):\n        for perm_type in ['add', 'change', 'delete']:\n            for model in [Page, Title]:\n                self._give_permission(user, model, perm_type, False)\n        gpp = GlobalPagePermission.objects.create(\n            user=user,\n            can_change=True,\n            can_delete=True,\n            can_change_advanced_settings=False,\n            can_publish=True,\n            can_change_permissions=False,\n            can_move_page=True,\n        )\n        gpp.sites = Site.objects.all()\n        if save:\n            user.save()\n\n    def _create_plugin(self):\n        plugin = add_plugin(self._placeholder, 'TextPlugin', 'en')\n        return plugin\n\n    def test_plugin_add_requires_permissions(self):\n        \"\"\"User tries to add a plugin but has no permissions. He can add the plugin after he got the permissions\"\"\"\n        admin = self._get_admin()\n        self._give_cms_permissions(admin)\n\n        if get_user_model().USERNAME_FIELD == 'email':\n            self.client.login(username='admin@django-cms.org', password='admin')\n        else:\n            self.client.login(username='admin', password='admin')\n\n        url = admin_reverse('cms_page_add_plugin')\n        data = {\n            'plugin_type': 'TextPlugin',\n            'placeholder_id': self._placeholder.pk,\n            'plugin_language': 'en',\n            'plugin_parent': '',\n        }\n        response = self.client.post(url, data)\n        self.assertEqual(response.status_code, HttpResponseForbidden.status_code)\n        self._give_permission(admin, Text, 'add')\n        response = self.client.post(url, data)\n        self.assertEqual(response.status_code, HttpResponse.status_code)\n\n    def test_plugin_edit_requires_permissions(self):\n        \"\"\"User tries to edit a plugin but has no permissions. He can edit the plugin after he got the permissions\"\"\"\n        plugin = self._create_plugin()\n        _, normal_guy = self._get_guys()\n\n        if get_user_model().USERNAME_FIELD == 'email':\n            self.client.login(username='test@test.com', password='test@test.com')\n        else:\n            self.client.login(username='test', password='test')\n\n        url = admin_reverse('cms_page_edit_plugin', args=[plugin.id])\n        response = self.client.post(url, dict())\n        self.assertEqual(response.status_code, HttpResponseForbidden.status_code)\n        # After he got the permissions, he can edit the plugin\n        self._give_permission(normal_guy, Text, 'change')\n        response = self.client.post(url, dict())\n        self.assertEqual(response.status_code, HttpResponse.status_code)\n\n    def test_plugin_edit_wrong_url(self):\n        \"\"\"User tries to edit a plugin using a random url. 404 response returned\"\"\"\n        plugin = self._create_plugin()\n        _, normal_guy = self._get_guys()\n\n        if get_user_model().USERNAME_FIELD == 'email':\n            self.client.login(username='test@test.com', password='test@test.com')\n        else:\n            self.client.login(username='test', password='test')\n\n        self._give_permission(normal_guy, Text, 'change')\n        url = '%s/edit-plugin/%s/' % (admin_reverse('cms_page_edit_plugin', args=[plugin.id]), plugin.id)\n        response = self.client.post(url, dict())\n        self.assertEqual(response.status_code, HttpResponseNotFound.status_code)\n        self.assertTrue(\"Plugin not found\" in force_unicode(response.content))\n\n    def test_plugin_remove_requires_permissions(self):\n        \"\"\"User tries to remove a plugin but has no permissions. He can remove the plugin after he got the permissions\"\"\"\n        plugin = self._create_plugin()\n        _, normal_guy = self._get_guys()\n\n        if get_user_model().USERNAME_FIELD == 'email':\n            self.client.login(username='test@test.com', password='test@test.com')\n        else:\n            self.client.login(username='test', password='test')\n\n        url = admin_reverse('cms_page_delete_plugin', args=[plugin.pk])\n        data = dict(plugin_id=plugin.id)\n        response = self.client.post(url, data)\n        self.assertEqual(response.status_code, HttpResponseForbidden.status_code)\n        # After he got the permissions, he can edit the plugin\n        self._give_permission(normal_guy, Text, 'delete')\n        response = self.client.post(url, data)\n        self.assertEqual(response.status_code, 302)\n\n    def test_plugin_move_requires_permissions(self):\n        \"\"\"User tries to move a plugin but has no permissions. He can move the plugin after he got the permissions\"\"\"\n        plugin = self._create_plugin()\n        _, normal_guy = self._get_guys()\n\n        if get_user_model().USERNAME_FIELD == 'email':\n            self.client.login(username='test@test.com', password='test@test.com')\n        else:\n            self.client.login(username='test', password='test')\n\n        url = admin_reverse('cms_page_move_plugin')\n        data = dict(plugin_id=plugin.id,\n                    placeholder_id=self._placeholder.pk,\n                    plugin_parent='',\n        )\n        response = self.client.post(url, data)\n        self.assertEqual(response.status_code, HttpResponseForbidden.status_code)\n        # After he got the permissions, he can edit the plugin\n        self._give_permission(normal_guy, Text, 'change')\n        response = self.client.post(url, data)\n        self.assertEqual(response.status_code, HttpResponse.status_code)\n\n    def test_plugins_copy_requires_permissions(self):\n        \"\"\"User tries to copy plugin but has no permissions. He can copy plugins after he got the permissions\"\"\"\n        plugin = self._create_plugin()\n        _, normal_guy = self._get_guys()\n\n        if get_user_model().USERNAME_FIELD == 'email':\n            self.client.login(username='test@test.com', password='test@test.com')\n        else:\n            self.client.login(username='test', password='test')\n\n        url = admin_reverse('cms_page_copy_plugins')\n        data = dict(source_plugin_id=plugin.id,\n                    source_placeholder_id=self._placeholder.pk,\n                    source_language='en',\n                    target_language='fr',\n                    target_placeholder_id=self._placeholder.pk,\n        )\n        response = self.client.post(url, data)\n        self.assertEqual(response.status_code, HttpResponseForbidden.status_code)\n        # After he got the permissions, he can edit the plugin\n        self._give_permission(normal_guy, Text, 'add')\n        response = self.client.post(url, data)\n        self.assertEqual(response.status_code, HttpResponse.status_code)\n\n    def test_plugins_copy_placeholder_ref(self):\n        \"\"\"User copies a placeholder into a clipboard. A PlaceholderReferencePlugin is created. Afterwards he copies this\n         into a placeholder and the PlaceholderReferencePlugin unpacks its content. After that he clear the clipboard\"\"\"\n        self.assertEqual(Placeholder.objects.count(), 2)\n        self._create_plugin()\n        self._create_plugin()\n        admin_user = self.get_superuser()\n        clipboard = Placeholder()\n        clipboard.save()\n        self.assertEqual(CMSPlugin.objects.count(), 2)\n        settings = UserSettings(language=\"fr\", clipboard=clipboard, user=admin_user)\n        settings.save()\n        self.assertEqual(Placeholder.objects.count(), 3)\n\n        if get_user_model().USERNAME_FIELD == 'email':\n            self.client.login(username='admin@django-cms.org', password='admin@django-cms.org')\n        else:\n            self.client.login(username='admin', password='admin')\n\n        url = admin_reverse('cms_page_copy_plugins')\n        data = dict(source_plugin_id='',\n                    source_placeholder_id=self._placeholder.pk,\n                    source_language='en',\n                    target_language='en',\n                    target_placeholder_id=clipboard.pk,\n        )\n        response = self.client.post(url, data)\n        self.assertEqual(response.status_code, HttpResponse.status_code)\n        clipboard_plugins = clipboard.get_plugins()\n        self.assertEqual(CMSPlugin.objects.count(), 5)\n        self.assertEqual(clipboard_plugins.count(), 1)\n        self.assertEqual(clipboard_plugins[0].plugin_type, \"PlaceholderPlugin\")\n        placeholder_plugin, _ = clipboard_plugins[0].get_plugin_instance()\n        ref_placeholder = placeholder_plugin.placeholder_ref\n        copied_plugins = ref_placeholder.get_plugins()\n        self.assertEqual(copied_plugins.count(), 2)\n        data = dict(source_plugin_id=placeholder_plugin.pk,\n                    source_placeholder_id=clipboard.pk,\n                    source_language='en',\n                    target_language='fr',\n                    target_placeholder_id=self._placeholder.pk,\n        )\n        response = self.client.post(url, data)\n        self.assertEqual(response.status_code, HttpResponse.status_code)\n        plugins = self._placeholder.get_plugins()\n        self.assertEqual(plugins.count(), 4)\n        self.assertEqual(CMSPlugin.objects.count(), 7)\n        self.assertEqual(Placeholder.objects.count(), 4)\n        url = admin_reverse('cms_page_clear_placeholder', args=[clipboard.pk])\n        with self.assertNumQueries(FuzzyInt(70, 80)):\n            response = self.client.post(url, {'test': 0})\n        self.assertEqual(response.status_code, 302)\n        self.assertEqual(CMSPlugin.objects.count(), 4)\n        self.assertEqual(Placeholder.objects.count(), 3)\n\n    def test_plugins_copy_language(self):\n        \"\"\"User tries to copy plugin but has no permissions. He can copy plugins after he got the permissions\"\"\"\n        self._create_plugin()\n        _, normal_guy = self._get_guys()\n\n        if get_user_model().USERNAME_FIELD != 'email':\n            self.client.login(username='test', password='test')\n        else:\n            self.client.login(username='test@test.com', password='test@test.com')\n\n        self.assertEqual(1, CMSPlugin.objects.all().count())\n        url = admin_reverse('cms_page_copy_language', args=[self._page.pk])\n        data = dict(\n            source_language='en',\n            target_language='fr',\n        )\n        response = self.client.post(url, data)\n        self.assertEqual(response.status_code, HttpResponseForbidden.status_code)\n        # After he got the permissions, he can edit the plugin\n        self._give_permission(normal_guy, Text, 'add')\n        response = self.client.post(url, data)\n        self.assertEqual(response.status_code, HttpResponse.status_code)\n        self.assertEqual(2, CMSPlugin.objects.all().count())\n\n    def test_page_permission_inline_visibility(self):\n        User = get_user_model()\n\n        fields = dict(email='user@domain.com', password='user', is_staff=True)\n\n        if get_user_model().USERNAME_FIELD != 'email':\n            fields[get_user_model().USERNAME_FIELD] = 'user'\n\n        user = User(**fields)\n        user.save()\n        self._give_page_permission_rights(user)\n        page = create_page('A', 'nav_playground.html', 'en')\n        page_permission = PagePermission.objects.create(\n            can_change_permissions=True, user=user, page=page)\n        request = self._get_change_page_request(user, page)\n        page_admin = PageAdmin(Page, None)\n        page_admin._current_page = page\n        # user has can_change_permission\n        # => must see the PagePermissionInline\n        self.assertTrue(\n            any(type(inline) is PagePermissionInlineAdmin\n                for inline in page_admin.get_inline_instances(request,\n                                                              page if not DJANGO_1_4 else None)))\n\n        page = Page.objects.get(pk=page.pk)\n        # remove can_change_permission\n        page_permission.can_change_permissions = False\n        page_permission.save()\n        request = self._get_change_page_request(user, page)\n        page_admin = PageAdmin(Page, None)\n        page_admin._current_page = page\n        # => PagePermissionInline is no longer visible\n        self.assertFalse(\n            any(type(inline) is PagePermissionInlineAdmin\n                for inline in page_admin.get_inline_instances(request, page if not DJANGO_1_4 else None)))\n\n    def test_edit_title_is_allowed_for_staff_user(self):\n        \"\"\"\n        We check here both the permission on a single page, and the global permissions\n        \"\"\"\n        user = self._create_user('user', is_staff=True)\n        another_user = self._create_user('another_user', is_staff=True)\n\n        page = create_page('A', 'nav_playground.html', 'en')\n        admin_url = reverse(\"admin:cms_page_edit_title_fields\", args=(\n            page.pk, 'en'\n        ))\n        page_admin = PageAdmin(Page, None)\n        page_admin._current_page = page\n\n        username = getattr(user, get_user_model().USERNAME_FIELD)\n        self.client.login(username=username, password=username)\n        response = self.client.get(admin_url)\n        self.assertEqual(response.status_code, HttpResponseForbidden.status_code)\n\n        assign_user_to_page(page, user, grant_all=True)\n        username = getattr(user, get_user_model().USERNAME_FIELD)\n        self.client.login(username=username, password=username)\n        response = self.client.get(admin_url)\n        self.assertEqual(response.status_code, HttpResponse.status_code)\n\n        self._give_cms_permissions(another_user)\n        username = getattr(another_user, get_user_model().USERNAME_FIELD)\n        self.client.login(username=username, password=username)\n        response = self.client.get(admin_url)\n        self.assertEqual(response.status_code, HttpResponse.status_code)\n\n    def test_plugin_add_returns_valid_pk_for_plugin(self):\n        admin_user = self._get_admin()\n        self._give_cms_permissions(admin_user)\n        self._give_permission(admin_user, Text, 'add')\n\n        username = getattr(admin_user, get_user_model().USERNAME_FIELD)\n        self.client.login(username=username, password='admin')\n\n        url = admin_reverse('cms_page_add_plugin')\n        data = {\n            'plugin_type': 'TextPlugin',\n            'placeholder_id': self._placeholder.pk,\n            'plugin_language': 'en',\n            'plugin_parent': '',\n        }\n        response = self.client.post(url, data)\n        self.assertEqual(response.status_code, HttpResponse.status_code)\n        self.assertEqual(response['content-type'], 'application/json')\n        pk = response.content.decode('utf8').split(\"edit-plugin/\")[1].split(\"/\")[0]\n        self.assertTrue(CMSPlugin.objects.filter(pk=int(pk)).exists())\n\n\nclass AdminFormsTests(AdminTestsBase):\n    def test_clean_overwrite_url(self):\n        user = AnonymousUser()\n        user.is_superuser = True\n        user.pk = 1\n        request = type('Request', (object,), {'user': user})\n        with SettingsOverride():\n            data = {\n                'title': 'TestPage',\n                'slug': 'test-page',\n                'language': 'en',\n                'overwrite_url': '/overwrite/url/',\n                'site': Site.objects.get_current().pk,\n                'template': get_cms_setting('TEMPLATES')[0][0],\n                'published': True\n            }\n\n            form = PageForm(data)\n            self.assertTrue(form.is_valid(), form.errors.as_text())\n            # WTF? WHY DOES form.save() not handle this stuff???\n            instance = form.save()\n            instance.permission_user_cache = user\n            instance.permission_advanced_settings_cache = True\n            Title.objects.set_or_create(request, instance, form, 'en')\n            form = PageForm(data, instance=instance)\n            self.assertTrue(form.is_valid(), form.errors.as_text())\n\n    def test_missmatching_site_parent_dotsite(self):\n        site0 = Site.objects.create(domain='foo.com', name='foo.com')\n        site1 = Site.objects.create(domain='foo.com', name='foo.com')\n        parent_page = Page.objects.create(\n            template='nav_playground.html',\n            site=site0)\n        new_page_data = {\n            'title': 'Title',\n            'slug': 'slug',\n            'language': 'en',\n            'site': site1.pk,\n            'template': get_cms_setting('TEMPLATES')[0][0],\n            'reverse_id': '',\n            'parent': parent_page.pk,\n        }\n        form = PageForm(data=new_page_data, files=None)\n        self.assertFalse(form.is_valid())\n        self.assertIn(u\"Site doesn't match the parent's page site\",\n                      form.errors['__all__'])\n\n    def test_reverse_id_error_location(self):\n        ''' Test moving the reverse_id validation error to a field specific one '''\n\n        # this is the Reverse ID we'll re-use to break things.\n        dupe_id = 'p1'\n        curren_site = Site.objects.get_current()\n        create_page('Page 1', 'nav_playground.html', 'en', reverse_id=dupe_id)\n        page2 = create_page('Page 2', 'nav_playground.html', 'en')\n        # Assemble a bunch of data to test the page form\n        page2_data = {\n            'language': 'en',\n            'site': curren_site.pk,\n            'reverse_id': dupe_id,\n            'template': 'col_two.html',\n        }\n        form = AdvancedSettingsForm(data=page2_data, files=None)\n        self.assertFalse(form.is_valid())\n\n        # reverse_id is the only item that is in __all__ as every other field\n        # has it's own clean method. Moving it to be a field error means\n        # __all__ is now not available.\n        self.assertNotIn('__all__', form.errors)\n        # In moving it to it's own field, it should be in form.errors, and\n        # the values contained therein should match these.\n        self.assertIn('reverse_id', form.errors)\n        self.assertEqual(1, len(form.errors['reverse_id']))\n        self.assertEqual([u'A page with this reverse URL id exists already.'],\n                         form.errors['reverse_id'])\n        page2_data['reverse_id'] = \"\"\n\n        form = AdvancedSettingsForm(data=page2_data, files=None)\n        self.assertTrue(form.is_valid())\n        admin_user = self._get_guys(admin_only=True)\n        # reset some of page2_data so we can use cms.api.create_page\n        page2 = page2.reload()\n        page2.site = curren_site\n        page2.save()\n        with self.login_user_context(admin_user):\n            # re-reset the page2_data for the admin form instance.\n            page2_data['reverse_id'] = dupe_id\n            page2_data['site'] = curren_site.pk\n\n            # post to the admin change form for page 2, and test that the\n            # reverse_id form row has an errors class. Django's admin avoids\n            # collapsing these, so that the error is visible.\n            resp = self.client.post(base.URL_CMS_PAGE_ADVANCED_CHANGE % page2.pk, page2_data)\n            self.assertContains(resp, '<div class=\"form-row errors reverse_id\">')\n\n    def test_create_page_type(self):\n        page = create_page('Test', 'static.html', 'en', published=True, reverse_id=\"home\")\n        for placeholder in Placeholder.objects.all():\n            add_plugin(placeholder, TextPlugin, 'en', body='<b>Test</b>')\n        page.publish('en')\n        self.assertEqual(Page.objects.count(), 2)\n        self.assertEqual(CMSPlugin.objects.count(), 4)\n        superuser = self.get_superuser()\n        with self.login_user_context(superuser):\n            response = self.client.get(\n                \"%s?copy_target=%s&language=%s\" % (admin_reverse(\"cms_page_add_page_type\"), page.pk, 'en'))\n            self.assertEqual(response.status_code, 302)\n            self.assertEqual(Page.objects.count(), 3)\n            self.assertEqual(Page.objects.filter(reverse_id=\"page_types\").count(), 1)\n            page_types = Page.objects.get(reverse_id='page_types')\n            url = response.url if hasattr(response, 'url') else response['Location']\n            expected_url_params = QueryDict(\n                'target=%s&position=first-child&add_page_type=1&copy_target=%s&language=en' % (page_types.pk, page.pk))\n            response_url_params = QueryDict(urlparse(url).query)\n            self.assertDictEqual(expected_url_params, response_url_params)\n            response = self.client.get(\"%s?copy_target=%s&language=%s\" % (\n                admin_reverse(\"cms_page_add_page_type\"), page.pk, 'en'), follow=True)\n            self.assertEqual(response.status_code, 200)\n\n            # test no page types if no page types there\n            response = self.client.get(admin_reverse('cms_page_add'))\n            self.assertNotContains(response, \"page_type\")\n            # create out first page type\n            page_data = {\n                'title': 'type1', 'slug': 'type1', '_save': 1, 'template': 'static.html', 'site': 1,\n                'language': 'en'\n            }\n            response = self.client.post(\n                \"/en/admin/cms/page/add/?target=%s&position=first-child&add_page_type=1&copy_target=%s&language=en\" % (\n                    page_types.pk, page.pk), data=page_data)\n            self.assertEqual(response.status_code, 302)\n            self.assertEqual(Page.objects.count(), 4)\n            self.assertEqual(CMSPlugin.objects.count(), 6)\n            response = self.client.get(admin_reverse('cms_page_add'))\n            self.assertContains(response, \"page_type\")\n            # no page types available if you use the copy_target\n            response = self.client.get(\"%s?copy_target=%s&language=en\" % (admin_reverse('cms_page_add'), page.pk))\n            self.assertNotContains(response, \"page_type\")\n\n    def test_render_edit_mode(self):\n        from django.core.cache import cache\n\n        cache.clear()\n        create_page('Test', 'static.html', 'en', published=True)\n        for placeholder in Placeholder.objects.all():\n            add_plugin(placeholder, TextPlugin, 'en', body='<b>Test</b>')\n\n        user = self.get_superuser()\n        self.assertEqual(Placeholder.objects.all().count(), 4)\n        with self.login_user_context(user):\n            with self.assertNumQueries(FuzzyInt(40, 66)):\n                output = force_unicode(self.client.get('/en/?%s' % get_cms_setting('CMS_TOOLBAR_URL__EDIT_ON')).content)\n            self.assertIn('<b>Test</b>', output)\n            self.assertEqual(Placeholder.objects.all().count(), 9)\n            self.assertEqual(StaticPlaceholder.objects.count(), 2)\n            for placeholder in Placeholder.objects.all():\n                add_plugin(placeholder, TextPlugin, 'en', body='<b>Test</b>')\n            with self.assertNumQueries(FuzzyInt(40, 60)):\n                output = force_unicode(self.client.get('/en/?%s' % get_cms_setting('CMS_TOOLBAR_URL__EDIT_ON')).content)\n            self.assertIn('<b>Test</b>', output)\n        with self.assertNumQueries(FuzzyInt(18, 48)):\n            force_unicode(self.client.get('/en/?%s' % get_cms_setting('CMS_TOOLBAR_URL__EDIT_ON')).content)\n        with self.assertNumQueries(FuzzyInt(12, 30)):\n            force_unicode(self.client.get('/en/').content)\n\n    def test_tree_view_queries(self):\n        from django.core.cache import cache\n\n        cache.clear()\n        for i in range(10):\n            create_page('Test%s' % i, 'col_two.html', 'en', published=True)\n        for placeholder in Placeholder.objects.all():\n            add_plugin(placeholder, TextPlugin, 'en', body='<b>Test</b>')\n\n        user = self.get_superuser()\n        with self.login_user_context(user):\n            with self.assertNumQueries(FuzzyInt(18, 33)):\n                force_unicode(self.client.get('/en/admin/cms/page/'))\n\n    def test_smart_link_published_pages(self):\n        admin, staff_guy = self._get_guys()\n        page_url = '/en/admin/cms/page/published-pages/' # Not sure how to achieve this with reverse...\n\n        with self.login_user_context(staff_guy):\n            multi_title_page = create_page('main_title', 'col_two.html', 'en', published=True,\n                                           overwrite_url='overwritten_url',\n                                           menu_title='menu_title')\n\n            title = multi_title_page.get_title_obj()\n            title.page_title = 'page_title'\n            title.save()\n\n            multi_title_page.save()\n            publish_page(multi_title_page, admin, 'en')\n\n            # Non ajax call should return a 403 as this page shouldn't be accessed by anything else but ajax queries\n            self.assertEqual(403, self.client.get(page_url).status_code)\n\n            self.assertEqual(200,\n                             self.client.get(page_url, HTTP_X_REQUESTED_WITH='XMLHttpRequest').status_code\n            )\n\n            # Test that the query param is working as expected.\n            self.assertEqual(1, len(json.loads(self.client.get(page_url, {'q':'main_title'},\n                                                    HTTP_X_REQUESTED_WITH='XMLHttpRequest').content.decode(\"utf-8\"))))\n\n            self.assertEqual(1, len(json.loads(self.client.get(page_url, {'q':'menu_title'},\n                                                    HTTP_X_REQUESTED_WITH='XMLHttpRequest').content.decode(\"utf-8\"))))\n\n            self.assertEqual(1, len(json.loads(self.client.get(page_url, {'q':'overwritten_url'},\n                                                    HTTP_X_REQUESTED_WITH='XMLHttpRequest').content.decode(\"utf-8\"))))\n\n            self.assertEqual(1, len(json.loads(self.client.get(page_url, {'q':'page_title'},\n                                                    HTTP_X_REQUESTED_WITH='XMLHttpRequest').content.decode(\"utf-8\"))))\n\n\nclass AdminPageEditContentSizeTests(AdminTestsBase):\n    \"\"\"\n    System user count influences the size of the page edit page,\n    but the users are only 2 times present on the page\n\n    The test relates to extra=0\n    at PagePermissionInlineAdminForm and ViewRestrictionInlineAdmin\n    \"\"\"\n\n    def test_editpage_contentsize(self):\n        \"\"\"\n        Expected a username only 2 times in the content, but a relationship\n        between usercount and pagesize\n        \"\"\"\n        with SettingsOverride(CMS_PERMISSION=True):\n            admin_user = self.get_superuser()\n            PAGE_NAME = 'TestPage'\n            USER_NAME = 'test_size_user_0'\n            current_site = Site.objects.get(pk=1)\n            page = create_page(PAGE_NAME, \"nav_playground.html\", \"en\", site=current_site, created_by=admin_user)\n            page.save()\n            self._page = page\n            with self.login_user_context(admin_user):\n                url = base.URL_CMS_PAGE_PERMISSION_CHANGE % self._page.pk\n                response = self.client.get(url)\n                self.assertEqual(response.status_code, 200)\n                old_response_size = len(response.content)\n                old_user_count = get_user_model().objects.count()\n                # create additionals user and reload the page\n                get_user_model().objects.create_user(username=USER_NAME, email=USER_NAME + '@django-cms.org',\n                                                     password=USER_NAME)\n                user_count = get_user_model().objects.count()\n                more_users_in_db = old_user_count < user_count\n                # we have more users\n                self.assertTrue(more_users_in_db, \"New users got NOT created\")\n                response = self.client.get(url)\n                new_response_size = len(response.content)\n                page_size_grown = old_response_size < new_response_size\n                # expect that the pagesize gets influenced by the useramount of the system\n                self.assertTrue(page_size_grown, \"Page size has not grown after user creation\")\n                # usernames are only 2 times in content\n                text = smart_str(response.content, response._charset)\n\n                foundcount = text.count(USER_NAME)\n                # 2 forms contain usernames as options\n                self.assertEqual(foundcount, 2,\n                                 \"Username %s appeared %s times in response.content, expected 2 times\" % (\n                                     USER_NAME, foundcount))\n", "target": 1}
{"idx": 933, "func": "\"\"\"Tornado handlers for nbconvert.\"\"\"\n\n# Copyright (c) Jupyter Development Team.\n# Distributed under the terms of the Modified BSD License.\n\nimport io\nimport os\nimport zipfile\n\nfrom tornado import web, escape\nfrom tornado.log import app_log\n\nfrom ..base.handlers import (\n    IPythonHandler, FilesRedirectHandler,\n    path_regex,\n)\nfrom nbformat import from_dict\n\nfrom ipython_genutils.py3compat import cast_bytes\nfrom ipython_genutils import text\n\ndef find_resource_files(output_files_dir):\n    files = []\n    for dirpath, dirnames, filenames in os.walk(output_files_dir):\n        files.extend([os.path.join(dirpath, f) for f in filenames])\n    return files\n\ndef respond_zip(handler, name, output, resources):\n    \"\"\"Zip up the output and resource files and respond with the zip file.\n\n    Returns True if it has served a zip file, False if there are no resource\n    files, in which case we serve the plain output file.\n    \"\"\"\n    # Check if we have resource files we need to zip\n    output_files = resources.get('outputs', None)\n    if not output_files:\n        return False\n\n    # Headers\n    zip_filename = os.path.splitext(name)[0] + '.zip'\n    handler.set_attachment_header(zip_filename)\n    handler.set_header('Content-Type', 'application/zip')\n    handler.set_header('Cache-Control', 'no-store, no-cache, must-revalidate, max-age=0')\n\n    # Prepare the zip file\n    buffer = io.BytesIO()\n    zipf = zipfile.ZipFile(buffer, mode='w', compression=zipfile.ZIP_DEFLATED)\n    output_filename = os.path.splitext(name)[0] + resources['output_extension']\n    zipf.writestr(output_filename, cast_bytes(output, 'utf-8'))\n    for filename, data in output_files.items():\n        zipf.writestr(os.path.basename(filename), data)\n    zipf.close()\n\n    handler.finish(buffer.getvalue())\n    return True\n\ndef get_exporter(format, **kwargs):\n    \"\"\"get an exporter, raising appropriate errors\"\"\"\n    # if this fails, will raise 500\n    try:\n        from nbconvert.exporters.base import get_exporter\n    except ImportError as e:\n        raise web.HTTPError(500, \"Could not import nbconvert: %s\" % e)\n\n    try:\n        Exporter = get_exporter(format)\n    except KeyError:\n        # should this be 400?\n        raise web.HTTPError(404, u\"No exporter for format: %s\" % format)\n\n    try:\n        return Exporter(**kwargs)\n    except Exception as e:\n        app_log.exception(\"Could not construct Exporter: %s\", Exporter)\n        raise web.HTTPError(500, \"Could not construct Exporter: %s\" % e)\n\nclass NbconvertFileHandler(IPythonHandler):\n\n    SUPPORTED_METHODS = ('GET',)\n\n    @property\n    def content_security_policy(self):\n        # In case we're serving HTML/SVG, confine any Javascript to a unique\n        # origin so it can't interact with the notebook server.\n        return super(NbconvertFileHandler, self).content_security_policy + \\\n               \"; sandbox allow-scripts\"\n\n    @web.authenticated\n    def get(self, format, path):\n\n        exporter = get_exporter(format, config=self.config, log=self.log)\n\n        path = path.strip('/')\n        # If the notebook relates to a real file (default contents manager),\n        # give its path to nbconvert.\n        if hasattr(self.contents_manager, '_get_os_path'):\n            os_path = self.contents_manager._get_os_path(path)\n            ext_resources_dir, basename = os.path.split(os_path)\n        else:\n            ext_resources_dir = None\n\n        model = self.contents_manager.get(path=path)\n        name = model['name']\n        if model['type'] != 'notebook':\n            # not a notebook, redirect to files\n            return FilesRedirectHandler.redirect_to_files(self, path)\n\n        nb = model['content']\n\n        self.set_header('Last-Modified', model['last_modified'])\n\n        # create resources dictionary\n        mod_date = model['last_modified'].strftime(text.date_format)\n        nb_title = os.path.splitext(name)[0]\n\n        resource_dict = {\n            \"metadata\": {\n                \"name\": nb_title,\n                \"modified_date\": mod_date\n            },\n            \"config_dir\": self.application.settings['config_dir']\n        }\n\n        if ext_resources_dir:\n            resource_dict['metadata']['path'] = ext_resources_dir\n\n        try:\n            output, resources = exporter.from_notebook_node(\n                nb,\n                resources=resource_dict\n            )\n        except Exception as e:\n            self.log.exception(\"nbconvert failed: %s\", e)\n            raise web.HTTPError(500, \"nbconvert failed: %s\" % e)\n\n        if respond_zip(self, name, output, resources):\n            return\n\n        # Force download if requested\n        if self.get_argument('download', 'false').lower() == 'true':\n            filename = os.path.splitext(name)[0] + resources['output_extension']\n            self.set_attachment_header(filename)\n\n        # MIME type\n        if exporter.output_mimetype:\n            self.set_header('Content-Type',\n                            '%s; charset=utf-8' % exporter.output_mimetype)\n\n        self.set_header('Cache-Control', 'no-store, no-cache, must-revalidate, max-age=0')\n        self.finish(output)\n\nclass NbconvertPostHandler(IPythonHandler):\n    SUPPORTED_METHODS = ('POST',)\n\n    @property\n    def content_security_policy(self):\n        # In case we're serving HTML/SVG, confine any Javascript to a unique\n        # origin so it can't interact with the notebook server.\n        return super(NbconvertPostHandler, self).content_security_policy + \\\n               \"; sandbox allow-scripts\"\n\n    @web.authenticated\n    def post(self, format):\n        exporter = get_exporter(format, config=self.config)\n\n        model = self.get_json_body()\n        name = model.get('name', 'notebook.ipynb')\n        nbnode = from_dict(model['content'])\n\n        try:\n            output, resources = exporter.from_notebook_node(nbnode, resources={\n                \"metadata\": {\"name\": name[:name.rfind('.')],},\n                \"config_dir\": self.application.settings['config_dir'],\n            })\n        except Exception as e:\n            raise web.HTTPError(500, \"nbconvert failed: %s\" % e)\n\n        if respond_zip(self, name, output, resources):\n            return\n\n        # MIME type\n        if exporter.output_mimetype:\n            self.set_header('Content-Type',\n                            '%s; charset=utf-8' % exporter.output_mimetype)\n\n        self.finish(output)\n\n\n#-----------------------------------------------------------------------------\n# URL to handler mappings\n#-----------------------------------------------------------------------------\n\n_format_regex = r\"(?P<format>\\w+)\"\n\n\ndefault_handlers = [\n    (r\"/nbconvert/%s\" % _format_regex, NbconvertPostHandler),\n    (r\"/nbconvert/%s%s\" % (_format_regex, path_regex),\n         NbconvertFileHandler),\n]\n", "target": 0}
{"idx": 934, "func": "# (c) 2012-2014, Michael DeHaan <michael.dehaan@gmail.com>\n#\n# This file is part of Ansible\n#\n# Ansible is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# Ansible is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.\n\n# Make coding more python3-ish\nfrom __future__ import (absolute_import, division, print_function)\n__metaclass__ = type\n\nimport ast\nimport contextlib\nimport datetime\nimport os\nimport pwd\nimport re\nimport time\n\nfrom io import StringIO\nfrom numbers import Number\n\ntry:\n    from hashlib import sha1\nexcept ImportError:\n    from sha import sha as sha1\n\nfrom jinja2 import Environment\nfrom jinja2.loaders import FileSystemLoader\nfrom jinja2.exceptions import TemplateSyntaxError, UndefinedError\nfrom jinja2.utils import concat as j2_concat\nfrom jinja2.runtime import Context, StrictUndefined\n\nfrom ansible import constants as C\nfrom ansible.errors import AnsibleError, AnsibleFilterError, AnsibleUndefinedVariable\nfrom ansible.module_utils.six import string_types, text_type\nfrom ansible.module_utils._text import to_native, to_text, to_bytes\nfrom ansible.plugins import filter_loader, lookup_loader, test_loader\nfrom ansible.template.safe_eval import safe_eval\nfrom ansible.template.template import AnsibleJ2Template\nfrom ansible.template.vars import AnsibleJ2Vars\nfrom ansible.utils.unsafe_proxy import UnsafeProxy, wrap_var\n\ntry:\n    from __main__ import display\nexcept ImportError:\n    from ansible.utils.display import Display\n    display = Display()\n\n\n__all__ = ['Templar', 'generate_ansible_template_vars']\n\n# A regex for checking to see if a variable we're trying to\n# expand is just a single variable name.\n\n# Primitive Types which we don't want Jinja to convert to strings.\nNON_TEMPLATED_TYPES = ( bool, Number )\n\nJINJA2_OVERRIDE = '#jinja2:'\n\n\ndef generate_ansible_template_vars(path):\n\n    b_path = to_bytes(path)\n    try:\n        template_uid = pwd.getpwuid(os.stat(b_path).st_uid).pw_name\n    except:\n        template_uid = os.stat(b_path).st_uid\n\n    temp_vars = {}\n    temp_vars['template_host']     = os.uname()[1]\n    temp_vars['template_path']     = b_path\n    temp_vars['template_mtime']    = datetime.datetime.fromtimestamp(os.path.getmtime(b_path))\n    temp_vars['template_uid']      = template_uid\n    temp_vars['template_fullpath'] = os.path.abspath(path)\n    temp_vars['template_run_date'] = datetime.datetime.now()\n\n    managed_default = C.DEFAULT_MANAGED_STR\n    managed_str = managed_default.format(\n        host = temp_vars['template_host'],\n        uid  = temp_vars['template_uid'],\n        file = temp_vars['template_path'],\n    )\n    temp_vars['ansible_managed'] = time.strftime( managed_str, time.localtime(os.path.getmtime(b_path)))\n\n    return temp_vars\n\n\ndef _escape_backslashes(data, jinja_env):\n    \"\"\"Double backslashes within jinja2 expressions\n\n    A user may enter something like this in a playbook::\n\n      debug:\n        msg: \"Test Case 1\\\\3; {{ test1_name | regex_replace('^(.*)_name$', '\\\\1')}}\"\n\n    The string inside of the {{ gets interpreted multiple times First by yaml.\n    Then by python.  And finally by jinja2 as part of it's variable.  Because\n    it is processed by both python and jinja2, the backslash escaped\n    characters get unescaped twice.  This means that we'd normally have to use\n    four backslashes to escape that.  This is painful for playbook authors as\n    they have to remember different rules for inside vs outside of a jinja2\n    expression (The backslashes outside of the \"{{ }}\" only get processed by\n    yaml and python.  So they only need to be escaped once).  The following\n    code fixes this by automatically performing the extra quoting of\n    backslashes inside of a jinja2 expression.\n\n    \"\"\"\n    if '\\\\' in data and '{{' in data:\n        new_data = []\n        d2 = jinja_env.preprocess(data)\n        in_var = False\n\n        for token in jinja_env.lex(d2):\n            if token[1] == 'variable_begin':\n                in_var = True\n                new_data.append(token[2])\n            elif token[1] == 'variable_end':\n                in_var = False\n                new_data.append(token[2])\n            elif in_var and token[1] == 'string':\n                # Double backslashes only if we're inside of a jinja2 variable\n                new_data.append(token[2].replace('\\\\','\\\\\\\\'))\n            else:\n                new_data.append(token[2])\n\n        data = ''.join(new_data)\n\n    return data\n\n\ndef _count_newlines_from_end(in_str):\n    '''\n    Counts the number of newlines at the end of a string. This is used during\n    the jinja2 templating to ensure the count matches the input, since some newlines\n    may be thrown away during the templating.\n    '''\n\n    try:\n        i = len(in_str)\n        j = i -1\n        while in_str[j] == '\\n':\n            j -= 1\n        return i - 1 - j\n    except IndexError:\n        # Uncommon cases: zero length string and string containing only newlines\n        return i\n\nclass AnsibleContext(Context):\n    '''\n    A custom context, which intercepts resolve() calls and sets a flag\n    internally if any variable lookup returns an AnsibleUnsafe value. This\n    flag is checked post-templating, and (when set) will result in the\n    final templated result being wrapped via UnsafeProxy.\n    '''\n    def __init__(self, *args, **kwargs):\n        super(AnsibleContext, self).__init__(*args, **kwargs)\n        self.unsafe = False\n\n    def _is_unsafe(self, val):\n        '''\n        Our helper function, which will also recursively check dict and\n        list entries due to the fact that they may be repr'd and contain\n        a key or value which contains jinja2 syntax and would otherwise\n        lose the AnsibleUnsafe value.\n        '''\n        if isinstance(val, dict):\n            for key in val.keys():\n                if self._is_unsafe(val[key]):\n                    return True\n        elif isinstance(val, list):\n            for item in val:\n                if self._is_unsafe(item):\n                    return True\n        elif isinstance(val, string_types) and hasattr(val, '__UNSAFE__'):\n            return True\n        return False\n\n    def _update_unsafe(self, val):\n        if val is not None and not self.unsafe and self._is_unsafe(val):\n            self.unsafe = True\n\n    def resolve(self, key):\n        '''\n        The intercepted resolve(), which uses the helper above to set the\n        internal flag whenever an unsafe variable value is returned.\n        '''\n        val = super(AnsibleContext, self).resolve(key)\n        self._update_unsafe(val)\n        return val\n\n    def resolve_or_missing(self, key):\n        val = super(AnsibleContext, self).resolve_or_missing(key)\n        self._update_unsafe(val)\n        return val\n\nclass AnsibleEnvironment(Environment):\n    '''\n    Our custom environment, which simply allows us to override the class-level\n    values for the Template and Context classes used by jinja2 internally.\n    '''\n    context_class = AnsibleContext\n    template_class = AnsibleJ2Template\n\nclass Templar:\n    '''\n    The main class for templating, with the main entry-point of template().\n    '''\n\n    def __init__(self, loader, shared_loader_obj=None, variables=dict()):\n        self._loader              = loader\n        self._filters             = None\n        self._tests               = None\n        self._available_variables = variables\n        self._cached_result       = {}\n\n        if loader:\n            self._basedir = loader.get_basedir()\n        else:\n            self._basedir = './'\n\n        if shared_loader_obj:\n            self._filter_loader = getattr(shared_loader_obj, 'filter_loader')\n            self._test_loader   = getattr(shared_loader_obj, 'test_loader')\n            self._lookup_loader = getattr(shared_loader_obj, 'lookup_loader')\n        else:\n            self._filter_loader = filter_loader\n            self._test_loader   = test_loader\n            self._lookup_loader = lookup_loader\n\n        # flags to determine whether certain failures during templating\n        # should result in fatal errors being raised\n        self._fail_on_lookup_errors    = True\n        self._fail_on_filter_errors    = True\n        self._fail_on_undefined_errors = C.DEFAULT_UNDEFINED_VAR_BEHAVIOR\n\n        self.environment = AnsibleEnvironment(\n            trim_blocks=True,\n            undefined=StrictUndefined,\n            extensions=self._get_extensions(),\n            finalize=self._finalize,\n            loader=FileSystemLoader(self._basedir),\n        )\n\n        # the current rendering context under which the templar class is working\n        self.cur_context = None\n\n        self.SINGLE_VAR = re.compile(r\"^%s\\s*(\\w*)\\s*%s$\" % (self.environment.variable_start_string, self.environment.variable_end_string))\n\n        self._clean_regex   = re.compile(r'(?:%s|%s|%s|%s)' % (\n            self.environment.variable_start_string,\n            self.environment.block_start_string,\n            self.environment.block_end_string,\n            self.environment.variable_end_string\n        ))\n        self._no_type_regex = re.compile(r'.*\\|\\s*(?:%s)\\s*(?:%s)?$' % ('|'.join(C.STRING_TYPE_FILTERS), self.environment.variable_end_string))\n\n    def _get_filters(self):\n        '''\n        Returns filter plugins, after loading and caching them if need be\n        '''\n\n        if self._filters is not None:\n            return self._filters.copy()\n\n        plugins = [x for x in self._filter_loader.all()]\n\n        self._filters = dict()\n        for fp in plugins:\n            self._filters.update(fp.filters())\n        self._filters.update(self._get_tests())\n\n        return self._filters.copy()\n\n    def _get_tests(self):\n        '''\n        Returns tests plugins, after loading and caching them if need be\n        '''\n\n        if self._tests is not None:\n            return self._tests.copy()\n\n        plugins = [x for x in self._test_loader.all()]\n\n        self._tests = dict()\n        for fp in plugins:\n            self._tests.update(fp.tests())\n\n        return self._tests.copy()\n\n    def _get_extensions(self):\n        '''\n        Return jinja2 extensions to load.\n\n        If some extensions are set via jinja_extensions in ansible.cfg, we try\n        to load them with the jinja environment.\n        '''\n\n        jinja_exts = []\n        if C.DEFAULT_JINJA2_EXTENSIONS:\n            # make sure the configuration directive doesn't contain spaces\n            # and split extensions in an array\n            jinja_exts = C.DEFAULT_JINJA2_EXTENSIONS.replace(\" \", \"\").split(',')\n\n        return jinja_exts\n\n    def _clean_data(self, orig_data):\n        ''' remove jinja2 template tags from data '''\n\n        if hasattr(orig_data, '__ENCRYPTED__'):\n            ret = orig_data\n\n        elif isinstance(orig_data, list):\n            clean_list = []\n            for list_item in orig_data:\n                clean_list.append(self._clean_data(list_item))\n            ret = clean_list\n\n        elif isinstance(orig_data, dict):\n            clean_dict = {}\n            for k in orig_data:\n                clean_dict[self._clean_data(k)] =  self._clean_data(orig_data[k])\n            ret = clean_dict\n\n        elif isinstance(orig_data, string_types):\n            # This will error with str data (needs unicode), but all strings should already be converted already.\n            # If you get exception, the problem is at the data origin, do not add to_text here.\n            with contextlib.closing(StringIO(orig_data)) as data:\n                # these variables keep track of opening block locations, as we only\n                # want to replace matched pairs of print/block tags\n                print_openings = []\n                block_openings = []\n                for mo in self._clean_regex.finditer(orig_data):\n                    token = mo.group(0)\n                    token_start = mo.start(0)\n\n                    if token[0] == self.environment.variable_start_string[0]:\n                        if token == self.environment.block_start_string:\n                            block_openings.append(token_start)\n                        elif token == self.environment.variable_start_string:\n                            print_openings.append(token_start)\n\n                    elif token[1] == self.environment.variable_end_string[1]:\n                        prev_idx = None\n                        if token == self.environment.block_end_string and block_openings:\n                            prev_idx = block_openings.pop()\n                        elif token == self.environment.variable_end_string and print_openings:\n                            prev_idx = print_openings.pop()\n\n                        if prev_idx is not None:\n                            # replace the opening\n                            data.seek(prev_idx, os.SEEK_SET)\n                            data.write(to_text(self.environment.comment_start_string))\n                            # replace the closing\n                            data.seek(token_start, os.SEEK_SET)\n                            data.write(to_text(self.environment.comment_end_string))\n\n                    else:\n                        raise AnsibleError(\"Error while cleaning data for safety: unhandled regex match\")\n\n                ret = data.getvalue()\n        else:\n            ret = orig_data\n\n        return ret\n\n    def set_available_variables(self, variables):\n        '''\n        Sets the list of template variables this Templar instance will use\n        to template things, so we don't have to pass them around between\n        internal methods. We also clear the template cache here, as the variables\n        are being changed.\n        '''\n\n        assert isinstance(variables, dict)\n        self._available_variables = variables\n        self._cached_result       = {}\n\n    def template(self, variable, convert_bare=False, preserve_trailing_newlines=True, escape_backslashes=True, fail_on_undefined=None, overrides=None,\n                 convert_data=True, static_vars=[''], cache=True, bare_deprecated=True, disable_lookups=False):\n        '''\n        Templates (possibly recursively) any given data as input. If convert_bare is\n        set to True, the given data will be wrapped as a jinja2 variable ('{{foo}}')\n        before being sent through the template engine.\n        '''\n\n        # Don't template unsafe variables, just return them.\n        if hasattr(variable, '__UNSAFE__'):\n            return variable\n\n        if fail_on_undefined is None:\n            fail_on_undefined = self._fail_on_undefined_errors\n\n        try:\n            if convert_bare:\n                variable = self._convert_bare_variable(variable, bare_deprecated=bare_deprecated)\n\n            if isinstance(variable, string_types):\n                result = variable\n\n                if self._contains_vars(variable):\n                    # Check to see if the string we are trying to render is just referencing a single\n                    # var.  In this case we don't want to accidentally change the type of the variable\n                    # to a string by using the jinja template renderer. We just want to pass it.\n                    only_one = self.SINGLE_VAR.match(variable)\n                    if only_one:\n                        var_name = only_one.group(1)\n                        if var_name in self._available_variables:\n                            resolved_val = self._available_variables[var_name]\n                            if isinstance(resolved_val, NON_TEMPLATED_TYPES):\n                                return resolved_val\n                            elif resolved_val is None:\n                                return C.DEFAULT_NULL_REPRESENTATION\n\n                    # Using a cache in order to prevent template calls with already templated variables\n                    sha1_hash = None\n                    if cache:\n                        variable_hash = sha1(text_type(variable).encode('utf-8'))\n                        options_hash = sha1(\n                            (\n                                text_type(preserve_trailing_newlines) +\n                                text_type(escape_backslashes) +\n                                text_type(fail_on_undefined) +\n                                text_type(overrides)\n                            ).encode('utf-8')\n                        )\n                        sha1_hash = variable_hash.hexdigest() + options_hash.hexdigest()\n                    if cache and sha1_hash in self._cached_result:\n                        result = self._cached_result[sha1_hash]\n                    else:\n                        result = self.do_template(\n                            variable,\n                            preserve_trailing_newlines=preserve_trailing_newlines,\n                            escape_backslashes=escape_backslashes,\n                            fail_on_undefined=fail_on_undefined,\n                            overrides=overrides,\n                            disable_lookups=disable_lookups,\n                        )\n\n                        unsafe = hasattr(result, '__UNSAFE__')\n                        if convert_data and not self._no_type_regex.match(variable):\n                            # if this looks like a dictionary or list, convert it to such using the safe_eval method\n                            if (result.startswith(\"{\") and not result.startswith(self.environment.variable_start_string)) or \\\n                                    result.startswith(\"[\") or result in (\"True\", \"False\"):\n                                eval_results = safe_eval(result, locals=self._available_variables, include_exceptions=True)\n                                if eval_results[1] is None:\n                                    result = eval_results[0]\n                                    if unsafe:\n                                        result = wrap_var(result)\n                                else:\n                                    # FIXME: if the safe_eval raised an error, should we do something with it?\n                                    pass\n\n                        # we only cache in the case where we have a single variable\n                        # name, to make sure we're not putting things which may otherwise\n                        # be dynamic in the cache (filters, lookups, etc.)\n                        if cache:\n                            self._cached_result[sha1_hash] = result\n\n                return result\n\n            elif isinstance(variable, (list, tuple)):\n                return [self.template(\n                    v,\n                    preserve_trailing_newlines=preserve_trailing_newlines,\n                    fail_on_undefined=fail_on_undefined,\n                    overrides=overrides,\n                    disable_lookups=disable_lookups,\n                    ) for v in variable]\n            elif isinstance(variable, dict):\n                d = {}\n                # we don't use iteritems() here to avoid problems if the underlying dict\n                # changes sizes due to the templating, which can happen with hostvars\n                for k in variable.keys():\n                    if k not in static_vars:\n                        d[k] = self.template(\n                            variable[k],\n                            preserve_trailing_newlines=preserve_trailing_newlines,\n                            fail_on_undefined=fail_on_undefined,\n                            overrides=overrides,\n                            disable_lookups=disable_lookups,\n                            )\n                    else:\n                        d[k] = variable[k]\n                return d\n            else:\n                return variable\n\n        except AnsibleFilterError:\n            if self._fail_on_filter_errors:\n                raise\n            else:\n                return variable\n\n    def is_template(self, data):\n        ''' lets us know if data has a template'''\n        if isinstance(data, string_types):\n            try:\n                new = self.do_template(data, fail_on_undefined=True)\n            except (AnsibleUndefinedVariable, UndefinedError):\n                return True\n            except:\n                return False\n            return (new != data)\n        elif isinstance(data, (list, tuple)):\n            for v in data:\n                if self.is_template(v):\n                    return True\n        elif isinstance(data, dict):\n            for k in data:\n                if self.is_template(k) or self.is_template(data[k]):\n                    return True\n        return False\n\n    def templatable(self, data):\n        '''\n        returns True if the data can be templated w/o errors\n        '''\n        templatable = True\n        try:\n            self.template(data)\n        except:\n            templatable = False\n        return templatable\n\n    def _contains_vars(self, data):\n        '''\n        returns True if the data contains a variable pattern\n        '''\n        if isinstance(data, string_types):\n            for marker in (self.environment.block_start_string, self.environment.variable_start_string, self.environment.comment_start_string):\n                if marker in data:\n                    return True\n        return False\n\n    def _convert_bare_variable(self, variable, bare_deprecated):\n        '''\n        Wraps a bare string, which may have an attribute portion (ie. foo.bar)\n        in jinja2 variable braces so that it is evaluated properly.\n        '''\n\n        if isinstance(variable, string_types):\n            contains_filters = \"|\" in variable\n            first_part = variable.split(\"|\")[0].split(\".\")[0].split(\"[\")[0]\n            if (contains_filters or first_part in self._available_variables) and self.environment.variable_start_string not in variable:\n                if bare_deprecated:\n                    display.deprecated(\"Using bare variables is deprecated.\"\n                            \" Update your playbooks so that the environment value uses the full variable syntax ('%s%s%s')\" %\n                            (self.environment.variable_start_string, variable, self.environment.variable_end_string), version='2.7')\n                return \"%s%s%s\" % (self.environment.variable_start_string, variable, self.environment.variable_end_string)\n\n        # the variable didn't meet the conditions to be converted,\n        # so just return it as-is\n        return variable\n\n    def _finalize(self, thing):\n        '''\n        A custom finalize method for jinja2, which prevents None from being returned\n        '''\n        return thing if thing is not None else ''\n\n    def _fail_lookup(self, name, *args, **kwargs):\n        raise AnsibleError(\"The lookup `%s` was found, however lookups were disabled from templating\" % name)\n\n    def _lookup(self, name, *args, **kwargs):\n        instance = self._lookup_loader.get(name.lower(), loader=self._loader, templar=self)\n\n        if instance is not None:\n            wantlist = kwargs.pop('wantlist', False)\n            allow_unsafe = kwargs.pop('allow_unsafe', C.DEFAULT_ALLOW_UNSAFE_LOOKUPS)\n\n            from ansible.utils.listify import listify_lookup_plugin_terms\n            loop_terms = listify_lookup_plugin_terms(terms=args, templar=self, loader=self._loader, fail_on_undefined=True, convert_bare=False)\n            # safely catch run failures per #5059\n            try:\n                ran = instance.run(loop_terms, variables=self._available_variables, **kwargs)\n            except (AnsibleUndefinedVariable, UndefinedError) as e:\n                raise AnsibleUndefinedVariable(e)\n            except Exception as e:\n                if self._fail_on_lookup_errors:\n                    raise AnsibleError(\"An unhandled exception occurred while running the lookup plugin '%s'. Error was a %s, \"\n                                       \"original message: %s\" % (name, type(e), e))\n                ran = None\n\n            if ran and not allow_unsafe:\n                from ansible.vars.unsafe_proxy import UnsafeProxy, wrap_var\n                if wantlist:\n                    ran = wrap_var(ran)\n                else:\n                    try:\n                        ran = UnsafeProxy(\",\".join(ran))\n                    except TypeError:\n                        if isinstance(ran, list) and len(ran) == 1:\n                            ran = wrap_var(ran[0])\n                        else:\n                            ran = wrap_var(ran)\n\n                if self.cur_context:\n                    self.cur_context.unsafe = True\n            return ran\n        else:\n            raise AnsibleError(\"lookup plugin (%s) not found\" % name)\n\n    def do_template(self, data, preserve_trailing_newlines=True, escape_backslashes=True, fail_on_undefined=None, overrides=None, disable_lookups=False):\n        # For preserving the number of input newlines in the output (used\n        # later in this method)\n        data_newlines = _count_newlines_from_end(data)\n\n        if fail_on_undefined is None:\n            fail_on_undefined = self._fail_on_undefined_errors\n\n        try:\n            # allows template header overrides to change jinja2 options.\n            if overrides is None:\n                myenv = self.environment.overlay()\n            else:\n                myenv = self.environment.overlay(overrides)\n\n            # Get jinja env overrides from template\n            if data.startswith(JINJA2_OVERRIDE):\n                eol = data.find('\\n')\n                line = data[len(JINJA2_OVERRIDE):eol]\n                data = data[eol+1:]\n                for pair in line.split(','):\n                    (key,val) = pair.split(':')\n                    key = key.strip()\n                    setattr(myenv, key, ast.literal_eval(val.strip()))\n\n            # Adds Ansible custom filters and tests\n            myenv.filters.update(self._get_filters())\n            myenv.tests.update(self._get_tests())\n\n            if escape_backslashes:\n                # Allow users to specify backslashes in playbooks as \"\\\\\" instead of as \"\\\\\\\\\".\n                data = _escape_backslashes(data, myenv)\n\n            try:\n                t = myenv.from_string(data)\n            except TemplateSyntaxError as e:\n                raise AnsibleError(\"template error while templating string: %s. String: %s\" % (to_native(e), to_native(data)))\n            except Exception as e:\n                if 'recursion' in to_native(e):\n                    raise AnsibleError(\"recursive loop detected in template string: %s\" % to_native(data))\n                else:\n                    return data\n\n            if disable_lookups:\n                t.globals['lookup'] = self._fail_lookup\n            else:\n                t.globals['lookup'] = self._lookup\n\n            t.globals['finalize'] = self._finalize\n\n            jvars = AnsibleJ2Vars(self, t.globals)\n\n            self.cur_context = new_context = t.new_context(jvars, shared=True)\n            rf = t.root_render_func(new_context)\n\n            try:\n                res = j2_concat(rf)\n                if new_context.unsafe:\n                    res = wrap_var(res)\n            except TypeError as te:\n                if 'StrictUndefined' in to_native(te):\n                    errmsg  = \"Unable to look up a name or access an attribute in template string (%s).\\n\" % to_native(data)\n                    errmsg += \"Make sure your variable name does not contain invalid characters like '-': %s\" % to_native(te)\n                    raise AnsibleUndefinedVariable(errmsg)\n                else:\n                    display.debug(\"failing because of a type error, template data is: %s\" % to_native(data))\n                    raise AnsibleError(\"Unexpected templating type error occurred on (%s): %s\" % (to_native(data),to_native(te)))\n\n            if preserve_trailing_newlines:\n                # The low level calls above do not preserve the newline\n                # characters at the end of the input data, so we use the\n                # calculate the difference in newlines and append them\n                # to the resulting output for parity\n                #\n                # jinja2 added a keep_trailing_newline option in 2.7 when\n                # creating an Environment.  That would let us make this code\n                # better (remove a single newline if\n                # preserve_trailing_newlines is False).  Once we can depend on\n                # that version being present, modify our code to set that when\n                # initializing self.environment and remove a single trailing\n                # newline here if preserve_newlines is False.\n                res_newlines = _count_newlines_from_end(res)\n                if data_newlines > res_newlines:\n                    res += self.environment.newline_sequence * (data_newlines - res_newlines)\n            return res\n        except (UndefinedError, AnsibleUndefinedVariable) as e:\n            if fail_on_undefined:\n                raise AnsibleUndefinedVariable(e)\n            else:\n                #TODO: return warning about undefined var\n                return data\n\n    # for backwards compatibility in case anyone is using old private method directly\n    _do_template = do_template\n", "target": 0}
{"idx": 935, "func": "# vim: ft=python fileencoding=utf-8 sts=4 sw=4 et:\n\n# Copyright 2016-2019 Florian Bruhin (The Compiler) <mail@qutebrowser.org>\n#\n# This file is part of qutebrowser.\n#\n# qutebrowser is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# qutebrowser is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with qutebrowser.  If not, see <http://www.gnu.org/licenses/>.\n\n\"\"\"Base class for a wrapper over QWebView/QWebEngineView.\"\"\"\n\nimport enum\nimport itertools\nimport typing\n\nimport attr\nfrom PyQt5.QtCore import (pyqtSignal, pyqtSlot, QUrl, QObject, QSizeF, Qt,\n                          QEvent, QPoint)\nfrom PyQt5.QtGui import QKeyEvent, QIcon\nfrom PyQt5.QtWidgets import QWidget, QApplication, QDialog\nfrom PyQt5.QtPrintSupport import QPrintDialog, QPrinter\nfrom PyQt5.QtNetwork import QNetworkAccessManager\n\nimport pygments\nimport pygments.lexers\nimport pygments.formatters\n\nfrom qutebrowser.keyinput import modeman\nfrom qutebrowser.config import config\nfrom qutebrowser.utils import (utils, objreg, usertypes, log, qtutils,\n                               urlutils, message)\nfrom qutebrowser.misc import miscwidgets, objects\nfrom qutebrowser.browser import mouse, hints\nfrom qutebrowser.qt import sip\nMYPY = False\nif MYPY:\n    # pylint can't interpret type comments with Python 3.7\n    # pylint: disable=unused-import,useless-suppression\n    from qutebrowser.browser import webelem\n    from qutebrowser.browser.inspector import AbstractWebInspector\n\n\ntab_id_gen = itertools.count(0)\n\n\ndef create(win_id: int,\n           private: bool,\n           parent: QWidget = None) -> 'AbstractTab':\n    \"\"\"Get a QtWebKit/QtWebEngine tab object.\n\n    Args:\n        win_id: The window ID where the tab will be shown.\n        private: Whether the tab is a private/off the record tab.\n        parent: The Qt parent to set.\n    \"\"\"\n    # Importing modules here so we don't depend on QtWebEngine without the\n    # argument and to avoid circular imports.\n    mode_manager = modeman.instance(win_id)\n    if objects.backend == usertypes.Backend.QtWebEngine:\n        from qutebrowser.browser.webengine import webenginetab\n        tab_class = webenginetab.WebEngineTab\n    else:\n        from qutebrowser.browser.webkit import webkittab\n        tab_class = webkittab.WebKitTab\n    return tab_class(win_id=win_id, mode_manager=mode_manager, private=private,\n                     parent=parent)\n\n\ndef init() -> None:\n    \"\"\"Initialize backend-specific modules.\"\"\"\n    if objects.backend == usertypes.Backend.QtWebEngine:\n        from qutebrowser.browser.webengine import webenginetab\n        webenginetab.init()\n\n\nclass WebTabError(Exception):\n\n    \"\"\"Base class for various errors.\"\"\"\n\n\nclass UnsupportedOperationError(WebTabError):\n\n    \"\"\"Raised when an operation is not supported with the given backend.\"\"\"\n\n\nTerminationStatus = enum.Enum('TerminationStatus', [\n    'normal',\n    'abnormal',  # non-zero exit status\n    'crashed',   # e.g. segfault\n    'killed',\n    'unknown',\n])\n\n\n@attr.s\nclass TabData:\n\n    \"\"\"A simple namespace with a fixed set of attributes.\n\n    Attributes:\n        keep_icon: Whether the (e.g. cloned) icon should not be cleared on page\n                   load.\n        inspector: The QWebInspector used for this webview.\n        viewing_source: Set if we're currently showing a source view.\n                        Only used when sources are shown via pygments.\n        open_target: Where to open the next link.\n                     Only used for QtWebKit.\n        override_target: Override for open_target for fake clicks (like hints).\n                         Only used for QtWebKit.\n        pinned: Flag to pin the tab.\n        fullscreen: Whether the tab has a video shown fullscreen currently.\n        netrc_used: Whether netrc authentication was performed.\n        input_mode: current input mode for the tab.\n    \"\"\"\n\n    keep_icon = attr.ib(False)  # type: bool\n    viewing_source = attr.ib(False)  # type: bool\n    inspector = attr.ib(None)  # type: typing.Optional[AbstractWebInspector]\n    open_target = attr.ib(\n        usertypes.ClickTarget.normal)  # type: usertypes.ClickTarget\n    override_target = attr.ib(None)  # type: usertypes.ClickTarget\n    pinned = attr.ib(False)  # type: bool\n    fullscreen = attr.ib(False)  # type: bool\n    netrc_used = attr.ib(False)  # type: bool\n    input_mode = attr.ib(usertypes.KeyMode.normal)  # type: usertypes.KeyMode\n\n    def should_show_icon(self) -> bool:\n        return (config.val.tabs.favicons.show == 'always' or\n                config.val.tabs.favicons.show == 'pinned' and self.pinned)\n\n\nclass AbstractAction:\n\n    \"\"\"Attribute ``action`` of AbstractTab for Qt WebActions.\"\"\"\n\n    # The class actions are defined on (QWeb{Engine,}Page)\n    action_class = None  # type: type\n    # The type of the actions (QWeb{Engine,}Page.WebAction)\n    action_base = None  # type: type\n\n    def __init__(self, tab: 'AbstractTab') -> None:\n        self._widget = typing.cast(QWidget, None)\n        self._tab = tab\n\n    def exit_fullscreen(self) -> None:\n        \"\"\"Exit the fullscreen mode.\"\"\"\n        raise NotImplementedError\n\n    def save_page(self) -> None:\n        \"\"\"Save the current page.\"\"\"\n        raise NotImplementedError\n\n    def run_string(self, name: str) -> None:\n        \"\"\"Run a webaction based on its name.\"\"\"\n        member = getattr(self.action_class, name, None)\n        if not isinstance(member, self.action_base):\n            raise WebTabError(\"{} is not a valid web action!\".format(name))\n        self._widget.triggerPageAction(member)\n\n    def show_source(\n            self,\n            pygments: bool = False  # pylint: disable=redefined-outer-name\n    ) -> None:\n        \"\"\"Show the source of the current page in a new tab.\"\"\"\n        raise NotImplementedError\n\n    def _show_source_pygments(self) -> None:\n\n        def show_source_cb(source: str) -> None:\n            \"\"\"Show source as soon as it's ready.\"\"\"\n            # WORKAROUND for https://github.com/PyCQA/pylint/issues/491\n            # pylint: disable=no-member\n            lexer = pygments.lexers.HtmlLexer()\n            formatter = pygments.formatters.HtmlFormatter(\n                full=True, linenos='table')\n            # pylint: enable=no-member\n            highlighted = pygments.highlight(source, lexer, formatter)\n\n            tb = objreg.get('tabbed-browser', scope='window',\n                            window=self._tab.win_id)\n            new_tab = tb.tabopen(background=False, related=True)\n            new_tab.set_html(highlighted, self._tab.url())\n            new_tab.data.viewing_source = True\n\n        self._tab.dump_async(show_source_cb)\n\n\nclass AbstractPrinting:\n\n    \"\"\"Attribute ``printing`` of AbstractTab for printing the page.\"\"\"\n\n    def __init__(self, tab: 'AbstractTab') -> None:\n        self._widget = None\n        self._tab = tab\n\n    def check_pdf_support(self) -> None:\n        \"\"\"Check whether writing to PDFs is supported.\n\n        If it's not supported (by the current Qt version), a WebTabError is\n        raised.\n        \"\"\"\n        raise NotImplementedError\n\n    def check_printer_support(self) -> None:\n        \"\"\"Check whether writing to a printer is supported.\n\n        If it's not supported (by the current Qt version), a WebTabError is\n        raised.\n        \"\"\"\n        raise NotImplementedError\n\n    def check_preview_support(self) -> None:\n        \"\"\"Check whether showing a print preview is supported.\n\n        If it's not supported (by the current Qt version), a WebTabError is\n        raised.\n        \"\"\"\n        raise NotImplementedError\n\n    def to_pdf(self, filename: str) -> bool:\n        \"\"\"Print the tab to a PDF with the given filename.\"\"\"\n        raise NotImplementedError\n\n    def to_printer(self, printer: QPrinter,\n                   callback: typing.Callable[[bool], None] = None) -> None:\n        \"\"\"Print the tab.\n\n        Args:\n            printer: The QPrinter to print to.\n            callback: Called with a boolean\n                      (True if printing succeeded, False otherwise)\n        \"\"\"\n        raise NotImplementedError\n\n    def show_dialog(self) -> None:\n        \"\"\"Print with a QPrintDialog.\"\"\"\n        self.check_printer_support()\n\n        def print_callback(ok: bool) -> None:\n            \"\"\"Called when printing finished.\"\"\"\n            if not ok:\n                message.error(\"Printing failed!\")\n            diag.deleteLater()\n\n        def do_print() -> None:\n            \"\"\"Called when the dialog was closed.\"\"\"\n            self.to_printer(diag.printer(), print_callback)\n\n        diag = QPrintDialog(self._tab)\n        if utils.is_mac:\n            # For some reason we get a segfault when using open() on macOS\n            ret = diag.exec_()\n            if ret == QDialog.Accepted:\n                do_print()\n        else:\n            diag.open(do_print)\n\n\nclass AbstractSearch(QObject):\n\n    \"\"\"Attribute ``search`` of AbstractTab for doing searches.\n\n    Attributes:\n        text: The last thing this view was searched for.\n        search_displayed: Whether we're currently displaying search results in\n                          this view.\n        _flags: The flags of the last search (needs to be set by subclasses).\n        _widget: The underlying WebView widget.\n    \"\"\"\n\n    #: Signal emitted when a search was finished\n    #: (True if the text was found, False otherwise)\n    finished = pyqtSignal(bool)\n    #: Signal emitted when an existing search was cleared.\n    cleared = pyqtSignal()\n\n    _Callback = typing.Callable[[bool], None]\n\n    def __init__(self, tab: 'AbstractTab', parent: QWidget = None):\n        super().__init__(parent)\n        self._tab = tab\n        self._widget = None\n        self.text = None  # type: typing.Optional[str]\n        self.search_displayed = False\n\n    def _is_case_sensitive(self, ignore_case: usertypes.IgnoreCase) -> bool:\n        \"\"\"Check if case-sensitivity should be used.\n\n        This assumes self.text is already set properly.\n\n        Arguments:\n            ignore_case: The ignore_case value from the config.\n        \"\"\"\n        assert self.text is not None\n        mapping = {\n            usertypes.IgnoreCase.smart: not self.text.islower(),\n            usertypes.IgnoreCase.never: True,\n            usertypes.IgnoreCase.always: False,\n        }\n        return mapping[ignore_case]\n\n    def search(self, text: str, *,\n               ignore_case: usertypes.IgnoreCase = usertypes.IgnoreCase.never,\n               reverse: bool = False,\n               result_cb: _Callback = None) -> None:\n        \"\"\"Find the given text on the page.\n\n        Args:\n            text: The text to search for.\n            ignore_case: Search case-insensitively.\n            reverse: Reverse search direction.\n            result_cb: Called with a bool indicating whether a match was found.\n        \"\"\"\n        raise NotImplementedError\n\n    def clear(self) -> None:\n        \"\"\"Clear the current search.\"\"\"\n        raise NotImplementedError\n\n    def prev_result(self, *, result_cb: _Callback = None) -> None:\n        \"\"\"Go to the previous result of the current search.\n\n        Args:\n            result_cb: Called with a bool indicating whether a match was found.\n        \"\"\"\n        raise NotImplementedError\n\n    def next_result(self, *, result_cb: _Callback = None) -> None:\n        \"\"\"Go to the next result of the current search.\n\n        Args:\n            result_cb: Called with a bool indicating whether a match was found.\n        \"\"\"\n        raise NotImplementedError\n\n\nclass AbstractZoom(QObject):\n\n    \"\"\"Attribute ``zoom`` of AbstractTab for controlling zoom.\"\"\"\n\n    def __init__(self, tab: 'AbstractTab', parent: QWidget = None) -> None:\n        super().__init__(parent)\n        self._tab = tab\n        self._widget = None\n        # Whether zoom was changed from the default.\n        self._default_zoom_changed = False\n        self._init_neighborlist()\n        config.instance.changed.connect(self._on_config_changed)\n        self._zoom_factor = float(config.val.zoom.default) / 100\n\n    @pyqtSlot(str)\n    def _on_config_changed(self, option: str) -> None:\n        if option in ['zoom.levels', 'zoom.default']:\n            if not self._default_zoom_changed:\n                factor = float(config.val.zoom.default) / 100\n                self.set_factor(factor)\n            self._init_neighborlist()\n\n    def _init_neighborlist(self) -> None:\n        \"\"\"Initialize self._neighborlist.\n\n        It is a NeighborList with the zoom levels.\"\"\"\n        levels = config.val.zoom.levels\n        self._neighborlist = usertypes.NeighborList(\n            levels, mode=usertypes.NeighborList.Modes.edge)\n        self._neighborlist.fuzzyval = config.val.zoom.default\n\n    def apply_offset(self, offset: int) -> None:\n        \"\"\"Increase/Decrease the zoom level by the given offset.\n\n        Args:\n            offset: The offset in the zoom level list.\n\n        Return:\n            The new zoom percentage.\n        \"\"\"\n        level = self._neighborlist.getitem(offset)\n        self.set_factor(float(level) / 100, fuzzyval=False)\n        return level\n\n    def _set_factor_internal(self, factor: float) -> None:\n        raise NotImplementedError\n\n    def set_factor(self, factor: float, *, fuzzyval: bool = True) -> None:\n        \"\"\"Zoom to a given zoom factor.\n\n        Args:\n            factor: The zoom factor as float.\n            fuzzyval: Whether to set the NeighborLists fuzzyval.\n        \"\"\"\n        if fuzzyval:\n            self._neighborlist.fuzzyval = int(factor * 100)\n        if factor < 0:\n            raise ValueError(\"Can't zoom to factor {}!\".format(factor))\n\n        default_zoom_factor = float(config.val.zoom.default) / 100\n        self._default_zoom_changed = (factor != default_zoom_factor)\n\n        self._zoom_factor = factor\n        self._set_factor_internal(factor)\n\n    def factor(self) -> float:\n        return self._zoom_factor\n\n    def apply_default(self) -> None:\n        self._set_factor_internal(float(config.val.zoom.default) / 100)\n\n    def reapply(self) -> None:\n        self._set_factor_internal(self._zoom_factor)\n\n\nclass AbstractCaret(QObject):\n\n    \"\"\"Attribute ``caret`` of AbstractTab for caret browsing.\"\"\"\n\n    #: Signal emitted when the selection was toggled.\n    #: (argument - whether the selection is now active)\n    selection_toggled = pyqtSignal(bool)\n    #: Emitted when a ``follow_selection`` action is done.\n    follow_selected_done = pyqtSignal()\n\n    def __init__(self,\n                 tab: 'AbstractTab',\n                 mode_manager: modeman.ModeManager,\n                 parent: QWidget = None) -> None:\n        super().__init__(parent)\n        self._tab = tab\n        self._widget = None\n        self.selection_enabled = False\n        self._mode_manager = mode_manager\n        mode_manager.entered.connect(self._on_mode_entered)\n        mode_manager.left.connect(self._on_mode_left)\n\n    def _on_mode_entered(self, mode: usertypes.KeyMode) -> None:\n        raise NotImplementedError\n\n    def _on_mode_left(self, mode: usertypes.KeyMode) -> None:\n        raise NotImplementedError\n\n    def move_to_next_line(self, count: int = 1) -> None:\n        raise NotImplementedError\n\n    def move_to_prev_line(self, count: int = 1) -> None:\n        raise NotImplementedError\n\n    def move_to_next_char(self, count: int = 1) -> None:\n        raise NotImplementedError\n\n    def move_to_prev_char(self, count: int = 1) -> None:\n        raise NotImplementedError\n\n    def move_to_end_of_word(self, count: int = 1) -> None:\n        raise NotImplementedError\n\n    def move_to_next_word(self, count: int = 1) -> None:\n        raise NotImplementedError\n\n    def move_to_prev_word(self, count: int = 1) -> None:\n        raise NotImplementedError\n\n    def move_to_start_of_line(self) -> None:\n        raise NotImplementedError\n\n    def move_to_end_of_line(self) -> None:\n        raise NotImplementedError\n\n    def move_to_start_of_next_block(self, count: int = 1) -> None:\n        raise NotImplementedError\n\n    def move_to_start_of_prev_block(self, count: int = 1) -> None:\n        raise NotImplementedError\n\n    def move_to_end_of_next_block(self, count: int = 1) -> None:\n        raise NotImplementedError\n\n    def move_to_end_of_prev_block(self, count: int = 1) -> None:\n        raise NotImplementedError\n\n    def move_to_start_of_document(self) -> None:\n        raise NotImplementedError\n\n    def move_to_end_of_document(self) -> None:\n        raise NotImplementedError\n\n    def toggle_selection(self) -> None:\n        raise NotImplementedError\n\n    def drop_selection(self) -> None:\n        raise NotImplementedError\n\n    def selection(self, callback: typing.Callable[[str], None]) -> None:\n        raise NotImplementedError\n\n    def reverse_selection(self) -> None:\n        raise NotImplementedError\n\n    def _follow_enter(self, tab: bool) -> None:\n        \"\"\"Follow a link by faking an enter press.\"\"\"\n        if tab:\n            self._tab.fake_key_press(Qt.Key_Enter, modifier=Qt.ControlModifier)\n        else:\n            self._tab.fake_key_press(Qt.Key_Enter)\n\n    def follow_selected(self, *, tab: bool = False) -> None:\n        raise NotImplementedError\n\n\nclass AbstractScroller(QObject):\n\n    \"\"\"Attribute ``scroller`` of AbstractTab to manage scroll position.\"\"\"\n\n    #: Signal emitted when the scroll position changed (int, int)\n    perc_changed = pyqtSignal(int, int)\n    #: Signal emitted before the user requested a jump.\n    #: Used to set the special ' mark so the user can return.\n    before_jump_requested = pyqtSignal()\n\n    def __init__(self, tab: 'AbstractTab', parent: QWidget = None):\n        super().__init__(parent)\n        self._tab = tab\n        self._widget = None  # type: typing.Optional[QWidget]\n        self.perc_changed.connect(self._log_scroll_pos_change)\n\n    @pyqtSlot()\n    def _log_scroll_pos_change(self) -> None:\n        log.webview.vdebug(  # type: ignore\n            \"Scroll position changed to {}\".format(self.pos_px()))\n\n    def _init_widget(self, widget: QWidget) -> None:\n        self._widget = widget\n\n    def pos_px(self) -> int:\n        raise NotImplementedError\n\n    def pos_perc(self) -> int:\n        raise NotImplementedError\n\n    def to_perc(self, x: int = None, y: int = None) -> None:\n        raise NotImplementedError\n\n    def to_point(self, point: QPoint) -> None:\n        raise NotImplementedError\n\n    def to_anchor(self, name: str) -> None:\n        raise NotImplementedError\n\n    def delta(self, x: int = 0, y: int = 0) -> None:\n        raise NotImplementedError\n\n    def delta_page(self, x: float = 0, y: float = 0) -> None:\n        raise NotImplementedError\n\n    def up(self, count: int = 1) -> None:\n        raise NotImplementedError\n\n    def down(self, count: int = 1) -> None:\n        raise NotImplementedError\n\n    def left(self, count: int = 1) -> None:\n        raise NotImplementedError\n\n    def right(self, count: int = 1) -> None:\n        raise NotImplementedError\n\n    def top(self) -> None:\n        raise NotImplementedError\n\n    def bottom(self) -> None:\n        raise NotImplementedError\n\n    def page_up(self, count: int = 1) -> None:\n        raise NotImplementedError\n\n    def page_down(self, count: int = 1) -> None:\n        raise NotImplementedError\n\n    def at_top(self) -> bool:\n        raise NotImplementedError\n\n    def at_bottom(self) -> bool:\n        raise NotImplementedError\n\n\nclass AbstractHistoryPrivate:\n\n    \"\"\"Private API related to the history.\"\"\"\n\n    def __init__(self, tab: 'AbstractTab'):\n        self._tab = tab\n        self._history = None\n\n    def serialize(self) -> bytes:\n        \"\"\"Serialize into an opaque format understood by self.deserialize.\"\"\"\n        raise NotImplementedError\n\n    def deserialize(self, data: bytes) -> None:\n        \"\"\"Deserialize from a format produced by self.serialize.\"\"\"\n        raise NotImplementedError\n\n    def load_items(self, items: typing.Sequence) -> None:\n        \"\"\"Deserialize from a list of WebHistoryItems.\"\"\"\n        raise NotImplementedError\n\n\nclass AbstractHistory:\n\n    \"\"\"The history attribute of a AbstractTab.\"\"\"\n\n    def __init__(self, tab: 'AbstractTab') -> None:\n        self._tab = tab\n        self._history = None\n        self.private_api = AbstractHistoryPrivate(tab)\n\n    def __len__(self) -> int:\n        raise NotImplementedError\n\n    def __iter__(self) -> typing.Iterable:\n        raise NotImplementedError\n\n    def _check_count(self, count: int) -> None:\n        \"\"\"Check whether the count is positive.\"\"\"\n        if count < 0:\n            raise WebTabError(\"count needs to be positive!\")\n\n    def current_idx(self) -> int:\n        raise NotImplementedError\n\n    def back(self, count: int = 1) -> None:\n        \"\"\"Go back in the tab's history.\"\"\"\n        self._check_count(count)\n        idx = self.current_idx() - count\n        if idx >= 0:\n            self._go_to_item(self._item_at(idx))\n        else:\n            self._go_to_item(self._item_at(0))\n            raise WebTabError(\"At beginning of history.\")\n\n    def forward(self, count: int = 1) -> None:\n        \"\"\"Go forward in the tab's history.\"\"\"\n        self._check_count(count)\n        idx = self.current_idx() + count\n        if idx < len(self):\n            self._go_to_item(self._item_at(idx))\n        else:\n            self._go_to_item(self._item_at(len(self) - 1))\n            raise WebTabError(\"At end of history.\")\n\n    def can_go_back(self) -> bool:\n        raise NotImplementedError\n\n    def can_go_forward(self) -> bool:\n        raise NotImplementedError\n\n    def _item_at(self, i: int) -> typing.Any:\n        raise NotImplementedError\n\n    def _go_to_item(self, item: typing.Any) -> None:\n        raise NotImplementedError\n\n\nclass AbstractElements:\n\n    \"\"\"Finding and handling of elements on the page.\"\"\"\n\n    _MultiCallback = typing.Callable[\n        [typing.Sequence['webelem.AbstractWebElement']], None]\n    _SingleCallback = typing.Callable[\n        [typing.Optional['webelem.AbstractWebElement']], None]\n    _ErrorCallback = typing.Callable[[Exception], None]\n\n    def __init__(self, tab: 'AbstractTab') -> None:\n        self._widget = None\n        self._tab = tab\n\n    def find_css(self, selector: str,\n                 callback: _MultiCallback,\n                 error_cb: _ErrorCallback, *,\n                 only_visible: bool = False) -> None:\n        \"\"\"Find all HTML elements matching a given selector async.\n\n        If there's an error, the callback is called with a webelem.Error\n        instance.\n\n        Args:\n            callback: The callback to be called when the search finished.\n            error_cb: The callback to be called when an error occurred.\n            selector: The CSS selector to search for.\n            only_visible: Only show elements which are visible on screen.\n        \"\"\"\n        raise NotImplementedError\n\n    def find_id(self, elem_id: str, callback: _SingleCallback) -> None:\n        \"\"\"Find the HTML element with the given ID async.\n\n        Args:\n            callback: The callback to be called when the search finished.\n                      Called with a WebEngineElement or None.\n            elem_id: The ID to search for.\n        \"\"\"\n        raise NotImplementedError\n\n    def find_focused(self, callback: _SingleCallback) -> None:\n        \"\"\"Find the focused element on the page async.\n\n        Args:\n            callback: The callback to be called when the search finished.\n                      Called with a WebEngineElement or None.\n        \"\"\"\n        raise NotImplementedError\n\n    def find_at_pos(self, pos: QPoint, callback: _SingleCallback) -> None:\n        \"\"\"Find the element at the given position async.\n\n        This is also called \"hit test\" elsewhere.\n\n        Args:\n            pos: The QPoint to get the element for.\n            callback: The callback to be called when the search finished.\n                      Called with a WebEngineElement or None.\n        \"\"\"\n        raise NotImplementedError\n\n\nclass AbstractAudio(QObject):\n\n    \"\"\"Handling of audio/muting for this tab.\"\"\"\n\n    muted_changed = pyqtSignal(bool)\n    recently_audible_changed = pyqtSignal(bool)\n\n    def __init__(self, tab: 'AbstractTab', parent: QWidget = None) -> None:\n        super().__init__(parent)\n        self._widget = None  # type: typing.Optional[QWidget]\n        self._tab = tab\n\n    def set_muted(self, muted: bool, override: bool = False) -> None:\n        \"\"\"Set this tab as muted or not.\n\n        Arguments:\n            override: If set to True, muting/unmuting was done manually and\n                      overrides future automatic mute/unmute changes based on\n                      the URL.\n        \"\"\"\n        raise NotImplementedError\n\n    def is_muted(self) -> bool:\n        raise NotImplementedError\n\n    def is_recently_audible(self) -> bool:\n        \"\"\"Whether this tab has had audio playing recently.\"\"\"\n        raise NotImplementedError\n\n\nclass AbstractTabPrivate:\n\n    \"\"\"Tab-related methods which are only needed in the core.\n\n    Those methods are not part of the API which is exposed to extensions, and\n    should ideally be removed at some point in the future.\n    \"\"\"\n\n    def __init__(self, mode_manager: modeman.ModeManager,\n                 tab: 'AbstractTab') -> None:\n        self._widget = None  # type: typing.Optional[QWidget]\n        self._tab = tab\n        self._mode_manager = mode_manager\n\n    def event_target(self) -> QWidget:\n        \"\"\"Return the widget events should be sent to.\"\"\"\n        raise NotImplementedError\n\n    def handle_auto_insert_mode(self, ok: bool) -> None:\n        \"\"\"Handle `input.insert_mode.auto_load` after loading finished.\"\"\"\n        if not config.val.input.insert_mode.auto_load or not ok:\n            return\n\n        cur_mode = self._mode_manager.mode\n        if cur_mode == usertypes.KeyMode.insert:\n            return\n\n        def _auto_insert_mode_cb(elem: 'webelem.AbstractWebElement') -> None:\n            \"\"\"Called from JS after finding the focused element.\"\"\"\n            if elem is None:\n                log.webview.debug(\"No focused element!\")\n                return\n            if elem.is_editable():\n                modeman.enter(self._tab.win_id, usertypes.KeyMode.insert,\n                              'load finished', only_if_normal=True)\n\n        self._tab.elements.find_focused(_auto_insert_mode_cb)\n\n    def clear_ssl_errors(self) -> None:\n        raise NotImplementedError\n\n    def networkaccessmanager(self) -> typing.Optional[QNetworkAccessManager]:\n        \"\"\"Get the QNetworkAccessManager for this tab.\n\n        This is only implemented for QtWebKit.\n        For QtWebEngine, always returns None.\n        \"\"\"\n        raise NotImplementedError\n\n    def user_agent(self) -> typing.Optional[str]:\n        \"\"\"Get the user agent for this tab.\n\n        This is only implemented for QtWebKit.\n        For QtWebEngine, always returns None.\n        \"\"\"\n        raise NotImplementedError\n\n    def shutdown(self) -> None:\n        raise NotImplementedError\n\n\nclass AbstractTab(QWidget):\n\n    \"\"\"An adapter for QWebView/QWebEngineView representing a single tab.\"\"\"\n\n    #: Signal emitted when a website requests to close this tab.\n    window_close_requested = pyqtSignal()\n    #: Signal emitted when a link is hovered (the hover text)\n    link_hovered = pyqtSignal(str)\n    #: Signal emitted when a page started loading\n    load_started = pyqtSignal()\n    #: Signal emitted when a page is loading (progress percentage)\n    load_progress = pyqtSignal(int)\n    #: Signal emitted when a page finished loading (success as bool)\n    load_finished = pyqtSignal(bool)\n    #: Signal emitted when a page's favicon changed (icon as QIcon)\n    icon_changed = pyqtSignal(QIcon)\n    #: Signal emitted when a page's title changed (new title as str)\n    title_changed = pyqtSignal(str)\n    #: Signal emitted when a new tab should be opened (url as QUrl)\n    new_tab_requested = pyqtSignal(QUrl)\n    #: Signal emitted when a page's URL changed (url as QUrl)\n    url_changed = pyqtSignal(QUrl)\n    #: Signal emitted when a tab's content size changed\n    #: (new size as QSizeF)\n    contents_size_changed = pyqtSignal(QSizeF)\n    #: Signal emitted when a page requested full-screen (bool)\n    fullscreen_requested = pyqtSignal(bool)\n    #: Signal emitted before load starts (URL as QUrl)\n    before_load_started = pyqtSignal(QUrl)\n\n    # Signal emitted when a page's load status changed\n    # (argument: usertypes.LoadStatus)\n    load_status_changed = pyqtSignal(usertypes.LoadStatus)\n    # Signal emitted before shutting down\n    shutting_down = pyqtSignal()\n    # Signal emitted when a history item should be added\n    history_item_triggered = pyqtSignal(QUrl, QUrl, str)\n    # Signal emitted when the underlying renderer process terminated.\n    # arg 0: A TerminationStatus member.\n    # arg 1: The exit code.\n    renderer_process_terminated = pyqtSignal(TerminationStatus, int)\n\n    def __init__(self, *, win_id: int, private: bool,\n                 parent: QWidget = None) -> None:\n        self.is_private = private\n        self.win_id = win_id\n        self.tab_id = next(tab_id_gen)\n        super().__init__(parent)\n\n        self.registry = objreg.ObjectRegistry()\n        tab_registry = objreg.get('tab-registry', scope='window',\n                                  window=win_id)\n        tab_registry[self.tab_id] = self\n        objreg.register('tab', self, registry=self.registry)\n\n        self.data = TabData()\n        self._layout = miscwidgets.WrapperLayout(self)\n        self._widget = None  # type: typing.Optional[QWidget]\n        self._progress = 0\n        self._has_ssl_errors = False\n        self._load_status = usertypes.LoadStatus.none\n        self._mouse_event_filter = mouse.MouseEventFilter(\n            self, parent=self)\n        self.backend = None\n\n        # FIXME:qtwebengine  Should this be public api via self.hints?\n        #                    Also, should we get it out of objreg?\n        hintmanager = hints.HintManager(win_id, self.tab_id, parent=self)\n        objreg.register('hintmanager', hintmanager, scope='tab',\n                        window=self.win_id, tab=self.tab_id)\n\n        self.before_load_started.connect(self._on_before_load_started)\n\n    def _set_widget(self, widget: QWidget) -> None:\n        # pylint: disable=protected-access\n        self._widget = widget\n        self._layout.wrap(self, widget)\n        self.history._history = widget.history()\n        self.history.private_api._history = widget.history()\n        self.scroller._init_widget(widget)\n        self.caret._widget = widget\n        self.zoom._widget = widget\n        self.search._widget = widget\n        self.printing._widget = widget\n        self.action._widget = widget\n        self.elements._widget = widget\n        self.audio._widget = widget\n        self.private_api._widget = widget\n        self.settings._settings = widget.settings()\n\n        self._install_event_filter()\n        self.zoom.apply_default()\n\n    def _install_event_filter(self) -> None:\n        raise NotImplementedError\n\n    def _set_load_status(self, val: usertypes.LoadStatus) -> None:\n        \"\"\"Setter for load_status.\"\"\"\n        if not isinstance(val, usertypes.LoadStatus):\n            raise TypeError(\"Type {} is no LoadStatus member!\".format(val))\n        log.webview.debug(\"load status for {}: {}\".format(repr(self), val))\n        self._load_status = val\n        self.load_status_changed.emit(val)\n\n    def send_event(self, evt: QEvent) -> None:\n        \"\"\"Send the given event to the underlying widget.\n\n        The event will be sent via QApplication.postEvent.\n        Note that a posted event must not be re-used in any way!\n        \"\"\"\n        # This only gives us some mild protection against re-using events, but\n        # it's certainly better than a segfault.\n        if getattr(evt, 'posted', False):\n            raise utils.Unreachable(\"Can't re-use an event which was already \"\n                                    \"posted!\")\n\n        recipient = self.private_api.event_target()\n        if recipient is None:\n            # https://github.com/qutebrowser/qutebrowser/issues/3888\n            log.webview.warning(\"Unable to find event target!\")\n            return\n\n        evt.posted = True\n        QApplication.postEvent(recipient, evt)\n\n    def navigation_blocked(self) -> bool:\n        \"\"\"Test if navigation is allowed on the current tab.\"\"\"\n        return self.data.pinned and config.val.tabs.pinned.frozen\n\n    @pyqtSlot(QUrl)\n    def _on_before_load_started(self, url: QUrl) -> None:\n        \"\"\"Adjust the title if we are going to visit a URL soon.\"\"\"\n        qtutils.ensure_valid(url)\n        url_string = url.toDisplayString()\n        log.webview.debug(\"Going to start loading: {}\".format(url_string))\n        self.title_changed.emit(url_string)\n\n    @pyqtSlot(QUrl)\n    def _on_url_changed(self, url: QUrl) -> None:\n        \"\"\"Update title when URL has changed and no title is available.\"\"\"\n        if url.isValid() and not self.title():\n            self.title_changed.emit(url.toDisplayString())\n        self.url_changed.emit(url)\n\n    @pyqtSlot()\n    def _on_load_started(self) -> None:\n        self._progress = 0\n        self._has_ssl_errors = False\n        self.data.viewing_source = False\n        self._set_load_status(usertypes.LoadStatus.loading)\n        self.load_started.emit()\n\n    @pyqtSlot(usertypes.NavigationRequest)\n    def _on_navigation_request(\n            self,\n            navigation: usertypes.NavigationRequest\n    ) -> None:\n        \"\"\"Handle common acceptNavigationRequest code.\"\"\"\n        url = utils.elide(navigation.url.toDisplayString(), 100)\n        log.webview.debug(\"navigation request: url {}, type {}, is_main_frame \"\n                          \"{}\".format(url,\n                                      navigation.navigation_type,\n                                      navigation.is_main_frame))\n\n        if not navigation.url.isValid():\n            # Also a WORKAROUND for missing IDNA 2008 support in QUrl, see\n            # https://bugreports.qt.io/browse/QTBUG-60364\n\n            if navigation.navigation_type == navigation.Type.link_clicked:\n                msg = urlutils.get_errstring(navigation.url,\n                                             \"Invalid link clicked\")\n                message.error(msg)\n                self.data.open_target = usertypes.ClickTarget.normal\n\n            log.webview.debug(\"Ignoring invalid URL {} in \"\n                              \"acceptNavigationRequest: {}\".format(\n                                  navigation.url.toDisplayString(),\n                                  navigation.url.errorString()))\n            navigation.accepted = False\n\n    @pyqtSlot(bool)\n    def _on_load_finished(self, ok: bool) -> None:\n        assert self._widget is not None\n        if sip.isdeleted(self._widget):\n            # https://github.com/qutebrowser/qutebrowser/issues/3498\n            return\n\n        try:\n            sess_manager = objreg.get('session-manager')\n        except KeyError:\n            # https://github.com/qutebrowser/qutebrowser/issues/4311\n            return\n\n        sess_manager.save_autosave()\n        self.load_finished.emit(ok)\n\n        if not self.title():\n            self.title_changed.emit(self.url().toDisplayString())\n\n        self.zoom.reapply()\n\n    def _update_load_status(self, ok: bool) -> None:\n        \"\"\"Update the load status after a page finished loading.\n\n        Needs to be called by subclasses to trigger a load status update, e.g.\n        as a response to a loadFinished signal.\n        \"\"\"\n        if ok and not self._has_ssl_errors:\n            if self.url().scheme() == 'https':\n                self._set_load_status(usertypes.LoadStatus.success_https)\n            else:\n                self._set_load_status(usertypes.LoadStatus.success)\n        elif ok:\n            self._set_load_status(usertypes.LoadStatus.warn)\n        else:\n            self._set_load_status(usertypes.LoadStatus.error)\n\n    @pyqtSlot()\n    def _on_history_trigger(self) -> None:\n        \"\"\"Emit history_item_triggered based on backend-specific signal.\"\"\"\n        raise NotImplementedError\n\n    @pyqtSlot(int)\n    def _on_load_progress(self, perc: int) -> None:\n        self._progress = perc\n        self.load_progress.emit(perc)\n\n    def url(self, *, requested: bool = False) -> QUrl:\n        raise NotImplementedError\n\n    def progress(self) -> int:\n        return self._progress\n\n    def load_status(self) -> usertypes.LoadStatus:\n        return self._load_status\n\n    def _load_url_prepare(self, url: QUrl, *,\n                          emit_before_load_started: bool = True) -> None:\n        qtutils.ensure_valid(url)\n        if emit_before_load_started:\n            self.before_load_started.emit(url)\n\n    def load_url(self, url: QUrl, *,\n                 emit_before_load_started: bool = True) -> None:\n        raise NotImplementedError\n\n    def reload(self, *, force: bool = False) -> None:\n        raise NotImplementedError\n\n    def stop(self) -> None:\n        raise NotImplementedError\n\n    def fake_key_press(self,\n                       key: Qt.Key,\n                       modifier: Qt.KeyboardModifier = Qt.NoModifier) -> None:\n        \"\"\"Send a fake key event to this tab.\"\"\"\n        press_evt = QKeyEvent(QEvent.KeyPress, key, modifier, 0, 0, 0)\n        release_evt = QKeyEvent(QEvent.KeyRelease, key, modifier,\n                                0, 0, 0)\n        self.send_event(press_evt)\n        self.send_event(release_evt)\n\n    def dump_async(self,\n                   callback: typing.Callable[[str], None], *,\n                   plain: bool = False) -> None:\n        \"\"\"Dump the current page's html asynchronously.\n\n        The given callback will be called with the result when dumping is\n        complete.\n        \"\"\"\n        raise NotImplementedError\n\n    def run_js_async(\n            self,\n            code: str,\n            callback: typing.Callable[[typing.Any], None] = None, *,\n            world: typing.Union[usertypes.JsWorld, int] = None\n    ) -> None:\n        \"\"\"Run javascript async.\n\n        The given callback will be called with the result when running JS is\n        complete.\n\n        Args:\n            code: The javascript code to run.\n            callback: The callback to call with the result, or None.\n            world: A world ID (int or usertypes.JsWorld member) to run the JS\n                   in the main world or in another isolated world.\n        \"\"\"\n        raise NotImplementedError\n\n    def title(self) -> str:\n        raise NotImplementedError\n\n    def icon(self) -> None:\n        raise NotImplementedError\n\n    def set_html(self, html: str, base_url: QUrl = QUrl()) -> None:\n        raise NotImplementedError\n\n    def __repr__(self) -> str:\n        try:\n            qurl = self.url()\n            url = qurl.toDisplayString(QUrl.EncodeUnicode)  # type: ignore\n        except (AttributeError, RuntimeError) as exc:\n            url = '<{}>'.format(exc.__class__.__name__)\n        else:\n            url = utils.elide(url, 100)\n        return utils.get_repr(self, tab_id=self.tab_id, url=url)\n\n    def is_deleted(self) -> bool:\n        assert self._widget is not None\n        return sip.isdeleted(self._widget)\n", "target": 1}
{"idx": 936, "func": "\"\"\"Tornado handlers for kernels.\"\"\"\n\n# Copyright (c) IPython Development Team.\n# Distributed under the terms of the Modified BSD License.\n\nimport json\nimport logging\nfrom tornado import gen, web\nfrom tornado.concurrent import Future\nfrom tornado.ioloop import IOLoop\n\nfrom IPython.utils.jsonutil import date_default\nfrom IPython.utils.py3compat import cast_unicode\nfrom IPython.html.utils import url_path_join, url_escape\n\nfrom ...base.handlers import IPythonHandler, json_errors\nfrom ...base.zmqhandlers import AuthenticatedZMQStreamHandler, deserialize_binary_message\n\nfrom IPython.core.release import kernel_protocol_version\n\nclass MainKernelHandler(IPythonHandler):\n\n    @web.authenticated\n    @json_errors\n    def get(self):\n        km = self.kernel_manager\n        self.finish(json.dumps(km.list_kernels()))\n\n    @web.authenticated\n    @json_errors\n    def post(self):\n        km = self.kernel_manager\n        model = self.get_json_body()\n        if model is None:\n            model = {\n                'name': km.default_kernel_name\n            }\n        else:\n            model.setdefault('name', km.default_kernel_name)\n\n        kernel_id = km.start_kernel(kernel_name=model['name'])\n        model = km.kernel_model(kernel_id)\n        location = url_path_join(self.base_url, 'api', 'kernels', kernel_id)\n        self.set_header('Location', url_escape(location))\n        self.set_status(201)\n        self.finish(json.dumps(model))\n\n\nclass KernelHandler(IPythonHandler):\n\n    SUPPORTED_METHODS = ('DELETE', 'GET')\n\n    @web.authenticated\n    @json_errors\n    def get(self, kernel_id):\n        km = self.kernel_manager\n        km._check_kernel_id(kernel_id)\n        model = km.kernel_model(kernel_id)\n        self.finish(json.dumps(model))\n\n    @web.authenticated\n    @json_errors\n    def delete(self, kernel_id):\n        km = self.kernel_manager\n        km.shutdown_kernel(kernel_id)\n        self.set_status(204)\n        self.finish()\n\n\nclass KernelActionHandler(IPythonHandler):\n\n    @web.authenticated\n    @json_errors\n    def post(self, kernel_id, action):\n        km = self.kernel_manager\n        if action == 'interrupt':\n            km.interrupt_kernel(kernel_id)\n            self.set_status(204)\n        if action == 'restart':\n            km.restart_kernel(kernel_id)\n            model = km.kernel_model(kernel_id)\n            self.set_header('Location', '{0}api/kernels/{1}'.format(self.base_url, kernel_id))\n            self.write(json.dumps(model))\n        self.finish()\n\n\nclass ZMQChannelsHandler(AuthenticatedZMQStreamHandler):\n    \n    @property\n    def kernel_info_timeout(self):\n        return self.settings.get('kernel_info_timeout', 10)\n    \n    def __repr__(self):\n        return \"%s(%s)\" % (self.__class__.__name__, getattr(self, 'kernel_id', 'uninitialized'))\n    \n    def create_stream(self):\n        km = self.kernel_manager\n        identity = self.session.bsession\n        for channel in ('shell', 'iopub', 'stdin'):\n            meth = getattr(km, 'connect_' + channel)\n            self.channels[channel] = stream = meth(self.kernel_id, identity=identity)\n            stream.channel = channel\n        km.add_restart_callback(self.kernel_id, self.on_kernel_restarted)\n        km.add_restart_callback(self.kernel_id, self.on_restart_failed, 'dead')\n    \n    def request_kernel_info(self):\n        \"\"\"send a request for kernel_info\"\"\"\n        km = self.kernel_manager\n        kernel = km.get_kernel(self.kernel_id)\n        try:\n            # check for previous request\n            future = kernel._kernel_info_future\n        except AttributeError:\n            self.log.debug(\"Requesting kernel info from %s\", self.kernel_id)\n            # Create a kernel_info channel to query the kernel protocol version.\n            # This channel will be closed after the kernel_info reply is received.\n            if self.kernel_info_channel is None:\n                self.kernel_info_channel = km.connect_shell(self.kernel_id)\n            self.kernel_info_channel.on_recv(self._handle_kernel_info_reply)\n            self.session.send(self.kernel_info_channel, \"kernel_info_request\")\n            # store the future on the kernel, so only one request is sent\n            kernel._kernel_info_future = self._kernel_info_future\n        else:\n            if not future.done():\n                self.log.debug(\"Waiting for pending kernel_info request\")\n            future.add_done_callback(lambda f: self._finish_kernel_info(f.result()))\n        return self._kernel_info_future\n    \n    def _handle_kernel_info_reply(self, msg):\n        \"\"\"process the kernel_info_reply\n        \n        enabling msg spec adaptation, if necessary\n        \"\"\"\n        idents,msg = self.session.feed_identities(msg)\n        try:\n            msg = self.session.deserialize(msg)\n        except:\n            self.log.error(\"Bad kernel_info reply\", exc_info=True)\n            self._kernel_info_future.set_result({})\n            return\n        else:\n            info = msg['content']\n            self.log.debug(\"Received kernel info: %s\", info)\n            if msg['msg_type'] != 'kernel_info_reply' or 'protocol_version' not in info:\n                self.log.error(\"Kernel info request failed, assuming current %s\", info)\n                info = {}\n            self._finish_kernel_info(info)\n        \n        # close the kernel_info channel, we don't need it anymore\n        if self.kernel_info_channel:\n            self.kernel_info_channel.close()\n        self.kernel_info_channel = None\n    \n    def _finish_kernel_info(self, info):\n        \"\"\"Finish handling kernel_info reply\n        \n        Set up protocol adaptation, if needed,\n        and signal that connection can continue.\n        \"\"\"\n        protocol_version = info.get('protocol_version', kernel_protocol_version)\n        if protocol_version != kernel_protocol_version:\n            self.session.adapt_version = int(protocol_version.split('.')[0])\n            self.log.info(\"Adapting to protocol v%s for kernel %s\", protocol_version, self.kernel_id)\n        if not self._kernel_info_future.done():\n            self._kernel_info_future.set_result(info)\n    \n    def initialize(self):\n        super(ZMQChannelsHandler, self).initialize()\n        self.zmq_stream = None\n        self.channels = {}\n        self.kernel_id = None\n        self.kernel_info_channel = None\n        self._kernel_info_future = Future()\n    \n    @gen.coroutine\n    def pre_get(self):\n        # authenticate first\n        super(ZMQChannelsHandler, self).pre_get()\n        # then request kernel info, waiting up to a certain time before giving up.\n        # We don't want to wait forever, because browsers don't take it well when\n        # servers never respond to websocket connection requests.\n        kernel = self.kernel_manager.get_kernel(self.kernel_id)\n        self.session.key = kernel.session.key\n        future = self.request_kernel_info()\n        \n        def give_up():\n            \"\"\"Don't wait forever for the kernel to reply\"\"\"\n            if future.done():\n                return\n            self.log.warn(\"Timeout waiting for kernel_info reply from %s\", self.kernel_id)\n            future.set_result({})\n        loop = IOLoop.current()\n        loop.add_timeout(loop.time() + self.kernel_info_timeout, give_up)\n        # actually wait for it\n        yield future\n    \n    @gen.coroutine\n    def get(self, kernel_id):\n        self.kernel_id = cast_unicode(kernel_id, 'ascii')\n        yield super(ZMQChannelsHandler, self).get(kernel_id=kernel_id)\n    \n    def open(self, kernel_id):\n        super(ZMQChannelsHandler, self).open()\n        try:\n            self.create_stream()\n        except web.HTTPError as e:\n            self.log.error(\"Error opening stream: %s\", e)\n            # WebSockets don't response to traditional error codes so we\n            # close the connection.\n            for channel, stream in self.channels.items():\n                if not stream.closed():\n                    stream.close()\n            self.close()\n        else:\n            for channel, stream in self.channels.items():\n                stream.on_recv_stream(self._on_zmq_reply)\n\n    def on_message(self, msg):\n        if not self.channels:\n            # already closed, ignore the message\n            self.log.debug(\"Received message on closed websocket %r\", msg)\n            return\n        if isinstance(msg, bytes):\n            msg = deserialize_binary_message(msg)\n        else:\n            msg = json.loads(msg)\n        channel = msg.pop('channel', None)\n        if channel is None:\n            self.log.warn(\"No channel specified, assuming shell: %s\", msg)\n            channel = 'shell'\n        if channel not in self.channels:\n            self.log.warn(\"No such channel: %r\", channel)\n            return\n        stream = self.channels[channel]\n        self.session.send(stream, msg)\n\n    def on_close(self):\n        km = self.kernel_manager\n        if self.kernel_id in km:\n            km.remove_restart_callback(\n                self.kernel_id, self.on_kernel_restarted,\n            )\n            km.remove_restart_callback(\n                self.kernel_id, self.on_restart_failed, 'dead',\n            )\n        # This method can be called twice, once by self.kernel_died and once\n        # from the WebSocket close event. If the WebSocket connection is\n        # closed before the ZMQ streams are setup, they could be None.\n        for channel, stream in self.channels.items():\n            if stream is not None and not stream.closed():\n                stream.on_recv(None)\n                # close the socket directly, don't wait for the stream\n                socket = stream.socket\n                stream.close()\n                socket.close()\n        \n        self.channels = {}\n\n    def _send_status_message(self, status):\n        msg = self.session.msg(\"status\",\n            {'execution_state': status}\n        )\n        msg['channel'] = 'iopub'\n        self.write_message(json.dumps(msg, default=date_default))\n\n    def on_kernel_restarted(self):\n        logging.warn(\"kernel %s restarted\", self.kernel_id)\n        self._send_status_message('restarting')\n\n    def on_restart_failed(self):\n        logging.error(\"kernel %s restarted failed!\", self.kernel_id)\n        self._send_status_message('dead')\n\n\n#-----------------------------------------------------------------------------\n# URL to handler mappings\n#-----------------------------------------------------------------------------\n\n\n_kernel_id_regex = r\"(?P<kernel_id>\\w+-\\w+-\\w+-\\w+-\\w+)\"\n_kernel_action_regex = r\"(?P<action>restart|interrupt)\"\n\ndefault_handlers = [\n    (r\"/api/kernels\", MainKernelHandler),\n    (r\"/api/kernels/%s\" % _kernel_id_regex, KernelHandler),\n    (r\"/api/kernels/%s/%s\" % (_kernel_id_regex, _kernel_action_regex), KernelActionHandler),\n    (r\"/api/kernels/%s/channels\" % _kernel_id_regex, ZMQChannelsHandler),\n]\n", "target": 1}
{"idx": 937, "func": "# -*- coding: utf-8 -*-\nfrom __future__ import unicode_literals\n\nimport datetime\nimport os\nimport tempfile\nimport uuid\n\nfrom django.contrib.auth.models import User\nfrom django.contrib.contenttypes.fields import (\n    GenericForeignKey, GenericRelation,\n)\nfrom django.contrib.contenttypes.models import ContentType\nfrom django.core.files.storage import FileSystemStorage\nfrom django.db import models\nfrom django.utils.encoding import python_2_unicode_compatible\n\n\nclass Section(models.Model):\n    \"\"\"\n    A simple section that links to articles, to test linking to related items\n    in admin views.\n    \"\"\"\n    name = models.CharField(max_length=100)\n\n    @property\n    def name_property(self):\n        \"\"\"\n        A property that simply returns the name. Used to test #24461\n        \"\"\"\n        return self.name\n\n\n@python_2_unicode_compatible\nclass Article(models.Model):\n    \"\"\"\n    A simple article to test admin views. Test backwards compatibility.\n    \"\"\"\n    title = models.CharField(max_length=100)\n    content = models.TextField()\n    date = models.DateTimeField()\n    section = models.ForeignKey(Section, null=True, blank=True)\n    sub_section = models.ForeignKey(Section, null=True, blank=True, on_delete=models.SET_NULL, related_name='+')\n\n    def __str__(self):\n        return self.title\n\n    def model_year(self):\n        return self.date.year\n    model_year.admin_order_field = 'date'\n    model_year.short_description = ''\n\n    def model_year_reversed(self):\n        return self.date.year\n    model_year_reversed.admin_order_field = '-date'\n    model_year_reversed.short_description = ''\n\n\n@python_2_unicode_compatible\nclass Book(models.Model):\n    \"\"\"\n    A simple book that has chapters.\n    \"\"\"\n    name = models.CharField(max_length=100, verbose_name='\u00bfName?')\n\n    def __str__(self):\n        return self.name\n\n\n@python_2_unicode_compatible\nclass Promo(models.Model):\n    name = models.CharField(max_length=100, verbose_name='\u00bfName?')\n    book = models.ForeignKey(Book)\n\n    def __str__(self):\n        return self.name\n\n\n@python_2_unicode_compatible\nclass Chapter(models.Model):\n    title = models.CharField(max_length=100, verbose_name='\u00bfTitle?')\n    content = models.TextField()\n    book = models.ForeignKey(Book)\n\n    def __str__(self):\n        return self.title\n\n    class Meta:\n        # Use a utf-8 bytestring to ensure it works (see #11710)\n        verbose_name = '\u00bfChapter?'\n\n\n@python_2_unicode_compatible\nclass ChapterXtra1(models.Model):\n    chap = models.OneToOneField(Chapter, verbose_name='\u00bfChap?')\n    xtra = models.CharField(max_length=100, verbose_name='\u00bfXtra?')\n\n    def __str__(self):\n        return '\u00bfXtra1: %s' % self.xtra\n\n\n@python_2_unicode_compatible\nclass ChapterXtra2(models.Model):\n    chap = models.OneToOneField(Chapter, verbose_name='\u00bfChap?')\n    xtra = models.CharField(max_length=100, verbose_name='\u00bfXtra?')\n\n    def __str__(self):\n        return '\u00bfXtra2: %s' % self.xtra\n\n\nclass RowLevelChangePermissionModel(models.Model):\n    name = models.CharField(max_length=100, blank=True)\n\n\nclass CustomArticle(models.Model):\n    content = models.TextField()\n    date = models.DateTimeField()\n\n\n@python_2_unicode_compatible\nclass ModelWithStringPrimaryKey(models.Model):\n    string_pk = models.CharField(max_length=255, primary_key=True)\n\n    def __str__(self):\n        return self.string_pk\n\n    def get_absolute_url(self):\n        return '/dummy/%s/' % self.string_pk\n\n\n@python_2_unicode_compatible\nclass Color(models.Model):\n    value = models.CharField(max_length=10)\n    warm = models.BooleanField(default=False)\n\n    def __str__(self):\n        return self.value\n\n\n# we replicate Color to register with another ModelAdmin\nclass Color2(Color):\n    class Meta:\n        proxy = True\n\n\n@python_2_unicode_compatible\nclass Thing(models.Model):\n    title = models.CharField(max_length=20)\n    color = models.ForeignKey(Color, limit_choices_to={'warm': True})\n    pub_date = models.DateField(blank=True, null=True)\n\n    def __str__(self):\n        return self.title\n\n\n@python_2_unicode_compatible\nclass Actor(models.Model):\n    name = models.CharField(max_length=50)\n    age = models.IntegerField()\n    title = models.CharField(max_length=50, null=True, blank=True)\n\n    def __str__(self):\n        return self.name\n\n\n@python_2_unicode_compatible\nclass Inquisition(models.Model):\n    expected = models.BooleanField(default=False)\n    leader = models.ForeignKey(Actor)\n    country = models.CharField(max_length=20)\n\n    def __str__(self):\n        return \"by %s from %s\" % (self.leader, self.country)\n\n\n@python_2_unicode_compatible\nclass Sketch(models.Model):\n    title = models.CharField(max_length=100)\n    inquisition = models.ForeignKey(Inquisition, limit_choices_to={'leader__name': 'Palin',\n                                                                   'leader__age': 27,\n                                                                   'expected': False,\n                                                                   })\n    defendant0 = models.ForeignKey(Actor, limit_choices_to={'title__isnull': False}, related_name='as_defendant0')\n    defendant1 = models.ForeignKey(Actor, limit_choices_to={'title__isnull': True}, related_name='as_defendant1')\n\n    def __str__(self):\n        return self.title\n\n\ndef today_callable_dict():\n    return {\"last_action__gte\": datetime.datetime.today()}\n\n\ndef today_callable_q():\n    return models.Q(last_action__gte=datetime.datetime.today())\n\n\n@python_2_unicode_compatible\nclass Character(models.Model):\n    username = models.CharField(max_length=100)\n    last_action = models.DateTimeField()\n\n    def __str__(self):\n        return self.username\n\n\n@python_2_unicode_compatible\nclass StumpJoke(models.Model):\n    variation = models.CharField(max_length=100)\n    most_recently_fooled = models.ForeignKey(Character, limit_choices_to=today_callable_dict, related_name=\"+\")\n    has_fooled_today = models.ManyToManyField(Character, limit_choices_to=today_callable_q, related_name=\"+\")\n\n    def __str__(self):\n        return self.variation\n\n\nclass Fabric(models.Model):\n    NG_CHOICES = (\n        ('Textured', (\n            ('x', 'Horizontal'),\n            ('y', 'Vertical'),\n        )),\n        ('plain', 'Smooth'),\n    )\n    surface = models.CharField(max_length=20, choices=NG_CHOICES)\n\n\n@python_2_unicode_compatible\nclass Person(models.Model):\n    GENDER_CHOICES = (\n        (1, \"Male\"),\n        (2, \"Female\"),\n    )\n    name = models.CharField(max_length=100)\n    gender = models.IntegerField(choices=GENDER_CHOICES)\n    age = models.IntegerField(default=21)\n    alive = models.BooleanField(default=True)\n\n    def __str__(self):\n        return self.name\n\n\n@python_2_unicode_compatible\nclass Persona(models.Model):\n    \"\"\"\n    A simple persona associated with accounts, to test inlining of related\n    accounts which inherit from a common accounts class.\n    \"\"\"\n    name = models.CharField(blank=False, max_length=80)\n\n    def __str__(self):\n        return self.name\n\n\n@python_2_unicode_compatible\nclass Account(models.Model):\n    \"\"\"\n    A simple, generic account encapsulating the information shared by all\n    types of accounts.\n    \"\"\"\n    username = models.CharField(blank=False, max_length=80)\n    persona = models.ForeignKey(Persona, related_name=\"accounts\")\n    servicename = 'generic service'\n\n    def __str__(self):\n        return \"%s: %s\" % (self.servicename, self.username)\n\n\nclass FooAccount(Account):\n    \"\"\"A service-specific account of type Foo.\"\"\"\n    servicename = 'foo'\n\n\nclass BarAccount(Account):\n    \"\"\"A service-specific account of type Bar.\"\"\"\n    servicename = 'bar'\n\n\n@python_2_unicode_compatible\nclass Subscriber(models.Model):\n    name = models.CharField(blank=False, max_length=80)\n    email = models.EmailField(blank=False, max_length=175)\n\n    def __str__(self):\n        return \"%s (%s)\" % (self.name, self.email)\n\n\nclass ExternalSubscriber(Subscriber):\n    pass\n\n\nclass OldSubscriber(Subscriber):\n    pass\n\n\nclass Media(models.Model):\n    name = models.CharField(max_length=60)\n\n\nclass Podcast(Media):\n    release_date = models.DateField()\n\n    class Meta:\n        ordering = ('release_date',)  # overridden in PodcastAdmin\n\n\nclass Vodcast(Media):\n    media = models.OneToOneField(Media, primary_key=True, parent_link=True)\n    released = models.BooleanField(default=False)\n\n\nclass Parent(models.Model):\n    name = models.CharField(max_length=128)\n\n\nclass Child(models.Model):\n    parent = models.ForeignKey(Parent, editable=False)\n    name = models.CharField(max_length=30, blank=True)\n\n\n@python_2_unicode_compatible\nclass EmptyModel(models.Model):\n    def __str__(self):\n        return \"Primary key = %s\" % self.id\n\n\ntemp_storage = FileSystemStorage(tempfile.mkdtemp())\nUPLOAD_TO = os.path.join(temp_storage.location, 'test_upload')\n\n\nclass Gallery(models.Model):\n    name = models.CharField(max_length=100)\n\n\nclass Picture(models.Model):\n    name = models.CharField(max_length=100)\n    image = models.FileField(storage=temp_storage, upload_to='test_upload')\n    gallery = models.ForeignKey(Gallery, related_name=\"pictures\")\n\n\nclass Language(models.Model):\n    iso = models.CharField(max_length=5, primary_key=True)\n    name = models.CharField(max_length=50)\n    english_name = models.CharField(max_length=50)\n    shortlist = models.BooleanField(default=False)\n\n    class Meta:\n        ordering = ('iso',)\n\n\n# a base class for Recommender and Recommendation\nclass Title(models.Model):\n    pass\n\n\nclass TitleTranslation(models.Model):\n    title = models.ForeignKey(Title)\n    text = models.CharField(max_length=100)\n\n\nclass Recommender(Title):\n    pass\n\n\nclass Recommendation(Title):\n    recommender = models.ForeignKey(Recommender)\n\n\nclass Collector(models.Model):\n    name = models.CharField(max_length=100)\n\n\nclass Widget(models.Model):\n    owner = models.ForeignKey(Collector)\n    name = models.CharField(max_length=100)\n\n\nclass DooHickey(models.Model):\n    code = models.CharField(max_length=10, primary_key=True)\n    owner = models.ForeignKey(Collector)\n    name = models.CharField(max_length=100)\n\n\nclass Grommet(models.Model):\n    code = models.AutoField(primary_key=True)\n    owner = models.ForeignKey(Collector)\n    name = models.CharField(max_length=100)\n\n\nclass Whatsit(models.Model):\n    index = models.IntegerField(primary_key=True)\n    owner = models.ForeignKey(Collector)\n    name = models.CharField(max_length=100)\n\n\nclass Doodad(models.Model):\n    name = models.CharField(max_length=100)\n\n\nclass FancyDoodad(Doodad):\n    owner = models.ForeignKey(Collector)\n    expensive = models.BooleanField(default=True)\n\n\n@python_2_unicode_compatible\nclass Category(models.Model):\n    collector = models.ForeignKey(Collector)\n    order = models.PositiveIntegerField()\n\n    class Meta:\n        ordering = ('order',)\n\n    def __str__(self):\n        return '%s:o%s' % (self.id, self.order)\n\n\nclass Link(models.Model):\n    posted = models.DateField(\n        default=lambda: datetime.date.today() - datetime.timedelta(days=7)\n    )\n    url = models.URLField()\n    post = models.ForeignKey(\"Post\")\n    readonly_link_content = models.TextField()\n\n\nclass PrePopulatedPost(models.Model):\n    title = models.CharField(max_length=100)\n    published = models.BooleanField(default=False)\n    slug = models.SlugField()\n\n\nclass PrePopulatedSubPost(models.Model):\n    post = models.ForeignKey(PrePopulatedPost)\n    subtitle = models.CharField(max_length=100)\n    subslug = models.SlugField()\n\n\nclass Post(models.Model):\n    title = models.CharField(max_length=100, help_text=\"Some help text for the title (with unicode \u0160\u0110\u0106\u017d\u0107\u017e\u0161\u0111)\")\n    content = models.TextField(help_text=\"Some help text for the content (with unicode \u0160\u0110\u0106\u017d\u0107\u017e\u0161\u0111)\")\n    readonly_content = models.TextField()\n    posted = models.DateField(\n        default=datetime.date.today,\n        help_text=\"Some help text for the date (with unicode \u0160\u0110\u0106\u017d\u0107\u017e\u0161\u0111)\"\n    )\n    public = models.NullBooleanField()\n\n    def awesomeness_level(self):\n        return \"Very awesome.\"\n\n\n# Proxy model to test overridden fields attrs on Post model so as not to\n# interfere with other tests.\nclass FieldOverridePost(Post):\n    class Meta:\n        proxy = True\n\n\n@python_2_unicode_compatible\nclass Gadget(models.Model):\n    name = models.CharField(max_length=100)\n\n    def __str__(self):\n        return self.name\n\n\n@python_2_unicode_compatible\nclass Villain(models.Model):\n    name = models.CharField(max_length=100)\n\n    def __str__(self):\n        return self.name\n\n\nclass SuperVillain(Villain):\n    pass\n\n\n@python_2_unicode_compatible\nclass FunkyTag(models.Model):\n    \"Because we all know there's only one real use case for GFKs.\"\n    name = models.CharField(max_length=25)\n    content_type = models.ForeignKey(ContentType)\n    object_id = models.PositiveIntegerField()\n    content_object = GenericForeignKey('content_type', 'object_id')\n\n    def __str__(self):\n        return self.name\n\n\n@python_2_unicode_compatible\nclass Plot(models.Model):\n    name = models.CharField(max_length=100)\n    team_leader = models.ForeignKey(Villain, related_name='lead_plots')\n    contact = models.ForeignKey(Villain, related_name='contact_plots')\n    tags = GenericRelation(FunkyTag)\n\n    def __str__(self):\n        return self.name\n\n\n@python_2_unicode_compatible\nclass PlotDetails(models.Model):\n    details = models.CharField(max_length=100)\n    plot = models.OneToOneField(Plot, null=True, blank=True)\n\n    def __str__(self):\n        return self.details\n\n\nclass PlotProxy(Plot):\n    class Meta:\n        proxy = True\n\n\n@python_2_unicode_compatible\nclass SecretHideout(models.Model):\n    \"\"\" Secret! Not registered with the admin! \"\"\"\n    location = models.CharField(max_length=100)\n    villain = models.ForeignKey(Villain)\n\n    def __str__(self):\n        return self.location\n\n\n@python_2_unicode_compatible\nclass SuperSecretHideout(models.Model):\n    \"\"\" Secret! Not registered with the admin! \"\"\"\n    location = models.CharField(max_length=100)\n    supervillain = models.ForeignKey(SuperVillain)\n\n    def __str__(self):\n        return self.location\n\n\n@python_2_unicode_compatible\nclass CyclicOne(models.Model):\n    name = models.CharField(max_length=25)\n    two = models.ForeignKey('CyclicTwo')\n\n    def __str__(self):\n        return self.name\n\n\n@python_2_unicode_compatible\nclass CyclicTwo(models.Model):\n    name = models.CharField(max_length=25)\n    one = models.ForeignKey(CyclicOne)\n\n    def __str__(self):\n        return self.name\n\n\nclass Topping(models.Model):\n    name = models.CharField(max_length=20)\n\n\nclass Pizza(models.Model):\n    name = models.CharField(max_length=20)\n    toppings = models.ManyToManyField('Topping', related_name='pizzas')\n\n\nclass Album(models.Model):\n    owner = models.ForeignKey(User, null=True, blank=True, on_delete=models.SET_NULL)\n    title = models.CharField(max_length=30)\n\n\nclass Employee(Person):\n    code = models.CharField(max_length=20)\n\n\nclass WorkHour(models.Model):\n    datum = models.DateField()\n    employee = models.ForeignKey(Employee)\n\n\nclass Question(models.Model):\n    question = models.CharField(max_length=20)\n\n\n@python_2_unicode_compatible\nclass Answer(models.Model):\n    question = models.ForeignKey(Question, on_delete=models.PROTECT)\n    answer = models.CharField(max_length=20)\n\n    def __str__(self):\n        return self.answer\n\n\nclass Reservation(models.Model):\n    start_date = models.DateTimeField()\n    price = models.IntegerField()\n\n\nDRIVER_CHOICES = (\n    ('bill', 'Bill G'),\n    ('steve', 'Steve J'),\n)\n\nRESTAURANT_CHOICES = (\n    ('indian', 'A Taste of India'),\n    ('thai', 'Thai Pography'),\n    ('pizza', 'Pizza Mama'),\n)\n\n\nclass FoodDelivery(models.Model):\n    reference = models.CharField(max_length=100)\n    driver = models.CharField(max_length=100, choices=DRIVER_CHOICES, blank=True)\n    restaurant = models.CharField(max_length=100, choices=RESTAURANT_CHOICES, blank=True)\n\n    class Meta:\n        unique_together = ((\"driver\", \"restaurant\"),)\n\n\n@python_2_unicode_compatible\nclass CoverLetter(models.Model):\n    author = models.CharField(max_length=30)\n    date_written = models.DateField(null=True, blank=True)\n\n    def __str__(self):\n        return self.author\n\n\nclass Paper(models.Model):\n    title = models.CharField(max_length=30)\n    author = models.CharField(max_length=30, blank=True, null=True)\n\n\nclass ShortMessage(models.Model):\n    content = models.CharField(max_length=140)\n    timestamp = models.DateTimeField(null=True, blank=True)\n\n\n@python_2_unicode_compatible\nclass Telegram(models.Model):\n    title = models.CharField(max_length=30)\n    date_sent = models.DateField(null=True, blank=True)\n\n    def __str__(self):\n        return self.title\n\n\nclass Story(models.Model):\n    title = models.CharField(max_length=100)\n    content = models.TextField()\n\n\nclass OtherStory(models.Model):\n    title = models.CharField(max_length=100)\n    content = models.TextField()\n\n\nclass ComplexSortedPerson(models.Model):\n    name = models.CharField(max_length=100)\n    age = models.PositiveIntegerField()\n    is_employee = models.NullBooleanField()\n\n\nclass PluggableSearchPerson(models.Model):\n    name = models.CharField(max_length=100)\n    age = models.PositiveIntegerField()\n\n\nclass PrePopulatedPostLargeSlug(models.Model):\n    \"\"\"\n    Regression test for #15938: a large max_length for the slugfield must not\n    be localized in prepopulated_fields_js.html or it might end up breaking\n    the javascript (ie, using THOUSAND_SEPARATOR ends up with maxLength=1,000)\n    \"\"\"\n    title = models.CharField(max_length=100)\n    published = models.BooleanField(default=False)\n    # `db_index=False` because MySQL cannot index large CharField (#21196).\n    slug = models.SlugField(max_length=1000, db_index=False)\n\n\nclass AdminOrderedField(models.Model):\n    order = models.IntegerField()\n    stuff = models.CharField(max_length=200)\n\n\nclass AdminOrderedModelMethod(models.Model):\n    order = models.IntegerField()\n    stuff = models.CharField(max_length=200)\n\n    def some_order(self):\n        return self.order\n    some_order.admin_order_field = 'order'\n\n\nclass AdminOrderedAdminMethod(models.Model):\n    order = models.IntegerField()\n    stuff = models.CharField(max_length=200)\n\n\nclass AdminOrderedCallable(models.Model):\n    order = models.IntegerField()\n    stuff = models.CharField(max_length=200)\n\n\n@python_2_unicode_compatible\nclass Report(models.Model):\n    title = models.CharField(max_length=100)\n\n    def __str__(self):\n        return self.title\n\n\nclass MainPrepopulated(models.Model):\n    name = models.CharField(max_length=100)\n    pubdate = models.DateField()\n    status = models.CharField(\n        max_length=20,\n        choices=(('option one', 'Option One'),\n                 ('option two', 'Option Two')))\n    slug1 = models.SlugField(blank=True)\n    slug2 = models.SlugField(blank=True)\n\n\nclass RelatedPrepopulated(models.Model):\n    parent = models.ForeignKey(MainPrepopulated)\n    name = models.CharField(max_length=75)\n    pubdate = models.DateField()\n    status = models.CharField(\n        max_length=20,\n        choices=(('option one', 'Option One'),\n                 ('option two', 'Option Two')))\n    slug1 = models.SlugField(max_length=50)\n    slug2 = models.SlugField(max_length=60)\n\n\nclass UnorderedObject(models.Model):\n    \"\"\"\n    Model without any defined `Meta.ordering`.\n    Refs #16819.\n    \"\"\"\n    name = models.CharField(max_length=255)\n    bool = models.BooleanField(default=True)\n\n\nclass UndeletableObject(models.Model):\n    \"\"\"\n    Model whose show_delete in admin change_view has been disabled\n    Refs #10057.\n    \"\"\"\n    name = models.CharField(max_length=255)\n\n\nclass UnchangeableObject(models.Model):\n    \"\"\"\n    Model whose change_view is disabled in admin\n    Refs #20640.\n    \"\"\"\n\n\nclass UserMessenger(models.Model):\n    \"\"\"\n    Dummy class for testing message_user functions on ModelAdmin\n    \"\"\"\n\n\nclass Simple(models.Model):\n    \"\"\"\n    Simple model with nothing on it for use in testing\n    \"\"\"\n\n\nclass Choice(models.Model):\n    choice = models.IntegerField(blank=True, null=True,\n        choices=((1, 'Yes'), (0, 'No'), (None, 'No opinion')))\n\n\nclass ParentWithDependentChildren(models.Model):\n    \"\"\"\n    Issue #20522\n    Model where the validation of child foreign-key relationships depends\n    on validation of the parent\n    \"\"\"\n    some_required_info = models.PositiveIntegerField()\n    family_name = models.CharField(max_length=255, blank=False)\n\n\nclass DependentChild(models.Model):\n    \"\"\"\n    Issue #20522\n    Model that depends on validation of the parent class for one of its\n    fields to validate during clean\n    \"\"\"\n    parent = models.ForeignKey(ParentWithDependentChildren)\n    family_name = models.CharField(max_length=255)\n\n\nclass _Manager(models.Manager):\n    def get_queryset(self):\n        return super(_Manager, self).get_queryset().filter(pk__gt=1)\n\n\nclass FilteredManager(models.Model):\n    def __str__(self):\n        return \"PK=%d\" % self.pk\n\n    pk_gt_1 = _Manager()\n    objects = models.Manager()\n\n\nclass EmptyModelVisible(models.Model):\n    \"\"\" See ticket #11277. \"\"\"\n\n\nclass EmptyModelHidden(models.Model):\n    \"\"\" See ticket #11277. \"\"\"\n\n\nclass EmptyModelMixin(models.Model):\n    \"\"\" See ticket #11277. \"\"\"\n\n\nclass State(models.Model):\n    name = models.CharField(max_length=100)\n\n\nclass City(models.Model):\n    state = models.ForeignKey(State)\n    name = models.CharField(max_length=100)\n\n    def get_absolute_url(self):\n        return '/dummy/%s/' % self.pk\n\n\nclass Restaurant(models.Model):\n    city = models.ForeignKey(City)\n    name = models.CharField(max_length=100)\n\n    def get_absolute_url(self):\n        return '/dummy/%s/' % self.pk\n\n\nclass Worker(models.Model):\n    work_at = models.ForeignKey(Restaurant)\n    name = models.CharField(max_length=50)\n    surname = models.CharField(max_length=50)\n\n\n# Models for #23329\nclass ReferencedByParent(models.Model):\n    name = models.CharField(max_length=20, unique=True)\n\n\nclass ParentWithFK(models.Model):\n    fk = models.ForeignKey(\n        ReferencedByParent, to_field='name', related_name='hidden+',\n    )\n\n\nclass ChildOfReferer(ParentWithFK):\n    pass\n\n\n# Models for #23431\nclass ReferencedByInline(models.Model):\n    name = models.CharField(max_length=20, unique=True)\n\n\nclass InlineReference(models.Model):\n    fk = models.ForeignKey(\n        ReferencedByInline, to_field='name', related_name='hidden+',\n    )\n\n\nclass InlineReferer(models.Model):\n    refs = models.ManyToManyField(InlineReference)\n\n\n# Models for #23604 and #23915\nclass Recipe(models.Model):\n    rname = models.CharField(max_length=20, unique=True)\n\n\nclass Ingredient(models.Model):\n    iname = models.CharField(max_length=20, unique=True)\n    recipes = models.ManyToManyField(Recipe, through='RecipeIngredient')\n\n\nclass RecipeIngredient(models.Model):\n    ingredient = models.ForeignKey(Ingredient, to_field='iname')\n    recipe = models.ForeignKey(Recipe, to_field='rname')\n\n\n# Model for #23839\nclass NotReferenced(models.Model):\n    # Don't point any FK at this model.\n    pass\n\n\n# Models for #23934\nclass ExplicitlyProvidedPK(models.Model):\n    name = models.IntegerField(primary_key=True)\n\n\nclass ImplicitlyGeneratedPK(models.Model):\n    name = models.IntegerField(unique=True)\n\n\n# Models for #25622\nclass ReferencedByGenRel(models.Model):\n    content_type = models.ForeignKey(ContentType, on_delete=models.CASCADE)\n    object_id = models.PositiveIntegerField()\n    content_object = GenericForeignKey('content_type', 'object_id')\n\n\nclass GenRelReference(models.Model):\n    references = GenericRelation(ReferencedByGenRel)\n\n\nclass ParentWithUUIDPK(models.Model):\n    id = models.UUIDField(primary_key=True, default=uuid.uuid4, editable=False)\n    title = models.CharField(max_length=100)\n\n    def __str__(self):\n        return str(self.id)\n\n\nclass RelatedWithUUIDPKModel(models.Model):\n    parent = models.ForeignKey(ParentWithUUIDPK, on_delete=models.CASCADE)\n", "target": 1}
{"idx": 938, "func": "\"\"\"Module for Trivia cog.\"\"\"\nimport asyncio\nimport math\nimport pathlib\nfrom collections import Counter\nfrom typing import List, Literal\n\nimport io\nimport yaml\nimport discord\n\nfrom redbot.core import Config, commands, checks\nfrom redbot.cogs.bank import is_owner_if_bank_global\nfrom redbot.core.data_manager import cog_data_path\nfrom redbot.core.i18n import Translator, cog_i18n\nfrom redbot.core.utils import AsyncIter\nfrom redbot.core.utils.chat_formatting import box, pagify, bold\nfrom redbot.core.utils.menus import start_adding_reactions\nfrom redbot.core.utils.predicates import MessagePredicate, ReactionPredicate\n\nfrom .checks import trivia_stop_check\nfrom .converters import finite_float\nfrom .log import LOG\nfrom .session import TriviaSession\n\n__all__ = [\"Trivia\", \"UNIQUE_ID\", \"get_core_lists\"]\n\nUNIQUE_ID = 0xB3C0E453\n\n_ = Translator(\"Trivia\", __file__)\n\n\nclass InvalidListError(Exception):\n    \"\"\"A Trivia list file is in invalid format.\"\"\"\n\n    pass\n\n\n@cog_i18n(_)\nclass Trivia(commands.Cog):\n    \"\"\"Play trivia with friends!\"\"\"\n\n    def __init__(self):\n        super().__init__()\n        self.trivia_sessions = []\n        self.config = Config.get_conf(self, identifier=UNIQUE_ID, force_registration=True)\n\n        self.config.register_guild(\n            max_score=10,\n            timeout=120.0,\n            delay=15.0,\n            bot_plays=False,\n            reveal_answer=True,\n            payout_multiplier=0.0,\n            allow_override=True,\n        )\n\n        self.config.register_member(wins=0, games=0, total_score=0)\n\n    async def red_delete_data_for_user(\n        self,\n        *,\n        requester: Literal[\"discord_deleted_user\", \"owner\", \"user\", \"user_strict\"],\n        user_id: int,\n    ):\n        if requester != \"discord_deleted_user\":\n            return\n\n        all_members = await self.config.all_members()\n\n        async for guild_id, guild_data in AsyncIter(all_members.items(), steps=100):\n            if user_id in guild_data:\n                await self.config.member_from_ids(guild_id, user_id).clear()\n\n    @commands.group()\n    @commands.guild_only()\n    @checks.mod_or_permissions(administrator=True)\n    async def triviaset(self, ctx: commands.Context):\n        \"\"\"Manage Trivia settings.\"\"\"\n\n    @triviaset.command(name=\"showsettings\")\n    async def triviaset_showsettings(self, ctx: commands.Context):\n        \"\"\"Show the current trivia settings.\"\"\"\n        settings = self.config.guild(ctx.guild)\n        settings_dict = await settings.all()\n        msg = box(\n            _(\n                \"Current settings\\n\"\n                \"Bot gains points: {bot_plays}\\n\"\n                \"Answer time limit: {delay} seconds\\n\"\n                \"Lack of response timeout: {timeout} seconds\\n\"\n                \"Points to win: {max_score}\\n\"\n                \"Reveal answer on timeout: {reveal_answer}\\n\"\n                \"Payout multiplier: {payout_multiplier}\\n\"\n                \"Allow lists to override settings: {allow_override}\"\n            ).format(**settings_dict),\n            lang=\"py\",\n        )\n        await ctx.send(msg)\n\n    @triviaset.command(name=\"maxscore\")\n    async def triviaset_max_score(self, ctx: commands.Context, score: int):\n        \"\"\"Set the total points required to win.\"\"\"\n        if score < 0:\n            await ctx.send(_(\"Score must be greater than 0.\"))\n            return\n        settings = self.config.guild(ctx.guild)\n        await settings.max_score.set(score)\n        await ctx.send(_(\"Done. Points required to win set to {num}.\").format(num=score))\n\n    @triviaset.command(name=\"timelimit\")\n    async def triviaset_timelimit(self, ctx: commands.Context, seconds: finite_float):\n        \"\"\"Set the maximum seconds permitted to answer a question.\"\"\"\n        if seconds < 4.0:\n            await ctx.send(_(\"Must be at least 4 seconds.\"))\n            return\n        settings = self.config.guild(ctx.guild)\n        await settings.delay.set(seconds)\n        await ctx.send(_(\"Done. Maximum seconds to answer set to {num}.\").format(num=seconds))\n\n    @triviaset.command(name=\"stopafter\")\n    async def triviaset_stopafter(self, ctx: commands.Context, seconds: finite_float):\n        \"\"\"Set how long until trivia stops due to no response.\"\"\"\n        settings = self.config.guild(ctx.guild)\n        if seconds < await settings.delay():\n            await ctx.send(_(\"Must be larger than the answer time limit.\"))\n            return\n        await settings.timeout.set(seconds)\n        await ctx.send(\n            _(\n                \"Done. Trivia sessions will now time out after {num} seconds of no responses.\"\n            ).format(num=seconds)\n        )\n\n    @triviaset.command(name=\"override\")\n    async def triviaset_allowoverride(self, ctx: commands.Context, enabled: bool):\n        \"\"\"Allow/disallow trivia lists to override settings.\"\"\"\n        settings = self.config.guild(ctx.guild)\n        await settings.allow_override.set(enabled)\n        if enabled:\n            await ctx.send(\n                _(\"Done. Trivia lists can now override the trivia settings for this server.\")\n            )\n        else:\n            await ctx.send(\n                _(\n                    \"Done. Trivia lists can no longer override the trivia settings for this \"\n                    \"server.\"\n                )\n            )\n\n    @triviaset.command(name=\"botplays\", usage=\"<true_or_false>\")\n    async def trivaset_bot_plays(self, ctx: commands.Context, enabled: bool):\n        \"\"\"Set whether or not the bot gains points.\n\n        If enabled, the bot will gain a point if no one guesses correctly.\n        \"\"\"\n        settings = self.config.guild(ctx.guild)\n        await settings.bot_plays.set(enabled)\n        if enabled:\n            await ctx.send(_(\"Done. I'll now gain a point if users don't answer in time.\"))\n        else:\n            await ctx.send(_(\"Alright, I won't embarass you at trivia anymore.\"))\n\n    @triviaset.command(name=\"revealanswer\", usage=\"<true_or_false>\")\n    async def trivaset_reveal_answer(self, ctx: commands.Context, enabled: bool):\n        \"\"\"Set whether or not the answer is revealed.\n\n        If enabled, the bot will reveal the answer if no one guesses correctly\n        in time.\n        \"\"\"\n        settings = self.config.guild(ctx.guild)\n        await settings.reveal_answer.set(enabled)\n        if enabled:\n            await ctx.send(_(\"Done. I'll reveal the answer if no one knows it.\"))\n        else:\n            await ctx.send(_(\"Alright, I won't reveal the answer to the questions anymore.\"))\n\n    @is_owner_if_bank_global()\n    @checks.admin_or_permissions(manage_guild=True)\n    @triviaset.command(name=\"payout\")\n    async def triviaset_payout_multiplier(self, ctx: commands.Context, multiplier: finite_float):\n        \"\"\"Set the payout multiplier.\n\n        This can be any positive decimal number. If a user wins trivia when at\n        least 3 members are playing, they will receive credits. Set to 0 to\n        disable.\n\n        The number of credits is determined by multiplying their total score by\n        this multiplier.\n        \"\"\"\n        settings = self.config.guild(ctx.guild)\n        if multiplier < 0:\n            await ctx.send(_(\"Multiplier must be at least 0.\"))\n            return\n        await settings.payout_multiplier.set(multiplier)\n        if multiplier:\n            await ctx.send(_(\"Done. Payout multiplier set to {num}.\").format(num=multiplier))\n        else:\n            await ctx.send(_(\"Done. I will no longer reward the winner with a payout.\"))\n\n    @triviaset.group(name=\"custom\")\n    @commands.is_owner()\n    async def triviaset_custom(self, ctx: commands.Context):\n        \"\"\"Manage Custom Trivia lists.\"\"\"\n        pass\n\n    @triviaset_custom.command(name=\"list\")\n    async def custom_trivia_list(self, ctx: commands.Context):\n        \"\"\"List uploaded custom trivia.\"\"\"\n        personal_lists = sorted([p.resolve().stem for p in cog_data_path(self).glob(\"*.yaml\")])\n        no_lists_uploaded = _(\"No custom Trivia lists uploaded.\")\n\n        if not personal_lists:\n            if await ctx.embed_requested():\n                await ctx.send(\n                    embed=discord.Embed(\n                        colour=await ctx.embed_colour(), description=no_lists_uploaded\n                    )\n                )\n            else:\n                await ctx.send(no_lists_uploaded)\n            return\n\n        if await ctx.embed_requested():\n            await ctx.send(\n                embed=discord.Embed(\n                    title=_(\"Uploaded trivia lists\"),\n                    colour=await ctx.embed_colour(),\n                    description=\", \".join(sorted(personal_lists)),\n                )\n            )\n        else:\n            msg = box(\n                bold(_(\"Uploaded trivia lists\")) + \"\\n\\n\" + \", \".join(sorted(personal_lists))\n            )\n            if len(msg) > 1000:\n                await ctx.author.send(msg)\n            else:\n                await ctx.send(msg)\n\n    @commands.is_owner()\n    @triviaset_custom.command(name=\"upload\", aliases=[\"add\"])\n    async def trivia_upload(self, ctx: commands.Context):\n        \"\"\"Upload a trivia file.\"\"\"\n        if not ctx.message.attachments:\n            await ctx.send(_(\"Supply a file with next message or type anything to cancel.\"))\n            try:\n                message = await ctx.bot.wait_for(\n                    \"message\", check=MessagePredicate.same_context(ctx), timeout=30\n                )\n            except asyncio.TimeoutError:\n                await ctx.send(_(\"You took too long to upload a list.\"))\n                return\n            if not message.attachments:\n                await ctx.send(_(\"You have cancelled the upload process.\"))\n                return\n            parsedfile = message.attachments[0]\n        else:\n            parsedfile = ctx.message.attachments[0]\n        try:\n            await self._save_trivia_list(ctx=ctx, attachment=parsedfile)\n        except yaml.error.MarkedYAMLError as exc:\n            await ctx.send(_(\"Invalid syntax: \") + str(exc))\n        except yaml.error.YAMLError:\n            await ctx.send(\n                _(\"There was an error parsing the trivia list. See logs for more info.\")\n            )\n            LOG.exception(\"Custom Trivia file %s failed to upload\", parsedfile.filename)\n\n    @commands.is_owner()\n    @triviaset_custom.command(name=\"delete\", aliases=[\"remove\"])\n    async def trivia_delete(self, ctx: commands.Context, name: str):\n        \"\"\"Delete a trivia file.\"\"\"\n        filepath = cog_data_path(self) / f\"{name}.yaml\"\n        if filepath.exists():\n            filepath.unlink()\n            await ctx.send(_(\"Trivia {filename} was deleted.\").format(filename=filepath.stem))\n        else:\n            await ctx.send(_(\"Trivia file was not found.\"))\n\n    @commands.group(invoke_without_command=True)\n    @commands.guild_only()\n    async def trivia(self, ctx: commands.Context, *categories: str):\n        \"\"\"Start trivia session on the specified category.\n\n        You may list multiple categories, in which case the trivia will involve\n        questions from all of them.\n        \"\"\"\n        if not categories:\n            await ctx.send_help()\n            return\n        categories = [c.lower() for c in categories]\n        session = self._get_trivia_session(ctx.channel)\n        if session is not None:\n            await ctx.send(_(\"There is already an ongoing trivia session in this channel.\"))\n            return\n        trivia_dict = {}\n        authors = []\n        for category in reversed(categories):\n            # We reverse the categories so that the first list's config takes\n            # priority over the others.\n            try:\n                dict_ = self.get_trivia_list(category)\n            except FileNotFoundError:\n                await ctx.send(\n                    _(\n                        \"Invalid category `{name}`. See `{prefix}trivia list` for a list of \"\n                        \"trivia categories.\"\n                    ).format(name=category, prefix=ctx.clean_prefix)\n                )\n            except InvalidListError:\n                await ctx.send(\n                    _(\n                        \"There was an error parsing the trivia list for the `{name}` category. It \"\n                        \"may be formatted incorrectly.\"\n                    ).format(name=category)\n                )\n            else:\n                trivia_dict.update(dict_)\n                authors.append(trivia_dict.pop(\"AUTHOR\", None))\n                continue\n            return\n        if not trivia_dict:\n            await ctx.send(\n                _(\"The trivia list was parsed successfully, however it appears to be empty!\")\n            )\n            return\n        settings = await self.config.guild(ctx.guild).all()\n        config = trivia_dict.pop(\"CONFIG\", None)\n        if config and settings[\"allow_override\"]:\n            settings.update(config)\n        settings[\"lists\"] = dict(zip(categories, reversed(authors)))\n        session = TriviaSession.start(ctx, trivia_dict, settings)\n        self.trivia_sessions.append(session)\n        LOG.debug(\"New trivia session; #%s in %d\", ctx.channel, ctx.guild.id)\n\n    @trivia_stop_check()\n    @trivia.command(name=\"stop\")\n    async def trivia_stop(self, ctx: commands.Context):\n        \"\"\"Stop an ongoing trivia session.\"\"\"\n        session = self._get_trivia_session(ctx.channel)\n        if session is None:\n            await ctx.send(_(\"There is no ongoing trivia session in this channel.\"))\n            return\n        await session.end_game()\n        session.force_stop()\n        await ctx.send(_(\"Trivia stopped.\"))\n\n    @trivia.command(name=\"list\")\n    async def trivia_list(self, ctx: commands.Context):\n        \"\"\"List available trivia categories.\"\"\"\n        lists = set(p.stem for p in self._all_lists())\n        if await ctx.embed_requested():\n            await ctx.send(\n                embed=discord.Embed(\n                    title=_(\"Available trivia lists\"),\n                    colour=await ctx.embed_colour(),\n                    description=\", \".join(sorted(lists)),\n                )\n            )\n        else:\n            msg = box(bold(_(\"Available trivia lists\")) + \"\\n\\n\" + \", \".join(sorted(lists)))\n            if len(msg) > 1000:\n                await ctx.author.send(msg)\n            else:\n                await ctx.send(msg)\n\n    @trivia.group(\n        name=\"leaderboard\", aliases=[\"lboard\"], autohelp=False, invoke_without_command=True\n    )\n    async def trivia_leaderboard(self, ctx: commands.Context):\n        \"\"\"Leaderboard for trivia.\n\n        Defaults to the top 10 of this server, sorted by total wins. Use\n        subcommands for a more customised leaderboard.\n        \"\"\"\n        cmd = self.trivia_leaderboard_server\n        if isinstance(ctx.channel, discord.abc.PrivateChannel):\n            cmd = self.trivia_leaderboard_global\n        await ctx.invoke(cmd, \"wins\", 10)\n\n    @trivia_leaderboard.command(name=\"server\")\n    @commands.guild_only()\n    async def trivia_leaderboard_server(\n        self, ctx: commands.Context, sort_by: str = \"wins\", top: int = 10\n    ):\n        \"\"\"Leaderboard for this server.\n\n        `<sort_by>` can be any of the following fields:\n         - `wins`  : total wins\n         - `avg`   : average score\n         - `total` : total correct answers\n         - `games` : total games played\n\n        `<top>` is the number of ranks to show on the leaderboard.\n        \"\"\"\n        key = self._get_sort_key(sort_by)\n        if key is None:\n            await ctx.send(\n                _(\n                    \"Unknown field `{field_name}`, see `{prefix}help trivia leaderboard server` \"\n                    \"for valid fields to sort by.\"\n                ).format(field_name=sort_by, prefix=ctx.clean_prefix)\n            )\n            return\n        guild = ctx.guild\n        data = await self.config.all_members(guild)\n        data = {guild.get_member(u): d for u, d in data.items()}\n        data.pop(None, None)  # remove any members which aren't in the guild\n        await self.send_leaderboard(ctx, data, key, top)\n\n    @trivia_leaderboard.command(name=\"global\")\n    async def trivia_leaderboard_global(\n        self, ctx: commands.Context, sort_by: str = \"wins\", top: int = 10\n    ):\n        \"\"\"Global trivia leaderboard.\n\n        `<sort_by>` can be any of the following fields:\n         - `wins`  : total wins\n         - `avg`   : average score\n         - `total` : total correct answers from all sessions\n         - `games` : total games played\n\n        `<top>` is the number of ranks to show on the leaderboard.\n        \"\"\"\n        key = self._get_sort_key(sort_by)\n        if key is None:\n            await ctx.send(\n                _(\n                    \"Unknown field `{field_name}`, see `{prefix}help trivia leaderboard server` \"\n                    \"for valid fields to sort by.\"\n                ).format(field_name=sort_by, prefix=ctx.clean_prefix)\n            )\n            return\n        data = await self.config.all_members()\n        collated_data = {}\n        for guild_id, guild_data in data.items():\n            guild = ctx.bot.get_guild(guild_id)\n            if guild is None:\n                continue\n            for member_id, member_data in guild_data.items():\n                member = guild.get_member(member_id)\n                if member is None:\n                    continue\n                collated_member_data = collated_data.get(member, Counter())\n                for v_key, value in member_data.items():\n                    collated_member_data[v_key] += value\n                collated_data[member] = collated_member_data\n        await self.send_leaderboard(ctx, collated_data, key, top)\n\n    @staticmethod\n    def _get_sort_key(key: str):\n        key = key.lower()\n        if key in (\"wins\", \"average_score\", \"total_score\", \"games\"):\n            return key\n        elif key in (\"avg\", \"average\"):\n            return \"average_score\"\n        elif key in (\"total\", \"score\", \"answers\", \"correct\"):\n            return \"total_score\"\n\n    async def send_leaderboard(self, ctx: commands.Context, data: dict, key: str, top: int):\n        \"\"\"Send the leaderboard from the given data.\n\n        Parameters\n        ----------\n        ctx : commands.Context\n            The context to send the leaderboard to.\n        data : dict\n            The data for the leaderboard. This must map `discord.Member` ->\n            `dict`.\n        key : str\n            The field to sort the data by. Can be ``wins``, ``total_score``,\n            ``games`` or ``average_score``.\n        top : int\n            The number of members to display on the leaderboard.\n\n        Returns\n        -------\n        `list` of `discord.Message`\n            The sent leaderboard messages.\n\n        \"\"\"\n        if not data:\n            await ctx.send(_(\"There are no scores on record!\"))\n            return\n        leaderboard = self._get_leaderboard(data, key, top)\n        ret = []\n        for page in pagify(leaderboard, shorten_by=10):\n            ret.append(await ctx.send(box(page, lang=\"py\")))\n        return ret\n\n    @staticmethod\n    def _get_leaderboard(data: dict, key: str, top: int):\n        # Mix in average score\n        for member, stats in data.items():\n            if stats[\"games\"] != 0:\n                stats[\"average_score\"] = stats[\"total_score\"] / stats[\"games\"]\n            else:\n                stats[\"average_score\"] = 0.0\n        # Sort by reverse order of priority\n        priority = [\"average_score\", \"total_score\", \"wins\", \"games\"]\n        try:\n            priority.remove(key)\n        except ValueError:\n            raise ValueError(f\"{key} is not a valid key.\")\n        # Put key last in reverse priority\n        priority.append(key)\n        items = data.items()\n        for key in priority:\n            items = sorted(items, key=lambda t: t[1][key], reverse=True)\n        max_name_len = max(map(lambda m: len(str(m)), data.keys()))\n        # Headers\n        headers = (\n            _(\"Rank\"),\n            _(\"Member\") + \" \" * (max_name_len - 6),\n            _(\"Wins\"),\n            _(\"Games Played\"),\n            _(\"Total Score\"),\n            _(\"Average Score\"),\n        )\n        lines = [\" | \".join(headers), \" | \".join((\"-\" * len(h) for h in headers))]\n        # Header underlines\n        for rank, tup in enumerate(items, 1):\n            member, m_data = tup\n            # Align fields to header width\n            fields = tuple(\n                map(\n                    str,\n                    (\n                        rank,\n                        member,\n                        m_data[\"wins\"],\n                        m_data[\"games\"],\n                        m_data[\"total_score\"],\n                        round(m_data[\"average_score\"], 2),\n                    ),\n                )\n            )\n            padding = [\" \" * (len(h) - len(f)) for h, f in zip(headers, fields)]\n            fields = tuple(f + padding[i] for i, f in enumerate(fields))\n            lines.append(\" | \".join(fields).format(member=member, **m_data))\n            if rank == top:\n                break\n        return \"\\n\".join(lines)\n\n    @commands.Cog.listener()\n    async def on_trivia_end(self, session: TriviaSession):\n        \"\"\"Event for a trivia session ending.\n\n        This method removes the session from this cog's sessions, and\n        cancels any tasks which it was running.\n\n        Parameters\n        ----------\n        session : TriviaSession\n            The session which has just ended.\n\n        \"\"\"\n        channel = session.ctx.channel\n        LOG.debug(\"Ending trivia session; #%s in %s\", channel, channel.guild.id)\n        if session in self.trivia_sessions:\n            self.trivia_sessions.remove(session)\n        if session.scores:\n            await self.update_leaderboard(session)\n\n    async def update_leaderboard(self, session):\n        \"\"\"Update the leaderboard with the given scores.\n\n        Parameters\n        ----------\n        session : TriviaSession\n            The trivia session to update scores from.\n\n        \"\"\"\n        max_score = session.settings[\"max_score\"]\n        for member, score in session.scores.items():\n            if member.id == session.ctx.bot.user.id:\n                continue\n            stats = await self.config.member(member).all()\n            if score == max_score:\n                stats[\"wins\"] += 1\n            stats[\"total_score\"] += score\n            stats[\"games\"] += 1\n            await self.config.member(member).set(stats)\n\n    def get_trivia_list(self, category: str) -> dict:\n        \"\"\"Get the trivia list corresponding to the given category.\n\n        Parameters\n        ----------\n        category : str\n            The desired category. Case sensitive.\n\n        Returns\n        -------\n        `dict`\n            A dict mapping questions (`str`) to answers (`list` of `str`).\n\n        \"\"\"\n        try:\n            path = next(p for p in self._all_lists() if p.stem == category)\n        except StopIteration:\n            raise FileNotFoundError(\"Could not find the `{}` category.\".format(category))\n\n        with path.open(encoding=\"utf-8\") as file:\n            try:\n                dict_ = yaml.safe_load(file)\n            except yaml.error.YAMLError as exc:\n                raise InvalidListError(\"YAML parsing failed.\") from exc\n            else:\n                return dict_\n\n    async def _save_trivia_list(\n        self, ctx: commands.Context, attachment: discord.Attachment\n    ) -> None:\n        \"\"\"Checks and saves a trivia list to data folder.\n\n        Parameters\n        ----------\n        file : discord.Attachment\n            A discord message attachment.\n\n        Returns\n        -------\n        None\n        \"\"\"\n        filename = attachment.filename.rsplit(\".\", 1)[0]\n\n        # Check if trivia filename exists in core files or if it is a command\n        if filename in self.trivia.all_commands or any(\n            filename == item.stem for item in get_core_lists()\n        ):\n            await ctx.send(\n                _(\n                    \"{filename} is a reserved trivia name and cannot be replaced.\\n\"\n                    \"Choose another name.\"\n                ).format(filename=filename)\n            )\n            return\n\n        file = cog_data_path(self) / f\"{filename}.yaml\"\n        if file.exists():\n            overwrite_message = _(\"{filename} already exists. Do you wish to overwrite?\").format(\n                filename=filename\n            )\n\n            can_react = ctx.channel.permissions_for(ctx.me).add_reactions\n            if not can_react:\n                overwrite_message += \" (y/n)\"\n\n            overwrite_message_object: discord.Message = await ctx.send(overwrite_message)\n            if can_react:\n                # noinspection PyAsyncCall\n                start_adding_reactions(\n                    overwrite_message_object, ReactionPredicate.YES_OR_NO_EMOJIS\n                )\n                pred = ReactionPredicate.yes_or_no(overwrite_message_object, ctx.author)\n                event = \"reaction_add\"\n            else:\n                pred = MessagePredicate.yes_or_no(ctx=ctx)\n                event = \"message\"\n            try:\n                await ctx.bot.wait_for(event, check=pred, timeout=30)\n            except asyncio.TimeoutError:\n                await ctx.send(_(\"You took too long answering.\"))\n                return\n\n            if pred.result is False:\n                await ctx.send(_(\"I am not replacing the existing file.\"))\n                return\n\n        buffer = io.BytesIO(await attachment.read())\n        yaml.safe_load(buffer)\n        buffer.seek(0)\n\n        with file.open(\"wb\") as fp:\n            fp.write(buffer.read())\n        await ctx.send(_(\"Saved Trivia list as {filename}.\").format(filename=filename))\n\n    def _get_trivia_session(self, channel: discord.TextChannel) -> TriviaSession:\n        return next(\n            (session for session in self.trivia_sessions if session.ctx.channel == channel), None\n        )\n\n    def _all_lists(self) -> List[pathlib.Path]:\n        personal_lists = [p.resolve() for p in cog_data_path(self).glob(\"*.yaml\")]\n\n        return personal_lists + get_core_lists()\n\n    def cog_unload(self):\n        for session in self.trivia_sessions:\n            session.force_stop()\n\n\ndef get_core_lists() -> List[pathlib.Path]:\n    \"\"\"Return a list of paths for all trivia lists packaged with the bot.\"\"\"\n    core_lists_path = pathlib.Path(__file__).parent.resolve() / \"data/lists\"\n    return list(core_lists_path.glob(\"*.yaml\"))\n", "target": 1}
{"idx": 939, "func": "\"\"\" A FastAPI app used to create an OpenAPI document for end-to-end testing \"\"\"\nimport json\nfrom datetime import date, datetime\nfrom enum import Enum\nfrom pathlib import Path\nfrom typing import Any, Dict, List, Union\n\nfrom fastapi import APIRouter, FastAPI, File, Header, Query, UploadFile\nfrom pydantic import BaseModel\n\napp = FastAPI(title=\"My Test API\", description=\"An API for testing openapi-python-client\",)\n\n\n@app.get(\"/ping\", response_model=bool)\nasync def ping():\n    \"\"\" A quick check to see if the system is running \"\"\"\n    return True\n\n\ntest_router = APIRouter()\n\n\nclass AnEnum(Enum):\n    \"\"\" For testing Enums in all the ways they can be used \"\"\"\n\n    FIRST_VALUE = \"FIRST_VALUE\"\n    SECOND_VALUE = \"SECOND_VALUE\"\n\n\nclass DifferentEnum(Enum):\n    FIRST_VALUE = \"DIFFERENT\"\n    SECOND_VALUE = \"OTHER\"\n\n\nclass OtherModel(BaseModel):\n    \"\"\" A different model for calling from TestModel \"\"\"\n\n    a_value: str\n\n\nclass AModel(BaseModel):\n    \"\"\" A Model for testing all the ways custom objects can be used \"\"\"\n\n    an_enum_value: AnEnum\n    nested_list_of_enums: List[List[DifferentEnum]] = []\n    some_dict: Dict[str, str] = {}\n    aCamelDateTime: Union[datetime, date]\n    a_date: date\n\n\n@test_router.get(\"/\", response_model=List[AModel], operation_id=\"getUserList\")\ndef get_list(an_enum_value: List[AnEnum] = Query(...), some_date: Union[date, datetime] = Query(...)):\n    \"\"\" Get a list of things \"\"\"\n    return\n\n\n@test_router.post(\"/upload\")\nasync def upload_file(some_file: UploadFile = File(...), keep_alive: bool = Header(None)):\n    \"\"\" Upload a file \"\"\"\n    data = await some_file.read()\n    return (some_file.filename, some_file.content_type, data)\n\n\n@test_router.post(\"/json_body\")\ndef json_body(body: AModel):\n    \"\"\" Try sending a JSON body \"\"\"\n    return\n\n\napp.include_router(test_router, prefix=\"/tests\", tags=[\"tests\"])\n\n\ndef generate_openapi_json():\n    path = Path(__file__).parent / \"openapi.json\"\n    path.write_text(json.dumps(app.openapi(), indent=4))\n\n\nif __name__ == \"__main__\":\n    generate_openapi_json()\n", "target": 1}
{"idx": 940, "func": "#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# Copyright 2016 OpenMarket Ltd\n# Copyright 2020 The Matrix.org Foundation C.I.C.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nimport contextlib\nimport logging\nimport sys\nfrom typing import Dict, Iterable, Optional, Set\n\nfrom typing_extensions import ContextManager\n\nfrom twisted.internet import address, reactor\n\nimport synapse\nimport synapse.events\nfrom synapse.api.errors import HttpResponseException, RequestSendFailed, SynapseError\nfrom synapse.api.urls import (\n    CLIENT_API_PREFIX,\n    FEDERATION_PREFIX,\n    LEGACY_MEDIA_PREFIX,\n    MEDIA_PREFIX,\n    SERVER_KEY_V2_PREFIX,\n)\nfrom synapse.app import _base\nfrom synapse.config._base import ConfigError\nfrom synapse.config.homeserver import HomeServerConfig\nfrom synapse.config.logger import setup_logging\nfrom synapse.config.server import ListenerConfig\nfrom synapse.federation import send_queue\nfrom synapse.federation.transport.server import TransportLayerServer\nfrom synapse.handlers.presence import (\n    BasePresenceHandler,\n    PresenceState,\n    get_interested_parties,\n)\nfrom synapse.http.server import JsonResource, OptionsResource\nfrom synapse.http.servlet import RestServlet, parse_json_object_from_request\nfrom synapse.http.site import SynapseSite\nfrom synapse.logging.context import LoggingContext\nfrom synapse.metrics import METRICS_PREFIX, MetricsResource, RegistryProxy\nfrom synapse.metrics.background_process_metrics import run_as_background_process\nfrom synapse.replication.http import REPLICATION_PREFIX, ReplicationRestResource\nfrom synapse.replication.http.presence import (\n    ReplicationBumpPresenceActiveTime,\n    ReplicationPresenceSetState,\n)\nfrom synapse.replication.slave.storage._base import BaseSlavedStore\nfrom synapse.replication.slave.storage.account_data import SlavedAccountDataStore\nfrom synapse.replication.slave.storage.appservice import SlavedApplicationServiceStore\nfrom synapse.replication.slave.storage.client_ips import SlavedClientIpStore\nfrom synapse.replication.slave.storage.deviceinbox import SlavedDeviceInboxStore\nfrom synapse.replication.slave.storage.devices import SlavedDeviceStore\nfrom synapse.replication.slave.storage.directory import DirectoryStore\nfrom synapse.replication.slave.storage.events import SlavedEventStore\nfrom synapse.replication.slave.storage.filtering import SlavedFilteringStore\nfrom synapse.replication.slave.storage.groups import SlavedGroupServerStore\nfrom synapse.replication.slave.storage.keys import SlavedKeyStore\nfrom synapse.replication.slave.storage.presence import SlavedPresenceStore\nfrom synapse.replication.slave.storage.profile import SlavedProfileStore\nfrom synapse.replication.slave.storage.push_rule import SlavedPushRuleStore\nfrom synapse.replication.slave.storage.pushers import SlavedPusherStore\nfrom synapse.replication.slave.storage.receipts import SlavedReceiptsStore\nfrom synapse.replication.slave.storage.registration import SlavedRegistrationStore\nfrom synapse.replication.slave.storage.room import RoomStore\nfrom synapse.replication.slave.storage.transactions import SlavedTransactionStore\nfrom synapse.replication.tcp.client import ReplicationDataHandler\nfrom synapse.replication.tcp.commands import ClearUserSyncsCommand\nfrom synapse.replication.tcp.streams import (\n    AccountDataStream,\n    DeviceListsStream,\n    GroupServerStream,\n    PresenceStream,\n    PushersStream,\n    PushRulesStream,\n    ReceiptsStream,\n    TagAccountDataStream,\n    ToDeviceStream,\n)\nfrom synapse.rest.admin import register_servlets_for_media_repo\nfrom synapse.rest.client.v1 import events\nfrom synapse.rest.client.v1.initial_sync import InitialSyncRestServlet\nfrom synapse.rest.client.v1.login import LoginRestServlet\nfrom synapse.rest.client.v1.profile import (\n    ProfileAvatarURLRestServlet,\n    ProfileDisplaynameRestServlet,\n    ProfileRestServlet,\n)\nfrom synapse.rest.client.v1.push_rule import PushRuleRestServlet\nfrom synapse.rest.client.v1.room import (\n    JoinedRoomMemberListRestServlet,\n    JoinRoomAliasServlet,\n    PublicRoomListRestServlet,\n    RoomEventContextServlet,\n    RoomInitialSyncRestServlet,\n    RoomMemberListRestServlet,\n    RoomMembershipRestServlet,\n    RoomMessageListRestServlet,\n    RoomSendEventRestServlet,\n    RoomStateEventRestServlet,\n    RoomStateRestServlet,\n    RoomTypingRestServlet,\n)\nfrom synapse.rest.client.v1.voip import VoipRestServlet\nfrom synapse.rest.client.v2_alpha import groups, sync, user_directory\nfrom synapse.rest.client.v2_alpha._base import client_patterns\nfrom synapse.rest.client.v2_alpha.account import ThreepidRestServlet\nfrom synapse.rest.client.v2_alpha.account_data import (\n    AccountDataServlet,\n    RoomAccountDataServlet,\n)\nfrom synapse.rest.client.v2_alpha.keys import KeyChangesServlet, KeyQueryServlet\nfrom synapse.rest.client.v2_alpha.register import RegisterRestServlet\nfrom synapse.rest.client.versions import VersionsRestServlet\nfrom synapse.rest.health import HealthResource\nfrom synapse.rest.key.v2 import KeyApiV2Resource\nfrom synapse.server import HomeServer, cache_in_self\nfrom synapse.storage.databases.main.censor_events import CensorEventsStore\nfrom synapse.storage.databases.main.client_ips import ClientIpWorkerStore\nfrom synapse.storage.databases.main.media_repository import MediaRepositoryStore\nfrom synapse.storage.databases.main.metrics import ServerMetricsStore\nfrom synapse.storage.databases.main.monthly_active_users import (\n    MonthlyActiveUsersWorkerStore,\n)\nfrom synapse.storage.databases.main.presence import UserPresenceState\nfrom synapse.storage.databases.main.search import SearchWorkerStore\nfrom synapse.storage.databases.main.stats import StatsStore\nfrom synapse.storage.databases.main.transactions import TransactionWorkerStore\nfrom synapse.storage.databases.main.ui_auth import UIAuthWorkerStore\nfrom synapse.storage.databases.main.user_directory import UserDirectoryStore\nfrom synapse.types import ReadReceipt\nfrom synapse.util.async_helpers import Linearizer\nfrom synapse.util.httpresourcetree import create_resource_tree\nfrom synapse.util.manhole import manhole\nfrom synapse.util.versionstring import get_version_string\n\nlogger = logging.getLogger(\"synapse.app.generic_worker\")\n\n\nclass PresenceStatusStubServlet(RestServlet):\n    \"\"\"If presence is disabled this servlet can be used to stub out setting\n    presence status.\n    \"\"\"\n\n    PATTERNS = client_patterns(\"/presence/(?P<user_id>[^/]*)/status\")\n\n    def __init__(self, hs):\n        super().__init__()\n        self.auth = hs.get_auth()\n\n    async def on_GET(self, request, user_id):\n        await self.auth.get_user_by_req(request)\n        return 200, {\"presence\": \"offline\"}\n\n    async def on_PUT(self, request, user_id):\n        await self.auth.get_user_by_req(request)\n        return 200, {}\n\n\nclass KeyUploadServlet(RestServlet):\n    \"\"\"An implementation of the `KeyUploadServlet` that responds to read only\n    requests, but otherwise proxies through to the master instance.\n    \"\"\"\n\n    PATTERNS = client_patterns(\"/keys/upload(/(?P<device_id>[^/]+))?$\")\n\n    def __init__(self, hs):\n        \"\"\"\n        Args:\n            hs (synapse.server.HomeServer): server\n        \"\"\"\n        super().__init__()\n        self.auth = hs.get_auth()\n        self.store = hs.get_datastore()\n        self.http_client = hs.get_simple_http_client()\n        self.main_uri = hs.config.worker_main_http_uri\n\n    async def on_POST(self, request, device_id):\n        requester = await self.auth.get_user_by_req(request, allow_guest=True)\n        user_id = requester.user.to_string()\n        body = parse_json_object_from_request(request)\n\n        if device_id is not None:\n            # passing the device_id here is deprecated; however, we allow it\n            # for now for compatibility with older clients.\n            if requester.device_id is not None and device_id != requester.device_id:\n                logger.warning(\n                    \"Client uploading keys for a different device \"\n                    \"(logged in as %s, uploading for %s)\",\n                    requester.device_id,\n                    device_id,\n                )\n        else:\n            device_id = requester.device_id\n\n        if device_id is None:\n            raise SynapseError(\n                400, \"To upload keys, you must pass device_id when authenticating\"\n            )\n\n        if body:\n            # They're actually trying to upload something, proxy to main synapse.\n\n            # Proxy headers from the original request, such as the auth headers\n            # (in case the access token is there) and the original IP /\n            # User-Agent of the request.\n            headers = {\n                header: request.requestHeaders.getRawHeaders(header, [])\n                for header in (b\"Authorization\", b\"User-Agent\")\n            }\n            # Add the previous hop the the X-Forwarded-For header.\n            x_forwarded_for = request.requestHeaders.getRawHeaders(\n                b\"X-Forwarded-For\", []\n            )\n            if isinstance(request.client, (address.IPv4Address, address.IPv6Address)):\n                previous_host = request.client.host.encode(\"ascii\")\n                # If the header exists, add to the comma-separated list of the first\n                # instance of the header. Otherwise, generate a new header.\n                if x_forwarded_for:\n                    x_forwarded_for = [\n                        x_forwarded_for[0] + b\", \" + previous_host\n                    ] + x_forwarded_for[1:]\n                else:\n                    x_forwarded_for = [previous_host]\n            headers[b\"X-Forwarded-For\"] = x_forwarded_for\n\n            try:\n                result = await self.http_client.post_json_get_json(\n                    self.main_uri + request.uri.decode(\"ascii\"), body, headers=headers\n                )\n            except HttpResponseException as e:\n                raise e.to_synapse_error() from e\n            except RequestSendFailed as e:\n                raise SynapseError(502, \"Failed to talk to master\") from e\n\n            return 200, result\n        else:\n            # Just interested in counts.\n            result = await self.store.count_e2e_one_time_keys(user_id, device_id)\n            return 200, {\"one_time_key_counts\": result}\n\n\nclass _NullContextManager(ContextManager[None]):\n    \"\"\"A context manager which does nothing.\"\"\"\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        pass\n\n\nUPDATE_SYNCING_USERS_MS = 10 * 1000\n\n\nclass GenericWorkerPresence(BasePresenceHandler):\n    def __init__(self, hs):\n        super().__init__(hs)\n        self.hs = hs\n        self.is_mine_id = hs.is_mine_id\n        self.http_client = hs.get_simple_http_client()\n\n        self._presence_enabled = hs.config.use_presence\n\n        # The number of ongoing syncs on this process, by user id.\n        # Empty if _presence_enabled is false.\n        self._user_to_num_current_syncs = {}  # type: Dict[str, int]\n\n        self.notifier = hs.get_notifier()\n        self.instance_id = hs.get_instance_id()\n\n        # user_id -> last_sync_ms. Lists the users that have stopped syncing\n        # but we haven't notified the master of that yet\n        self.users_going_offline = {}\n\n        self._bump_active_client = ReplicationBumpPresenceActiveTime.make_client(hs)\n        self._set_state_client = ReplicationPresenceSetState.make_client(hs)\n\n        self._send_stop_syncing_loop = self.clock.looping_call(\n            self.send_stop_syncing, UPDATE_SYNCING_USERS_MS\n        )\n\n        hs.get_reactor().addSystemEventTrigger(\n            \"before\",\n            \"shutdown\",\n            run_as_background_process,\n            \"generic_presence.on_shutdown\",\n            self._on_shutdown,\n        )\n\n    def _on_shutdown(self):\n        if self._presence_enabled:\n            self.hs.get_tcp_replication().send_command(\n                ClearUserSyncsCommand(self.instance_id)\n            )\n\n    def send_user_sync(self, user_id, is_syncing, last_sync_ms):\n        if self._presence_enabled:\n            self.hs.get_tcp_replication().send_user_sync(\n                self.instance_id, user_id, is_syncing, last_sync_ms\n            )\n\n    def mark_as_coming_online(self, user_id):\n        \"\"\"A user has started syncing. Send a UserSync to the master, unless they\n        had recently stopped syncing.\n\n        Args:\n            user_id (str)\n        \"\"\"\n        going_offline = self.users_going_offline.pop(user_id, None)\n        if not going_offline:\n            # Safe to skip because we haven't yet told the master they were offline\n            self.send_user_sync(user_id, True, self.clock.time_msec())\n\n    def mark_as_going_offline(self, user_id):\n        \"\"\"A user has stopped syncing. We wait before notifying the master as\n        its likely they'll come back soon. This allows us to avoid sending\n        a stopped syncing immediately followed by a started syncing notification\n        to the master\n\n        Args:\n            user_id (str)\n        \"\"\"\n        self.users_going_offline[user_id] = self.clock.time_msec()\n\n    def send_stop_syncing(self):\n        \"\"\"Check if there are any users who have stopped syncing a while ago\n        and haven't come back yet. If there are poke the master about them.\n        \"\"\"\n        now = self.clock.time_msec()\n        for user_id, last_sync_ms in list(self.users_going_offline.items()):\n            if now - last_sync_ms > UPDATE_SYNCING_USERS_MS:\n                self.users_going_offline.pop(user_id, None)\n                self.send_user_sync(user_id, False, last_sync_ms)\n\n    async def user_syncing(\n        self, user_id: str, affect_presence: bool\n    ) -> ContextManager[None]:\n        \"\"\"Record that a user is syncing.\n\n        Called by the sync and events servlets to record that a user has connected to\n        this worker and is waiting for some events.\n        \"\"\"\n        if not affect_presence or not self._presence_enabled:\n            return _NullContextManager()\n\n        curr_sync = self._user_to_num_current_syncs.get(user_id, 0)\n        self._user_to_num_current_syncs[user_id] = curr_sync + 1\n\n        # If we went from no in flight sync to some, notify replication\n        if self._user_to_num_current_syncs[user_id] == 1:\n            self.mark_as_coming_online(user_id)\n\n        def _end():\n            # We check that the user_id is in user_to_num_current_syncs because\n            # user_to_num_current_syncs may have been cleared if we are\n            # shutting down.\n            if user_id in self._user_to_num_current_syncs:\n                self._user_to_num_current_syncs[user_id] -= 1\n\n                # If we went from one in flight sync to non, notify replication\n                if self._user_to_num_current_syncs[user_id] == 0:\n                    self.mark_as_going_offline(user_id)\n\n        @contextlib.contextmanager\n        def _user_syncing():\n            try:\n                yield\n            finally:\n                _end()\n\n        return _user_syncing()\n\n    async def notify_from_replication(self, states, stream_id):\n        parties = await get_interested_parties(self.store, states)\n        room_ids_to_states, users_to_states = parties\n\n        self.notifier.on_new_event(\n            \"presence_key\",\n            stream_id,\n            rooms=room_ids_to_states.keys(),\n            users=users_to_states.keys(),\n        )\n\n    async def process_replication_rows(self, token, rows):\n        states = [\n            UserPresenceState(\n                row.user_id,\n                row.state,\n                row.last_active_ts,\n                row.last_federation_update_ts,\n                row.last_user_sync_ts,\n                row.status_msg,\n                row.currently_active,\n            )\n            for row in rows\n        ]\n\n        for state in states:\n            self.user_to_current_state[state.user_id] = state\n\n        stream_id = token\n        await self.notify_from_replication(states, stream_id)\n\n    def get_currently_syncing_users_for_replication(self) -> Iterable[str]:\n        return [\n            user_id\n            for user_id, count in self._user_to_num_current_syncs.items()\n            if count > 0\n        ]\n\n    async def set_state(self, target_user, state, ignore_status_msg=False):\n        \"\"\"Set the presence state of the user.\n        \"\"\"\n        presence = state[\"presence\"]\n\n        valid_presence = (\n            PresenceState.ONLINE,\n            PresenceState.UNAVAILABLE,\n            PresenceState.OFFLINE,\n        )\n        if presence not in valid_presence:\n            raise SynapseError(400, \"Invalid presence state\")\n\n        user_id = target_user.to_string()\n\n        # If presence is disabled, no-op\n        if not self.hs.config.use_presence:\n            return\n\n        # Proxy request to master\n        await self._set_state_client(\n            user_id=user_id, state=state, ignore_status_msg=ignore_status_msg\n        )\n\n    async def bump_presence_active_time(self, user):\n        \"\"\"We've seen the user do something that indicates they're interacting\n        with the app.\n        \"\"\"\n        # If presence is disabled, no-op\n        if not self.hs.config.use_presence:\n            return\n\n        # Proxy request to master\n        user_id = user.to_string()\n        await self._bump_active_client(user_id=user_id)\n\n\nclass GenericWorkerSlavedStore(\n    # FIXME(#3714): We need to add UserDirectoryStore as we write directly\n    # rather than going via the correct worker.\n    UserDirectoryStore,\n    StatsStore,\n    UIAuthWorkerStore,\n    SlavedDeviceInboxStore,\n    SlavedDeviceStore,\n    SlavedReceiptsStore,\n    SlavedPushRuleStore,\n    SlavedGroupServerStore,\n    SlavedAccountDataStore,\n    SlavedPusherStore,\n    CensorEventsStore,\n    ClientIpWorkerStore,\n    SlavedEventStore,\n    SlavedKeyStore,\n    RoomStore,\n    DirectoryStore,\n    SlavedApplicationServiceStore,\n    SlavedRegistrationStore,\n    SlavedTransactionStore,\n    SlavedProfileStore,\n    SlavedClientIpStore,\n    SlavedPresenceStore,\n    SlavedFilteringStore,\n    MonthlyActiveUsersWorkerStore,\n    MediaRepositoryStore,\n    ServerMetricsStore,\n    SearchWorkerStore,\n    TransactionWorkerStore,\n    BaseSlavedStore,\n):\n    pass\n\n\nclass GenericWorkerServer(HomeServer):\n    DATASTORE_CLASS = GenericWorkerSlavedStore\n\n    def _listen_http(self, listener_config: ListenerConfig):\n        port = listener_config.port\n        bind_addresses = listener_config.bind_addresses\n\n        assert listener_config.http_options is not None\n\n        site_tag = listener_config.http_options.tag\n        if site_tag is None:\n            site_tag = port\n\n        # We always include a health resource.\n        resources = {\"/health\": HealthResource()}\n\n        for res in listener_config.http_options.resources:\n            for name in res.names:\n                if name == \"metrics\":\n                    resources[METRICS_PREFIX] = MetricsResource(RegistryProxy)\n                elif name == \"client\":\n                    resource = JsonResource(self, canonical_json=False)\n\n                    PublicRoomListRestServlet(self).register(resource)\n                    RoomMemberListRestServlet(self).register(resource)\n                    JoinedRoomMemberListRestServlet(self).register(resource)\n                    RoomStateRestServlet(self).register(resource)\n                    RoomEventContextServlet(self).register(resource)\n                    RoomMessageListRestServlet(self).register(resource)\n                    RegisterRestServlet(self).register(resource)\n                    LoginRestServlet(self).register(resource)\n                    ThreepidRestServlet(self).register(resource)\n                    KeyQueryServlet(self).register(resource)\n                    KeyChangesServlet(self).register(resource)\n                    VoipRestServlet(self).register(resource)\n                    PushRuleRestServlet(self).register(resource)\n                    VersionsRestServlet(self).register(resource)\n                    RoomSendEventRestServlet(self).register(resource)\n                    RoomMembershipRestServlet(self).register(resource)\n                    RoomStateEventRestServlet(self).register(resource)\n                    JoinRoomAliasServlet(self).register(resource)\n                    ProfileAvatarURLRestServlet(self).register(resource)\n                    ProfileDisplaynameRestServlet(self).register(resource)\n                    ProfileRestServlet(self).register(resource)\n                    KeyUploadServlet(self).register(resource)\n                    AccountDataServlet(self).register(resource)\n                    RoomAccountDataServlet(self).register(resource)\n                    RoomTypingRestServlet(self).register(resource)\n\n                    sync.register_servlets(self, resource)\n                    events.register_servlets(self, resource)\n                    InitialSyncRestServlet(self).register(resource)\n                    RoomInitialSyncRestServlet(self).register(resource)\n\n                    user_directory.register_servlets(self, resource)\n\n                    # If presence is disabled, use the stub servlet that does\n                    # not allow sending presence\n                    if not self.config.use_presence:\n                        PresenceStatusStubServlet(self).register(resource)\n\n                    groups.register_servlets(self, resource)\n\n                    resources.update({CLIENT_API_PREFIX: resource})\n                elif name == \"federation\":\n                    resources.update({FEDERATION_PREFIX: TransportLayerServer(self)})\n                elif name == \"media\":\n                    if self.config.can_load_media_repo:\n                        media_repo = self.get_media_repository_resource()\n\n                        # We need to serve the admin servlets for media on the\n                        # worker.\n                        admin_resource = JsonResource(self, canonical_json=False)\n                        register_servlets_for_media_repo(self, admin_resource)\n\n                        resources.update(\n                            {\n                                MEDIA_PREFIX: media_repo,\n                                LEGACY_MEDIA_PREFIX: media_repo,\n                                \"/_synapse/admin\": admin_resource,\n                            }\n                        )\n                    else:\n                        logger.warning(\n                            \"A 'media' listener is configured but the media\"\n                            \" repository is disabled. Ignoring.\"\n                        )\n\n                if name == \"openid\" and \"federation\" not in res.names:\n                    # Only load the openid resource separately if federation resource\n                    # is not specified since federation resource includes openid\n                    # resource.\n                    resources.update(\n                        {\n                            FEDERATION_PREFIX: TransportLayerServer(\n                                self, servlet_groups=[\"openid\"]\n                            )\n                        }\n                    )\n\n                if name in [\"keys\", \"federation\"]:\n                    resources[SERVER_KEY_V2_PREFIX] = KeyApiV2Resource(self)\n\n                if name == \"replication\":\n                    resources[REPLICATION_PREFIX] = ReplicationRestResource(self)\n\n        root_resource = create_resource_tree(resources, OptionsResource())\n\n        _base.listen_tcp(\n            bind_addresses,\n            port,\n            SynapseSite(\n                \"synapse.access.http.%s\" % (site_tag,),\n                site_tag,\n                listener_config,\n                root_resource,\n                self.version_string,\n            ),\n            reactor=self.get_reactor(),\n        )\n\n        logger.info(\"Synapse worker now listening on port %d\", port)\n\n    def start_listening(self, listeners: Iterable[ListenerConfig]):\n        for listener in listeners:\n            if listener.type == \"http\":\n                self._listen_http(listener)\n            elif listener.type == \"manhole\":\n                _base.listen_tcp(\n                    listener.bind_addresses,\n                    listener.port,\n                    manhole(\n                        username=\"matrix\", password=\"rabbithole\", globals={\"hs\": self}\n                    ),\n                )\n            elif listener.type == \"metrics\":\n                if not self.get_config().enable_metrics:\n                    logger.warning(\n                        (\n                            \"Metrics listener configured, but \"\n                            \"enable_metrics is not True!\"\n                        )\n                    )\n                else:\n                    _base.listen_metrics(listener.bind_addresses, listener.port)\n            else:\n                logger.warning(\"Unsupported listener type: %s\", listener.type)\n\n        self.get_tcp_replication().start_replication(self)\n\n    async def remove_pusher(self, app_id, push_key, user_id):\n        self.get_tcp_replication().send_remove_pusher(app_id, push_key, user_id)\n\n    @cache_in_self\n    def get_replication_data_handler(self):\n        return GenericWorkerReplicationHandler(self)\n\n    @cache_in_self\n    def get_presence_handler(self):\n        return GenericWorkerPresence(self)\n\n\nclass GenericWorkerReplicationHandler(ReplicationDataHandler):\n    def __init__(self, hs):\n        super().__init__(hs)\n\n        self.store = hs.get_datastore()\n        self.presence_handler = hs.get_presence_handler()  # type: GenericWorkerPresence\n        self.notifier = hs.get_notifier()\n\n        self.notify_pushers = hs.config.start_pushers\n        self.pusher_pool = hs.get_pusherpool()\n\n        self.send_handler = None  # type: Optional[FederationSenderHandler]\n        if hs.config.send_federation:\n            self.send_handler = FederationSenderHandler(hs)\n\n    async def on_rdata(self, stream_name, instance_name, token, rows):\n        await super().on_rdata(stream_name, instance_name, token, rows)\n        await self._process_and_notify(stream_name, instance_name, token, rows)\n\n    async def _process_and_notify(self, stream_name, instance_name, token, rows):\n        try:\n            if self.send_handler:\n                await self.send_handler.process_replication_rows(\n                    stream_name, token, rows\n                )\n\n            if stream_name == PushRulesStream.NAME:\n                self.notifier.on_new_event(\n                    \"push_rules_key\", token, users=[row.user_id for row in rows]\n                )\n            elif stream_name in (AccountDataStream.NAME, TagAccountDataStream.NAME):\n                self.notifier.on_new_event(\n                    \"account_data_key\", token, users=[row.user_id for row in rows]\n                )\n            elif stream_name == ReceiptsStream.NAME:\n                self.notifier.on_new_event(\n                    \"receipt_key\", token, rooms=[row.room_id for row in rows]\n                )\n                await self.pusher_pool.on_new_receipts(\n                    token, token, {row.room_id for row in rows}\n                )\n            elif stream_name == ToDeviceStream.NAME:\n                entities = [row.entity for row in rows if row.entity.startswith(\"@\")]\n                if entities:\n                    self.notifier.on_new_event(\"to_device_key\", token, users=entities)\n            elif stream_name == DeviceListsStream.NAME:\n                all_room_ids = set()  # type: Set[str]\n                for row in rows:\n                    if row.entity.startswith(\"@\"):\n                        room_ids = await self.store.get_rooms_for_user(row.entity)\n                        all_room_ids.update(room_ids)\n                self.notifier.on_new_event(\"device_list_key\", token, rooms=all_room_ids)\n            elif stream_name == PresenceStream.NAME:\n                await self.presence_handler.process_replication_rows(token, rows)\n            elif stream_name == GroupServerStream.NAME:\n                self.notifier.on_new_event(\n                    \"groups_key\", token, users=[row.user_id for row in rows]\n                )\n            elif stream_name == PushersStream.NAME:\n                for row in rows:\n                    if row.deleted:\n                        self.stop_pusher(row.user_id, row.app_id, row.pushkey)\n                    else:\n                        await self.start_pusher(row.user_id, row.app_id, row.pushkey)\n        except Exception:\n            logger.exception(\"Error processing replication\")\n\n    async def on_position(self, stream_name: str, instance_name: str, token: int):\n        await super().on_position(stream_name, instance_name, token)\n        # Also call on_rdata to ensure that stream positions are properly reset.\n        await self.on_rdata(stream_name, instance_name, token, [])\n\n    def stop_pusher(self, user_id, app_id, pushkey):\n        if not self.notify_pushers:\n            return\n\n        key = \"%s:%s\" % (app_id, pushkey)\n        pushers_for_user = self.pusher_pool.pushers.get(user_id, {})\n        pusher = pushers_for_user.pop(key, None)\n        if pusher is None:\n            return\n        logger.info(\"Stopping pusher %r / %r\", user_id, key)\n        pusher.on_stop()\n\n    async def start_pusher(self, user_id, app_id, pushkey):\n        if not self.notify_pushers:\n            return\n\n        key = \"%s:%s\" % (app_id, pushkey)\n        logger.info(\"Starting pusher %r / %r\", user_id, key)\n        return await self.pusher_pool.start_pusher_by_id(app_id, pushkey, user_id)\n\n    def on_remote_server_up(self, server: str):\n        \"\"\"Called when get a new REMOTE_SERVER_UP command.\"\"\"\n\n        # Let's wake up the transaction queue for the server in case we have\n        # pending stuff to send to it.\n        if self.send_handler:\n            self.send_handler.wake_destination(server)\n\n\nclass FederationSenderHandler:\n    \"\"\"Processes the fedration replication stream\n\n    This class is only instantiate on the worker responsible for sending outbound\n    federation transactions. It receives rows from the replication stream and forwards\n    the appropriate entries to the FederationSender class.\n    \"\"\"\n\n    def __init__(self, hs: GenericWorkerServer):\n        self.store = hs.get_datastore()\n        self._is_mine_id = hs.is_mine_id\n        self.federation_sender = hs.get_federation_sender()\n        self._hs = hs\n\n        # Stores the latest position in the federation stream we've gotten up\n        # to. This is always set before we use it.\n        self.federation_position = None\n\n        self._fed_position_linearizer = Linearizer(name=\"_fed_position_linearizer\")\n\n    def on_start(self):\n        # There may be some events that are persisted but haven't been sent,\n        # so send them now.\n        self.federation_sender.notify_new_events(\n            self.store.get_room_max_stream_ordering()\n        )\n\n    def wake_destination(self, server: str):\n        self.federation_sender.wake_destination(server)\n\n    async def process_replication_rows(self, stream_name, token, rows):\n        # The federation stream contains things that we want to send out, e.g.\n        # presence, typing, etc.\n        if stream_name == \"federation\":\n            send_queue.process_rows_for_federation(self.federation_sender, rows)\n            await self.update_token(token)\n\n        # ... and when new receipts happen\n        elif stream_name == ReceiptsStream.NAME:\n            await self._on_new_receipts(rows)\n\n        # ... as well as device updates and messages\n        elif stream_name == DeviceListsStream.NAME:\n            # The entities are either user IDs (starting with '@') whose devices\n            # have changed, or remote servers that we need to tell about\n            # changes.\n            hosts = {row.entity for row in rows if not row.entity.startswith(\"@\")}\n            for host in hosts:\n                self.federation_sender.send_device_messages(host)\n\n        elif stream_name == ToDeviceStream.NAME:\n            # The to_device stream includes stuff to be pushed to both local\n            # clients and remote servers, so we ignore entities that start with\n            # '@' (since they'll be local users rather than destinations).\n            hosts = {row.entity for row in rows if not row.entity.startswith(\"@\")}\n            for host in hosts:\n                self.federation_sender.send_device_messages(host)\n\n    async def _on_new_receipts(self, rows):\n        \"\"\"\n        Args:\n            rows (Iterable[synapse.replication.tcp.streams.ReceiptsStream.ReceiptsStreamRow]):\n                new receipts to be processed\n        \"\"\"\n        for receipt in rows:\n            # we only want to send on receipts for our own users\n            if not self._is_mine_id(receipt.user_id):\n                continue\n            receipt_info = ReadReceipt(\n                receipt.room_id,\n                receipt.receipt_type,\n                receipt.user_id,\n                [receipt.event_id],\n                receipt.data,\n            )\n            await self.federation_sender.send_read_receipt(receipt_info)\n\n    async def update_token(self, token):\n        \"\"\"Update the record of where we have processed to in the federation stream.\n\n        Called after we have processed a an update received over replication. Sends\n        a FEDERATION_ACK back to the master, and stores the token that we have processed\n         in `federation_stream_position` so that we can restart where we left off.\n        \"\"\"\n        self.federation_position = token\n\n        # We save and send the ACK to master asynchronously, so we don't block\n        # processing on persistence. We don't need to do this operation for\n        # every single RDATA we receive, we just need to do it periodically.\n\n        if self._fed_position_linearizer.is_queued(None):\n            # There is already a task queued up to save and send the token, so\n            # no need to queue up another task.\n            return\n\n        run_as_background_process(\"_save_and_send_ack\", self._save_and_send_ack)\n\n    async def _save_and_send_ack(self):\n        \"\"\"Save the current federation position in the database and send an ACK\n        to master with where we're up to.\n        \"\"\"\n        try:\n            # We linearize here to ensure we don't have races updating the token\n            #\n            # XXX this appears to be redundant, since the ReplicationCommandHandler\n            # has a linearizer which ensures that we only process one line of\n            # replication data at a time. Should we remove it, or is it doing useful\n            # service for robustness? Or could we replace it with an assertion that\n            # we're not being re-entered?\n\n            with (await self._fed_position_linearizer.queue(None)):\n                # We persist and ack the same position, so we take a copy of it\n                # here as otherwise it can get modified from underneath us.\n                current_position = self.federation_position\n\n                await self.store.update_federation_out_pos(\n                    \"federation\", current_position\n                )\n\n                # We ACK this token over replication so that the master can drop\n                # its in memory queues\n                self._hs.get_tcp_replication().send_federation_ack(current_position)\n        except Exception:\n            logger.exception(\"Error updating federation stream position\")\n\n\ndef start(config_options):\n    try:\n        config = HomeServerConfig.load_config(\"Synapse worker\", config_options)\n    except ConfigError as e:\n        sys.stderr.write(\"\\n\" + str(e) + \"\\n\")\n        sys.exit(1)\n\n    # For backwards compatibility let any of the old app names.\n    assert config.worker_app in (\n        \"synapse.app.appservice\",\n        \"synapse.app.client_reader\",\n        \"synapse.app.event_creator\",\n        \"synapse.app.federation_reader\",\n        \"synapse.app.federation_sender\",\n        \"synapse.app.frontend_proxy\",\n        \"synapse.app.generic_worker\",\n        \"synapse.app.media_repository\",\n        \"synapse.app.pusher\",\n        \"synapse.app.synchrotron\",\n        \"synapse.app.user_dir\",\n    )\n\n    if config.worker_app == \"synapse.app.appservice\":\n        if config.appservice.notify_appservices:\n            sys.stderr.write(\n                \"\\nThe appservices must be disabled in the main synapse process\"\n                \"\\nbefore they can be run in a separate worker.\"\n                \"\\nPlease add ``notify_appservices: false`` to the main config\"\n                \"\\n\"\n            )\n            sys.exit(1)\n\n        # Force the appservice to start since they will be disabled in the main config\n        config.appservice.notify_appservices = True\n    else:\n        # For other worker types we force this to off.\n        config.appservice.notify_appservices = False\n\n    if config.worker_app == \"synapse.app.pusher\":\n        if config.server.start_pushers:\n            sys.stderr.write(\n                \"\\nThe pushers must be disabled in the main synapse process\"\n                \"\\nbefore they can be run in a separate worker.\"\n                \"\\nPlease add ``start_pushers: false`` to the main config\"\n                \"\\n\"\n            )\n            sys.exit(1)\n\n        # Force the pushers to start since they will be disabled in the main config\n        config.server.start_pushers = True\n    else:\n        # For other worker types we force this to off.\n        config.server.start_pushers = False\n\n    if config.worker_app == \"synapse.app.user_dir\":\n        if config.server.update_user_directory:\n            sys.stderr.write(\n                \"\\nThe update_user_directory must be disabled in the main synapse process\"\n                \"\\nbefore they can be run in a separate worker.\"\n                \"\\nPlease add ``update_user_directory: false`` to the main config\"\n                \"\\n\"\n            )\n            sys.exit(1)\n\n        # Force the pushers to start since they will be disabled in the main config\n        config.server.update_user_directory = True\n    else:\n        # For other worker types we force this to off.\n        config.server.update_user_directory = False\n\n    if config.worker_app == \"synapse.app.federation_sender\":\n        if config.worker.send_federation:\n            sys.stderr.write(\n                \"\\nThe send_federation must be disabled in the main synapse process\"\n                \"\\nbefore they can be run in a separate worker.\"\n                \"\\nPlease add ``send_federation: false`` to the main config\"\n                \"\\n\"\n            )\n            sys.exit(1)\n\n        # Force the pushers to start since they will be disabled in the main config\n        config.worker.send_federation = True\n    else:\n        # For other worker types we force this to off.\n        config.worker.send_federation = False\n\n    synapse.events.USE_FROZEN_DICTS = config.use_frozen_dicts\n\n    hs = GenericWorkerServer(\n        config.server_name,\n        config=config,\n        version_string=\"Synapse/\" + get_version_string(synapse),\n    )\n\n    setup_logging(hs, config, use_worker_options=True)\n\n    hs.setup()\n\n    # Ensure the replication streamer is always started in case we write to any\n    # streams. Will no-op if no streams can be written to by this worker.\n    hs.get_replication_streamer()\n\n    reactor.addSystemEventTrigger(\n        \"before\", \"startup\", _base.start, hs, config.worker_listeners\n    )\n\n    _base.start_worker_reactor(\"synapse-generic-worker\", config)\n\n\nif __name__ == \"__main__\":\n    with LoggingContext(\"main\"):\n        start(sys.argv[1:])\n", "target": 1}
{"idx": 941, "func": "# vim: ft=python fileencoding=utf-8 sts=4 sw=4 et:\n\n# Copyright 2016-2020 Florian Bruhin (The Compiler) <mail@qutebrowser.org>\n#\n# This file is part of qutebrowser.\n#\n# qutebrowser is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# qutebrowser is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with qutebrowser.  If not, see <http://www.gnu.org/licenses/>.\n\n\"\"\"Wrapper over a QWebEngineView.\"\"\"\n\nimport math\nimport functools\nimport re\nimport html as html_utils\nimport typing\n\nfrom PyQt5.QtCore import (pyqtSignal, pyqtSlot, Qt, QPoint, QPointF, QUrl,\n                          QTimer, QObject)\nfrom PyQt5.QtNetwork import QAuthenticator\nfrom PyQt5.QtWidgets import QApplication, QWidget\nfrom PyQt5.QtWebEngineWidgets import QWebEnginePage, QWebEngineScript\n\nfrom qutebrowser.config import configdata, config\nfrom qutebrowser.browser import (browsertab, eventfilter, shared, webelem,\n                                 history, greasemonkey)\nfrom qutebrowser.browser.webengine import (webview, webengineelem, tabhistory,\n                                           interceptor, webenginequtescheme,\n                                           cookies, webenginedownloads,\n                                           webenginesettings, certificateerror)\nfrom qutebrowser.misc import miscwidgets, objects\nfrom qutebrowser.utils import (usertypes, qtutils, log, javascript, utils,\n                               message, objreg, jinja, debug)\nfrom qutebrowser.qt import sip\n\n\n_qute_scheme_handler = None\n\n\ndef init():\n    \"\"\"Initialize QtWebEngine-specific modules.\"\"\"\n    # For some reason we need to keep a reference, otherwise the scheme handler\n    # won't work...\n    # https://www.riverbankcomputing.com/pipermail/pyqt/2016-September/038075.html\n    global _qute_scheme_handler\n\n    app = QApplication.instance()\n    log.init.debug(\"Initializing qute://* handler...\")\n    _qute_scheme_handler = webenginequtescheme.QuteSchemeHandler(parent=app)\n    _qute_scheme_handler.install(webenginesettings.default_profile)\n    if webenginesettings.private_profile:\n        _qute_scheme_handler.install(webenginesettings.private_profile)\n\n    log.init.debug(\"Initializing request interceptor...\")\n    req_interceptor = interceptor.RequestInterceptor(parent=app)\n    req_interceptor.install(webenginesettings.default_profile)\n    if webenginesettings.private_profile:\n        req_interceptor.install(webenginesettings.private_profile)\n\n    log.init.debug(\"Initializing QtWebEngine downloads...\")\n    download_manager = webenginedownloads.DownloadManager(parent=app)\n    download_manager.install(webenginesettings.default_profile)\n    if webenginesettings.private_profile:\n        download_manager.install(webenginesettings.private_profile)\n    objreg.register('webengine-download-manager', download_manager)\n\n    log.init.debug(\"Initializing cookie filter...\")\n    cookies.install_filter(webenginesettings.default_profile)\n    if webenginesettings.private_profile:\n        cookies.install_filter(webenginesettings.private_profile)\n\n    # Clear visited links on web history clear\n    for p in [webenginesettings.default_profile,\n              webenginesettings.private_profile]:\n        if not p:\n            continue\n        history.web_history.history_cleared.connect(p.clearAllVisitedLinks)\n        history.web_history.url_cleared.connect(\n            lambda url, profile=p: profile.clearVisitedLinks([url]))\n\n\n# Mapping worlds from usertypes.JsWorld to QWebEngineScript world IDs.\n_JS_WORLD_MAP = {\n    usertypes.JsWorld.main: QWebEngineScript.MainWorld,\n    usertypes.JsWorld.application: QWebEngineScript.ApplicationWorld,\n    usertypes.JsWorld.user: QWebEngineScript.UserWorld,\n    usertypes.JsWorld.jseval: QWebEngineScript.UserWorld + 1,\n}\n\n\nclass WebEngineAction(browsertab.AbstractAction):\n\n    \"\"\"QtWebEngine implementations related to web actions.\"\"\"\n\n    action_class = QWebEnginePage\n    action_base = QWebEnginePage.WebAction\n\n    def exit_fullscreen(self):\n        self._widget.triggerPageAction(QWebEnginePage.ExitFullScreen)\n\n    def save_page(self):\n        \"\"\"Save the current page.\"\"\"\n        self._widget.triggerPageAction(QWebEnginePage.SavePage)\n\n    def show_source(self, pygments=False):\n        if pygments:\n            self._show_source_pygments()\n            return\n\n        try:\n            self._widget.triggerPageAction(QWebEnginePage.ViewSource)\n        except AttributeError:\n            # Qt < 5.8\n            tb = objreg.get('tabbed-browser', scope='window',\n                            window=self._tab.win_id)\n            urlstr = self._tab.url().toString(\n                QUrl.RemoveUserInfo)  # type: ignore\n            # The original URL becomes the path of a view-source: URL\n            # (without a host), but query/fragment should stay.\n            url = QUrl('view-source:' + urlstr)\n            tb.tabopen(url, background=False, related=True)\n\n\nclass WebEnginePrinting(browsertab.AbstractPrinting):\n\n    \"\"\"QtWebEngine implementations related to printing.\"\"\"\n\n    def check_pdf_support(self):\n        pass\n\n    def check_printer_support(self):\n        if not hasattr(self._widget.page(), 'print'):\n            raise browsertab.WebTabError(\n                \"Printing is unsupported with QtWebEngine on Qt < 5.8\")\n\n    def check_preview_support(self):\n        raise browsertab.WebTabError(\n            \"Print previews are unsupported with QtWebEngine\")\n\n    def to_pdf(self, filename):\n        self._widget.page().printToPdf(filename)\n\n    def to_printer(self, printer, callback=None):\n        if callback is None:\n            callback = lambda _ok: None\n        self._widget.page().print(printer, callback)\n\n\nclass _WebEngineSearchWrapHandler:\n\n    \"\"\"QtWebEngine implementations related to wrapping when searching.\n\n    Attributes:\n        flag_wrap: An additional flag indicating whether the last search\n                   used wrapping.\n        _active_match: The 1-based index of the currently active match\n                       on the page.\n        _total_matches: The total number of search matches on the page.\n        _nowrap_available: Whether the functionality to prevent wrapping\n                           is available.\n    \"\"\"\n\n    def __init__(self):\n        self._active_match = 0\n        self._total_matches = 0\n        self.flag_wrap = True\n        self._nowrap_available = False\n\n    def connect_signal(self, page):\n        \"\"\"Connect to the findTextFinished signal of the page.\n\n        Args:\n            page: The QtWebEnginePage to connect to this handler.\n        \"\"\"\n        if qtutils.version_check(\"5.14\"):\n            page.findTextFinished.connect(self._store_match_data)\n            self._nowrap_available = True\n\n    def _store_match_data(self, result):\n        \"\"\"Store information on the last match.\n\n        The information will be checked against when wrapping is turned off.\n\n        Args:\n            result: A FindTextResult passed by the findTextFinished signal.\n        \"\"\"\n        self._active_match = result.activeMatch()\n        self._total_matches = result.numberOfMatches()\n        log.webview.debug(\"Active search match: {}/{}\"\n                          .format(self._active_match, self._total_matches))\n\n    def reset_match_data(self):\n        \"\"\"Reset match information.\n\n        Stale information could lead to next_result or prev_result misbehaving.\n        \"\"\"\n        self._active_match = 0\n        self._total_matches = 0\n\n    def prevent_wrapping(self, *, going_up):\n        \"\"\"Prevent wrapping if possible and required.\n\n        Returns True if a wrap was prevented and False if not.\n\n        Args:\n            going_up: Whether the search would scroll the page up or down.\n        \"\"\"\n        if (not self._nowrap_available or\n                self.flag_wrap or self._total_matches == 0):\n            return False\n        elif going_up and self._active_match == 1:\n            message.info(\"Search hit TOP\")\n            return True\n        elif not going_up and self._active_match == self._total_matches:\n            message.info(\"Search hit BOTTOM\")\n            return True\n        else:\n            return False\n\n\nclass WebEngineSearch(browsertab.AbstractSearch):\n\n    \"\"\"QtWebEngine implementations related to searching on the page.\n\n    Attributes:\n        _flags: The QWebEnginePage.FindFlags of the last search.\n        _pending_searches: How many searches have been started but not called\n                           back yet.\n    \"\"\"\n\n    def __init__(self, tab, parent=None):\n        super().__init__(tab, parent)\n        self._flags = QWebEnginePage.FindFlags(0)  # type: ignore\n        self._pending_searches = 0\n        # The API necessary to stop wrapping was added in this version\n        self._wrap_handler = _WebEngineSearchWrapHandler()\n\n    def connect_signals(self):\n        self._wrap_handler.connect_signal(self._widget.page())\n\n    def _find(self, text, flags, callback, caller):\n        \"\"\"Call findText on the widget.\"\"\"\n        self.search_displayed = True\n        self._pending_searches += 1\n\n        def wrapped_callback(found):\n            \"\"\"Wrap the callback to do debug logging.\"\"\"\n            self._pending_searches -= 1\n            if self._pending_searches > 0:\n                # See https://github.com/qutebrowser/qutebrowser/issues/2442\n                # and https://github.com/qt/qtwebengine/blob/5.10/src/core/web_contents_adapter.cpp#L924-L934\n                log.webview.debug(\"Ignoring cancelled search callback with \"\n                                  \"{} pending searches\".format(\n                                      self._pending_searches))\n                return\n\n            if sip.isdeleted(self._widget):\n                # This happens when starting a search, and closing the tab\n                # before results arrive.\n                log.webview.debug(\"Ignoring finished search for deleted \"\n                                  \"widget\")\n                return\n\n            found_text = 'found' if found else \"didn't find\"\n            if flags:\n                flag_text = 'with flags {}'.format(debug.qflags_key(\n                    QWebEnginePage, flags, klass=QWebEnginePage.FindFlag))\n            else:\n                flag_text = ''\n            log.webview.debug(' '.join([caller, found_text, text, flag_text])\n                              .strip())\n\n            if callback is not None:\n                callback(found)\n            self.finished.emit(found)\n\n        self._widget.page().findText(text, flags, wrapped_callback)\n\n    def search(self, text, *, ignore_case=usertypes.IgnoreCase.never,\n               reverse=False, wrap=True, result_cb=None):\n        # Don't go to next entry on duplicate search\n        if self.text == text and self.search_displayed:\n            log.webview.debug(\"Ignoring duplicate search request\"\n                              \" for {}\".format(text))\n            return\n\n        self.text = text\n        self._flags = QWebEnginePage.FindFlags(0)  # type: ignore\n        self._wrap_handler.reset_match_data()\n        self._wrap_handler.flag_wrap = wrap\n        if self._is_case_sensitive(ignore_case):\n            self._flags |= QWebEnginePage.FindCaseSensitively\n        if reverse:\n            self._flags |= QWebEnginePage.FindBackward\n\n        self._find(text, self._flags, result_cb, 'search')\n\n    def clear(self):\n        if self.search_displayed:\n            self.cleared.emit()\n        self.search_displayed = False\n        self._wrap_handler.reset_match_data()\n        self._widget.page().findText('')\n\n    def prev_result(self, *, result_cb=None):\n        # The int() here makes sure we get a copy of the flags.\n        flags = QWebEnginePage.FindFlags(int(self._flags))  # type: ignore\n        if flags & QWebEnginePage.FindBackward:\n            if self._wrap_handler.prevent_wrapping(going_up=False):\n                return\n            flags &= ~QWebEnginePage.FindBackward\n        else:\n            if self._wrap_handler.prevent_wrapping(going_up=True):\n                return\n            flags |= QWebEnginePage.FindBackward\n        self._find(self.text, flags, result_cb, 'prev_result')\n\n    def next_result(self, *, result_cb=None):\n        going_up = self._flags & QWebEnginePage.FindBackward\n        if self._wrap_handler.prevent_wrapping(going_up=going_up):\n            return\n        self._find(self.text, self._flags, result_cb, 'next_result')\n\n\nclass WebEngineCaret(browsertab.AbstractCaret):\n\n    \"\"\"QtWebEngine implementations related to moving the cursor/selection.\"\"\"\n\n    def _flags(self):\n        \"\"\"Get flags to pass to JS.\"\"\"\n        flags = set()\n        if qtutils.version_check('5.7.1', compiled=False):\n            flags.add('filter-prefix')\n        if utils.is_windows:\n            flags.add('windows')\n        return list(flags)\n\n    @pyqtSlot(usertypes.KeyMode)\n    def _on_mode_entered(self, mode):\n        if mode != usertypes.KeyMode.caret:\n            return\n\n        if self._tab.search.search_displayed:\n            # We are currently in search mode.\n            # convert the search to a blue selection so we can operate on it\n            # https://bugreports.qt.io/browse/QTBUG-60673\n            self._tab.search.clear()\n\n        self._tab.run_js_async(\n            javascript.assemble('caret', 'setFlags', self._flags()))\n\n        self._js_call('setInitialCursor', callback=self._selection_cb)\n\n    def _selection_cb(self, enabled):\n        \"\"\"Emit selection_toggled based on setInitialCursor.\"\"\"\n        if self._mode_manager.mode != usertypes.KeyMode.caret:\n            log.webview.debug(\"Ignoring selection cb due to mode change.\")\n            return\n        if enabled is None:\n            log.webview.debug(\"Ignoring selection status None\")\n            return\n        self.selection_toggled.emit(enabled)\n\n    @pyqtSlot(usertypes.KeyMode)\n    def _on_mode_left(self, mode):\n        if mode != usertypes.KeyMode.caret:\n            return\n\n        self.drop_selection()\n        self._js_call('disableCaret')\n\n    def move_to_next_line(self, count=1):\n        self._js_call('moveDown', count)\n\n    def move_to_prev_line(self, count=1):\n        self._js_call('moveUp', count)\n\n    def move_to_next_char(self, count=1):\n        self._js_call('moveRight', count)\n\n    def move_to_prev_char(self, count=1):\n        self._js_call('moveLeft', count)\n\n    def move_to_end_of_word(self, count=1):\n        self._js_call('moveToEndOfWord', count)\n\n    def move_to_next_word(self, count=1):\n        self._js_call('moveToNextWord', count)\n\n    def move_to_prev_word(self, count=1):\n        self._js_call('moveToPreviousWord', count)\n\n    def move_to_start_of_line(self):\n        self._js_call('moveToStartOfLine')\n\n    def move_to_end_of_line(self):\n        self._js_call('moveToEndOfLine')\n\n    def move_to_start_of_next_block(self, count=1):\n        self._js_call('moveToStartOfNextBlock', count)\n\n    def move_to_start_of_prev_block(self, count=1):\n        self._js_call('moveToStartOfPrevBlock', count)\n\n    def move_to_end_of_next_block(self, count=1):\n        self._js_call('moveToEndOfNextBlock', count)\n\n    def move_to_end_of_prev_block(self, count=1):\n        self._js_call('moveToEndOfPrevBlock', count)\n\n    def move_to_start_of_document(self):\n        self._js_call('moveToStartOfDocument')\n\n    def move_to_end_of_document(self):\n        self._js_call('moveToEndOfDocument')\n\n    def toggle_selection(self):\n        self._js_call('toggleSelection', callback=self.selection_toggled.emit)\n\n    def drop_selection(self):\n        self._js_call('dropSelection')\n\n    def selection(self, callback):\n        # Not using selectedText() as WORKAROUND for\n        # https://bugreports.qt.io/browse/QTBUG-53134\n        # Even on Qt 5.10 selectedText() seems to work poorly, see\n        # https://github.com/qutebrowser/qutebrowser/issues/3523\n        self._tab.run_js_async(javascript.assemble('caret', 'getSelection'),\n                               callback)\n\n    def reverse_selection(self):\n        self._js_call('reverseSelection')\n\n    def _follow_selected_cb_wrapped(self, js_elem, tab):\n        try:\n            self._follow_selected_cb(js_elem, tab)\n        finally:\n            self.follow_selected_done.emit()\n\n    def _follow_selected_cb(self, js_elem, tab):\n        \"\"\"Callback for javascript which clicks the selected element.\n\n        Args:\n            js_elem: The element serialized from javascript.\n            tab: Open in a new tab.\n        \"\"\"\n        if js_elem is None:\n            return\n\n        if js_elem == \"focused\":\n            # we had a focused element, not a selected one. Just send <enter>\n            self._follow_enter(tab)\n            return\n\n        assert isinstance(js_elem, dict), js_elem\n        elem = webengineelem.WebEngineElement(js_elem, tab=self._tab)\n        if tab:\n            click_type = usertypes.ClickTarget.tab\n        else:\n            click_type = usertypes.ClickTarget.normal\n\n        # Only click if we see a link\n        if elem.is_link():\n            log.webview.debug(\"Found link in selection, clicking. ClickTarget \"\n                              \"{}, elem {}\".format(click_type, elem))\n            try:\n                elem.click(click_type)\n            except webelem.Error as e:\n                message.error(str(e))\n\n    def follow_selected(self, *, tab=False):\n        if self._tab.search.search_displayed:\n            # We are currently in search mode.\n            # let's click the link via a fake-click\n            # https://bugreports.qt.io/browse/QTBUG-60673\n            self._tab.search.clear()\n\n            log.webview.debug(\"Clicking a searched link via fake key press.\")\n            # send a fake enter, clicking the orange selection box\n            self._follow_enter(tab)\n        else:\n            # click an existing blue selection\n            js_code = javascript.assemble('webelem',\n                                          'find_selected_focused_link')\n            self._tab.run_js_async(\n                js_code,\n                lambda jsret: self._follow_selected_cb_wrapped(jsret, tab))\n\n    def _js_call(self, command, *args, callback=None):\n        code = javascript.assemble('caret', command, *args)\n        self._tab.run_js_async(code, callback)\n\n\nclass WebEngineScroller(browsertab.AbstractScroller):\n\n    \"\"\"QtWebEngine implementations related to scrolling.\"\"\"\n\n    def __init__(self, tab, parent=None):\n        super().__init__(tab, parent)\n        self._pos_perc = (0, 0)\n        self._pos_px = QPoint()\n        self._at_bottom = False\n\n    def _init_widget(self, widget):\n        super()._init_widget(widget)\n        page = widget.page()\n        page.scrollPositionChanged.connect(self._update_pos)\n\n    def _repeated_key_press(self, key, count=1, modifier=Qt.NoModifier):\n        \"\"\"Send count fake key presses to this scroller's WebEngineTab.\"\"\"\n        for _ in range(min(count, 1000)):\n            self._tab.fake_key_press(key, modifier)\n\n    @pyqtSlot(QPointF)\n    def _update_pos(self, pos):\n        \"\"\"Update the scroll position attributes when it changed.\"\"\"\n        self._pos_px = pos.toPoint()\n        contents_size = self._widget.page().contentsSize()\n\n        scrollable_x = contents_size.width() - self._widget.width()\n        if scrollable_x == 0:\n            perc_x = 0\n        else:\n            try:\n                perc_x = min(100, round(100 / scrollable_x * pos.x()))\n            except ValueError:\n                # https://github.com/qutebrowser/qutebrowser/issues/3219\n                log.misc.debug(\"Got ValueError for perc_x!\")\n                log.misc.debug(\"contents_size.width(): {}\".format(\n                    contents_size.width()))\n                log.misc.debug(\"self._widget.width(): {}\".format(\n                    self._widget.width()))\n                log.misc.debug(\"scrollable_x: {}\".format(scrollable_x))\n                log.misc.debug(\"pos.x(): {}\".format(pos.x()))\n                raise\n\n        scrollable_y = contents_size.height() - self._widget.height()\n        if scrollable_y == 0:\n            perc_y = 0\n        else:\n            try:\n                perc_y = min(100, round(100 / scrollable_y * pos.y()))\n            except ValueError:\n                # https://github.com/qutebrowser/qutebrowser/issues/3219\n                log.misc.debug(\"Got ValueError for perc_y!\")\n                log.misc.debug(\"contents_size.height(): {}\".format(\n                    contents_size.height()))\n                log.misc.debug(\"self._widget.height(): {}\".format(\n                    self._widget.height()))\n                log.misc.debug(\"scrollable_y: {}\".format(scrollable_y))\n                log.misc.debug(\"pos.y(): {}\".format(pos.y()))\n                raise\n\n        self._at_bottom = math.ceil(pos.y()) >= scrollable_y\n\n        if (self._pos_perc != (perc_x, perc_y) or\n                'no-scroll-filtering' in objects.debug_flags):\n            self._pos_perc = perc_x, perc_y\n            self.perc_changed.emit(*self._pos_perc)\n\n    def pos_px(self):\n        return self._pos_px\n\n    def pos_perc(self):\n        return self._pos_perc\n\n    def to_perc(self, x=None, y=None):\n        js_code = javascript.assemble('scroll', 'to_perc', x, y)\n        self._tab.run_js_async(js_code)\n\n    def to_point(self, point):\n        js_code = javascript.assemble('window', 'scroll', point.x(), point.y())\n        self._tab.run_js_async(js_code)\n\n    def to_anchor(self, name):\n        url = self._tab.url()\n        url.setFragment(name)\n        self._tab.load_url(url)\n\n    def delta(self, x=0, y=0):\n        self._tab.run_js_async(javascript.assemble('window', 'scrollBy', x, y))\n\n    def delta_page(self, x=0, y=0):\n        js_code = javascript.assemble('scroll', 'delta_page', x, y)\n        self._tab.run_js_async(js_code)\n\n    def up(self, count=1):\n        self._repeated_key_press(Qt.Key_Up, count)\n\n    def down(self, count=1):\n        self._repeated_key_press(Qt.Key_Down, count)\n\n    def left(self, count=1):\n        self._repeated_key_press(Qt.Key_Left, count)\n\n    def right(self, count=1):\n        self._repeated_key_press(Qt.Key_Right, count)\n\n    def top(self):\n        self._tab.fake_key_press(Qt.Key_Home)\n\n    def bottom(self):\n        self._tab.fake_key_press(Qt.Key_End)\n\n    def page_up(self, count=1):\n        self._repeated_key_press(Qt.Key_PageUp, count)\n\n    def page_down(self, count=1):\n        self._repeated_key_press(Qt.Key_PageDown, count)\n\n    def at_top(self):\n        return self.pos_px().y() == 0\n\n    def at_bottom(self):\n        return self._at_bottom\n\n\nclass WebEngineHistoryPrivate(browsertab.AbstractHistoryPrivate):\n\n    \"\"\"History-related methods which are not part of the extension API.\"\"\"\n\n    def serialize(self):\n        if not qtutils.version_check('5.9', compiled=False):\n            # WORKAROUND for\n            # https://github.com/qutebrowser/qutebrowser/issues/2289\n            # Don't use the history's currentItem here, because of\n            # https://bugreports.qt.io/browse/QTBUG-59599 and because it doesn't\n            # contain view-source.\n            scheme = self._tab.url().scheme()\n            if scheme in ['view-source', 'chrome']:\n                raise browsertab.WebTabError(\"Can't serialize special URL!\")\n        return qtutils.serialize(self._history)\n\n    def deserialize(self, data):\n        qtutils.deserialize(data, self._history)\n\n    def load_items(self, items):\n        if qtutils.version_check('5.15', compiled=False):\n            # WORKAROUND for https://github.com/qutebrowser/qutebrowser/issues/5359\n            if items:\n                self._tab.load_url(items[-1].url)\n            return\n\n        if items:\n            self._tab.before_load_started.emit(items[-1].url)\n\n        stream, _data, cur_data = tabhistory.serialize(items)\n        qtutils.deserialize_stream(stream, self._history)\n\n        @pyqtSlot()\n        def _on_load_finished():\n            self._tab.scroller.to_point(cur_data['scroll-pos'])\n            self._tab.load_finished.disconnect(_on_load_finished)\n\n        if cur_data is not None:\n            if 'zoom' in cur_data:\n                self._tab.zoom.set_factor(cur_data['zoom'])\n            if ('scroll-pos' in cur_data and\n                    self._tab.scroller.pos_px() == QPoint(0, 0)):\n                self._tab.load_finished.connect(_on_load_finished)\n\n\nclass WebEngineHistory(browsertab.AbstractHistory):\n\n    \"\"\"QtWebEngine implementations related to page history.\"\"\"\n\n    def __init__(self, tab):\n        super().__init__(tab)\n        self.private_api = WebEngineHistoryPrivate(tab)\n\n    def __len__(self):\n        return len(self._history)\n\n    def __iter__(self):\n        return iter(self._history.items())\n\n    def current_idx(self):\n        return self._history.currentItemIndex()\n\n    def can_go_back(self):\n        return self._history.canGoBack()\n\n    def can_go_forward(self):\n        return self._history.canGoForward()\n\n    def _item_at(self, i):\n        return self._history.itemAt(i)\n\n    def _go_to_item(self, item):\n        self._tab.before_load_started.emit(item.url())\n        self._history.goToItem(item)\n\n\nclass WebEngineZoom(browsertab.AbstractZoom):\n\n    \"\"\"QtWebEngine implementations related to zooming.\"\"\"\n\n    def _set_factor_internal(self, factor):\n        self._widget.setZoomFactor(factor)\n\n\nclass WebEngineElements(browsertab.AbstractElements):\n\n    \"\"\"QtWebEngine implemementations related to elements on the page.\"\"\"\n\n    def _js_cb_multiple(self, callback, error_cb, js_elems):\n        \"\"\"Handle found elements coming from JS and call the real callback.\n\n        Args:\n            callback: The callback to call with the found elements.\n            error_cb: The callback to call in case of an error.\n            js_elems: The elements serialized from javascript.\n        \"\"\"\n        if js_elems is None:\n            error_cb(webelem.Error(\"Unknown error while getting \"\n                                   \"elements\"))\n            return\n        elif not js_elems['success']:\n            error_cb(webelem.Error(js_elems['error']))\n            return\n\n        elems = []\n        for js_elem in js_elems['result']:\n            elem = webengineelem.WebEngineElement(js_elem, tab=self._tab)\n            elems.append(elem)\n        callback(elems)\n\n    def _js_cb_single(self, callback, js_elem):\n        \"\"\"Handle a found focus elem coming from JS and call the real callback.\n\n        Args:\n            callback: The callback to call with the found element.\n                      Called with a WebEngineElement or None.\n            js_elem: The element serialized from javascript.\n        \"\"\"\n        debug_str = ('None' if js_elem is None\n                     else utils.elide(repr(js_elem), 1000))\n        log.webview.debug(\"Got element from JS: {}\".format(debug_str))\n\n        if js_elem is None:\n            callback(None)\n        else:\n            elem = webengineelem.WebEngineElement(js_elem, tab=self._tab)\n            callback(elem)\n\n    def find_css(self, selector, callback, error_cb, *,\n                 only_visible=False):\n        js_code = javascript.assemble('webelem', 'find_css', selector,\n                                      only_visible)\n        js_cb = functools.partial(self._js_cb_multiple, callback, error_cb)\n        self._tab.run_js_async(js_code, js_cb)\n\n    def find_id(self, elem_id, callback):\n        js_code = javascript.assemble('webelem', 'find_id', elem_id)\n        js_cb = functools.partial(self._js_cb_single, callback)\n        self._tab.run_js_async(js_code, js_cb)\n\n    def find_focused(self, callback):\n        js_code = javascript.assemble('webelem', 'find_focused')\n        js_cb = functools.partial(self._js_cb_single, callback)\n        self._tab.run_js_async(js_code, js_cb)\n\n    def find_at_pos(self, pos, callback):\n        assert pos.x() >= 0, pos\n        assert pos.y() >= 0, pos\n        pos /= self._tab.zoom.factor()\n        js_code = javascript.assemble('webelem', 'find_at_pos',\n                                      pos.x(), pos.y())\n        js_cb = functools.partial(self._js_cb_single, callback)\n        self._tab.run_js_async(js_code, js_cb)\n\n\nclass WebEngineAudio(browsertab.AbstractAudio):\n\n    \"\"\"QtWebEngine implemementations related to audio/muting.\n\n    Attributes:\n        _overridden: Whether the user toggled muting manually.\n                     If that's the case, we leave it alone.\n    \"\"\"\n\n    def __init__(self, tab, parent=None):\n        super().__init__(tab, parent)\n        self._overridden = False\n\n    def _connect_signals(self):\n        page = self._widget.page()\n        page.audioMutedChanged.connect(self.muted_changed)\n        page.recentlyAudibleChanged.connect(self.recently_audible_changed)\n        self._tab.url_changed.connect(self._on_url_changed)\n        config.instance.changed.connect(self._on_config_changed)\n\n    def set_muted(self, muted: bool, override: bool = False) -> None:\n        self._overridden = override\n        assert self._widget is not None\n        page = self._widget.page()\n        page.setAudioMuted(muted)\n\n    def is_muted(self):\n        page = self._widget.page()\n        return page.isAudioMuted()\n\n    def is_recently_audible(self):\n        page = self._widget.page()\n        return page.recentlyAudible()\n\n    @pyqtSlot(QUrl)\n    def _on_url_changed(self, url):\n        if self._overridden:\n            return\n        mute = config.instance.get('content.mute', url=url)\n        self.set_muted(mute)\n\n    @config.change_filter('content.mute')\n    def _on_config_changed(self):\n        self._on_url_changed(self._tab.url())\n\n\nclass _WebEnginePermissions(QObject):\n\n    \"\"\"Handling of various permission-related signals.\"\"\"\n\n    # Using 0 as WORKAROUND for:\n    # https://www.riverbankcomputing.com/pipermail/pyqt/2019-July/041903.html\n\n    _options = {\n        0: 'content.notifications',\n        QWebEnginePage.Geolocation: 'content.geolocation',\n        QWebEnginePage.MediaAudioCapture: 'content.media_capture',\n        QWebEnginePage.MediaVideoCapture: 'content.media_capture',\n        QWebEnginePage.MediaAudioVideoCapture: 'content.media_capture',\n    }\n\n    _messages = {\n        0: 'show notifications',\n        QWebEnginePage.Geolocation: 'access your location',\n        QWebEnginePage.MediaAudioCapture: 'record audio',\n        QWebEnginePage.MediaVideoCapture: 'record video',\n        QWebEnginePage.MediaAudioVideoCapture: 'record audio/video',\n    }\n\n    def __init__(self, tab, parent=None):\n        super().__init__(parent)\n        self._tab = tab\n        self._widget = typing.cast(QWidget, None)\n\n        try:\n            self._options.update({\n                QWebEnginePage.MouseLock:\n                    'content.mouse_lock',\n            })\n            self._messages.update({\n                QWebEnginePage.MouseLock:\n                    'hide your mouse pointer',\n            })\n        except AttributeError:\n            # Added in Qt 5.8\n            pass\n        try:\n            self._options.update({\n                QWebEnginePage.DesktopVideoCapture:\n                    'content.desktop_capture',\n                QWebEnginePage.DesktopAudioVideoCapture:\n                    'content.desktop_capture',\n            })\n            self._messages.update({\n                QWebEnginePage.DesktopVideoCapture:\n                    'capture your desktop',\n                QWebEnginePage.DesktopAudioVideoCapture:\n                    'capture your desktop and audio',\n            })\n        except AttributeError:\n            # Added in Qt 5.10\n            pass\n\n        assert self._options.keys() == self._messages.keys()\n\n    def connect_signals(self):\n        \"\"\"Connect related signals from the QWebEnginePage.\"\"\"\n        page = self._widget.page()\n        page.fullScreenRequested.connect(\n            self._on_fullscreen_requested)\n        page.featurePermissionRequested.connect(\n            self._on_feature_permission_requested)\n\n        if qtutils.version_check('5.11'):\n            page.quotaRequested.connect(\n                self._on_quota_requested)\n            page.registerProtocolHandlerRequested.connect(\n                self._on_register_protocol_handler_requested)\n\n    @pyqtSlot('QWebEngineFullScreenRequest')\n    def _on_fullscreen_requested(self, request):\n        request.accept()\n        on = request.toggleOn()\n\n        self._tab.data.fullscreen = on\n        self._tab.fullscreen_requested.emit(on)\n        if on:\n            timeout = config.val.content.fullscreen.overlay_timeout\n            if timeout != 0:\n                notification = miscwidgets.FullscreenNotification(self._widget)\n                notification.set_timeout(timeout)\n                notification.show()\n\n    @pyqtSlot(QUrl, 'QWebEnginePage::Feature')\n    def _on_feature_permission_requested(self, url, feature):\n        \"\"\"Ask the user for approval for geolocation/media/etc..\"\"\"\n        page = self._widget.page()\n        grant_permission = functools.partial(\n            page.setFeaturePermission, url, feature,\n            QWebEnginePage.PermissionGrantedByUser)\n        deny_permission = functools.partial(\n            page.setFeaturePermission, url, feature,\n            QWebEnginePage.PermissionDeniedByUser)\n\n        if feature not in self._options:\n            log.webview.error(\"Unhandled feature permission {}\".format(\n                debug.qenum_key(QWebEnginePage, feature)))\n            deny_permission()\n            return\n\n        if (\n                hasattr(QWebEnginePage, 'DesktopVideoCapture') and\n                feature in [QWebEnginePage.DesktopVideoCapture,\n                            QWebEnginePage.DesktopAudioVideoCapture] and\n                qtutils.version_check('5.13', compiled=False) and\n                not qtutils.version_check('5.13.2', compiled=False)\n        ):\n            # WORKAROUND for https://bugreports.qt.io/browse/QTBUG-78016\n            log.webview.warning(\"Ignoring desktop sharing request due to \"\n                                \"crashes in Qt < 5.13.2\")\n            deny_permission()\n            return\n\n        question = shared.feature_permission(\n            url=url.adjusted(QUrl.RemovePath),\n            option=self._options[feature], msg=self._messages[feature],\n            yes_action=grant_permission, no_action=deny_permission,\n            abort_on=[self._tab.abort_questions])\n\n        if question is not None:\n            page.featurePermissionRequestCanceled.connect(\n                functools.partial(self._on_feature_permission_cancelled,\n                                  question, url, feature))\n\n    def _on_feature_permission_cancelled(self, question, url, feature,\n                                         cancelled_url, cancelled_feature):\n        \"\"\"Slot invoked when a feature permission request was cancelled.\n\n        To be used with functools.partial.\n        \"\"\"\n        if url == cancelled_url and feature == cancelled_feature:\n            try:\n                question.abort()\n            except RuntimeError:\n                # The question could already be deleted, e.g. because it was\n                # aborted after a loadStarted signal.\n                pass\n\n    def _on_quota_requested(self, request):\n        size = utils.format_size(request.requestedSize())\n        shared.feature_permission(\n            url=request.origin().adjusted(QUrl.RemovePath),\n            option='content.persistent_storage',\n            msg='use {} of persistent storage'.format(size),\n            yes_action=request.accept, no_action=request.reject,\n            abort_on=[self._tab.abort_questions],\n            blocking=True)\n\n    def _on_register_protocol_handler_requested(self, request):\n        shared.feature_permission(\n            url=request.origin().adjusted(QUrl.RemovePath),\n            option='content.register_protocol_handler',\n            msg='open all {} links'.format(request.scheme()),\n            yes_action=request.accept, no_action=request.reject,\n            abort_on=[self._tab.abort_questions],\n            blocking=True)\n\n\nclass _WebEngineScripts(QObject):\n\n    def __init__(self, tab, parent=None):\n        super().__init__(parent)\n        self._tab = tab\n        self._widget = typing.cast(QWidget, None)\n        self._greasemonkey = greasemonkey.gm_manager\n\n    def connect_signals(self):\n        \"\"\"Connect signals to our private slots.\"\"\"\n        config.instance.changed.connect(self._on_config_changed)\n\n        self._tab.search.cleared.connect(functools.partial(\n            self._update_stylesheet, searching=False))\n        self._tab.search.finished.connect(self._update_stylesheet)\n\n    @pyqtSlot(str)\n    def _on_config_changed(self, option):\n        if option in ['scrolling.bar', 'content.user_stylesheets']:\n            self._init_stylesheet()\n            self._update_stylesheet()\n\n    @pyqtSlot(bool)\n    def _update_stylesheet(self, searching=False):\n        \"\"\"Update the custom stylesheet in existing tabs.\"\"\"\n        css = shared.get_user_stylesheet(searching=searching)\n        code = javascript.assemble('stylesheet', 'set_css', css)\n        self._tab.run_js_async(code)\n\n    def _inject_early_js(self, name, js_code, *,\n                         world=QWebEngineScript.ApplicationWorld,\n                         subframes=False):\n        \"\"\"Inject the given script to run early on a page load.\n\n        This runs the script both on DocumentCreation and DocumentReady as on\n        some internal pages, DocumentCreation will not work.\n\n        That is a WORKAROUND for https://bugreports.qt.io/browse/QTBUG-66011\n        \"\"\"\n        scripts = self._widget.page().scripts()\n        for injection in ['creation', 'ready']:\n            injection_points = {\n                'creation': QWebEngineScript.DocumentCreation,\n                'ready': QWebEngineScript.DocumentReady,\n            }\n            script = QWebEngineScript()\n            script.setInjectionPoint(injection_points[injection])\n            script.setSourceCode(js_code)\n            script.setWorldId(world)\n            script.setRunsOnSubFrames(subframes)\n            script.setName('_qute_{}_{}'.format(name, injection))\n            scripts.insert(script)\n\n    def _remove_early_js(self, name):\n        \"\"\"Remove an early QWebEngineScript.\"\"\"\n        scripts = self._widget.page().scripts()\n        for injection in ['creation', 'ready']:\n            full_name = '_qute_{}_{}'.format(name, injection)\n            script = scripts.findScript(full_name)\n            if not script.isNull():\n                scripts.remove(script)\n\n    def init(self):\n        \"\"\"Initialize global qutebrowser JavaScript.\"\"\"\n        js_code = javascript.wrap_global(\n            'scripts',\n            utils.read_file('javascript/scroll.js'),\n            utils.read_file('javascript/webelem.js'),\n            utils.read_file('javascript/caret.js'),\n        )\n        if not qtutils.version_check('5.12'):\n            # WORKAROUND for Qt versions < 5.12 not exposing window.print().\n            # Qt 5.12 has a printRequested() signal so we don't need this hack\n            # anymore.\n            self._inject_early_js('js',\n                                  utils.read_file('javascript/print.js'),\n                                  subframes=True,\n                                  world=QWebEngineScript.MainWorld)\n        # FIXME:qtwebengine what about subframes=True?\n        self._inject_early_js('js', js_code, subframes=True)\n        self._init_stylesheet()\n\n        # The Greasemonkey metadata block support in QtWebEngine only starts at\n        # Qt 5.8. With 5.7.1, we need to inject the scripts ourselves in\n        # response to urlChanged.\n        if not qtutils.version_check('5.8'):\n            self._tab.url_changed.connect(\n                self._inject_greasemonkey_scripts_for_url)\n        else:\n            self._greasemonkey.scripts_reloaded.connect(\n                self._inject_all_greasemonkey_scripts)\n            self._inject_all_greasemonkey_scripts()\n            self._inject_site_specific_quirks()\n\n    def _init_stylesheet(self):\n        \"\"\"Initialize custom stylesheets.\n\n        Partially inspired by QupZilla:\n        https://github.com/QupZilla/qupzilla/blob/v2.0/src/lib/app/mainapplication.cpp#L1063-L1101\n        \"\"\"\n        self._remove_early_js('stylesheet')\n        css = shared.get_user_stylesheet()\n        js_code = javascript.wrap_global(\n            'stylesheet',\n            utils.read_file('javascript/stylesheet.js'),\n            javascript.assemble('stylesheet', 'set_css', css),\n        )\n        self._inject_early_js('stylesheet', js_code, subframes=True)\n\n    @pyqtSlot(QUrl)\n    def _inject_greasemonkey_scripts_for_url(self, url):\n        matching_scripts = self._greasemonkey.scripts_for(url)\n        self._inject_greasemonkey_scripts(\n            matching_scripts.start, QWebEngineScript.DocumentCreation, True)\n        self._inject_greasemonkey_scripts(\n            matching_scripts.end, QWebEngineScript.DocumentReady, False)\n        self._inject_greasemonkey_scripts(\n            matching_scripts.idle, QWebEngineScript.Deferred, False)\n\n    @pyqtSlot()\n    def _inject_all_greasemonkey_scripts(self):\n        scripts = self._greasemonkey.all_scripts()\n        self._inject_greasemonkey_scripts(scripts)\n\n    def _remove_all_greasemonkey_scripts(self):\n        page_scripts = self._widget.page().scripts()\n        for script in page_scripts.toList():\n            if script.name().startswith(\"GM-\"):\n                log.greasemonkey.debug('Removing script: {}'\n                                       .format(script.name()))\n                removed = page_scripts.remove(script)\n                assert removed, script.name()\n\n    def _inject_greasemonkey_scripts(self, scripts=None, injection_point=None,\n                                     remove_first=True):\n        \"\"\"Register user JavaScript files with the current tab.\n\n        Args:\n            scripts: A list of GreasemonkeyScripts, or None to add all\n                     known by the Greasemonkey subsystem.\n            injection_point: The QWebEngineScript::InjectionPoint stage\n                             to inject the script into, None to use\n                             auto-detection.\n            remove_first: Whether to remove all previously injected\n                          scripts before adding these ones.\n        \"\"\"\n        if sip.isdeleted(self._widget):\n            return\n\n        # Since we are inserting scripts into a per-tab collection,\n        # rather than just injecting scripts on page load, we need to\n        # make sure we replace existing scripts, not just add new ones.\n        # While, taking care not to remove any other scripts that might\n        # have been added elsewhere, like the one for stylesheets.\n        page_scripts = self._widget.page().scripts()\n        if remove_first:\n            self._remove_all_greasemonkey_scripts()\n\n        if not scripts:\n            return\n\n        for script in scripts:\n            new_script = QWebEngineScript()\n            try:\n                world = int(script.jsworld)\n                if not 0 <= world <= qtutils.MAX_WORLD_ID:\n                    log.greasemonkey.error(\n                        \"script {} has invalid value for '@qute-js-world'\"\n                        \": {}, should be between 0 and {}\"\n                        .format(\n                            script.name,\n                            script.jsworld,\n                            qtutils.MAX_WORLD_ID))\n                    continue\n            except ValueError:\n                try:\n                    world = _JS_WORLD_MAP[usertypes.JsWorld[\n                        script.jsworld.lower()]]\n                except KeyError:\n                    log.greasemonkey.error(\n                        \"script {} has invalid value for '@qute-js-world'\"\n                        \": {}\".format(script.name, script.jsworld))\n                    continue\n            new_script.setWorldId(world)\n            new_script.setSourceCode(script.code())\n            new_script.setName(\"GM-{}\".format(script.name))\n            new_script.setRunsOnSubFrames(script.runs_on_sub_frames)\n\n            # Override the @run-at value parsed by QWebEngineScript if desired.\n            if injection_point:\n                new_script.setInjectionPoint(injection_point)\n            elif script.needs_document_end_workaround():\n                log.greasemonkey.debug(\"Forcing @run-at document-end for {}\"\n                                       .format(script.name))\n                new_script.setInjectionPoint(QWebEngineScript.DocumentReady)\n\n            log.greasemonkey.debug('adding script: {}'\n                                   .format(new_script.name()))\n            page_scripts.insert(new_script)\n\n    def _inject_site_specific_quirks(self):\n        \"\"\"Add site-specific quirk scripts.\n\n        NOTE: This isn't implemented for Qt 5.7 because of different UserScript\n        semantics there. We only have a quirk for WhatsApp Web right now. It\n        looks like that quirk isn't needed for Qt < 5.13.\n        \"\"\"\n        if not config.val.content.site_specific_quirks:\n            return\n\n        page_scripts = self._widget.page().scripts()\n\n        for filename in ['whatsapp_web_quirk']:\n            script = QWebEngineScript()\n            script.setName(filename)\n            script.setWorldId(QWebEngineScript.ApplicationWorld)\n            script.setInjectionPoint(QWebEngineScript.DocumentReady)\n            src = utils.read_file(\"javascript/{}.user.js\".format(filename))\n            script.setSourceCode(src)\n            page_scripts.insert(script)\n\n\nclass WebEngineTabPrivate(browsertab.AbstractTabPrivate):\n\n    \"\"\"QtWebEngine-related methods which aren't part of the public API.\"\"\"\n\n    def networkaccessmanager(self):\n        return None\n\n    def user_agent(self):\n        return None\n\n    def clear_ssl_errors(self):\n        raise browsertab.UnsupportedOperationError\n\n    def event_target(self):\n        return self._widget.render_widget()\n\n    def shutdown(self):\n        self._tab.shutting_down.emit()\n        self._tab.action.exit_fullscreen()\n        self._widget.shutdown()\n\n\nclass WebEngineTab(browsertab.AbstractTab):\n\n    \"\"\"A QtWebEngine tab in the browser.\n\n    Signals:\n        abort_questions: Emitted when a new load started or we're shutting\n            down.\n    \"\"\"\n\n    abort_questions = pyqtSignal()\n\n    def __init__(self, *, win_id, mode_manager, private, parent=None):\n        super().__init__(win_id=win_id, private=private, parent=parent)\n        widget = webview.WebEngineView(tabdata=self.data, win_id=win_id,\n                                       private=private)\n        self.history = WebEngineHistory(tab=self)\n        self.scroller = WebEngineScroller(tab=self, parent=self)\n        self.caret = WebEngineCaret(mode_manager=mode_manager,\n                                    tab=self, parent=self)\n        self.zoom = WebEngineZoom(tab=self, parent=self)\n        self.search = WebEngineSearch(tab=self, parent=self)\n        self.printing = WebEnginePrinting(tab=self)\n        self.elements = WebEngineElements(tab=self)\n        self.action = WebEngineAction(tab=self)\n        self.audio = WebEngineAudio(tab=self, parent=self)\n        self.private_api = WebEngineTabPrivate(mode_manager=mode_manager,\n                                               tab=self)\n        self._permissions = _WebEnginePermissions(tab=self, parent=self)\n        self._scripts = _WebEngineScripts(tab=self, parent=self)\n        # We're assigning settings in _set_widget\n        self.settings = webenginesettings.WebEngineSettings(settings=None)\n        self._set_widget(widget)\n        self._connect_signals()\n        self.backend = usertypes.Backend.QtWebEngine\n        self._child_event_filter = None\n        self._saved_zoom = None\n        self._reload_url = None  # type: typing.Optional[QUrl]\n        self._scripts.init()\n\n    def _set_widget(self, widget):\n        # pylint: disable=protected-access\n        super()._set_widget(widget)\n        self._permissions._widget = widget\n        self._scripts._widget = widget\n\n    def _install_event_filter(self):\n        fp = self._widget.focusProxy()\n        if fp is not None:\n            fp.installEventFilter(self._tab_event_filter)\n        self._child_event_filter = eventfilter.ChildEventFilter(\n            eventfilter=self._tab_event_filter, widget=self._widget,\n            win_id=self.win_id, parent=self)\n        self._widget.installEventFilter(self._child_event_filter)\n\n    @pyqtSlot()\n    def _restore_zoom(self):\n        if sip.isdeleted(self._widget):\n            # https://github.com/qutebrowser/qutebrowser/issues/3498\n            return\n        if self._saved_zoom is None:\n            return\n        self.zoom.set_factor(self._saved_zoom)\n        self._saved_zoom = None\n\n    def load_url(self, url, *, emit_before_load_started=True):\n        \"\"\"Load the given URL in this tab.\n\n        Arguments:\n            url: The QUrl to load.\n            emit_before_load_started: If set to False, before_load_started is\n                                      not emitted.\n        \"\"\"\n        if sip.isdeleted(self._widget):\n            # https://github.com/qutebrowser/qutebrowser/issues/3896\n            return\n        self._saved_zoom = self.zoom.factor()\n        self._load_url_prepare(\n            url, emit_before_load_started=emit_before_load_started)\n        self._widget.load(url)\n\n    def url(self, *, requested=False):\n        page = self._widget.page()\n        if requested:\n            return page.requestedUrl()\n        else:\n            return page.url()\n\n    def dump_async(self, callback, *, plain=False):\n        if plain:\n            self._widget.page().toPlainText(callback)\n        else:\n            self._widget.page().toHtml(callback)\n\n    def run_js_async(self, code, callback=None, *, world=None):\n        world_id_type = typing.Union[QWebEngineScript.ScriptWorldId, int]\n        if world is None:\n            world_id = QWebEngineScript.ApplicationWorld  # type: world_id_type\n        elif isinstance(world, int):\n            world_id = world\n            if not 0 <= world_id <= qtutils.MAX_WORLD_ID:\n                raise browsertab.WebTabError(\n                    \"World ID should be between 0 and {}\"\n                    .format(qtutils.MAX_WORLD_ID))\n        else:\n            world_id = _JS_WORLD_MAP[world]\n\n        if callback is None:\n            self._widget.page().runJavaScript(code, world_id)\n        else:\n            self._widget.page().runJavaScript(code, world_id, callback)\n\n    def reload(self, *, force=False):\n        if force:\n            action = QWebEnginePage.ReloadAndBypassCache\n        else:\n            action = QWebEnginePage.Reload\n        self._widget.triggerPageAction(action)\n\n    def stop(self):\n        self._widget.stop()\n\n    def title(self):\n        return self._widget.title()\n\n    def icon(self):\n        return self._widget.icon()\n\n    def set_html(self, html, base_url=QUrl()):\n        # FIXME:qtwebengine\n        # check this and raise an exception if too big:\n        # Warning: The content will be percent encoded before being sent to the\n        # renderer via IPC. This may increase its size. The maximum size of the\n        # percent encoded content is 2 megabytes minus 30 bytes.\n        self._widget.setHtml(html, base_url)\n\n    def _show_error_page(self, url, error):\n        \"\"\"Show an error page in the tab.\"\"\"\n        log.misc.debug(\"Showing error page for {}\".format(error))\n        url_string = url.toDisplayString()\n        error_page = jinja.render(\n            'error.html',\n            title=\"Error loading page: {}\".format(url_string),\n            url=url_string, error=error)\n        self.set_html(error_page)\n\n    @pyqtSlot()\n    def _on_history_trigger(self):\n        try:\n            self._widget.page()\n        except RuntimeError:\n            # Looks like this slot can be triggered on destroyed tabs:\n            # https://crashes.qutebrowser.org/view/3abffbed (Qt 5.9.1)\n            # wrapped C/C++ object of type WebEngineView has been deleted\n            log.misc.debug(\"Ignoring history trigger for destroyed tab\")\n            return\n\n        url = self.url()\n        requested_url = self.url(requested=True)\n\n        # Don't save the title if it's generated from the URL\n        title = self.title()\n        title_url = QUrl(url)\n        title_url.setScheme('')\n        title_url_str = title_url.toDisplayString(\n            QUrl.RemoveScheme)  # type: ignore\n        if title == title_url_str.strip('/'):\n            title = \"\"\n\n        # Don't add history entry if the URL is invalid anyways\n        if not url.isValid():\n            log.misc.debug(\"Ignoring invalid URL being added to history\")\n            return\n\n        self.history_item_triggered.emit(url, requested_url, title)\n\n    @pyqtSlot(QUrl, 'QAuthenticator*', 'QString')\n    def _on_proxy_authentication_required(self, url, authenticator,\n                                          proxy_host):\n        \"\"\"Called when a proxy needs authentication.\"\"\"\n        msg = \"<b>{}</b> requires a username and password.\".format(\n            html_utils.escape(proxy_host))\n        urlstr = url.toString(QUrl.RemovePassword | QUrl.FullyEncoded)\n        answer = message.ask(\n            title=\"Proxy authentication required\", text=msg,\n            mode=usertypes.PromptMode.user_pwd,\n            abort_on=[self.abort_questions], url=urlstr)\n        if answer is not None:\n            authenticator.setUser(answer.user)\n            authenticator.setPassword(answer.password)\n        else:\n            try:\n                sip.assign(authenticator, QAuthenticator())  # type: ignore\n            except AttributeError:\n                self._show_error_page(url, \"Proxy authentication required\")\n\n    @pyqtSlot(QUrl, 'QAuthenticator*')\n    def _on_authentication_required(self, url, authenticator):\n        log.network.debug(\"Authentication requested for {}, netrc_used {}\"\n                          .format(url.toDisplayString(), self.data.netrc_used))\n\n        netrc_success = False\n        if not self.data.netrc_used:\n            self.data.netrc_used = True\n            netrc_success = shared.netrc_authentication(url, authenticator)\n\n        if not netrc_success:\n            log.network.debug(\"Asking for credentials\")\n            answer = shared.authentication_required(\n                url, authenticator, abort_on=[self.abort_questions])\n        if not netrc_success and answer is None:\n            log.network.debug(\"Aborting auth\")\n            try:\n                sip.assign(authenticator, QAuthenticator())  # type: ignore\n            except AttributeError:\n                # WORKAROUND for\n                # https://www.riverbankcomputing.com/pipermail/pyqt/2016-December/038400.html\n                self._show_error_page(url, \"Authentication required\")\n\n    @pyqtSlot()\n    def _on_load_started(self):\n        \"\"\"Clear search when a new load is started if needed.\"\"\"\n        # WORKAROUND for\n        # https://bugreports.qt.io/browse/QTBUG-61506\n        # (seems to be back in later Qt versions as well)\n        self.search.clear()\n        super()._on_load_started()\n        self.data.netrc_used = False\n\n    @pyqtSlot(QWebEnginePage.RenderProcessTerminationStatus, int)\n    def _on_render_process_terminated(self, status, exitcode):\n        \"\"\"Show an error when the renderer process terminated.\"\"\"\n        if (status == QWebEnginePage.AbnormalTerminationStatus and\n                exitcode == 256):\n            # WORKAROUND for https://bugreports.qt.io/browse/QTBUG-58697\n            status = QWebEnginePage.CrashedTerminationStatus\n\n        status_map = {\n            QWebEnginePage.NormalTerminationStatus:\n                browsertab.TerminationStatus.normal,\n            QWebEnginePage.AbnormalTerminationStatus:\n                browsertab.TerminationStatus.abnormal,\n            QWebEnginePage.CrashedTerminationStatus:\n                browsertab.TerminationStatus.crashed,\n            QWebEnginePage.KilledTerminationStatus:\n                browsertab.TerminationStatus.killed,\n            -1:\n                browsertab.TerminationStatus.unknown,\n        }\n        self.renderer_process_terminated.emit(status_map[status], exitcode)\n\n    def _error_page_workaround(self, js_enabled, html):\n        \"\"\"Check if we're displaying a Chromium error page.\n\n        This gets called if we got a loadFinished(False), so we can display at\n        least some error page in situations where Chromium's can't be\n        displayed.\n\n        WORKAROUND for https://bugreports.qt.io/browse/QTBUG-66643\n        WORKAROUND for https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=882805\n\n        Needs to check the page content as a WORKAROUND for\n        https://bugreports.qt.io/browse/QTBUG-66661\n        \"\"\"\n        match = re.search(r'\"errorCode\":\"([^\"]*)\"', html)\n        if match is None:\n            return\n\n        error = match.group(1)\n        log.webview.error(\"Load error: {}\".format(error))\n\n        missing_jst = 'jstProcess(' in html and 'jstProcess=' not in html\n        if js_enabled and not missing_jst:\n            return\n\n        self._show_error_page(self.url(), error=error)\n\n    @pyqtSlot(int)\n    def _on_load_progress(self, perc: int) -> None:\n        \"\"\"QtWebEngine-specific loadProgress workarounds.\n\n        WORKAROUND for https://bugreports.qt.io/browse/QTBUG-65223\n        \"\"\"\n        super()._on_load_progress(perc)\n        if (perc == 100 and\n                qtutils.version_check('5.10', compiled=False) and\n                self.load_status() != usertypes.LoadStatus.error):\n            self._update_load_status(ok=True)\n\n    @pyqtSlot(bool)\n    def _on_load_finished(self, ok: bool) -> None:\n        \"\"\"QtWebEngine-specific loadFinished workarounds.\"\"\"\n        super()._on_load_finished(ok)\n\n        # WORKAROUND for https://bugreports.qt.io/browse/QTBUG-65223\n        if qtutils.version_check('5.10', compiled=False):\n            if not ok:\n                self._update_load_status(ok)\n        else:\n            self._update_load_status(ok)\n\n        if not ok:\n            self.dump_async(functools.partial(\n                self._error_page_workaround,\n                self.settings.test_attribute('content.javascript.enabled')))\n\n        if ok and self._reload_url is not None:\n            # WORKAROUND for https://bugreports.qt.io/browse/QTBUG-66656\n            log.config.debug(\n                \"Loading {} again because of config change\".format(\n                    self._reload_url.toDisplayString()))\n            QTimer.singleShot(100, functools.partial(\n                self.load_url, self._reload_url,\n                emit_before_load_started=False))\n            self._reload_url = None\n\n    @pyqtSlot(certificateerror.CertificateErrorWrapper)\n    def _on_ssl_errors(self, error):\n        url = error.url()\n        self._insecure_hosts.add(url.host())\n\n        log.webview.debug(\"Certificate error: {}\".format(error))\n\n        if error.is_overridable():\n            error.ignore = shared.ignore_certificate_errors(\n                url, [error], abort_on=[self.abort_questions])\n        else:\n            log.webview.error(\"Non-overridable certificate error: \"\n                              \"{}\".format(error))\n\n        log.webview.debug(\"ignore {}, URL {}, requested {}\".format(\n            error.ignore, url, self.url(requested=True)))\n\n        # WORKAROUND for https://bugreports.qt.io/browse/QTBUG-56207\n        show_cert_error = (\n            not qtutils.version_check('5.9') and\n            not error.ignore\n        )\n        # WORKAROUND for https://codereview.qt-project.org/c/qt/qtwebengine/+/270556\n        show_non_overr_cert_error = (\n            not error.is_overridable() and (\n                # Affected Qt versions:\n                # 5.13 before 5.13.2\n                # 5.12 before 5.12.6\n                # < 5.12\n                (qtutils.version_check('5.13') and\n                 not qtutils.version_check('5.13.2')) or\n                (qtutils.version_check('5.12') and\n                 not qtutils.version_check('5.12.6')) or\n                not qtutils.version_check('5.12')\n            )\n        )\n\n        # We can't really know when to show an error page, as the error might\n        # have happened when loading some resource.\n        # However, self.url() is not available yet and the requested URL\n        # might not match the URL we get from the error - so we just apply a\n        # heuristic here.\n        if ((show_cert_error or show_non_overr_cert_error) and\n                url.matches(self.data.last_navigation.url, QUrl.RemoveScheme)):\n            self._show_error_page(url, str(error))\n\n    @pyqtSlot(QUrl)\n    def _on_before_load_started(self, url):\n        \"\"\"If we know we're going to visit a URL soon, change the settings.\n\n        This is a WORKAROUND for https://bugreports.qt.io/browse/QTBUG-66656\n        \"\"\"\n        super()._on_before_load_started(url)\n        if not qtutils.version_check('5.11.1', compiled=False):\n            self.settings.update_for_url(url)\n\n    @pyqtSlot()\n    def _on_print_requested(self):\n        \"\"\"Slot for window.print() in JS.\"\"\"\n        try:\n            self.printing.show_dialog()\n        except browsertab.WebTabError as e:\n            message.error(str(e))\n\n    @pyqtSlot(QUrl)\n    def _on_url_changed(self, url: QUrl) -> None:\n        \"\"\"Update settings for the current URL.\n\n        Normally this is done below in _on_navigation_request, but we also need\n        to do it here as WORKAROUND for\n        https://bugreports.qt.io/browse/QTBUG-77137\n\n        Since update_for_url() is idempotent, it doesn't matter much if we end\n        up doing it twice.\n        \"\"\"\n        super()._on_url_changed(url)\n        if url.isValid() and qtutils.version_check('5.13'):\n            self.settings.update_for_url(url)\n\n    @pyqtSlot(usertypes.NavigationRequest)\n    def _on_navigation_request(self, navigation):\n        super()._on_navigation_request(navigation)\n\n        if navigation.url == QUrl('qute://print'):\n            self._on_print_requested()\n            navigation.accepted = False\n\n        if not navigation.accepted or not navigation.is_main_frame:\n            return\n\n        settings_needing_reload = {\n            'content.plugins',\n            'content.javascript.enabled',\n            'content.javascript.can_access_clipboard',\n            'content.print_element_backgrounds',\n            'input.spatial_navigation',\n        }\n        assert settings_needing_reload.issubset(configdata.DATA)\n\n        changed = self.settings.update_for_url(navigation.url)\n        reload_needed = bool(changed & settings_needing_reload)\n\n        # On Qt < 5.11, we don't don't need a reload when type == link_clicked.\n        # On Qt 5.11.0, we always need a reload.\n        # On Qt > 5.11.0, we never need a reload:\n        # https://codereview.qt-project.org/#/c/229525/1\n        # WORKAROUND for https://bugreports.qt.io/browse/QTBUG-66656\n        if qtutils.version_check('5.11.1', compiled=False):\n            reload_needed = False\n        elif not qtutils.version_check('5.11.0', exact=True, compiled=False):\n            if navigation.navigation_type == navigation.Type.link_clicked:\n                reload_needed = False\n\n        if reload_needed:\n            self._reload_url = navigation.url\n\n    def _on_select_client_certificate(self, selection):\n        \"\"\"Handle client certificates.\n\n        Currently, we simply pick the first available certificate and show an\n        additional note if there are multiple matches.\n        \"\"\"\n        certificate = selection.certificates()[0]\n        text = ('<b>Subject:</b> {subj}<br/>'\n                '<b>Issuer:</b> {issuer}<br/>'\n                '<b>Serial:</b> {serial}'.format(\n                    subj=html_utils.escape(certificate.subjectDisplayName()),\n                    issuer=html_utils.escape(certificate.issuerDisplayName()),\n                    serial=bytes(certificate.serialNumber()).decode('ascii')))\n        if len(selection.certificates()) > 1:\n            text += ('<br/><br/><b>Note:</b> Multiple matching certificates '\n                     'were found, but certificate selection is not '\n                     'implemented yet!')\n        urlstr = selection.host().host()\n\n        present = message.ask(\n            title='Present client certificate to {}?'.format(urlstr),\n            text=text,\n            mode=usertypes.PromptMode.yesno,\n            abort_on=[self.abort_questions],\n            url=urlstr)\n\n        if present:\n            selection.select(certificate)\n        else:\n            selection.selectNone()\n\n    def _connect_signals(self):\n        view = self._widget\n        page = view.page()\n\n        page.windowCloseRequested.connect(self.window_close_requested)\n        page.linkHovered.connect(self.link_hovered)\n        page.loadProgress.connect(self._on_load_progress)\n        page.loadStarted.connect(self._on_load_started)\n        page.certificate_error.connect(self._on_ssl_errors)\n        page.authenticationRequired.connect(self._on_authentication_required)\n        page.proxyAuthenticationRequired.connect(\n            self._on_proxy_authentication_required)\n        page.contentsSizeChanged.connect(self.contents_size_changed)\n        page.navigation_request.connect(self._on_navigation_request)\n\n        if qtutils.version_check('5.12'):\n            page.printRequested.connect(self._on_print_requested)\n\n        try:\n            # pylint: disable=unused-import\n            from PyQt5.QtWebEngineWidgets import (  # type: ignore\n                QWebEngineClientCertificateSelection)\n        except ImportError:\n            pass\n        else:\n            page.selectClientCertificate.connect(\n                self._on_select_client_certificate)\n\n        view.titleChanged.connect(self.title_changed)\n        view.urlChanged.connect(self._on_url_changed)\n        view.renderProcessTerminated.connect(\n            self._on_render_process_terminated)\n        view.iconChanged.connect(self.icon_changed)\n\n        page.loadFinished.connect(self._on_history_trigger)\n        page.loadFinished.connect(self._restore_zoom)\n        page.loadFinished.connect(self._on_load_finished)\n\n        self.before_load_started.connect(self._on_before_load_started)\n        self.shutting_down.connect(self.abort_questions)  # type: ignore\n        self.load_started.connect(self.abort_questions)  # type: ignore\n\n        # pylint: disable=protected-access\n        self.audio._connect_signals()\n        self.search.connect_signals()\n        self._permissions.connect_signals()\n        self._scripts.connect_signals()\n", "target": 0}
{"idx": 942, "func": "# vim: ft=python fileencoding=utf-8 sts=4 sw=4 et:\n\n# Copyright 2016-2019 Florian Bruhin (The Compiler) <mail@qutebrowser.org>\n#\n# This file is part of qutebrowser.\n#\n# qutebrowser is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# qutebrowser is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with qutebrowser.  If not, see <http://www.gnu.org/licenses/>.\n\n\"\"\"Wrapper over our (QtWebKit) WebView.\"\"\"\n\nimport re\nimport functools\nimport xml.etree.ElementTree\n\nfrom PyQt5.QtCore import pyqtSlot, Qt, QUrl, QPoint, QTimer, QSizeF, QSize\nfrom PyQt5.QtGui import QIcon\nfrom PyQt5.QtWebKitWidgets import QWebPage, QWebFrame\nfrom PyQt5.QtWebKit import QWebSettings\nfrom PyQt5.QtPrintSupport import QPrinter\n\nfrom qutebrowser.browser import browsertab, shared\nfrom qutebrowser.browser.webkit import (webview, tabhistory, webkitelem,\n                                        webkitsettings)\nfrom qutebrowser.utils import qtutils, usertypes, utils, log, debug\nfrom qutebrowser.qt import sip\n\n\nclass WebKitAction(browsertab.AbstractAction):\n\n    \"\"\"QtWebKit implementations related to web actions.\"\"\"\n\n    action_class = QWebPage\n    action_base = QWebPage.WebAction\n\n    def exit_fullscreen(self):\n        raise browsertab.UnsupportedOperationError\n\n    def save_page(self):\n        \"\"\"Save the current page.\"\"\"\n        raise browsertab.UnsupportedOperationError\n\n    def show_source(self, pygments=False):\n        self._show_source_pygments()\n\n\nclass WebKitPrinting(browsertab.AbstractPrinting):\n\n    \"\"\"QtWebKit implementations related to printing.\"\"\"\n\n    def check_pdf_support(self):\n        pass\n\n    def check_printer_support(self):\n        pass\n\n    def check_preview_support(self):\n        pass\n\n    def to_pdf(self, filename):\n        printer = QPrinter()\n        printer.setOutputFileName(filename)\n        self.to_printer(printer)\n\n    def to_printer(self, printer, callback=None):\n        self._widget.print(printer)\n        # Can't find out whether there was an error...\n        if callback is not None:\n            callback(True)\n\n\nclass WebKitSearch(browsertab.AbstractSearch):\n\n    \"\"\"QtWebKit implementations related to searching on the page.\"\"\"\n\n    def __init__(self, tab, parent=None):\n        super().__init__(tab, parent)\n        self._flags = QWebPage.FindFlags(0)\n\n    def _call_cb(self, callback, found, text, flags, caller):\n        \"\"\"Call the given callback if it's non-None.\n\n        Delays the call via a QTimer so the website is re-rendered in between.\n\n        Args:\n            callback: What to call\n            found: If the text was found\n            text: The text searched for\n            flags: The flags searched with\n            caller: Name of the caller.\n        \"\"\"\n        found_text = 'found' if found else \"didn't find\"\n        # Removing FindWrapsAroundDocument to get the same logging as with\n        # QtWebEngine\n        debug_flags = debug.qflags_key(\n            QWebPage, flags & ~QWebPage.FindWrapsAroundDocument,\n            klass=QWebPage.FindFlag)\n        if debug_flags != '0x0000':\n            flag_text = 'with flags {}'.format(debug_flags)\n        else:\n            flag_text = ''\n        log.webview.debug(' '.join([caller, found_text, text, flag_text])\n                          .strip())\n        if callback is not None:\n            QTimer.singleShot(0, functools.partial(callback, found))\n\n        self.finished.emit(found)\n\n    def clear(self):\n        if self.search_displayed:\n            self.cleared.emit()\n        self.search_displayed = False\n        # We first clear the marked text, then the highlights\n        self._widget.findText('')\n        self._widget.findText('', QWebPage.HighlightAllOccurrences)\n\n    def search(self, text, *, ignore_case=usertypes.IgnoreCase.never,\n               reverse=False, result_cb=None):\n        # Don't go to next entry on duplicate search\n        if self.text == text and self.search_displayed:\n            log.webview.debug(\"Ignoring duplicate search request\"\n                              \" for {}\".format(text))\n            return\n\n        # Clear old search results, this is done automatically on QtWebEngine.\n        self.clear()\n\n        self.text = text\n        self.search_displayed = True\n        self._flags = QWebPage.FindWrapsAroundDocument\n        if self._is_case_sensitive(ignore_case):\n            self._flags |= QWebPage.FindCaseSensitively\n        if reverse:\n            self._flags |= QWebPage.FindBackward\n        # We actually search *twice* - once to highlight everything, then again\n        # to get a mark so we can navigate.\n        found = self._widget.findText(text, self._flags)\n        self._widget.findText(text,\n                              self._flags | QWebPage.HighlightAllOccurrences)\n        self._call_cb(result_cb, found, text, self._flags, 'search')\n\n    def next_result(self, *, result_cb=None):\n        self.search_displayed = True\n        found = self._widget.findText(self.text, self._flags)\n        self._call_cb(result_cb, found, self.text, self._flags, 'next_result')\n\n    def prev_result(self, *, result_cb=None):\n        self.search_displayed = True\n        # The int() here makes sure we get a copy of the flags.\n        flags = QWebPage.FindFlags(int(self._flags))\n        if flags & QWebPage.FindBackward:\n            flags &= ~QWebPage.FindBackward\n        else:\n            flags |= QWebPage.FindBackward\n        found = self._widget.findText(self.text, flags)\n        self._call_cb(result_cb, found, self.text, flags, 'prev_result')\n\n\nclass WebKitCaret(browsertab.AbstractCaret):\n\n    \"\"\"QtWebKit implementations related to moving the cursor/selection.\"\"\"\n\n    @pyqtSlot(usertypes.KeyMode)\n    def _on_mode_entered(self, mode):\n        if mode != usertypes.KeyMode.caret:\n            return\n\n        self.selection_enabled = self._widget.hasSelection()\n        self.selection_toggled.emit(self.selection_enabled)\n        settings = self._widget.settings()\n        settings.setAttribute(QWebSettings.CaretBrowsingEnabled, True)\n\n        if self._widget.isVisible():\n            # Sometimes the caret isn't immediately visible, but unfocusing\n            # and refocusing it fixes that.\n            self._widget.clearFocus()\n            self._widget.setFocus(Qt.OtherFocusReason)\n\n            # Move the caret to the first element in the viewport if there\n            # isn't any text which is already selected.\n            #\n            # Note: We can't use hasSelection() here, as that's always\n            # true in caret mode.\n            if not self.selection_enabled:\n                self._widget.page().currentFrame().evaluateJavaScript(\n                    utils.read_file('javascript/position_caret.js'))\n\n    @pyqtSlot(usertypes.KeyMode)\n    def _on_mode_left(self, _mode):\n        settings = self._widget.settings()\n        if settings.testAttribute(QWebSettings.CaretBrowsingEnabled):\n            if self.selection_enabled and self._widget.hasSelection():\n                # Remove selection if it exists\n                self._widget.triggerPageAction(QWebPage.MoveToNextChar)\n            settings.setAttribute(QWebSettings.CaretBrowsingEnabled, False)\n            self.selection_enabled = False\n\n    def move_to_next_line(self, count=1):\n        if not self.selection_enabled:\n            act = QWebPage.MoveToNextLine\n        else:\n            act = QWebPage.SelectNextLine\n        for _ in range(count):\n            self._widget.triggerPageAction(act)\n\n    def move_to_prev_line(self, count=1):\n        if not self.selection_enabled:\n            act = QWebPage.MoveToPreviousLine\n        else:\n            act = QWebPage.SelectPreviousLine\n        for _ in range(count):\n            self._widget.triggerPageAction(act)\n\n    def move_to_next_char(self, count=1):\n        if not self.selection_enabled:\n            act = QWebPage.MoveToNextChar\n        else:\n            act = QWebPage.SelectNextChar\n        for _ in range(count):\n            self._widget.triggerPageAction(act)\n\n    def move_to_prev_char(self, count=1):\n        if not self.selection_enabled:\n            act = QWebPage.MoveToPreviousChar\n        else:\n            act = QWebPage.SelectPreviousChar\n        for _ in range(count):\n            self._widget.triggerPageAction(act)\n\n    def move_to_end_of_word(self, count=1):\n        if not self.selection_enabled:\n            act = [QWebPage.MoveToNextWord]\n            if utils.is_windows:  # pragma: no cover\n                act.append(QWebPage.MoveToPreviousChar)\n        else:\n            act = [QWebPage.SelectNextWord]\n            if utils.is_windows:  # pragma: no cover\n                act.append(QWebPage.SelectPreviousChar)\n        for _ in range(count):\n            for a in act:\n                self._widget.triggerPageAction(a)\n\n    def move_to_next_word(self, count=1):\n        if not self.selection_enabled:\n            act = [QWebPage.MoveToNextWord]\n            if not utils.is_windows:  # pragma: no branch\n                act.append(QWebPage.MoveToNextChar)\n        else:\n            act = [QWebPage.SelectNextWord]\n            if not utils.is_windows:  # pragma: no branch\n                act.append(QWebPage.SelectNextChar)\n        for _ in range(count):\n            for a in act:\n                self._widget.triggerPageAction(a)\n\n    def move_to_prev_word(self, count=1):\n        if not self.selection_enabled:\n            act = QWebPage.MoveToPreviousWord\n        else:\n            act = QWebPage.SelectPreviousWord\n        for _ in range(count):\n            self._widget.triggerPageAction(act)\n\n    def move_to_start_of_line(self):\n        if not self.selection_enabled:\n            act = QWebPage.MoveToStartOfLine\n        else:\n            act = QWebPage.SelectStartOfLine\n        self._widget.triggerPageAction(act)\n\n    def move_to_end_of_line(self):\n        if not self.selection_enabled:\n            act = QWebPage.MoveToEndOfLine\n        else:\n            act = QWebPage.SelectEndOfLine\n        self._widget.triggerPageAction(act)\n\n    def move_to_start_of_next_block(self, count=1):\n        if not self.selection_enabled:\n            act = [QWebPage.MoveToNextLine,\n                   QWebPage.MoveToStartOfBlock]\n        else:\n            act = [QWebPage.SelectNextLine,\n                   QWebPage.SelectStartOfBlock]\n        for _ in range(count):\n            for a in act:\n                self._widget.triggerPageAction(a)\n\n    def move_to_start_of_prev_block(self, count=1):\n        if not self.selection_enabled:\n            act = [QWebPage.MoveToPreviousLine,\n                   QWebPage.MoveToStartOfBlock]\n        else:\n            act = [QWebPage.SelectPreviousLine,\n                   QWebPage.SelectStartOfBlock]\n        for _ in range(count):\n            for a in act:\n                self._widget.triggerPageAction(a)\n\n    def move_to_end_of_next_block(self, count=1):\n        if not self.selection_enabled:\n            act = [QWebPage.MoveToNextLine,\n                   QWebPage.MoveToEndOfBlock]\n        else:\n            act = [QWebPage.SelectNextLine,\n                   QWebPage.SelectEndOfBlock]\n        for _ in range(count):\n            for a in act:\n                self._widget.triggerPageAction(a)\n\n    def move_to_end_of_prev_block(self, count=1):\n        if not self.selection_enabled:\n            act = [QWebPage.MoveToPreviousLine, QWebPage.MoveToEndOfBlock]\n        else:\n            act = [QWebPage.SelectPreviousLine, QWebPage.SelectEndOfBlock]\n        for _ in range(count):\n            for a in act:\n                self._widget.triggerPageAction(a)\n\n    def move_to_start_of_document(self):\n        if not self.selection_enabled:\n            act = QWebPage.MoveToStartOfDocument\n        else:\n            act = QWebPage.SelectStartOfDocument\n        self._widget.triggerPageAction(act)\n\n    def move_to_end_of_document(self):\n        if not self.selection_enabled:\n            act = QWebPage.MoveToEndOfDocument\n        else:\n            act = QWebPage.SelectEndOfDocument\n        self._widget.triggerPageAction(act)\n\n    def toggle_selection(self):\n        self.selection_enabled = not self.selection_enabled\n        self.selection_toggled.emit(self.selection_enabled)\n\n    def drop_selection(self):\n        self._widget.triggerPageAction(QWebPage.MoveToNextChar)\n\n    def selection(self, callback):\n        callback(self._widget.selectedText())\n\n    def reverse_selection(self):\n        self._tab.run_js_async(\"\"\"{\n            const sel = window.getSelection();\n            sel.setBaseAndExtent(\n                sel.extentNode, sel.extentOffset, sel.baseNode,\n                sel.baseOffset\n            );\n        }\"\"\")\n\n    def _follow_selected(self, *, tab=False):\n        if QWebSettings.globalSettings().testAttribute(\n                QWebSettings.JavascriptEnabled):\n            if tab:\n                self._tab.data.override_target = usertypes.ClickTarget.tab\n            self._tab.run_js_async(\"\"\"\n                const aElm = document.activeElement;\n                if (window.getSelection().anchorNode) {\n                    window.getSelection().anchorNode.parentNode.click();\n                } else if (aElm && aElm !== document.body) {\n                    aElm.click();\n                }\n            \"\"\")\n        else:\n            selection = self._widget.selectedHtml()\n            if not selection:\n                # Getting here may mean we crashed, but we can't do anything\n                # about that until this commit is released:\n                # https://github.com/annulen/webkit/commit/0e75f3272d149bc64899c161f150eb341a2417af\n                # TODO find a way to check if something is focused\n                self._follow_enter(tab)\n                return\n            try:\n                selected_element = xml.etree.ElementTree.fromstring(\n                    '<html>{}</html>'.format(selection)).find('a')\n            except xml.etree.ElementTree.ParseError:\n                raise browsertab.WebTabError('Could not parse selected '\n                                             'element!')\n\n            if selected_element is not None:\n                try:\n                    url = selected_element.attrib['href']\n                except KeyError:\n                    raise browsertab.WebTabError('Anchor element without '\n                                                 'href!')\n                url = self._tab.url().resolved(QUrl(url))\n                if tab:\n                    self._tab.new_tab_requested.emit(url)\n                else:\n                    self._tab.load_url(url)\n\n    def follow_selected(self, *, tab=False):\n        try:\n            self._follow_selected(tab=tab)\n        finally:\n            self.follow_selected_done.emit()\n\n\nclass WebKitZoom(browsertab.AbstractZoom):\n\n    \"\"\"QtWebKit implementations related to zooming.\"\"\"\n\n    def _set_factor_internal(self, factor):\n        self._widget.setZoomFactor(factor)\n\n\nclass WebKitScroller(browsertab.AbstractScroller):\n\n    \"\"\"QtWebKit implementations related to scrolling.\"\"\"\n\n    # FIXME:qtwebengine When to use the main frame, when the current one?\n\n    def pos_px(self):\n        return self._widget.page().mainFrame().scrollPosition()\n\n    def pos_perc(self):\n        return self._widget.scroll_pos\n\n    def to_point(self, point):\n        self._widget.page().mainFrame().setScrollPosition(point)\n\n    def to_anchor(self, name):\n        self._widget.page().mainFrame().scrollToAnchor(name)\n\n    def delta(self, x=0, y=0):\n        qtutils.check_overflow(x, 'int')\n        qtutils.check_overflow(y, 'int')\n        self._widget.page().mainFrame().scroll(x, y)\n\n    def delta_page(self, x=0.0, y=0.0):\n        if y.is_integer():\n            y = int(y)\n            if y == 0:\n                pass\n            elif y < 0:\n                self.page_up(count=-y)\n            elif y > 0:\n                self.page_down(count=y)\n            y = 0\n        if x == 0 and y == 0:\n            return\n        size = self._widget.page().mainFrame().geometry()\n        self.delta(x * size.width(), y * size.height())\n\n    def to_perc(self, x=None, y=None):\n        if x is None and y == 0:\n            self.top()\n        elif x is None and y == 100:\n            self.bottom()\n        else:\n            for val, orientation in [(x, Qt.Horizontal), (y, Qt.Vertical)]:\n                if val is not None:\n                    frame = self._widget.page().mainFrame()\n                    maximum = frame.scrollBarMaximum(orientation)\n                    if maximum == 0:\n                        continue\n                    pos = int(maximum * val / 100)\n                    pos = qtutils.check_overflow(pos, 'int', fatal=False)\n                    frame.setScrollBarValue(orientation, pos)\n\n    def _key_press(self, key, count=1, getter_name=None, direction=None):\n        frame = self._widget.page().mainFrame()\n        getter = None if getter_name is None else getattr(frame, getter_name)\n\n        # FIXME:qtwebengine needed?\n        # self._widget.setFocus()\n\n        for _ in range(min(count, 5000)):\n            # Abort scrolling if the minimum/maximum was reached.\n            if (getter is not None and\n                    frame.scrollBarValue(direction) == getter(direction)):\n                return\n            self._tab.fake_key_press(key)\n\n    def up(self, count=1):\n        self._key_press(Qt.Key_Up, count, 'scrollBarMinimum', Qt.Vertical)\n\n    def down(self, count=1):\n        self._key_press(Qt.Key_Down, count, 'scrollBarMaximum', Qt.Vertical)\n\n    def left(self, count=1):\n        self._key_press(Qt.Key_Left, count, 'scrollBarMinimum', Qt.Horizontal)\n\n    def right(self, count=1):\n        self._key_press(Qt.Key_Right, count, 'scrollBarMaximum', Qt.Horizontal)\n\n    def top(self):\n        self._key_press(Qt.Key_Home)\n\n    def bottom(self):\n        self._key_press(Qt.Key_End)\n\n    def page_up(self, count=1):\n        self._key_press(Qt.Key_PageUp, count, 'scrollBarMinimum', Qt.Vertical)\n\n    def page_down(self, count=1):\n        self._key_press(Qt.Key_PageDown, count, 'scrollBarMaximum',\n                        Qt.Vertical)\n\n    def at_top(self):\n        return self.pos_px().y() == 0\n\n    def at_bottom(self):\n        frame = self._widget.page().currentFrame()\n        return self.pos_px().y() >= frame.scrollBarMaximum(Qt.Vertical)\n\n\nclass WebKitHistoryPrivate(browsertab.AbstractHistoryPrivate):\n\n    \"\"\"History-related methods which are not part of the extension API.\"\"\"\n\n    def serialize(self):\n        return qtutils.serialize(self._history)\n\n    def deserialize(self, data):\n        qtutils.deserialize(data, self._history)\n\n    def load_items(self, items):\n        if items:\n            self._tab.before_load_started.emit(items[-1].url)\n\n        stream, _data, user_data = tabhistory.serialize(items)\n        qtutils.deserialize_stream(stream, self._history)\n        for i, data in enumerate(user_data):\n            self._history.itemAt(i).setUserData(data)\n        cur_data = self._history.currentItem().userData()\n        if cur_data is not None:\n            if 'zoom' in cur_data:\n                self._tab.zoom.set_factor(cur_data['zoom'])\n            if ('scroll-pos' in cur_data and\n                    self._tab.scroller.pos_px() == QPoint(0, 0)):\n                QTimer.singleShot(0, functools.partial(\n                    self._tab.scroller.to_point, cur_data['scroll-pos']))\n\n\nclass WebKitHistory(browsertab.AbstractHistory):\n\n    \"\"\"QtWebKit implementations related to page history.\"\"\"\n\n    def __init__(self, tab):\n        super().__init__(tab)\n        self.private_api = WebKitHistoryPrivate(tab)\n\n    def __len__(self):\n        return len(self._history)\n\n    def __iter__(self):\n        return iter(self._history.items())\n\n    def current_idx(self):\n        return self._history.currentItemIndex()\n\n    def can_go_back(self):\n        return self._history.canGoBack()\n\n    def can_go_forward(self):\n        return self._history.canGoForward()\n\n    def _item_at(self, i):\n        return self._history.itemAt(i)\n\n    def _go_to_item(self, item):\n        self._tab.before_load_started.emit(item.url())\n        self._history.goToItem(item)\n\n\nclass WebKitElements(browsertab.AbstractElements):\n\n    \"\"\"QtWebKit implemementations related to elements on the page.\"\"\"\n\n    def find_css(self, selector, callback, error_cb, *, only_visible=False):\n        utils.unused(error_cb)\n        mainframe = self._widget.page().mainFrame()\n        if mainframe is None:\n            raise browsertab.WebTabError(\"No frame focused!\")\n\n        elems = []\n        frames = webkitelem.get_child_frames(mainframe)\n        for f in frames:\n            for elem in f.findAllElements(selector):\n                elems.append(webkitelem.WebKitElement(elem, tab=self._tab))\n\n        if only_visible:\n            # pylint: disable=protected-access\n            elems = [e for e in elems if e._is_visible(mainframe)]\n            # pylint: enable=protected-access\n\n        callback(elems)\n\n    def find_id(self, elem_id, callback):\n        def find_id_cb(elems):\n            \"\"\"Call the real callback with the found elements.\"\"\"\n            if not elems:\n                callback(None)\n            else:\n                callback(elems[0])\n\n        # Escape non-alphanumeric characters in the selector\n        # https://www.w3.org/TR/CSS2/syndata.html#value-def-identifier\n        elem_id = re.sub(r'[^a-zA-Z0-9_-]', r'\\\\\\g<0>', elem_id)\n        self.find_css('#' + elem_id, find_id_cb, error_cb=lambda exc: None)\n\n    def find_focused(self, callback):\n        frame = self._widget.page().currentFrame()\n        if frame is None:\n            callback(None)\n            return\n\n        elem = frame.findFirstElement('*:focus')\n        if elem.isNull():\n            callback(None)\n        else:\n            callback(webkitelem.WebKitElement(elem, tab=self._tab))\n\n    def find_at_pos(self, pos, callback):\n        assert pos.x() >= 0\n        assert pos.y() >= 0\n        frame = self._widget.page().frameAt(pos)\n        if frame is None:\n            # This happens when we click inside the webview, but not actually\n            # on the QWebPage - for example when clicking the scrollbar\n            # sometimes.\n            log.webview.debug(\"Hit test at {} but frame is None!\".format(pos))\n            callback(None)\n            return\n\n        # You'd think we have to subtract frame.geometry().topLeft() from the\n        # position, but it seems QWebFrame::hitTestContent wants a position\n        # relative to the QWebView, not to the frame. This makes no sense to\n        # me, but it works this way.\n        hitresult = frame.hitTestContent(pos)\n        if hitresult.isNull():\n            # For some reason, the whole hit result can be null sometimes (e.g.\n            # on doodle menu links).\n            log.webview.debug(\"Hit test result is null!\")\n            callback(None)\n            return\n\n        try:\n            elem = webkitelem.WebKitElement(hitresult.element(), tab=self._tab)\n        except webkitelem.IsNullError:\n            # For some reason, the hit result element can be a null element\n            # sometimes (e.g. when clicking the timetable fields on\n            # http://www.sbb.ch/ ).\n            log.webview.debug(\"Hit test result element is null!\")\n            callback(None)\n            return\n\n        callback(elem)\n\n\nclass WebKitAudio(browsertab.AbstractAudio):\n\n    \"\"\"Dummy handling of audio status for QtWebKit.\"\"\"\n\n    def set_muted(self, muted: bool, override: bool = False) -> None:\n        raise browsertab.WebTabError('Muting is not supported on QtWebKit!')\n\n    def is_muted(self):\n        return False\n\n    def is_recently_audible(self):\n        return False\n\n\nclass WebKitTabPrivate(browsertab.AbstractTabPrivate):\n\n    \"\"\"QtWebKit-related methods which aren't part of the public API.\"\"\"\n\n    def networkaccessmanager(self):\n        return self._widget.page().networkAccessManager()\n\n    def user_agent(self):\n        page = self._widget.page()\n        return page.userAgentForUrl(self._tab.url())\n\n    def clear_ssl_errors(self):\n        self.networkaccessmanager().clear_all_ssl_errors()\n\n    def event_target(self):\n        return self._widget\n\n    def shutdown(self):\n        self._widget.shutdown()\n\n\nclass WebKitTab(browsertab.AbstractTab):\n\n    \"\"\"A QtWebKit tab in the browser.\"\"\"\n\n    def __init__(self, *, win_id, mode_manager, private, parent=None):\n        super().__init__(win_id=win_id, private=private, parent=parent)\n        widget = webview.WebView(win_id=win_id, tab_id=self.tab_id,\n                                 private=private, tab=self)\n        if private:\n            self._make_private(widget)\n        self.history = WebKitHistory(tab=self)\n        self.scroller = WebKitScroller(tab=self, parent=self)\n        self.caret = WebKitCaret(mode_manager=mode_manager,\n                                 tab=self, parent=self)\n        self.zoom = WebKitZoom(tab=self, parent=self)\n        self.search = WebKitSearch(tab=self, parent=self)\n        self.printing = WebKitPrinting(tab=self)\n        self.elements = WebKitElements(tab=self)\n        self.action = WebKitAction(tab=self)\n        self.audio = WebKitAudio(tab=self, parent=self)\n        self.private_api = WebKitTabPrivate(mode_manager=mode_manager,\n                                            tab=self)\n        # We're assigning settings in _set_widget\n        self.settings = webkitsettings.WebKitSettings(settings=None)\n        self._set_widget(widget)\n        self._connect_signals()\n        self.backend = usertypes.Backend.QtWebKit\n\n    def _install_event_filter(self):\n        self._widget.installEventFilter(self._mouse_event_filter)\n\n    def _make_private(self, widget):\n        settings = widget.settings()\n        settings.setAttribute(QWebSettings.PrivateBrowsingEnabled, True)\n\n    def load_url(self, url, *, emit_before_load_started=True):\n        self._load_url_prepare(\n            url, emit_before_load_started=emit_before_load_started)\n        self._widget.load(url)\n\n    def url(self, *, requested=False):\n        frame = self._widget.page().mainFrame()\n        if requested:\n            return frame.requestedUrl()\n        else:\n            return frame.url()\n\n    def dump_async(self, callback, *, plain=False):\n        frame = self._widget.page().mainFrame()\n        if plain:\n            callback(frame.toPlainText())\n        else:\n            callback(frame.toHtml())\n\n    def run_js_async(self, code, callback=None, *, world=None):\n        if world is not None and world != usertypes.JsWorld.jseval:\n            log.webview.warning(\"Ignoring world ID {}\".format(world))\n        document_element = self._widget.page().mainFrame().documentElement()\n        result = document_element.evaluateJavaScript(code)\n        if callback is not None:\n            callback(result)\n\n    def icon(self):\n        return self._widget.icon()\n\n    def reload(self, *, force=False):\n        if force:\n            action = QWebPage.ReloadAndBypassCache\n        else:\n            action = QWebPage.Reload\n        self._widget.triggerPageAction(action)\n\n    def stop(self):\n        self._widget.stop()\n\n    def title(self):\n        return self._widget.title()\n\n    @pyqtSlot()\n    def _on_history_trigger(self):\n        url = self.url()\n        requested_url = self.url(requested=True)\n        self.history_item_triggered.emit(url, requested_url, self.title())\n\n    def set_html(self, html, base_url=QUrl()):\n        self._widget.setHtml(html, base_url)\n\n    @pyqtSlot()\n    def _on_load_started(self):\n        super()._on_load_started()\n        nam = self._widget.page().networkAccessManager()\n        nam.netrc_used = False\n        # Make sure the icon is cleared when navigating to a page without one.\n        self.icon_changed.emit(QIcon())\n\n    @pyqtSlot(bool)\n    def _on_load_finished(self, ok: bool) -> None:\n        super()._on_load_finished(ok)\n        self._update_load_status(ok)\n\n    @pyqtSlot()\n    def _on_frame_load_finished(self):\n        \"\"\"Make sure we emit an appropriate status when loading finished.\n\n        While Qt has a bool \"ok\" attribute for loadFinished, it always is True\n        when using error pages... See\n        https://github.com/qutebrowser/qutebrowser/issues/84\n        \"\"\"\n        self._on_load_finished(not self._widget.page().error_occurred)\n\n    @pyqtSlot()\n    def _on_webkit_icon_changed(self):\n        \"\"\"Emit iconChanged with a QIcon like QWebEngineView does.\"\"\"\n        if sip.isdeleted(self._widget):\n            log.webview.debug(\"Got _on_webkit_icon_changed for deleted view!\")\n            return\n        self.icon_changed.emit(self._widget.icon())\n\n    @pyqtSlot(QWebFrame)\n    def _on_frame_created(self, frame):\n        \"\"\"Connect the contentsSizeChanged signal of each frame.\"\"\"\n        # FIXME:qtwebengine those could theoretically regress:\n        # https://github.com/qutebrowser/qutebrowser/issues/152\n        # https://github.com/qutebrowser/qutebrowser/issues/263\n        frame.contentsSizeChanged.connect(self._on_contents_size_changed)\n\n    @pyqtSlot(QSize)\n    def _on_contents_size_changed(self, size):\n        self.contents_size_changed.emit(QSizeF(size))\n\n    @pyqtSlot(usertypes.NavigationRequest)\n    def _on_navigation_request(self, navigation):\n        super()._on_navigation_request(navigation)\n        if not navigation.accepted:\n            return\n\n        log.webview.debug(\"target {} override {}\".format(\n            self.data.open_target, self.data.override_target))\n\n        if self.data.override_target is not None:\n            target = self.data.override_target\n            self.data.override_target = None\n        else:\n            target = self.data.open_target\n\n        if (navigation.navigation_type == navigation.Type.link_clicked and\n                target != usertypes.ClickTarget.normal):\n            tab = shared.get_tab(self.win_id, target)\n            tab.load_url(navigation.url)\n            self.data.open_target = usertypes.ClickTarget.normal\n            navigation.accepted = False\n\n        if navigation.is_main_frame:\n            self.settings.update_for_url(navigation.url)\n\n    @pyqtSlot()\n    def _on_ssl_errors(self):\n        self._has_ssl_errors = True\n\n    def _connect_signals(self):\n        view = self._widget\n        page = view.page()\n        frame = page.mainFrame()\n        page.windowCloseRequested.connect(self.window_close_requested)\n        page.linkHovered.connect(self.link_hovered)\n        page.loadProgress.connect(self._on_load_progress)\n        frame.loadStarted.connect(self._on_load_started)\n        view.scroll_pos_changed.connect(self.scroller.perc_changed)\n        view.titleChanged.connect(self.title_changed)\n        view.urlChanged.connect(self._on_url_changed)\n        view.shutting_down.connect(self.shutting_down)\n        page.networkAccessManager().sslErrors.connect(self._on_ssl_errors)\n        frame.loadFinished.connect(self._on_frame_load_finished)\n        view.iconChanged.connect(self._on_webkit_icon_changed)\n        page.frameCreated.connect(self._on_frame_created)\n        frame.contentsSizeChanged.connect(self._on_contents_size_changed)\n        frame.initialLayoutCompleted.connect(self._on_history_trigger)\n        page.navigation_request.connect(self._on_navigation_request)\n", "target": 1}
{"idx": 943, "func": "from typing import Union, Optional, Dict, Any, List\n\nimport ujson\nfrom django.http import HttpRequest, HttpResponse\n\nfrom django.utils.translation import ugettext as _\nfrom django.shortcuts import redirect, render\nfrom django.conf import settings\n\nfrom zerver.decorator import require_realm_admin, require_member_or_admin\nfrom zerver.forms import CreateUserForm\nfrom zerver.lib.events import get_raw_user_data\nfrom zerver.lib.actions import do_change_avatar_fields, do_change_bot_owner, \\\n    do_change_is_admin, do_change_default_all_public_streams, \\\n    do_change_default_events_register_stream, do_change_default_sending_stream, \\\n    do_create_user, do_deactivate_user, do_reactivate_user, do_regenerate_api_key, \\\n    check_change_full_name, notify_created_bot, do_update_outgoing_webhook_service, \\\n    do_update_bot_config_data, check_change_bot_full_name, do_change_is_guest, \\\n    do_update_user_custom_profile_data_if_changed, check_remove_custom_profile_field_value\nfrom zerver.lib.avatar import avatar_url, get_gravatar_url\nfrom zerver.lib.bot_config import set_bot_config\nfrom zerver.lib.exceptions import CannotDeactivateLastUserError\nfrom zerver.lib.integrations import EMBEDDED_BOTS\nfrom zerver.lib.request import has_request_variables, REQ\nfrom zerver.lib.response import json_error, json_success\nfrom zerver.lib.storage import static_path\nfrom zerver.lib.streams import access_stream_by_name\nfrom zerver.lib.upload import upload_avatar_image\nfrom zerver.lib.users import get_api_key\nfrom zerver.lib.validator import check_bool, check_string, check_int, check_url, check_dict, check_list\nfrom zerver.lib.users import check_valid_bot_type, check_bot_creation_policy, \\\n    check_full_name, check_short_name, check_valid_interface_type, check_valid_bot_config, \\\n    access_bot_by_id, add_service, access_user_by_id, check_bot_name_available, \\\n    validate_user_custom_profile_data\nfrom zerver.lib.utils import generate_api_key, generate_random_token\nfrom zerver.models import UserProfile, Stream, Message, email_allowed_for_realm, \\\n    get_user_by_delivery_email, Service, get_user_including_cross_realm, \\\n    DomainNotAllowedForRealmError, DisposableEmailError, get_user_profile_by_id_in_realm, \\\n    EmailContainsPlusError, get_user_by_id_in_realm_including_cross_realm, Realm, \\\n    InvalidFakeEmailDomain\n\ndef deactivate_user_backend(request: HttpRequest, user_profile: UserProfile,\n                            user_id: int) -> HttpResponse:\n    target = access_user_by_id(user_profile, user_id)\n    if check_last_admin(target):\n        return json_error(_('Cannot deactivate the only organization administrator'))\n    return _deactivate_user_profile_backend(request, user_profile, target)\n\ndef deactivate_user_own_backend(request: HttpRequest, user_profile: UserProfile) -> HttpResponse:\n    if UserProfile.objects.filter(realm=user_profile.realm, is_active=True).count() == 1:\n        raise CannotDeactivateLastUserError(is_last_admin=False)\n    if user_profile.is_realm_admin and check_last_admin(user_profile):\n        raise CannotDeactivateLastUserError(is_last_admin=True)\n\n    do_deactivate_user(user_profile, acting_user=user_profile)\n    return json_success()\n\ndef check_last_admin(user_profile: UserProfile) -> bool:\n    admins = set(user_profile.realm.get_human_admin_users())\n    return user_profile.is_realm_admin and not user_profile.is_bot and len(admins) == 1\n\ndef deactivate_bot_backend(request: HttpRequest, user_profile: UserProfile,\n                           bot_id: int) -> HttpResponse:\n    target = access_bot_by_id(user_profile, bot_id)\n    return _deactivate_user_profile_backend(request, user_profile, target)\n\ndef _deactivate_user_profile_backend(request: HttpRequest, user_profile: UserProfile,\n                                     target: UserProfile) -> HttpResponse:\n    do_deactivate_user(target, acting_user=user_profile)\n    return json_success()\n\ndef reactivate_user_backend(request: HttpRequest, user_profile: UserProfile,\n                            user_id: int) -> HttpResponse:\n    target = access_user_by_id(user_profile, user_id, allow_deactivated=True, allow_bots=True)\n    if target.is_bot:\n        assert target.bot_type is not None\n        check_bot_creation_policy(user_profile, target.bot_type)\n    do_reactivate_user(target, acting_user=user_profile)\n    return json_success()\n\n@has_request_variables\ndef update_user_backend(request: HttpRequest, user_profile: UserProfile, user_id: int,\n                        full_name: Optional[str]=REQ(default=\"\", validator=check_string),\n                        is_admin: Optional[bool]=REQ(default=None, validator=check_bool),\n                        is_guest: Optional[bool]=REQ(default=None, validator=check_bool),\n                        profile_data: Optional[List[Dict[str, Union[int, str, List[int]]]]]=\n                        REQ(default=None,\n                            validator=check_list(check_dict([('id', check_int)])))) -> HttpResponse:\n    target = access_user_by_id(user_profile, user_id, allow_deactivated=True, allow_bots=True)\n\n    # Historically, UserProfile had two fields, is_guest and is_realm_admin.\n    # This condition protected against situations where update_user_backend\n    # could cause both is_guest and is_realm_admin to be set.\n    # Once we update the frontend to just send a 'role' value, we can remove this check.\n    if (((is_guest is None and target.is_guest) or is_guest) and\n            ((is_admin is None and target.is_realm_admin) or is_admin)):\n        return json_error(_(\"Guests cannot be organization administrators\"))\n\n    if is_admin is not None and target.is_realm_admin != is_admin:\n        if not is_admin and check_last_admin(user_profile):\n            return json_error(_('Cannot remove the only organization administrator'))\n        do_change_is_admin(target, is_admin)\n\n    if is_guest is not None and target.is_guest != is_guest:\n        do_change_is_guest(target, is_guest)\n\n    if (full_name is not None and target.full_name != full_name and\n            full_name.strip() != \"\"):\n        # We don't respect `name_changes_disabled` here because the request\n        # is on behalf of the administrator.\n        check_change_full_name(target, full_name, user_profile)\n\n    if profile_data is not None:\n        clean_profile_data = []\n        for entry in profile_data:\n            if not entry[\"value\"]:\n                field_id = entry[\"id\"]\n                check_remove_custom_profile_field_value(target, field_id)\n            else:\n                clean_profile_data.append(entry)\n        validate_user_custom_profile_data(target.realm.id, clean_profile_data)\n        do_update_user_custom_profile_data_if_changed(target, clean_profile_data)\n\n    return json_success()\n\ndef avatar(request: HttpRequest, user_profile: UserProfile,\n           email_or_id: str, medium: bool=False) -> HttpResponse:\n    \"\"\"Accepts an email address or user ID and returns the avatar\"\"\"\n    is_email = False\n    try:\n        int(email_or_id)\n    except ValueError:\n        is_email = True\n\n    try:\n        realm = user_profile.realm\n        if is_email:\n            avatar_user_profile = get_user_including_cross_realm(email_or_id, realm)\n        else:\n            avatar_user_profile = get_user_by_id_in_realm_including_cross_realm(int(email_or_id), realm)\n        # If there is a valid user account passed in, use its avatar\n        url = avatar_url(avatar_user_profile, medium=medium)\n    except UserProfile.DoesNotExist:\n        # If there is no such user, treat it as a new gravatar\n        email = email_or_id\n        avatar_version = 1\n        url = get_gravatar_url(email, avatar_version, medium)\n\n    # We can rely on the url already having query parameters. Because\n    # our templates depend on being able to use the ampersand to\n    # add query parameters to our url, get_avatar_url does '?x=x'\n    # hacks to prevent us from having to jump through decode/encode hoops.\n    assert url is not None\n    assert '?' in url\n    url += '&' + request.META['QUERY_STRING']\n    return redirect(url)\n\ndef get_stream_name(stream: Optional[Stream]) -> Optional[str]:\n    if stream:\n        return stream.name\n    return None\n\n@require_member_or_admin\n@has_request_variables\ndef patch_bot_backend(\n        request: HttpRequest, user_profile: UserProfile, bot_id: int,\n        full_name: Optional[str]=REQ(default=None),\n        bot_owner_id: Optional[int]=REQ(validator=check_int, default=None),\n        config_data: Optional[Dict[str, str]]=REQ(default=None,\n                                                  validator=check_dict(value_validator=check_string)),\n        service_payload_url: Optional[str]=REQ(validator=check_url, default=None),\n        service_interface: Optional[int]=REQ(validator=check_int, default=1),\n        default_sending_stream: Optional[str]=REQ(default=None),\n        default_events_register_stream: Optional[str]=REQ(default=None),\n        default_all_public_streams: Optional[bool]=REQ(default=None, validator=check_bool)\n) -> HttpResponse:\n    bot = access_bot_by_id(user_profile, bot_id)\n\n    if full_name is not None:\n        check_change_bot_full_name(bot, full_name, user_profile)\n    if bot_owner_id is not None:\n        try:\n            owner = get_user_profile_by_id_in_realm(bot_owner_id, user_profile.realm)\n        except UserProfile.DoesNotExist:\n            return json_error(_('Failed to change owner, no such user'))\n        if not owner.is_active:\n            return json_error(_('Failed to change owner, user is deactivated'))\n        if owner.is_bot:\n            return json_error(_(\"Failed to change owner, bots can't own other bots\"))\n\n        previous_owner = bot.bot_owner\n        if previous_owner != owner:\n            do_change_bot_owner(bot, owner, user_profile)\n\n    if default_sending_stream is not None:\n        if default_sending_stream == \"\":\n            stream = None  # type: Optional[Stream]\n        else:\n            (stream, recipient, sub) = access_stream_by_name(\n                user_profile, default_sending_stream)\n        do_change_default_sending_stream(bot, stream)\n    if default_events_register_stream is not None:\n        if default_events_register_stream == \"\":\n            stream = None\n        else:\n            (stream, recipient, sub) = access_stream_by_name(\n                user_profile, default_events_register_stream)\n        do_change_default_events_register_stream(bot, stream)\n    if default_all_public_streams is not None:\n        do_change_default_all_public_streams(bot, default_all_public_streams)\n\n    if service_payload_url is not None:\n        check_valid_interface_type(service_interface)\n        assert service_interface is not None\n        do_update_outgoing_webhook_service(bot, service_interface, service_payload_url)\n\n    if config_data is not None:\n        do_update_bot_config_data(bot, config_data)\n\n    if len(request.FILES) == 0:\n        pass\n    elif len(request.FILES) == 1:\n        user_file = list(request.FILES.values())[0]\n        upload_avatar_image(user_file, user_profile, bot)\n        avatar_source = UserProfile.AVATAR_FROM_USER\n        do_change_avatar_fields(bot, avatar_source)\n    else:\n        return json_error(_(\"You may only upload one file at a time\"))\n\n    json_result = dict(\n        full_name=bot.full_name,\n        avatar_url=avatar_url(bot),\n        service_interface = service_interface,\n        service_payload_url = service_payload_url,\n        config_data = config_data,\n        default_sending_stream=get_stream_name(bot.default_sending_stream),\n        default_events_register_stream=get_stream_name(bot.default_events_register_stream),\n        default_all_public_streams=bot.default_all_public_streams,\n    )\n\n    # Don't include the bot owner in case it is not set.\n    # Default bots have no owner.\n    if bot.bot_owner is not None:\n        json_result['bot_owner'] = bot.bot_owner.email\n\n    return json_success(json_result)\n\n@require_member_or_admin\n@has_request_variables\ndef regenerate_bot_api_key(request: HttpRequest, user_profile: UserProfile, bot_id: int) -> HttpResponse:\n    bot = access_bot_by_id(user_profile, bot_id)\n\n    new_api_key = do_regenerate_api_key(bot, user_profile)\n    json_result = dict(\n        api_key=new_api_key\n    )\n    return json_success(json_result)\n\n@require_member_or_admin\n@has_request_variables\ndef add_bot_backend(\n        request: HttpRequest, user_profile: UserProfile,\n        full_name_raw: str=REQ(\"full_name\"), short_name_raw: str=REQ(\"short_name\"),\n        bot_type: int=REQ(validator=check_int, default=UserProfile.DEFAULT_BOT),\n        payload_url: Optional[str]=REQ(validator=check_url, default=\"\"),\n        service_name: Optional[str]=REQ(default=None),\n        config_data: Dict[str, str]=REQ(default={},\n                                        validator=check_dict(value_validator=check_string)),\n        interface_type: int=REQ(validator=check_int, default=Service.GENERIC),\n        default_sending_stream_name: Optional[str]=REQ('default_sending_stream', default=None),\n        default_events_register_stream_name: Optional[str]=REQ('default_events_register_stream',\n                                                               default=None),\n        default_all_public_streams: Optional[bool]=REQ(validator=check_bool, default=None)\n) -> HttpResponse:\n    short_name = check_short_name(short_name_raw)\n    if bot_type != UserProfile.INCOMING_WEBHOOK_BOT:\n        service_name = service_name or short_name\n    short_name += \"-bot\"\n    full_name = check_full_name(full_name_raw)\n    try:\n        email = '%s@%s' % (short_name, user_profile.realm.get_bot_domain())\n    except InvalidFakeEmailDomain:\n        return json_error(_(\"Can't create bots until FAKE_EMAIL_DOMAIN is correctly configured.\\n\"\n                            \"Please contact your server administrator.\"))\n    form = CreateUserForm({'full_name': full_name, 'email': email})\n\n    if bot_type == UserProfile.EMBEDDED_BOT:\n        if not settings.EMBEDDED_BOTS_ENABLED:\n            return json_error(_(\"Embedded bots are not enabled.\"))\n        if service_name not in [bot.name for bot in EMBEDDED_BOTS]:\n            return json_error(_(\"Invalid embedded bot name.\"))\n\n    if not form.is_valid():\n        # We validate client-side as well\n        return json_error(_('Bad name or username'))\n    try:\n        get_user_by_delivery_email(email, user_profile.realm)\n        return json_error(_(\"Username already in use\"))\n    except UserProfile.DoesNotExist:\n        pass\n\n    check_bot_name_available(\n        realm_id=user_profile.realm_id,\n        full_name=full_name,\n    )\n\n    check_bot_creation_policy(user_profile, bot_type)\n    check_valid_bot_type(user_profile, bot_type)\n    check_valid_interface_type(interface_type)\n\n    if len(request.FILES) == 0:\n        avatar_source = UserProfile.AVATAR_FROM_GRAVATAR\n    elif len(request.FILES) != 1:\n        return json_error(_(\"You may only upload one file at a time\"))\n    else:\n        avatar_source = UserProfile.AVATAR_FROM_USER\n\n    default_sending_stream = None\n    if default_sending_stream_name is not None:\n        (default_sending_stream, ignored_rec, ignored_sub) = access_stream_by_name(\n            user_profile, default_sending_stream_name)\n\n    default_events_register_stream = None\n    if default_events_register_stream_name is not None:\n        (default_events_register_stream, ignored_rec, ignored_sub) = access_stream_by_name(\n            user_profile, default_events_register_stream_name)\n\n    if bot_type in (UserProfile.INCOMING_WEBHOOK_BOT, UserProfile.EMBEDDED_BOT) and service_name:\n        check_valid_bot_config(bot_type, service_name, config_data)\n\n    bot_profile = do_create_user(email=email, password=None,\n                                 realm=user_profile.realm, full_name=full_name,\n                                 short_name=short_name,\n                                 bot_type=bot_type,\n                                 bot_owner=user_profile,\n                                 avatar_source=avatar_source,\n                                 default_sending_stream=default_sending_stream,\n                                 default_events_register_stream=default_events_register_stream,\n                                 default_all_public_streams=default_all_public_streams)\n    if len(request.FILES) == 1:\n        user_file = list(request.FILES.values())[0]\n        upload_avatar_image(user_file, user_profile, bot_profile)\n\n    if bot_type in (UserProfile.OUTGOING_WEBHOOK_BOT, UserProfile.EMBEDDED_BOT):\n        assert(isinstance(service_name, str))\n        add_service(name=service_name,\n                    user_profile=bot_profile,\n                    base_url=payload_url,\n                    interface=interface_type,\n                    token=generate_api_key())\n\n    if bot_type == UserProfile.INCOMING_WEBHOOK_BOT and service_name:\n        set_bot_config(bot_profile, \"integration_id\", service_name)\n\n    if bot_type in (UserProfile.INCOMING_WEBHOOK_BOT, UserProfile.EMBEDDED_BOT):\n        for key, value in config_data.items():\n            set_bot_config(bot_profile, key, value)\n\n    notify_created_bot(bot_profile)\n\n    api_key = get_api_key(bot_profile)\n\n    json_result = dict(\n        api_key=api_key,\n        avatar_url=avatar_url(bot_profile),\n        default_sending_stream=get_stream_name(bot_profile.default_sending_stream),\n        default_events_register_stream=get_stream_name(bot_profile.default_events_register_stream),\n        default_all_public_streams=bot_profile.default_all_public_streams,\n    )\n    return json_success(json_result)\n\n@require_member_or_admin\ndef get_bots_backend(request: HttpRequest, user_profile: UserProfile) -> HttpResponse:\n    bot_profiles = UserProfile.objects.filter(is_bot=True, is_active=True,\n                                              bot_owner=user_profile)\n    bot_profiles = bot_profiles.select_related('default_sending_stream', 'default_events_register_stream')\n    bot_profiles = bot_profiles.order_by('date_joined')\n\n    def bot_info(bot_profile: UserProfile) -> Dict[str, Any]:\n        default_sending_stream = get_stream_name(bot_profile.default_sending_stream)\n        default_events_register_stream = get_stream_name(bot_profile.default_events_register_stream)\n\n        # Bots are supposed to have only one API key, at least for now.\n        # Therefore we can safely asume that one and only valid API key will be\n        # the first one.\n        api_key = get_api_key(bot_profile)\n\n        return dict(\n            username=bot_profile.email,\n            full_name=bot_profile.full_name,\n            api_key=api_key,\n            avatar_url=avatar_url(bot_profile),\n            default_sending_stream=default_sending_stream,\n            default_events_register_stream=default_events_register_stream,\n            default_all_public_streams=bot_profile.default_all_public_streams,\n        )\n\n    return json_success({'bots': list(map(bot_info, bot_profiles))})\n\n@has_request_variables\ndef get_members_backend(request: HttpRequest, user_profile: UserProfile,\n                        include_custom_profile_fields: bool=REQ(validator=check_bool,\n                                                                default=False),\n                        client_gravatar: bool=REQ(validator=check_bool, default=False)\n                        ) -> HttpResponse:\n    '''\n    The client_gravatar field here is set to True if clients can compute\n    their own gravatars, which saves us bandwidth.  We want to eventually\n    make this the default behavior, but we have old clients that expect\n    the server to compute this for us.\n    '''\n    realm = user_profile.realm\n    if realm.email_address_visibility == Realm.EMAIL_ADDRESS_VISIBILITY_ADMINS:\n        # If email addresses are only available to administrators,\n        # clients cannot compute gravatars, so we force-set it to false.\n        client_gravatar = False\n    members = get_raw_user_data(realm,\n                                user_profile=user_profile,\n                                client_gravatar=client_gravatar,\n                                include_custom_profile_fields=include_custom_profile_fields)\n    return json_success({'members': members.values()})\n\n@require_realm_admin\n@has_request_variables\ndef create_user_backend(request: HttpRequest, user_profile: UserProfile,\n                        email: str=REQ(), password: str=REQ(), full_name_raw: str=REQ(\"full_name\"),\n                        short_name: str=REQ()) -> HttpResponse:\n    full_name = check_full_name(full_name_raw)\n    form = CreateUserForm({'full_name': full_name, 'email': email})\n    if not form.is_valid():\n        return json_error(_('Bad name or username'))\n\n    # Check that the new user's email address belongs to the admin's realm\n    # (Since this is an admin API, we don't require the user to have been\n    # invited first.)\n    realm = user_profile.realm\n    try:\n        email_allowed_for_realm(email, user_profile.realm)\n    except DomainNotAllowedForRealmError:\n        return json_error(_(\"Email '%(email)s' not allowed in this organization\") %\n                          {'email': email})\n    except DisposableEmailError:\n        return json_error(_(\"Disposable email addresses are not allowed in this organization\"))\n    except EmailContainsPlusError:\n        return json_error(_(\"Email addresses containing + are not allowed.\"))\n\n    try:\n        get_user_by_delivery_email(email, user_profile.realm)\n        return json_error(_(\"Email '%s' already in use\") % (email,))\n    except UserProfile.DoesNotExist:\n        pass\n\n    do_create_user(email, password, realm, full_name, short_name)\n    return json_success()\n\ndef generate_client_id() -> str:\n    return generate_random_token(32)\n\ndef get_profile_backend(request: HttpRequest, user_profile: UserProfile) -> HttpResponse:\n    result = dict(pointer        = user_profile.pointer,\n                  client_id      = generate_client_id(),\n                  max_message_id = -1,\n                  user_id        = user_profile.id,\n                  avatar_url     = avatar_url(user_profile),\n                  full_name      = user_profile.full_name,\n                  email          = user_profile.email,\n                  is_bot         = user_profile.is_bot,\n                  is_admin       = user_profile.is_realm_admin,\n                  short_name     = user_profile.short_name)\n\n    if not user_profile.is_bot:\n        custom_profile_field_values = user_profile.customprofilefieldvalue_set.all()\n        profile_data = dict()  # type: Dict[int, Dict[str, Any]]\n        for profile_field in custom_profile_field_values:\n            if profile_field.field.is_renderable():\n                profile_data[profile_field.field_id] = {\n                    \"value\": profile_field.value,\n                    \"rendered_value\": profile_field.rendered_value\n                }\n            else:\n                profile_data[profile_field.field_id] = {\n                    \"value\": profile_field.value\n                }\n        result[\"profile_data\"] = profile_data\n\n    messages = Message.objects.filter(usermessage__user_profile=user_profile).order_by('-id')[:1]\n    if messages:\n        result['max_message_id'] = messages[0].id\n\n    return json_success(result)\n\ndef team_view(request: HttpRequest) -> HttpResponse:\n    with open(static_path('generated/github-contributors.json')) as f:\n        data = ujson.load(f)\n\n    return render(\n        request,\n        'zerver/team.html',\n        context={\n            'page_params': {\n                'contrib': data['contrib'],\n            },\n            'date': data['date'],\n        },\n    )\n", "target": 0}
{"idx": 944, "func": "# Copyright 2011 OpenStack LLC.\n# Copyright 2012 Justin Santa Barbara\n# All Rights Reserved.\n#\n#    Licensed under the Apache License, Version 2.0 (the \"License\"); you may\n#    not use this file except in compliance with the License. You may obtain\n#    a copy of the License at\n#\n#         http://www.apache.org/licenses/LICENSE-2.0\n#\n#    Unless required by applicable law or agreed to in writing, software\n#    distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n#    License for the specific language governing permissions and limitations\n#    under the License.\n\n\"\"\"The security groups extension.\"\"\"\n\nimport urllib\nfrom xml.dom import minidom\n\nfrom webob import exc\nimport webob\n\nfrom nova.api.openstack import common\nfrom nova.api.openstack import extensions\nfrom nova.api.openstack import wsgi\nfrom nova.api.openstack import xmlutil\nfrom nova import compute\nfrom nova import db\nfrom nova import exception\nfrom nova import flags\nfrom nova import log as logging\nfrom nova import utils\n\n\nLOG = logging.getLogger(__name__)\nFLAGS = flags.FLAGS\nauthorize = extensions.extension_authorizer('compute', 'security_groups')\n\n\ndef make_rule(elem):\n    elem.set('id')\n    elem.set('parent_group_id')\n\n    proto = xmlutil.SubTemplateElement(elem, 'ip_protocol')\n    proto.text = 'ip_protocol'\n\n    from_port = xmlutil.SubTemplateElement(elem, 'from_port')\n    from_port.text = 'from_port'\n\n    to_port = xmlutil.SubTemplateElement(elem, 'to_port')\n    to_port.text = 'to_port'\n\n    group = xmlutil.SubTemplateElement(elem, 'group', selector='group')\n    name = xmlutil.SubTemplateElement(group, 'name')\n    name.text = 'name'\n    tenant_id = xmlutil.SubTemplateElement(group, 'tenant_id')\n    tenant_id.text = 'tenant_id'\n\n    ip_range = xmlutil.SubTemplateElement(elem, 'ip_range',\n                                          selector='ip_range')\n    cidr = xmlutil.SubTemplateElement(ip_range, 'cidr')\n    cidr.text = 'cidr'\n\n\ndef make_sg(elem):\n    elem.set('id')\n    elem.set('tenant_id')\n    elem.set('name')\n\n    desc = xmlutil.SubTemplateElement(elem, 'description')\n    desc.text = 'description'\n\n    rules = xmlutil.SubTemplateElement(elem, 'rules')\n    rule = xmlutil.SubTemplateElement(rules, 'rule', selector='rules')\n    make_rule(rule)\n\n\nsg_nsmap = {None: wsgi.XMLNS_V11}\n\n\nclass SecurityGroupRuleTemplate(xmlutil.TemplateBuilder):\n    def construct(self):\n        root = xmlutil.TemplateElement('security_group_rule',\n                                       selector='security_group_rule')\n        make_rule(root)\n        return xmlutil.MasterTemplate(root, 1, nsmap=sg_nsmap)\n\n\nclass SecurityGroupTemplate(xmlutil.TemplateBuilder):\n    def construct(self):\n        root = xmlutil.TemplateElement('security_group',\n                                       selector='security_group')\n        make_sg(root)\n        return xmlutil.MasterTemplate(root, 1, nsmap=sg_nsmap)\n\n\nclass SecurityGroupsTemplate(xmlutil.TemplateBuilder):\n    def construct(self):\n        root = xmlutil.TemplateElement('security_groups')\n        elem = xmlutil.SubTemplateElement(root, 'security_group',\n                                          selector='security_groups')\n        make_sg(elem)\n        return xmlutil.MasterTemplate(root, 1, nsmap=sg_nsmap)\n\n\nclass SecurityGroupXMLDeserializer(wsgi.MetadataXMLDeserializer):\n    \"\"\"\n    Deserializer to handle xml-formatted security group requests.\n    \"\"\"\n    def default(self, string):\n        \"\"\"Deserialize an xml-formatted security group create request\"\"\"\n        dom = minidom.parseString(string)\n        security_group = {}\n        sg_node = self.find_first_child_named(dom,\n                                               'security_group')\n        if sg_node is not None:\n            if sg_node.hasAttribute('name'):\n                security_group['name'] = sg_node.getAttribute('name')\n            desc_node = self.find_first_child_named(sg_node,\n                                                     \"description\")\n            if desc_node:\n                security_group['description'] = self.extract_text(desc_node)\n        return {'body': {'security_group': security_group}}\n\n\nclass SecurityGroupRulesXMLDeserializer(wsgi.MetadataXMLDeserializer):\n    \"\"\"\n    Deserializer to handle xml-formatted security group requests.\n    \"\"\"\n\n    def default(self, string):\n        \"\"\"Deserialize an xml-formatted security group create request\"\"\"\n        dom = minidom.parseString(string)\n        security_group_rule = self._extract_security_group_rule(dom)\n        return {'body': {'security_group_rule': security_group_rule}}\n\n    def _extract_security_group_rule(self, node):\n        \"\"\"Marshal the security group rule attribute of a parsed request\"\"\"\n        sg_rule = {}\n        sg_rule_node = self.find_first_child_named(node,\n                                                   'security_group_rule')\n        if sg_rule_node is not None:\n            ip_protocol_node = self.find_first_child_named(sg_rule_node,\n                                                           \"ip_protocol\")\n            if ip_protocol_node is not None:\n                sg_rule['ip_protocol'] = self.extract_text(ip_protocol_node)\n\n            from_port_node = self.find_first_child_named(sg_rule_node,\n                                                         \"from_port\")\n            if from_port_node is not None:\n                sg_rule['from_port'] = self.extract_text(from_port_node)\n\n            to_port_node = self.find_first_child_named(sg_rule_node, \"to_port\")\n            if to_port_node is not None:\n                sg_rule['to_port'] = self.extract_text(to_port_node)\n\n            parent_group_id_node = self.find_first_child_named(sg_rule_node,\n                                                            \"parent_group_id\")\n            if parent_group_id_node is not None:\n                sg_rule['parent_group_id'] = self.extract_text(\n                                                         parent_group_id_node)\n\n            group_id_node = self.find_first_child_named(sg_rule_node,\n                                                        \"group_id\")\n            if group_id_node is not None:\n                sg_rule['group_id'] = self.extract_text(group_id_node)\n\n            cidr_node = self.find_first_child_named(sg_rule_node, \"cidr\")\n            if cidr_node is not None:\n                sg_rule['cidr'] = self.extract_text(cidr_node)\n\n        return sg_rule\n\n\nclass SecurityGroupControllerBase(object):\n    \"\"\"Base class for Security Group controllers.\"\"\"\n\n    def __init__(self):\n        self.compute_api = compute.API()\n        self.sgh = utils.import_object(FLAGS.security_group_handler)\n\n    def _format_security_group_rule(self, context, rule):\n        sg_rule = {}\n        sg_rule['id'] = rule.id\n        sg_rule['parent_group_id'] = rule.parent_group_id\n        sg_rule['ip_protocol'] = rule.protocol\n        sg_rule['from_port'] = rule.from_port\n        sg_rule['to_port'] = rule.to_port\n        sg_rule['group'] = {}\n        sg_rule['ip_range'] = {}\n        if rule.group_id:\n            source_group = db.security_group_get(context, rule.group_id)\n            sg_rule['group'] = {'name': source_group.name,\n                             'tenant_id': source_group.project_id}\n        else:\n            sg_rule['ip_range'] = {'cidr': rule.cidr}\n        return sg_rule\n\n    def _format_security_group(self, context, group):\n        security_group = {}\n        security_group['id'] = group.id\n        security_group['description'] = group.description\n        security_group['name'] = group.name\n        security_group['tenant_id'] = group.project_id\n        security_group['rules'] = []\n        for rule in group.rules:\n            security_group['rules'] += [self._format_security_group_rule(\n                    context, rule)]\n        return security_group\n\n\nclass SecurityGroupController(SecurityGroupControllerBase):\n    \"\"\"The Security group API controller for the OpenStack API.\"\"\"\n\n    def _get_security_group(self, context, id):\n        try:\n            id = int(id)\n            security_group = db.security_group_get(context, id)\n        except ValueError:\n            msg = _(\"Security group id should be integer\")\n            raise exc.HTTPBadRequest(explanation=msg)\n        except exception.NotFound as exp:\n            raise exc.HTTPNotFound(explanation=unicode(exp))\n        return security_group\n\n    @wsgi.serializers(xml=SecurityGroupTemplate)\n    def show(self, req, id):\n        \"\"\"Return data about the given security group.\"\"\"\n        context = req.environ['nova.context']\n        authorize(context)\n        security_group = self._get_security_group(context, id)\n        return {'security_group': self._format_security_group(context,\n                                                              security_group)}\n\n    def delete(self, req, id):\n        \"\"\"Delete a security group.\"\"\"\n        context = req.environ['nova.context']\n        authorize(context)\n        security_group = self._get_security_group(context, id)\n        if db.security_group_in_use(context, security_group.id):\n            msg = _(\"Security group is still in use\")\n            raise exc.HTTPBadRequest(explanation=msg)\n        LOG.audit(_(\"Delete security group %s\"), id, context=context)\n        db.security_group_destroy(context, security_group.id)\n        self.sgh.trigger_security_group_destroy_refresh(\n            context, security_group.id)\n\n        return webob.Response(status_int=202)\n\n    @wsgi.serializers(xml=SecurityGroupsTemplate)\n    def index(self, req):\n        \"\"\"Returns a list of security groups\"\"\"\n        context = req.environ['nova.context']\n        authorize(context)\n\n        self.compute_api.ensure_default_security_group(context)\n        groups = db.security_group_get_by_project(context,\n                                                  context.project_id)\n        limited_list = common.limited(groups, req)\n        result = [self._format_security_group(context, group)\n                     for group in limited_list]\n\n        return {'security_groups':\n                list(sorted(result,\n                            key=lambda k: (k['tenant_id'], k['name'])))}\n\n    @wsgi.serializers(xml=SecurityGroupTemplate)\n    @wsgi.deserializers(xml=SecurityGroupXMLDeserializer)\n    def create(self, req, body):\n        \"\"\"Creates a new security group.\"\"\"\n        context = req.environ['nova.context']\n        authorize(context)\n        if not body:\n            raise exc.HTTPUnprocessableEntity()\n\n        security_group = body.get('security_group', None)\n\n        if security_group is None:\n            raise exc.HTTPUnprocessableEntity()\n\n        group_name = security_group.get('name', None)\n        group_description = security_group.get('description', None)\n\n        self._validate_security_group_property(group_name, \"name\")\n        self._validate_security_group_property(group_description,\n                                               \"description\")\n        group_name = group_name.strip()\n        group_description = group_description.strip()\n\n        LOG.audit(_(\"Create Security Group %s\"), group_name, context=context)\n        self.compute_api.ensure_default_security_group(context)\n        if db.security_group_exists(context, context.project_id, group_name):\n            msg = _('Security group %s already exists') % group_name\n            raise exc.HTTPBadRequest(explanation=msg)\n\n        group = {'user_id': context.user_id,\n                 'project_id': context.project_id,\n                 'name': group_name,\n                 'description': group_description}\n        group_ref = db.security_group_create(context, group)\n        self.sgh.trigger_security_group_create_refresh(context, group)\n\n        return {'security_group': self._format_security_group(context,\n                                                                 group_ref)}\n\n    def _validate_security_group_property(self, value, typ):\n        \"\"\" typ will be either 'name' or 'description',\n            depending on the caller\n        \"\"\"\n        try:\n            val = value.strip()\n        except AttributeError:\n            msg = _(\"Security group %s is not a string or unicode\") % typ\n            raise exc.HTTPBadRequest(explanation=msg)\n        if not val:\n            msg = _(\"Security group %s cannot be empty.\") % typ\n            raise exc.HTTPBadRequest(explanation=msg)\n        if len(val) > 255:\n            msg = _(\"Security group %s should not be greater \"\n                            \"than 255 characters.\") % typ\n            raise exc.HTTPBadRequest(explanation=msg)\n\n\nclass SecurityGroupRulesController(SecurityGroupControllerBase):\n\n    @wsgi.serializers(xml=SecurityGroupRuleTemplate)\n    @wsgi.deserializers(xml=SecurityGroupRulesXMLDeserializer)\n    def create(self, req, body):\n        context = req.environ['nova.context']\n        authorize(context)\n\n        if not body:\n            raise exc.HTTPUnprocessableEntity()\n\n        if not 'security_group_rule' in body:\n            raise exc.HTTPUnprocessableEntity()\n\n        self.compute_api.ensure_default_security_group(context)\n\n        sg_rule = body['security_group_rule']\n        parent_group_id = sg_rule.get('parent_group_id', None)\n        try:\n            parent_group_id = int(parent_group_id)\n            security_group = db.security_group_get(context, parent_group_id)\n        except ValueError:\n            msg = _(\"Parent group id is not integer\")\n            raise exc.HTTPBadRequest(explanation=msg)\n        except exception.NotFound as exp:\n            msg = _(\"Security group (%s) not found\") % parent_group_id\n            raise exc.HTTPNotFound(explanation=msg)\n\n        msg = _(\"Authorize security group ingress %s\")\n        LOG.audit(msg, security_group['name'], context=context)\n\n        try:\n            values = self._rule_args_to_dict(context,\n                              to_port=sg_rule.get('to_port'),\n                              from_port=sg_rule.get('from_port'),\n                              parent_group_id=sg_rule.get('parent_group_id'),\n                              ip_protocol=sg_rule.get('ip_protocol'),\n                              cidr=sg_rule.get('cidr'),\n                              group_id=sg_rule.get('group_id'))\n        except Exception as exp:\n            raise exc.HTTPBadRequest(explanation=unicode(exp))\n\n        if values is None:\n            msg = _(\"Not enough parameters to build a \"\n                                       \"valid rule.\")\n            raise exc.HTTPBadRequest(explanation=msg)\n\n        values['parent_group_id'] = security_group.id\n\n        if self._security_group_rule_exists(security_group, values):\n            msg = _('This rule already exists in group %s') % parent_group_id\n            raise exc.HTTPBadRequest(explanation=msg)\n\n        security_group_rule = db.security_group_rule_create(context, values)\n        self.sgh.trigger_security_group_rule_create_refresh(\n            context, [security_group_rule['id']])\n        self.compute_api.trigger_security_group_rules_refresh(context,\n                                    security_group_id=security_group['id'])\n\n        return {\"security_group_rule\": self._format_security_group_rule(\n                                                        context,\n                                                        security_group_rule)}\n\n    def _security_group_rule_exists(self, security_group, values):\n        \"\"\"Indicates whether the specified rule values are already\n           defined in the given security group.\n        \"\"\"\n        for rule in security_group.rules:\n            is_duplicate = True\n            keys = ('group_id', 'cidr', 'from_port', 'to_port', 'protocol')\n            for key in keys:\n                if rule.get(key) != values.get(key):\n                    is_duplicate = False\n                    break\n            if is_duplicate:\n                return True\n        return False\n\n    def _rule_args_to_dict(self, context, to_port=None, from_port=None,\n                                  parent_group_id=None, ip_protocol=None,\n                                  cidr=None, group_id=None):\n        values = {}\n\n        if group_id is not None:\n            try:\n                parent_group_id = int(parent_group_id)\n                group_id = int(group_id)\n            except ValueError:\n                msg = _(\"Parent or group id is not integer\")\n                raise exception.InvalidInput(reason=msg)\n\n            values['group_id'] = group_id\n            #check if groupId exists\n            db.security_group_get(context, group_id)\n        elif cidr:\n            # If this fails, it throws an exception. This is what we want.\n            try:\n                cidr = urllib.unquote(cidr).decode()\n            except Exception:\n                raise exception.InvalidCidr(cidr=cidr)\n\n            if not utils.is_valid_cidr(cidr):\n                # Raise exception for non-valid address\n                raise exception.InvalidCidr(cidr=cidr)\n\n            values['cidr'] = cidr\n        else:\n            values['cidr'] = '0.0.0.0/0'\n\n        if group_id:\n            # Open everything if an explicit port range or type/code are not\n            # specified, but only if a source group was specified.\n            ip_proto_upper = ip_protocol.upper() if ip_protocol else ''\n            if (ip_proto_upper == 'ICMP' and\n                from_port is None and to_port is None):\n                from_port = -1\n                to_port = -1\n            elif (ip_proto_upper in ['TCP', 'UDP'] and from_port is None\n                  and to_port is None):\n                from_port = 1\n                to_port = 65535\n\n        if ip_protocol and from_port is not None and to_port is not None:\n\n            ip_protocol = str(ip_protocol)\n            try:\n                from_port = int(from_port)\n                to_port = int(to_port)\n            except ValueError:\n                if ip_protocol.upper() == 'ICMP':\n                    raise exception.InvalidInput(reason=\"Type and\"\n                         \" Code must be integers for ICMP protocol type\")\n                else:\n                    raise exception.InvalidInput(reason=\"To and From ports \"\n                          \"must be integers\")\n\n            if ip_protocol.upper() not in ['TCP', 'UDP', 'ICMP']:\n                raise exception.InvalidIpProtocol(protocol=ip_protocol)\n\n            # Verify that from_port must always be less than\n            # or equal to to_port\n            if (ip_protocol.upper() in ['TCP', 'UDP'] and\n                from_port > to_port):\n                raise exception.InvalidPortRange(from_port=from_port,\n                      to_port=to_port, msg=\"Former value cannot\"\n                                            \" be greater than the later\")\n\n            # Verify valid TCP, UDP port ranges\n            if (ip_protocol.upper() in ['TCP', 'UDP'] and\n                (from_port < 1 or to_port > 65535)):\n                raise exception.InvalidPortRange(from_port=from_port,\n                      to_port=to_port, msg=\"Valid TCP ports should\"\n                                           \" be between 1-65535\")\n\n            # Verify ICMP type and code\n            if (ip_protocol.upper() == \"ICMP\" and\n                (from_port < -1 or from_port > 255 or\n                to_port < -1 or to_port > 255)):\n                raise exception.InvalidPortRange(from_port=from_port,\n                      to_port=to_port, msg=\"For ICMP, the\"\n                                           \" type:code must be valid\")\n\n            values['protocol'] = ip_protocol\n            values['from_port'] = from_port\n            values['to_port'] = to_port\n        else:\n            # If cidr based filtering, protocol and ports are mandatory\n            if 'cidr' in values:\n                return None\n\n        return values\n\n    def delete(self, req, id):\n        context = req.environ['nova.context']\n        authorize(context)\n\n        self.compute_api.ensure_default_security_group(context)\n        try:\n            id = int(id)\n            rule = db.security_group_rule_get(context, id)\n        except ValueError:\n            msg = _(\"Rule id is not integer\")\n            raise exc.HTTPBadRequest(explanation=msg)\n        except exception.NotFound:\n            msg = _(\"Rule (%s) not found\") % id\n            raise exc.HTTPNotFound(explanation=msg)\n\n        group_id = rule.parent_group_id\n        self.compute_api.ensure_default_security_group(context)\n        security_group = db.security_group_get(context, group_id)\n\n        msg = _(\"Revoke security group ingress %s\")\n        LOG.audit(msg, security_group['name'], context=context)\n\n        db.security_group_rule_destroy(context, rule['id'])\n        self.sgh.trigger_security_group_rule_destroy_refresh(\n            context, [rule['id']])\n        self.compute_api.trigger_security_group_rules_refresh(context,\n                                    security_group_id=security_group['id'])\n\n        return webob.Response(status_int=202)\n\n\nclass ServerSecurityGroupController(SecurityGroupControllerBase):\n\n    @wsgi.serializers(xml=SecurityGroupsTemplate)\n    def index(self, req, server_id):\n        \"\"\"Returns a list of security groups for the given instance.\"\"\"\n        context = req.environ['nova.context']\n        authorize(context)\n\n        self.compute_api.ensure_default_security_group(context)\n\n        try:\n            instance = self.compute_api.get(context, server_id)\n            groups = db.security_group_get_by_instance(context,\n                                                       instance['id'])\n        except exception.ApiError, e:\n            raise webob.exc.HTTPBadRequest(explanation=e.message)\n        except exception.NotAuthorized, e:\n            raise webob.exc.HTTPUnauthorized()\n\n        result = [self._format_security_group(context, group)\n                    for group in groups]\n\n        return {'security_groups':\n                list(sorted(result,\n                            key=lambda k: (k['tenant_id'], k['name'])))}\n\n\nclass SecurityGroupActionController(wsgi.Controller):\n    def __init__(self, *args, **kwargs):\n        super(SecurityGroupActionController, self).__init__(*args, **kwargs)\n        self.compute_api = compute.API()\n        self.sgh = utils.import_object(FLAGS.security_group_handler)\n\n    @wsgi.action('addSecurityGroup')\n    def _addSecurityGroup(self, req, id, body):\n        context = req.environ['nova.context']\n        authorize(context)\n\n        try:\n            body = body['addSecurityGroup']\n            group_name = body['name']\n        except TypeError:\n            msg = _(\"Missing parameter dict\")\n            raise webob.exc.HTTPBadRequest(explanation=msg)\n        except KeyError:\n            msg = _(\"Security group not specified\")\n            raise webob.exc.HTTPBadRequest(explanation=msg)\n\n        if not group_name or group_name.strip() == '':\n            msg = _(\"Security group name cannot be empty\")\n            raise webob.exc.HTTPBadRequest(explanation=msg)\n\n        try:\n            instance = self.compute_api.get(context, id)\n            self.compute_api.add_security_group(context, instance, group_name)\n            self.sgh.trigger_instance_add_security_group_refresh(\n                context, instance, group_name)\n        except exception.SecurityGroupNotFound as exp:\n            raise exc.HTTPNotFound(explanation=unicode(exp))\n        except exception.InstanceNotFound as exp:\n            raise exc.HTTPNotFound(explanation=unicode(exp))\n        except exception.Invalid as exp:\n            raise exc.HTTPBadRequest(explanation=unicode(exp))\n\n        return webob.Response(status_int=202)\n\n    @wsgi.action('removeSecurityGroup')\n    def _removeSecurityGroup(self, req, id, body):\n        context = req.environ['nova.context']\n        authorize(context)\n\n        try:\n            body = body['removeSecurityGroup']\n            group_name = body['name']\n        except TypeError:\n            msg = _(\"Missing parameter dict\")\n            raise webob.exc.HTTPBadRequest(explanation=msg)\n        except KeyError:\n            msg = _(\"Security group not specified\")\n            raise webob.exc.HTTPBadRequest(explanation=msg)\n\n        if not group_name or group_name.strip() == '':\n            msg = _(\"Security group name cannot be empty\")\n            raise webob.exc.HTTPBadRequest(explanation=msg)\n\n        try:\n            instance = self.compute_api.get(context, id)\n            self.compute_api.remove_security_group(context, instance,\n                                                   group_name)\n            self.sgh.trigger_instance_remove_security_group_refresh(\n                context, instance, group_name)\n        except exception.SecurityGroupNotFound as exp:\n            raise exc.HTTPNotFound(explanation=unicode(exp))\n        except exception.InstanceNotFound as exp:\n            raise exc.HTTPNotFound(explanation=unicode(exp))\n        except exception.Invalid as exp:\n            raise exc.HTTPBadRequest(explanation=unicode(exp))\n\n        return webob.Response(status_int=202)\n\n\nclass Security_groups(extensions.ExtensionDescriptor):\n    \"\"\"Security group support\"\"\"\n\n    name = \"SecurityGroups\"\n    alias = \"security_groups\"\n    namespace = \"http://docs.openstack.org/compute/ext/securitygroups/api/v1.1\"\n    updated = \"2011-07-21T00:00:00+00:00\"\n\n    def get_controller_extensions(self):\n        controller = SecurityGroupActionController()\n        extension = extensions.ControllerExtension(self, 'servers', controller)\n        return [extension]\n\n    def get_resources(self):\n        resources = []\n\n        res = extensions.ResourceExtension('os-security-groups',\n                                controller=SecurityGroupController())\n\n        resources.append(res)\n\n        res = extensions.ResourceExtension('os-security-group-rules',\n                                controller=SecurityGroupRulesController())\n        resources.append(res)\n\n        res = extensions.ResourceExtension(\n            'os-security-groups',\n            controller=ServerSecurityGroupController(),\n            parent=dict(member_name='server', collection_name='servers'))\n        resources.append(res)\n\n        return resources\n", "target": 1}
{"idx": 945, "func": "import itertools\nimport random\nfrom typing import Union\n\nimport aiohttp\nimport discord\nimport inflection\nfrom redbot.core import Config, checks, commands\nfrom redbot.core.i18n import get_locale\nfrom redbot.core.utils.chat_formatting import italics\n\nfrom .helpers import *\n\n\nclass Act(commands.Cog):\n    \"\"\"\n    This cog makes all commands, e.g. [p]fluff, into valid commands if\n    you command the bot to act on a user, e.g. [p]fluff [botname].\n    \"\"\"\n\n    __author__ = \"Zephyrkul\"\n\n    async def red_get_data_for_user(self, *, user_id):\n        return {}  # No data to get\n\n    async def red_delete_data_for_user(self, *, requester, user_id):\n        pass  # No data to delete\n\n    def __init__(self, bot):\n        super().__init__()\n        self.bot = bot\n        self.config = Config.get_conf(self, identifier=2_113_674_295, force_registration=True)\n        self.config.register_global(custom={}, tenorkey=None)\n        self.config.register_guild(custom={})\n        self.try_after = None\n\n    async def initialize(self, bot):\n        # temporary backwards compatibility\n        key = await self.config.tenorkey()\n        if not key:\n            return\n        await bot.set_shared_api_tokens(\"tenor\", api_key=key)\n        await self.config.tenorkey.clear()\n\n    @commands.command(hidden=True)\n    async def act(self, ctx, *, target: Union[discord.Member, str] = None):\n        \"\"\"\n        Acts on the specified user.\n        \"\"\"\n        if not target or isinstance(target, str):\n            return  # no help text\n\n        try:\n            if not ctx.guild:\n                raise KeyError()\n            message = await self.config.guild(ctx.guild).get_raw(\"custom\", ctx.invoked_with)\n        except KeyError:\n            try:\n                message = await self.config.get_raw(\"custom\", ctx.invoked_with)\n            except KeyError:\n                message = NotImplemented\n\n        if message is None:  # ignored command\n            return\n        elif message is NotImplemented:  # default\n            # humanize action text\n            action = inflection.humanize(ctx.invoked_with).split()\n            iverb = -1\n\n            for cycle in range(2):\n                if iverb > -1:\n                    break\n                for i, act in enumerate(action):\n                    act = act.lower()\n                    if (\n                        act in NOLY_ADV\n                        or act in CONJ\n                        or (act.endswith(\"ly\") and act not in LY_VERBS)\n                        or (not cycle and act in SOFT_VERBS)\n                    ):\n                        continue\n                    action[i] = inflection.pluralize(action[i])\n                    iverb = max(iverb, i)\n\n            if iverb < 0:\n                return\n            action.insert(iverb + 1, target.mention)\n            message = italics(\" \".join(action))\n        else:\n            message = message.format(target, user=target)\n\n        # add reaction gif\n        if self.try_after and ctx.message.created_at < self.try_after:\n            return await ctx.send(message)\n        if not await ctx.embed_requested():\n            return await ctx.send(message)\n        key = (await ctx.bot.get_shared_api_tokens(\"tenor\")).get(\"api_key\")\n        if not key:\n            return await ctx.send(message)\n        async with aiohttp.request(\n            \"GET\",\n            \"https://api.tenor.com/v1/search\",\n            params={\n                \"q\": ctx.invoked_with,\n                \"key\": key,\n                \"anon_id\": str(ctx.author.id ^ ctx.me.id),\n                \"media_filter\": \"minimal\",\n                \"contentfilter\": \"off\" if getattr(ctx.channel, \"nsfw\", False) else \"low\",\n                \"ar_range\": \"wide\",\n                \"limit\": \"8\",\n                \"locale\": get_locale(),\n            },\n        ) as response:\n            json: dict\n            if response.status == 429:\n                self.try_after = ctx.message.created_at + 30\n                json = {}\n            elif response.status >= 400:\n                json = {}\n            else:\n                json = await response.json()\n        if not json.get(\"results\"):\n            return await ctx.send(message)\n        message = f\"{message}\\n\\n{random.choice(json['results'])['itemurl']}\"\n        await ctx.send(\n            message,\n            allowed_mentions=discord.AllowedMentions(\n                users=False if target in ctx.message.mentions else [target]\n            ),\n        )\n\n    @commands.group()\n    @checks.is_owner()\n    async def actset(self, ctx):\n        \"\"\"\n        Configure various settings for the act cog.\n        \"\"\"\n\n    @actset.group(aliases=[\"custom\"], invoke_without_command=True)\n    @checks.admin_or_permissions(manage_guild=True)\n    @commands.guild_only()\n    async def customize(self, ctx, command: str.lower, *, response: str = None):\n        \"\"\"\n        Customize the response to an action.\n\n        You can use {0} or {user} to dynamically replace with the specified target of the action.\n        Formats like {0.name} or {0.mention} can also be used.\n        \"\"\"\n        if not response:\n            await self.config.guild(ctx.guild).clear_raw(\"custom\", command)\n        else:\n            await self.config.guild(ctx.guild).set_raw(\"custom\", command, value=response)\n        await ctx.tick()\n\n    @customize.command(name=\"global\")\n    @checks.is_owner()\n    async def customize_global(self, ctx, command: str.lower, *, response: str = None):\n        \"\"\"\n        Globally customize the response to an action.\n\n        You can use {0} or {user} to dynamically replace with the specified target of the action.\n        Formats like {0.name} or {0.mention} can also be used.\n        \"\"\"\n        if not response:\n            await self.config.clear_raw(\"custom\", command)\n        else:\n            await self.config.set_raw(\"custom\", command, value=response)\n        await ctx.tick()\n\n    @actset.group(invoke_without_command=True)\n    @checks.admin_or_permissions(manage_guild=True)\n    @commands.guild_only()\n    async def ignore(self, ctx, command: str.lower):\n        \"\"\"\n        Ignore or unignore the specified action.\n\n        The bot will no longer respond to these actions.\n        \"\"\"\n        try:\n            custom = await self.config.guild(ctx.guild).get_raw(\"custom\", command)\n        except KeyError:\n            custom = NotImplemented\n        if custom is None:\n            await self.config.guild(ctx.guild).clear_raw(\"custom\", command)\n            await ctx.send(\"I will no longer ignore the {command} action\".format(command=command))\n        else:\n            await self.config.guild(ctx.guild).set_raw(\"custom\", command, value=None)\n            await ctx.send(\"I will now ignore the {command} action\".format(command=command))\n\n    @ignore.command(name=\"global\")\n    @checks.is_owner()\n    async def ignore_global(self, ctx, command: str.lower):\n        \"\"\"\n        Globally ignore or unignore the specified action.\n\n        The bot will no longer respond to these actions.\n        \"\"\"\n        try:\n            await self.config.get_raw(\"custom\", command)\n        except KeyError:\n            await self.config.set_raw(\"custom\", command, value=None)\n        else:\n            await self.config.clear_raw(\"custom\", command)\n        await ctx.tick()\n\n    @actset.command()\n    @checks.is_owner()\n    async def tenorkey(self, ctx):\n        \"\"\"\n        Sets a Tenor GIF API key to enable reaction gifs with act commands.\n\n        You can obtain a key from here: https://tenor.com/developer/dashboard\n        \"\"\"\n        instructions = [\n            \"Go to the Tenor developer dashboard: https://tenor.com/developer/dashboard\",\n            \"Log in or sign up if you haven't already.\",\n            \"Click `+ Create new app` and fill out the form.\",\n            \"Copy the key from the app you just created.\",\n            \"Give the key to Red with this command:\\n\"\n            f\"`{ctx.prefix}set api tenor api_key your_api_key`\\n\"\n            \"Replace `your_api_key` with the key you just got.\\n\"\n            \"Everything else should be the same.\",\n        ]\n        instructions = [f\"**{i}.** {v}\" for i, v in enumerate(instructions, 1)]\n        await ctx.maybe_send_embed(\"\\n\".join(instructions))\n\n    @commands.Cog.listener()\n    async def on_message(self, message):\n        if message.author.bot:\n            return\n\n        ctx = await self.bot.get_context(message)\n        if ctx.prefix is None or not ctx.invoked_with.replace(\"_\", \"\").isalpha():\n            return\n\n        if ctx.valid and ctx.command.enabled:\n            try:\n                if await ctx.command.can_run(ctx):\n                    return\n            except commands.errors.CheckFailure:\n                return\n\n        ctx.command = self.act\n        await self.bot.invoke(ctx)\n", "target": 1}
{"idx": 946, "func": "\"\"\"Serve files directly from the ContentsManager.\"\"\"\n\n# Copyright (c) Jupyter Development Team.\n# Distributed under the terms of the Modified BSD License.\n\nimport os\nimport mimetypes\nimport json\nimport base64\n\nfrom tornado import web\n\nfrom notebook.base.handlers import IPythonHandler\n\nclass FilesHandler(IPythonHandler):\n    \"\"\"serve files via ContentsManager\"\"\"\n\n    @web.authenticated\n    def get(self, path):\n        cm = self.contents_manager\n        if cm.is_hidden(path):\n            self.log.info(\"Refusing to serve hidden file, via 404 Error\")\n            raise web.HTTPError(404)\n        \n        path = path.strip('/')\n        if '/' in path:\n            _, name = path.rsplit('/', 1)\n        else:\n            name = path\n        \n        model = cm.get(path, type='file')\n        \n        if self.get_argument(\"download\", False):\n            self.set_header('Content-Disposition','attachment; filename=\"%s\"' % name)\n        \n        # get mimetype from filename\n        if name.endswith('.ipynb'):\n            self.set_header('Content-Type', 'application/json')\n        else:\n            cur_mime = mimetypes.guess_type(name)[0]\n            if cur_mime is not None:\n                self.set_header('Content-Type', cur_mime)\n        \n        if model['format'] == 'base64':\n            b64_bytes = model['content'].encode('ascii')\n            self.write(base64.decodestring(b64_bytes))\n        elif model['format'] == 'json':\n            self.write(json.dumps(model['content']))\n        else:\n            self.write(model['content'])\n        self.flush()\n\ndefault_handlers = [\n    (r\"/files/(.*)\", FilesHandler),\n]", "target": 1}
{"idx": 947, "func": "# -*- coding: utf-8 -*-\n#Canto-curses - ncurses RSS reader\n#   Copyright (C) 2014 Jack Miller <jack@codezen.org>\n#\n#   This program is free software; you can redistribute it and/or modify\n#   it under the terms of the GNU General Public License version 2 as \n#   published by the Free Software Foundation.\n\nfrom canto_next.hooks import on_hook\nfrom canto_next.plugins import Plugin\nfrom canto_next.remote import assign_to_dict, access_dict\n\nfrom .command import CommandHandler, register_commands, register_arg_types, unregister_all, _string, register_aliases, commands, command_help\nfrom .tagcore import tag_updater\nfrom .parser import prep_for_display\nfrom .config import needs_eval\n\nimport logging\n\nlog = logging.getLogger(\"COMMON\")\n\nimport subprocess\nimport tempfile\nimport urllib.request, urllib.error, urllib.parse\nimport shlex\nimport sys\n\nimport os\nimport os.path\n\nclass BasePlugin(Plugin):\n    pass\n\nclass GuiBase(CommandHandler):\n    def init(self):\n        args = {\n            \"key\": (\"[key]: Simple keys (a), basic chords (C-r, M-a), or named whitespace like space or tab\", _string),\n            \"command\": (\"[command]: Any canto-curses command. (Will show current binding if not given)\\n  Simple: goto\\n  Chained: foritems \\\\\\\\& goto \\\\\\\\& item-state read \\\\\\\\& clearitems \\\\\\\\& next-item\", self.type_unescape_command),\n            \"remote-cmd\": (\"[remote cmd]\", self.type_remote_cmd),\n            \"url\" : (\"[URL]\", _string),\n            \"help-command\" : (\"[help-command]: Any canto-curses command, if blank, 'any' or unknown, will display help overview\", self.type_help_cmd),\n            \"config-option\" : (\"[config-option]: Any canto-curses option\", self.type_config_option),\n            \"executable\" : (\"[executable]: A program in your PATH\", self.type_executable),\n        }\n\n        cmds = {\n            \"bind\" : (self.cmd_bind, [ \"key\", \"command\" ], \"Add or query %s keybinds\" % self.get_opt_name()),\n            \"transform\" : (self.cmd_transform, [\"string\"], \"Set user transform\"),\n            \"remote addfeed\" : (lambda x : self.cmd_remote(\"addfeed\", x), [\"url\"], \"Subscribe to a feed\"),\n            \"remote listfeeds\" : (lambda : self.cmd_remote(\"listfeeds\", \"\"), [], \"List feeds\"),\n            \"remote\": (self.cmd_remote, [\"remote-cmd\", \"string\"], \"Give a command to canto-remote\"),\n            \"destroy\": (self.cmd_destroy, [], \"Destroy this %s\" % self.get_opt_name()),\n            \"set\" : (self.cmd_set, [\"config-option\", \"string\"], \"Set configuration options\"),\n            \"set browser.path\" : (lambda x : self.cmd_set(\"browser.path\", x), [\"executable\"], \"Set desired browser\"),\n        }\n\n        help_cmds = {\n            \"help\" : (self.cmd_help, [\"help-command\"], \"Get help on a specific command\")\n        }\n\n        aliases = {\n            \"add\" : \"remote addfeed\",\n            \"del\" : \"remote delfeed\",\n            \"list\" : \"remote listfeeds\",\n\n            # Compatibility / evaluation aliases\n            \"set global_transform\" : \"set defaults.global_transform\",\n            \"set keep_time\" : \"set defaults.keep_time\",\n            \"set keep_unread\" : \"set defaults.keep_unread\",\n            \"set browser \" : \"set browser.path \",\n            \"set txt_browser \" : \"set browser.text \",\n            \"set update.auto \" : \"set update.auto.enabled \",\n            \"set border\" : \"set taglist.border\",\n\n            \"filter\" : \"transform\",\n            \"sort\" : \"transform\",\n\n            \"next-item\" : \"rel-set-cursor 1\",\n            \"prev-item\" : \"rel-set-cursor -1\",\n        }\n\n        register_arg_types(self, args)\n\n        register_commands(self, cmds, \"Base\")\n        register_commands(self, help_cmds, \"Help\")\n\n        register_aliases(self, aliases)\n\n        self.editor = None\n\n        self.plugin_class = BasePlugin\n        self.update_plugin_lookups()\n\n    def cmd_destroy(self):\n        self.callbacks[\"die\"](self)\n\n    def die(self):\n        unregister_all(self)\n\n    # Provide completions, but we don't care to verify settings.\n\n    def type_executable(self):\n        executables = []\n        for path_dir in os.environ[\"PATH\"].split(os.pathsep):\n            for f in os.listdir(path_dir):\n                fullpath = os.path.join(path_dir, f)\n                if os.path.isfile(fullpath) and os.access(fullpath, os.X_OK):\n                    executables.append(f)\n\n        return (executables, lambda x : (True, x))\n\n    def _fork(self, path, href, text, fetch=False):\n\n        # Prepare temporary files, if fetch.\n\n        if fetch:\n            # Get a path (sans query strings, etc.) for the URL\n            tmppath = urllib.parse.urlparse(href).path\n\n            # Return just the basename of the path (no directories)\n            fname = os.path.basename(tmppath)\n\n            # Grab a temporary directory. This allows us to create a file with\n            # an unperturbed filename so scripts can freely use regex /\n            # extension matching in addition to mimetype detection.\n\n            tmpdir = tempfile.mkdtemp(prefix=\"canto-\")\n            tmpnam = tmpdir + '/' + fname\n\n            on_hook(\"curses_exit\", lambda : (os.unlink(tmpnam)))\n            on_hook(\"curses_exit\", lambda : (os.rmdir(tmpdir)))\n\n        pid = os.fork()\n\n        # Parents can now bail.\n        if pid:\n            return pid\n\n        if fetch:\n            tmp = open(tmpnam, 'w+b')\n\n            # Grab the HTTP info / prepare to read.\n            response = urllib.request.urlopen(href)\n\n            # Grab in kilobyte chunks to avoid wasting memory on something\n            # that's going to be immediately written to disk.\n\n            while True:\n                r = response.read(1024)\n                if not r:\n                    break\n                tmp.write(r)\n\n            response.close()\n            tmp.close()\n\n            href = tmpnam\n\n        # Make sure that we quote href such that malicious URLs like\n        # \"http://example.com & rm -rf ~/\" won't be interpreted by the shell.\n\n        href = shlex.quote(href)\n\n        # A lot of programs don't appreciate\n        # having their fds closed, so instead\n        # we dup them to /dev/null.\n\n        fd = os.open(\"/dev/null\", os.O_RDWR)\n        os.dup2(fd, sys.stderr.fileno())\n\n        if not text:\n            os.setpgid(os.getpid(), os.getpid())\n            os.dup2(fd, sys.stdout.fileno())\n\n        if \"%u\" in path:\n            path = path.replace(\"%u\", href)\n        elif href:\n            path = path + \" \" + href\n\n        os.execv(\"/bin/sh\", [\"/bin/sh\", \"-c\", path])\n\n        # Just in case.\n        sys.exit(0)\n\n    def _edit(self, text):\n        if not self.editor:\n            self.editor = os.getenv(\"EDITOR\")\n        if not self.editor:\n            self.editor = self.input(\"editor: \")\n\n        # No editor, or cancelled dialog, no change.\n        if not self.editor:\n            return text\n\n        self.callbacks[\"pause_interface\"]()\n\n        # Setup tempfile to edit.\n        fd, path = tempfile.mkstemp(text=True)\n\n        f = os.fdopen(fd, \"w\")\n        f.write(text)\n        f.close()\n\n        # Invoke editor\n        logging.info(\"Invoking editor on %s\" % path)\n        pid = self._fork(self.editor + \" %u\", path, True)\n        pid, status = os.waitpid(pid, 0)\n\n        if status == 0:\n            f = open(path, \"r\")\n            r = f.read()\n            f.close()\n        else:\n            self.callbacks[\"set_var\"](\"error_msg\",\n                    \"Editor failed! Status = %d\" % (status,))\n            r = text\n\n        # Cleanup temp file.\n        os.unlink(path)\n\n        self.callbacks[\"unpause_interface\"]()\n\n        return r\n\n    def cmd_edit(self, **kwargs):\n        t = self.callbacks[\"get_opt\"](kwargs[\"opt\"])\n        r = self._edit(t)\n        log.info(\"Edited %s to %s\" % (kwargs[\"opt\"], r))\n        self.callbacks[\"set_opt\"](kwargs[\"opt\"], r)\n\n    def type_remote_cmd(self):\n        remote_cmds = [ \"help\", \"addfeed\", \"listfeeds\", \"delfeed\",\n                \"force-update\", \"config\", \"one-config\", \"export\",\n                \"import\", \"kill\" ]\n        return (remote_cmds, lambda x : (x in remote_cmds, x))\n\n    def _remote_argv(self, argv):\n        loc_args = self.callbacks[\"get_var\"](\"location\")\n        argv = [argv[0]] + loc_args + argv[1:]\n\n        log.debug(\"Calling remote: %s\" % argv)\n\n        # check_output return bytes, we must decode.\n        out = subprocess.check_output(argv).decode()\n\n        log.debug(\"Output:\")\n        log.debug(out.rstrip())\n\n        # Strip anything that could be misconstrued as style\n        # from remote output.\n\n        out = out.replace(\"%\",\"\\\\%\")\n\n        log.info(out.rstrip())\n\n    def _remote(self, args):\n        args = \"canto-remote \" + args\n\n        # Add location args, so the remote is connecting\n        # to the correct daemon.\n\n        self._remote_argv(shlex.split(args))\n\n    def remote_args(self, args):\n        return self.string(args, \"remote: \")\n\n    def cmd_remote(self, remote_cmd, args):\n        self._remote(\"%s %s\" % (remote_cmd, args))\n\n    def _goto(self, urls, fetch=False):\n        browser = self.callbacks[\"get_conf\"]()[\"browser\"]\n\n        if not browser[\"path\"]:\n            log.error(\"No browser defined! Cannot goto.\")\n            return\n\n        if browser[\"text\"]:\n            self.callbacks[\"pause_interface\"]()\n\n        for url in urls:\n            pid = self._fork(browser[\"path\"], url, browser[\"text\"], fetch)\n            if browser[\"text\"]:\n                os.waitpid(pid, 0)\n\n        if browser[\"text\"]:\n            self.callbacks[\"unpause_interface\"]()\n\n    # Like goto, except download the file to /tmp before executing browser.\n\n    def _fetch(self, urls):\n        self._goto(urls, True)\n\n    def cmd_transform(self, transform):\n        tag_updater.transform(\"user\", transform)\n        tag_updater.reset(True)\n        tag_updater.update()\n\n    def type_unescape_command(self):\n        def validate_uescape_command(x):\n            # Change the escaped '&' from shlex into a raw &\n            return (True, x.replace(\" '&' \", \" & \"))\n        return (None, validate_uescape_command)\n\n    def cmd_bind(self, key, cmd):\n        self.bind(key, cmd.lstrip().rstrip(), True)\n\n    def bind(self, key, cmd, overwrite=False):\n        opt = self.get_opt_name()\n        key = self.translate_key(key)\n        c = self.callbacks[\"get_conf\"]()\n        if not cmd:\n            if key in c[opt][\"key\"]:\n                log.info(\"[%s] %s = %s\" % (opt, key, c[opt][\"key\"][key]))\n                return True\n            else:\n                return False\n        else:\n            if key in c[opt][\"key\"] and c[opt][\"key\"][key] and not overwrite:\n                log.debug(\"%s already bound to %s\" % (key, c[opt][\"key\"][key]))\n                return False\n\n            log.debug(\"Binding %s.%s to %s\" % (opt, key, cmd))\n\n            c[opt][\"key\"][key] = cmd\n            self.callbacks[\"set_conf\"](c)\n            return True\n\n    def type_help_cmd(self):\n        help_cmds = commands()\n\n        def help_validator(x):\n            if x in [\"commands\", \"cmds\"]:\n                return (True, 'commands')\n            for group in help_cmds:\n                if x in help_cmds[group]:\n                    return (True, x)\n            return (True, 'all')\n\n        return (help_cmds, help_validator)\n\n    def cmd_help(self, cmd):\n        if self.callbacks[\"get_var\"](\"info_msg\"):\n            self.callbacks[\"set_var\"](\"info_msg\", \"\")\n\n        if cmd == 'all':\n            log.info(\"%BHELP%b\\n\")\n            log.info(\"This is a list of available keybinds.\\n\")\n            log.info(\"For a list of commands, type ':help commands'\\n\")\n            log.info(\"For help with a specific command, type ':help [command]'\\n\")\n            log.info(\"%BBinds%b\")\n\n            config = self.callbacks[\"get_conf\"]()\n\n            for optname in [ \"main\", \"taglist\", \"reader\" ]:\n                if \"key\" in config[optname] and list(config[optname][\"key\"].keys()) != []:\n                    maxbindl = max([ len(x) for x in config[optname][\"key\"].keys() ]) + 1\n                    log.info(\"\\n%B\" + optname + \"%b\\n\")\n                    for bind in sorted(config[optname][\"key\"]):\n                        bindeff = prep_for_display(bind + (\" \" * (maxbindl - len(bind))))\n                        cmd = prep_for_display(config[optname][\"key\"][bind])\n                        log.info(\"%s %s\" % (bindeff, cmd))\n\n        elif cmd == 'commands':\n            gc = commands()\n            for group in sorted(gc.keys()):\n                log.info(\"%B\" + group + \"%b\\n\")\n                for c in sorted(gc[group]):\n                    log.info(command_help(c))\n                log.info(\"\")\n        else:\n            log.info(command_help(cmd, True))\n\n    # Validate a single config option\n    # Will offer completions for any recognized config option\n    # Will *not* reject validly formatted options that don't already exist\n\n    def _get_current_config_options(self, obj, stack):\n        r = []\n\n        for item in obj.keys():\n            stack.append(item)\n\n            if type(obj[item]) == dict:\n                r.extend(self._get_current_config_options(obj[item], stack[:]))\n            else:\n                r.append(shlex.quote(\".\".join(stack)))\n\n            stack = stack[:-1]\n\n        return r\n\n    def type_config_option(self):\n        conf = self.callbacks[\"get_conf\"]()\n\n        possibles = self._get_current_config_options(conf, [])\n        possibles.sort()\n\n        return (possibles, lambda x : (True, x))\n\n    def cmd_set(self, opt, val):\n        log.debug(\"SET: %s '%s'\" % (opt, val))\n\n        evaluate = needs_eval(opt)\n\n        if val != \"\" and evaluate:\n            log.debug(\"Evaluating...\")\n            try:\n                val = eval(val)\n            except Exception as e:\n                log.error(\"Couldn't eval '%s': %s\" % (val, e))\n                return\n\n        if opt.startswith(\"defaults.\"):\n            conf = { \"defaults\" : self.callbacks[\"get_defaults\"]() }\n\n            if val != \"\":\n                assign_to_dict(conf, opt, val)\n                self.callbacks[\"set_defaults\"](conf[\"defaults\"])\n        elif opt.startswith(\"feed.\"):\n            sel = self.callbacks[\"get_var\"](\"selected\")\n            if not sel:\n                log.info(\"Feed settings only work with a selected item\")\n                return\n\n            if sel.is_tag:\n                try_tag = sel\n            else:\n                try_tag = sel.parent_tag\n\n            if not try_tag.tag.startswith(\"maintag:\"):\n                log.info(\"Selection is in a user tag, cannot set feed settings\")\n                return\n\n            name = try_tag.tag[8:]\n\n            conf = { \"feed\" : self.callbacks[\"get_feed_conf\"](name) }\n\n            if val != \"\":\n                assign_to_dict(conf, opt, val)\n                self.callbacks[\"set_feed_conf\"](name, conf[\"feed\"])\n        elif opt.startswith(\"tag.\"):\n            sel = self.callbacks[\"get_var\"](\"selected\")\n            if not sel:\n                log.info(\"Tag settings only work with a selected item\")\n                return\n\n            if sel.is_tag:\n                tag = sel\n            else:\n                tag = sel.parent_tag\n\n            conf = { \"tag\" : self.callbacks[\"get_tag_conf\"](tag.tag) }\n\n            if val != \"\":\n                assign_to_dict(conf, opt, val)\n                self.callbacks[\"set_tag_conf\"](tag.tag, conf[\"tag\"])\n        else:\n            conf = self.callbacks[\"get_conf\"]()\n\n            if val != \"\":\n                assign_to_dict(conf, opt, val)\n                self.callbacks[\"set_conf\"](conf)\n\n        ok, val = access_dict(conf, opt)\n        if not ok:\n            log.error(\"Unknown option %s\" % opt)\n            log.error(\"Full conf: %s\" % conf)\n        else:\n            log.info(\"%s = %s\" % (opt, val))\n", "target": 0}
{"idx": 948, "func": "#\n# Copyright (c) 2008--2015 Red Hat, Inc.\n#\n# This software is licensed to you under the GNU General Public License,\n# version 2 (GPLv2). There is NO WARRANTY for this software, express or\n# implied, including the implied warranties of MERCHANTABILITY or FITNESS\n# FOR A PARTICULAR PURPOSE. You should have received a copy of GPLv2\n# along with this software; if not, see\n# http://www.gnu.org/licenses/old-licenses/gpl-2.0.txt.\n#\n# Red Hat trademarks are not licensed under GPLv2. No permission is\n# granted to use or replicate Red Hat trademarks that are incorporated\n# in this software or its documentation.\n#\n\nimport os\n\nfrom types import ListType\n\nfrom spacewalk.common import rhnFlags\nfrom spacewalk.common.rhnLog import log_debug, log_error\nfrom spacewalk.common.rhnConfig import CFG\nfrom spacewalk.common.rhnException import rhnFault\nfrom spacewalk.common.rhnTranslate import _\nfrom spacewalk.server import rhnSQL\nfrom rhnLib import parseRPMFilename\n\n\n#\n# Functions that deal with the database\n#\n\n# New client\n# Returns a package path, given a server_id, package filename and channel label\ndef get_package_path(server_id, pkg_spec, channel):\n    log_debug(3, server_id, pkg_spec, channel)\n    if isinstance(pkg_spec, ListType):\n        pkg = pkg_spec[:4]\n        # Insert EPOCH\n        pkg.insert(1, None)\n    else:\n        pkg = parseRPMFilename(pkg_spec)\n        if pkg is None:\n            log_debug(4, \"Error\", \"Requested weird package\", pkg_spec)\n            raise rhnFault(17, _(\"Invalid RPM package %s requested\") % pkg_spec)\n\n    statement = \"\"\"\n        select  p.id, p.path path, pe.epoch epoch\n        from\n                rhnPackageArch pa,\n                rhnChannelPackage cp,\n                rhnPackage p,\n                rhnPackageEVR pe,\n                rhnServerChannel sc,\n                rhnPackageName pn,\n                rhnChannel c\n        where 1=1\n            and c.label = :channel\n            and pn.name = :name\n            and sc.server_id = :server_id\n            and pe.version = :ver\n            and pe.release = :rel\n            and c.id = sc.channel_id\n            and c.id = cp.channel_id\n            and pa.label = :arch\n            and pn.id = p.name_id\n            and p.id = cp.package_id\n            and p.evr_id = pe.id\n            and sc.channel_id = cp.channel_id\n            and p.package_arch_id = pa.id\n    \"\"\"\n    h = rhnSQL.prepare(statement)\n    pkg = map(str, pkg)\n    h.execute(name=pkg[0], ver=pkg[2], rel=pkg[3], arch=pkg[4],\n              channel=channel, server_id=server_id)\n    rs = h.fetchall_dict()\n    if not rs:\n        log_debug(4, \"Error\", \"Non-existant package requested\", server_id,\n                  pkg_spec, channel)\n        raise rhnFault(17, _(\"Invalid RPM package %s requested\") % pkg_spec)\n    # It is unlikely for this query to return more than one row,\n    # but it is possible\n    # (having two packages with the same n, v, r, a and different epoch in\n    # the same channel is prohibited by the RPM naming scheme; but extra\n    # care won't hurt)\n    max_row = rs[0]\n    for each in rs[1:]:\n        # Compare the epoch as string\n        if _none2emptyString(each['epoch']) > _none2emptyString(max_row['epoch']):\n            max_row = each\n\n    # Set the flag for the proxy download accelerator\n    rhnFlags.set(\"Download-Accelerator-Path\", max_row['path'])\n    return check_package_file(max_row['path'], max_row['id'], pkg_spec), max_row['id']\n\n\ndef check_package_file(rel_path, logpkg, raisepkg):\n    if rel_path is None:\n        log_error(\"Package path null for package id\", logpkg)\n        raise rhnFault(17, _(\"Invalid RPM package %s requested\") % raisepkg)\n    filePath = \"%s/%s\" % (CFG.MOUNT_POINT, rel_path)\n    if not os.access(filePath, os.R_OK):\n        # Package not found on the filesystem\n        log_error(\"Package not found\", filePath)\n        raise rhnFault(17, _(\"Package not found\"))\n\n    return filePath\n\n\ndef unlink_package_file(path):\n    try:\n        os.unlink(path)\n    except OSError:\n        log_debug(1,  \"Error unlinking %s;\" % path)\n    dirname = os.path.dirname(path)\n    base_dirs = (CFG.MOUNT_POINT + '/' + CFG.PREPENDED_DIR, CFG.MOUNT_POINT)\n    while dirname not in base_dirs:\n        try:\n            os.rmdir(dirname)\n        except OSError, e:\n            if e.errno == 39:  # OSError: [Errno 39] Directory not empty\n                break\n            else:\n                raise\n        dirname = os.path.dirname(dirname)\n\n\ndef get_all_package_paths(server_id, pkg_spec, channel):\n    \"\"\"\n    return the remote path if available and localpath\n    for the requested package with respect to package id\n    \"\"\"\n    log_debug(3, server_id, pkg_spec, channel)\n    remotepath = None\n    # get the path and package\n    localpath, pkg_id = get_package_path(server_id, pkg_spec, channel)\n\n    return remotepath, localpath\n\n# New client\n# Returns the path to a source rpm\n\n\ndef get_source_package_path(server_id, pkgFilename, channel):\n    log_debug(3, server_id, pkgFilename, channel)\n    rs = __query_source_package_path_by_name(server_id, pkgFilename, channel)\n    if rs is None:\n        log_debug(4, \"Error\", \"Non-existant package requested\", server_id,\n                  pkgFilename, channel)\n        raise rhnFault(17, _(\"Invalid RPM package %s requested\") % pkgFilename)\n\n    # Set the flag for the proxy download accelerator\n    rhnFlags.set(\"Download-Accelerator-Path\", rs['path'])\n    return check_package_file(rs['path'], pkgFilename, pkgFilename)\n\n\n# 0 or 1: is this source in this channel?\ndef package_source_in_channel(server_id, pkgFilename, channel):\n    log_debug(3, server_id, pkgFilename, channel)\n    rs = __query_source_package_path_by_name(server_id, pkgFilename, channel)\n    if rs is None:\n        return 0\n    return 1\n\n\n# The query used both in get_source_package_path and package_source_in_channel\ndef __query_source_package_path_by_name(server_id, pkgFilename, channel):\n    statement = \"\"\"\n    select\n            unique ps.path\n    from\n            rhnSourceRPM sr,\n            rhnPackageSource ps,\n            rhnPackage p,\n            rhnChannelPackage cp,\n            rhnChannel c,\n            rhnServerChannel sc\n    where\n                sc.server_id = :server_id\n            and sc.channel_id = cp.channel_id\n            and cp.channel_id = c.id\n            and c.label = :channel\n            and cp.package_id = p.id\n            and p.source_rpm_id = sr.id\n            and sr.name = :name\n            and p.source_rpm_id = ps.source_rpm_id\n            and ((p.org_id is null and ps.org_id is null)\n                or p.org_id = ps.org_id)\n    \"\"\"\n    h = rhnSQL.prepare(statement)\n    h.execute(name=pkgFilename, channel=channel, server_id=server_id)\n    return h.fetchone_dict()\n\n\ndef get_info_for_package(pkg, channel_id, org_id):\n    log_debug(3, pkg)\n    pkg = map(str, pkg)\n    params = {'name': pkg[0],\n              'ver': pkg[1],\n              'rel': pkg[2],\n              'epoch': pkg[3],\n              'arch': pkg[4],\n              'channel_id': channel_id,\n              'org_id': org_id}\n    # yum repo has epoch=\"0\" not only when epoch is \"0\" but also if it's NULL\n    if pkg[3] == '0' or pkg[3] == '' or pkg[3]==None:\n        epochStatement = \"(epoch is null or epoch = :epoch)\"\n    else:\n        epochStatement = \"epoch = :epoch\"\n    if params['org_id']:\n        orgStatement = \"org_id = :org_id\"\n    else:\n        orgStatement = \"org_id is null\"\n\n    statement = \"\"\"\n    select p.path, cp.channel_id,\n           cv.checksum_type, cv.checksum\n      from rhnPackage p\n      join rhnPackageName pn\n        on p.name_id = pn.id\n      join rhnPackageEVR pe\n        on p.evr_id = pe.id\n      join rhnPackageArch pa\n        on p.package_arch_id = pa.id\n      left join rhnChannelPackage cp\n        on p.id = cp.package_id\n       and cp.channel_id = :channel_id\n      join rhnChecksumView cv\n        on p.checksum_id = cv.id\n     where pn.name = :name\n       and pe.version = :ver\n       and pe.release = :rel\n       and %s\n       and pa.label = :arch\n       and %s\n     order by cp.channel_id nulls last\n    \"\"\" % (epochStatement, orgStatement)\n\n    h = rhnSQL.prepare(statement)\n    h.execute(**params)\n\n    ret = h.fetchone_dict()\n    if not ret:\n        return {'path':          None,\n                'channel_id': None,\n                'checksum_type': None,\n                'checksum':      None,\n                }\n    return ret\n\n\ndef _none2emptyString(foo):\n    if foo is None:\n        return \"\"\n    return str(foo)\n\nif __name__ == '__main__':\n    \"\"\"Test code.\n    \"\"\"\n    from spacewalk.common.rhnLog import initLOG\n    initLOG(\"stdout\", 1)\n    rhnSQL.initDB()\n    print\n    # new client\n    print get_package_path(1000463284, 'kernel-2.4.2-2.i686.rpm', 'redhat-linux-i386-7.1')\n    print get_source_package_path(1000463284, 'kernel-2.4.2-2.i686.rpm', 'redhat-linux-i386-7.1')\n", "target": 0}
{"idx": 949, "func": "#!/usr/bin/python\nfrom k5test import *\n\n# Skip this test if pkinit wasn't built.\nif not os.path.exists(os.path.join(plugins, 'preauth', 'pkinit.so')):\n    skip_rest('PKINIT tests', 'PKINIT module not built')\n\n# Check if soft-pkcs11.so is available.\ntry:\n    import ctypes\n    lib = ctypes.LibraryLoader(ctypes.CDLL).LoadLibrary('soft-pkcs11.so')\n    del lib\n    have_soft_pkcs11 = True\nexcept:\n    have_soft_pkcs11 = False\n\n# Construct a krb5.conf fragment configuring pkinit.\ncerts = os.path.join(srctop, 'tests', 'dejagnu', 'pkinit-certs')\nca_pem = os.path.join(certs, 'ca.pem')\nkdc_pem = os.path.join(certs, 'kdc.pem')\nuser_pem = os.path.join(certs, 'user.pem')\nprivkey_pem = os.path.join(certs, 'privkey.pem')\nprivkey_enc_pem = os.path.join(certs, 'privkey-enc.pem')\nuser_p12 = os.path.join(certs, 'user.p12')\nuser_enc_p12 = os.path.join(certs, 'user-enc.p12')\nuser_upn_p12 = os.path.join(certs, 'user-upn.p12')\nuser_upn2_p12 = os.path.join(certs, 'user-upn2.p12')\nuser_upn3_p12 = os.path.join(certs, 'user-upn3.p12')\npath = os.path.join(os.getcwd(), 'testdir', 'tmp-pkinit-certs')\npath_enc = os.path.join(os.getcwd(), 'testdir', 'tmp-pkinit-certs-enc')\n\npkinit_krb5_conf = {'realms': {'$realm': {\n            'pkinit_anchors': 'FILE:%s' % ca_pem}}}\npkinit_kdc_conf = {'realms': {'$realm': {\n            'default_principal_flags': '+preauth',\n            'pkinit_eku_checking': 'none',\n            'pkinit_identity': 'FILE:%s,%s' % (kdc_pem, privkey_pem),\n            'pkinit_indicator': ['indpkinit1', 'indpkinit2']}}}\nrestrictive_kdc_conf = {'realms': {'$realm': {\n            'restrict_anonymous_to_tgt': 'true' }}}\n\ntestprincs = {'krbtgt/KRBTEST.COM': {'keys': 'aes128-cts'},\n              'user': {'keys': 'aes128-cts', 'flags': '+preauth'},\n              'user2': {'keys': 'aes128-cts', 'flags': '+preauth'}}\nalias_kdc_conf = {'realms': {'$realm': {\n            'default_principal_flags': '+preauth',\n            'pkinit_eku_checking': 'none',\n            'pkinit_allow_upn': 'true',\n            'pkinit_identity': 'FILE:%s,%s' % (kdc_pem, privkey_pem),\n            'database_module': 'test'}},\n                  'dbmodules': {'test': {\n                      'db_library': 'test',\n                      'alias': {'user@krbtest.com': 'user'},\n                      'princs': testprincs}}}\n\nfile_identity = 'FILE:%s,%s' % (user_pem, privkey_pem)\nfile_enc_identity = 'FILE:%s,%s' % (user_pem, privkey_enc_pem)\ndir_identity = 'DIR:%s' % path\ndir_enc_identity = 'DIR:%s' % path_enc\ndir_file_identity = 'FILE:%s,%s' % (os.path.join(path, 'user.crt'),\n                                    os.path.join(path, 'user.key'))\ndir_file_enc_identity = 'FILE:%s,%s' % (os.path.join(path_enc, 'user.crt'),\n                                        os.path.join(path_enc, 'user.key'))\np12_identity = 'PKCS12:%s' % user_p12\np12_upn_identity = 'PKCS12:%s' % user_upn_p12\np12_upn2_identity = 'PKCS12:%s' % user_upn2_p12\np12_upn3_identity = 'PKCS12:%s' % user_upn3_p12\np12_enc_identity = 'PKCS12:%s' % user_enc_p12\np11_identity = 'PKCS11:soft-pkcs11.so'\np11_token_identity = ('PKCS11:module_name=soft-pkcs11.so:'\n                      'slotid=1:token=SoftToken (token)')\n\n# Start a realm with the test kdb module for the following UPN SAN tests.\nrealm = K5Realm(krb5_conf=pkinit_krb5_conf, kdc_conf=alias_kdc_conf,\n                create_kdb=False)\nrealm.start_kdc()\n\n# Compatibility check: cert contains UPN \"user\", which matches the\n# request principal user@KRBTEST.COM if parsed as a normal principal.\nrealm.kinit(realm.user_princ,\n            flags=['-X', 'X509_user_identity=%s' % p12_upn2_identity])\n\n# Compatibility check: cert contains UPN \"user@KRBTEST.COM\", which matches\n# the request principal user@KRBTEST.COM if parsed as a normal principal.\nrealm.kinit(realm.user_princ,\n            flags=['-X', 'X509_user_identity=%s' % p12_upn3_identity])\n\n# Cert contains UPN \"user@krbtest.com\" which is aliased to the request\n# principal.\nrealm.kinit(realm.user_princ,\n            flags=['-X', 'X509_user_identity=%s' % p12_upn_identity])\n\n# Test an id-pkinit-san match to a post-canonical principal.\nrealm.kinit('user@krbtest.com',\n            flags=['-E', '-X', 'X509_user_identity=%s' % p12_identity])\n\n# Test a UPN match to a post-canonical principal.  (This only works\n# for the cert with the UPN containing just \"user\", as we don't allow\n# UPN reparsing when comparing to the canonicalized client principal.)\nrealm.kinit('user@krbtest.com',\n            flags=['-E', '-X', 'X509_user_identity=%s' % p12_upn2_identity])\n\n# Test a mismatch.\nmsg = 'kinit: Client name mismatch while getting initial credentials'\nrealm.run([kinit, '-X', 'X509_user_identity=%s' % p12_upn2_identity, 'user2'],\n          expected_code=1, expected_msg=msg)\nrealm.stop()\n\nrealm = K5Realm(krb5_conf=pkinit_krb5_conf, kdc_conf=pkinit_kdc_conf,\n                get_creds=False)\n\n# Sanity check - password-based preauth should still work.\nrealm.run(['./responder', '-r', 'password=%s' % password('user'),\n           realm.user_princ])\nrealm.kinit(realm.user_princ, password=password('user'))\nrealm.klist(realm.user_princ)\nrealm.run([kvno, realm.host_princ])\n\n# Test anonymous PKINIT.\nrealm.kinit('@%s' % realm.realm, flags=['-n'], expected_code=1,\n            expected_msg='not found in Kerberos database')\nrealm.addprinc('WELLKNOWN/ANONYMOUS')\nrealm.kinit('@%s' % realm.realm, flags=['-n'])\nrealm.klist('WELLKNOWN/ANONYMOUS@WELLKNOWN:ANONYMOUS')\nrealm.run([kvno, realm.host_princ])\nout = realm.run(['./adata', realm.host_princ])\nif '97:' in out:\n    fail('auth indicators seen in anonymous PKINIT ticket')\n\n# Test anonymous kadmin.\nf = open(os.path.join(realm.testdir, 'acl'), 'a')\nf.write('WELLKNOWN/ANONYMOUS@WELLKNOWN:ANONYMOUS a *')\nf.close()\nrealm.start_kadmind()\nrealm.run([kadmin, '-n', 'addprinc', '-pw', 'test', 'testadd'])\nrealm.run([kadmin, '-n', 'getprinc', 'testadd'], expected_code=1,\n          expected_msg=\"Operation requires ``get'' privilege\")\nrealm.stop_kadmind()\n\n# Test with anonymous restricted; FAST should work but kvno should fail.\nr_env = realm.special_env('restrict', True, kdc_conf=restrictive_kdc_conf)\nrealm.stop_kdc()\nrealm.start_kdc(env=r_env)\nrealm.kinit('@%s' % realm.realm, flags=['-n'])\nrealm.kinit('@%s' % realm.realm, flags=['-n', '-T', realm.ccache])\nrealm.run([kvno, realm.host_princ], expected_code=1,\n          expected_msg='KDC policy rejects request')\n\n# Regression test for #8458: S4U2Self requests crash the KDC if\n# anonymous is restricted.\nrealm.kinit(realm.host_princ, flags=['-k'])\nrealm.run([kvno, '-U', 'user', realm.host_princ])\n\n# Go back to a normal KDC and disable anonymous PKINIT.\nrealm.stop_kdc()\nrealm.start_kdc()\nrealm.run([kadminl, 'delprinc', 'WELLKNOWN/ANONYMOUS'])\n\n# Run the basic test - PKINIT with FILE: identity, with no password on the key.\nrealm.run(['./responder', '-x', 'pkinit=',\n           '-X', 'X509_user_identity=%s' % file_identity, realm.user_princ])\nrealm.kinit(realm.user_princ,\n            flags=['-X', 'X509_user_identity=%s' % file_identity])\nrealm.klist(realm.user_princ)\nrealm.run([kvno, realm.host_princ])\n\n# Try again using RSA instead of DH.\nrealm.kinit(realm.user_princ,\n            flags=['-X', 'X509_user_identity=%s' % file_identity,\n                   '-X', 'flag_RSA_PROTOCOL=yes'])\nrealm.klist(realm.user_princ)\n\n# Test a DH parameter renegotiation by temporarily setting a 4096-bit\n# minimum on the KDC.  (Preauth type 16 is PKINIT PA_PK_AS_REQ;\n# 109 is PKINIT TD_DH_PARAMETERS; 133 is FAST PA-FX-COOKIE.)\nminbits_kdc_conf = {'realms': {'$realm': {'pkinit_dh_min_bits': '4096'}}}\nminbits_env = realm.special_env('restrict', True, kdc_conf=minbits_kdc_conf)\nrealm.stop_kdc()\nrealm.start_kdc(env=minbits_env)\nexpected_trace = ('Sending unauthenticated request',\n                  '/Additional pre-authentication required',\n                  'Preauthenticating using KDC method data',\n                  'Preauth module pkinit (16) (real) returned: 0/Success',\n                  'Produced preauth for next request: 133, 16',\n                  '/Key parameters not accepted',\n                  'Preauth tryagain input types (16): 109, 133',\n                  'trying again with KDC-provided parameters',\n                  'Preauth module pkinit (16) tryagain returned: 0/Success',\n                  'Followup preauth for next request: 16, 133')\nrealm.kinit(realm.user_princ,\n            flags=['-X', 'X509_user_identity=%s' % file_identity],\n            expected_trace=expected_trace)\nrealm.stop_kdc()\nrealm.start_kdc()\n\n# Run the basic test - PKINIT with FILE: identity, with a password on the key,\n# supplied by the prompter.\n# Expect failure if the responder does nothing, and we have no prompter.\nrealm.run(['./responder', '-x', 'pkinit={\"%s\": 0}' % file_enc_identity,\n          '-X', 'X509_user_identity=%s' % file_enc_identity, realm.user_princ],\n          expected_code=2)\nrealm.kinit(realm.user_princ,\n            flags=['-X', 'X509_user_identity=%s' % file_enc_identity],\n            password='encrypted')\nrealm.klist(realm.user_princ)\nrealm.run([kvno, realm.host_princ])\nrealm.run(['./adata', realm.host_princ],\n          expected_msg='+97: [indpkinit1, indpkinit2]')\n\n# Run the basic test - PKINIT with FILE: identity, with a password on the key,\n# supplied by the responder.\n# Supply the response in raw form.\nrealm.run(['./responder', '-x', 'pkinit={\"%s\": 0}' % file_enc_identity,\n           '-r', 'pkinit={\"%s\": \"encrypted\"}' % file_enc_identity,\n           '-X', 'X509_user_identity=%s' % file_enc_identity,\n           realm.user_princ])\n# Supply the response through the convenience API.\nrealm.run(['./responder', '-X', 'X509_user_identity=%s' % file_enc_identity,\n           '-p', '%s=%s' % (file_enc_identity, 'encrypted'), realm.user_princ])\nrealm.klist(realm.user_princ)\nrealm.run([kvno, realm.host_princ])\n\n# PKINIT with DIR: identity, with no password on the key.\nos.mkdir(path)\nos.mkdir(path_enc)\nshutil.copy(privkey_pem, os.path.join(path, 'user.key'))\nshutil.copy(privkey_enc_pem, os.path.join(path_enc, 'user.key'))\nshutil.copy(user_pem, os.path.join(path, 'user.crt'))\nshutil.copy(user_pem, os.path.join(path_enc, 'user.crt'))\nrealm.run(['./responder', '-x', 'pkinit=', '-X',\n           'X509_user_identity=%s' % dir_identity, realm.user_princ])\nrealm.kinit(realm.user_princ,\n            flags=['-X', 'X509_user_identity=%s' % dir_identity])\nrealm.klist(realm.user_princ)\nrealm.run([kvno, realm.host_princ])\n\n# PKINIT with DIR: identity, with a password on the key, supplied by the\n# prompter.\n# Expect failure if the responder does nothing, and we have no prompter.\nrealm.run(['./responder', '-x', 'pkinit={\"%s\": 0}' % dir_file_enc_identity,\n           '-X', 'X509_user_identity=%s' % dir_enc_identity, realm.user_princ],\n           expected_code=2)\nrealm.kinit(realm.user_princ,\n            flags=['-X', 'X509_user_identity=%s' % dir_enc_identity],\n            password='encrypted')\nrealm.klist(realm.user_princ)\nrealm.run([kvno, realm.host_princ])\n\n# PKINIT with DIR: identity, with a password on the key, supplied by the\n# responder.\n# Supply the response in raw form.\nrealm.run(['./responder', '-x', 'pkinit={\"%s\": 0}' % dir_file_enc_identity,\n           '-r', 'pkinit={\"%s\": \"encrypted\"}' % dir_file_enc_identity,\n           '-X', 'X509_user_identity=%s' % dir_enc_identity, realm.user_princ])\n# Supply the response through the convenience API.\nrealm.run(['./responder', '-X', 'X509_user_identity=%s' % dir_enc_identity,\n           '-p', '%s=%s' % (dir_file_enc_identity, 'encrypted'),\n           realm.user_princ])\nrealm.klist(realm.user_princ)\nrealm.run([kvno, realm.host_princ])\n\n# PKINIT with PKCS12: identity, with no password on the bundle.\nrealm.run(['./responder', '-x', 'pkinit=',\n           '-X', 'X509_user_identity=%s' % p12_identity, realm.user_princ])\nrealm.kinit(realm.user_princ,\n            flags=['-X', 'X509_user_identity=%s' % p12_identity])\nrealm.klist(realm.user_princ)\nrealm.run([kvno, realm.host_princ])\n\n# PKINIT with PKCS12: identity, with a password on the bundle, supplied by the\n# prompter.\n# Expect failure if the responder does nothing, and we have no prompter.\nrealm.run(['./responder', '-x', 'pkinit={\"%s\": 0}' % p12_enc_identity,\n           '-X', 'X509_user_identity=%s' % p12_enc_identity, realm.user_princ],\n           expected_code=2)\nrealm.kinit(realm.user_princ,\n            flags=['-X', 'X509_user_identity=%s' % p12_enc_identity],\n            password='encrypted')\nrealm.klist(realm.user_princ)\nrealm.run([kvno, realm.host_princ])\n\n# PKINIT with PKCS12: identity, with a password on the bundle, supplied by the\n# responder.\n# Supply the response in raw form.\nrealm.run(['./responder', '-x', 'pkinit={\"%s\": 0}' % p12_enc_identity,\n           '-r', 'pkinit={\"%s\": \"encrypted\"}' % p12_enc_identity,\n           '-X', 'X509_user_identity=%s' % p12_enc_identity, realm.user_princ])\n# Supply the response through the convenience API.\nrealm.run(['./responder', '-X', 'X509_user_identity=%s' % p12_enc_identity,\n           '-p', '%s=%s' % (p12_enc_identity, 'encrypted'),\n           realm.user_princ])\nrealm.klist(realm.user_princ)\nrealm.run([kvno, realm.host_princ])\n\n# Match a single rule.\nrule = '<SAN>^user@KRBTEST.COM$'\nrealm.run([kadminl, 'setstr', realm.user_princ, 'pkinit_cert_match', rule])\nrealm.kinit(realm.user_princ,\n            flags=['-X', 'X509_user_identity=%s' % p12_identity])\nrealm.klist(realm.user_princ)\n\n# Match a combined rule (default prefix is &&).\nrule = '<SUBJECT>CN=user$<KU>digitalSignature,keyEncipherment'\nrealm.run([kadminl, 'setstr', realm.user_princ, 'pkinit_cert_match', rule])\nrealm.kinit(realm.user_princ,\n            flags=['-X', 'X509_user_identity=%s' % p12_identity])\nrealm.klist(realm.user_princ)\n\n# Fail an && rule.\nrule = '&&<SUBJECT>O=OTHER.COM<SAN>^user@KRBTEST.COM$'\nrealm.run([kadminl, 'setstr', realm.user_princ, 'pkinit_cert_match', rule])\nmsg = 'kinit: Certificate mismatch while getting initial credentials'\nrealm.kinit(realm.user_princ,\n            flags=['-X', 'X509_user_identity=%s' % p12_identity],\n            expected_code=1, expected_msg=msg)\n\n# Pass an || rule.\nrule = '||<SUBJECT>O=KRBTEST.COM<SAN>^otheruser@KRBTEST.COM$'\nrealm.run([kadminl, 'setstr', realm.user_princ, 'pkinit_cert_match', rule])\nrealm.kinit(realm.user_princ,\n            flags=['-X', 'X509_user_identity=%s' % p12_identity])\nrealm.klist(realm.user_princ)\n\n# Fail an || rule.\nrule = '||<SUBJECT>O=OTHER.COM<SAN>^otheruser@KRBTEST.COM$'\nrealm.run([kadminl, 'setstr', realm.user_princ, 'pkinit_cert_match', rule])\nmsg = 'kinit: Certificate mismatch while getting initial credentials'\nrealm.kinit(realm.user_princ,\n            flags=['-X', 'X509_user_identity=%s' % p12_identity],\n            expected_code=1, expected_msg=msg)\n\nif not have_soft_pkcs11:\n    skip_rest('PKINIT PKCS11 tests', 'soft-pkcs11.so not found')\n\nsoftpkcs11rc = os.path.join(os.getcwd(), 'testdir', 'soft-pkcs11.rc')\nrealm.env['SOFTPKCS11RC'] = softpkcs11rc\n\n# PKINIT with PKCS11: identity, with no need for a PIN.\nconf = open(softpkcs11rc, 'w')\nconf.write(\"%s\\t%s\\t%s\\t%s\\n\" % ('user', 'user token', user_pem, privkey_pem))\nconf.close()\n# Expect to succeed without having to supply any more information.\nrealm.run(['./responder', '-x', 'pkinit=',\n           '-X', 'X509_user_identity=%s' % p11_identity, realm.user_princ])\nrealm.kinit(realm.user_princ,\n            flags=['-X', 'X509_user_identity=%s' % p11_identity])\nrealm.klist(realm.user_princ)\nrealm.run([kvno, realm.host_princ])\n\n# PKINIT with PKCS11: identity, with a PIN supplied by the prompter.\nos.remove(softpkcs11rc)\nconf = open(softpkcs11rc, 'w')\nconf.write(\"%s\\t%s\\t%s\\t%s\\n\" % ('user', 'user token', user_pem,\n                                 privkey_enc_pem))\nconf.close()\n# Expect failure if the responder does nothing, and there's no prompter\nrealm.run(['./responder', '-x', 'pkinit={\"%s\": 0}' % p11_token_identity,\n           '-X', 'X509_user_identity=%s' % p11_identity, realm.user_princ],\n          expected_code=2)\nrealm.kinit(realm.user_princ,\n            flags=['-X', 'X509_user_identity=%s' % p11_identity],\n            password='encrypted')\nrealm.klist(realm.user_princ)\nrealm.run([kvno, realm.host_princ])\n\n# Supply the wrong PIN, and verify that we ignore the draft9 padata offer\n# in the KDC method data after RFC 4556 PKINIT fails.\nexpected_trace = ('PKINIT client has no configured identity; giving up',\n                  'PKINIT client ignoring draft 9 offer from RFC 4556 KDC')\nrealm.kinit(realm.user_princ,\n            flags=['-X', 'X509_user_identity=%s' % p11_identity],\n            password='wrong', expected_code=1, expected_trace=expected_trace)\n\n# PKINIT with PKCS11: identity, with a PIN supplied by the responder.\n# Supply the response in raw form.\nrealm.run(['./responder', '-x', 'pkinit={\"%s\": 0}' % p11_token_identity,\n           '-r', 'pkinit={\"%s\": \"encrypted\"}' % p11_token_identity,\n           '-X', 'X509_user_identity=%s' % p11_identity, realm.user_princ])\n# Supply the response through the convenience API.\nrealm.run(['./responder', '-X', 'X509_user_identity=%s' % p11_identity,\n           '-p', '%s=%s' % (p11_token_identity, 'encrypted'),\n           realm.user_princ])\nrealm.klist(realm.user_princ)\nrealm.run([kvno, realm.host_princ])\n\nsuccess('PKINIT tests')\n", "target": 1}
{"idx": 950, "func": "# -*- coding: utf-8 -*-\n\n\"\"\"Simple security for Flask apps.\"\"\"\n\nimport io\nimport re\nfrom setuptools import find_packages, setup\n\nwith io.open(\"README.rst\", \"rt\", encoding=\"utf8\") as f:\n    readme = f.read()\n\nwith io.open(\"flask_security/__init__.py\", \"rt\", encoding=\"utf8\") as f:\n    version = re.search(r'__version__ = \"(.*?)\"', f.read()).group(1)\n\ntests_require = [\n    \"Flask-Mongoengine>=0.9.5\",\n    \"peewee>=3.11.2\",\n    \"Flask-SQLAlchemy>=2.3\",\n    \"argon2_cffi>=19.1.0\",\n    \"bcrypt>=3.1.5\",\n    \"cachetools>=3.1.0\",\n    \"check-manifest>=0.25\",\n    \"coverage>=4.5.4\",\n    \"cryptography>=2.3.1\",\n    \"isort>=4.2.2\",\n    \"mock>=1.3.0\",\n    \"mongoengine>=0.15.3\",\n    \"mongomock>=3.14.0\",\n    \"msgcheck>=2.9\",\n    \"pony>=0.7.11\",\n    \"phonenumberslite>=8.11.1\",\n    \"psycopg2>=2.8.4\",\n    \"pydocstyle>=1.0.0\",\n    \"pymysql>=0.9.3\",\n    \"pyqrcode>=1.2\",\n    \"pytest==4.6.11\",\n    \"pytest-black>=0.3.8\",\n    \"pytest-cache>=1.0\",\n    \"pytest-cov>=2.5.1\",\n    \"pytest-flake8>=1.0.6\",\n    \"pytest-mongo>=1.2.1\",\n    \"pytest>=3.5.1\",\n    \"sqlalchemy>=1.2.6\",\n    \"sqlalchemy-utils>=0.33.0\",\n    \"werkzeug>=0.15.5\",\n    \"zxcvbn~=4.4.28\",\n]\n\nextras_require = {\n    \"docs\": [\"Pallets-Sphinx-Themes>=1.2.0\", \"Sphinx>=1.8.5\", \"sphinx-issues>=1.2.0\"],\n    \"tests\": tests_require,\n}\n\nextras_require[\"all\"] = []\nfor reqs in extras_require.values():\n    extras_require[\"all\"].extend(reqs)\n\nsetup_requires = [\"Babel>=1.3\", \"pytest-runner>=2.6.2\", \"twine\", \"wheel\"]\n\ninstall_requires = [\n    \"Flask>=1.0.2\",\n    \"Flask-Login>=0.4.1\",\n    \"Flask-Mail>=0.9.1\",\n    \"Flask-Principal>=0.4.0\",\n    \"Flask-WTF>=0.14.2\",\n    \"Flask-BabelEx>=0.9.3\",\n    \"email-validator>=1.0.5\",\n    \"itsdangerous>=1.1.0\",\n    \"passlib>=1.7.1\",\n]\n\npackages = find_packages()\n\nsetup(\n    name=\"Flask-Security-Too\",\n    version=version,\n    description=__doc__,\n    long_description=readme,\n    keywords=\"flask security\",\n    license=\"MIT\",\n    author=\"Matt Wright & Chris Wagner\",\n    author_email=\"jwag.wagner+github@gmail.com\",\n    url=\"https://github.com/Flask-Middleware/flask-security\",\n    project_urls={\n        \"Documentation\": \"https://flask-security-too.readthedocs.io\",\n        \"Releases\": \"https://pypi.org/project/Flask-Security-Too/\",\n        \"Code\": \"https://github.com/Flask-Middleware/flask-security\",\n        \"Issue tracker\": \"https://github.com/Flask-Middleware/flask-security/issues\",\n    },\n    packages=packages,\n    zip_safe=False,\n    include_package_data=True,\n    platforms=\"any\",\n    python_requires=\">=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*\",\n    extras_require=extras_require,\n    install_requires=install_requires,\n    setup_requires=setup_requires,\n    tests_require=tests_require,\n    classifiers=[\n        \"Environment :: Web Environment\",\n        \"Framework :: Flask\",\n        \"Intended Audience :: Developers\",\n        \"License :: OSI Approved :: MIT License\",\n        \"Operating System :: OS Independent\",\n        \"Programming Language :: Python\",\n        \"Topic :: Internet :: WWW/HTTP :: Dynamic Content\",\n        \"Topic :: Software Development :: Libraries :: Python Modules\",\n        \"Programming Language :: Python :: 2\",\n        \"Programming Language :: Python :: 2.7\",\n        \"Programming Language :: Python :: 3\",\n        \"Programming Language :: Python :: 3.5\",\n        \"Programming Language :: Python :: 3.6\",\n        \"Programming Language :: Python :: 3.7\",\n        \"Programming Language :: Python :: 3.8\",\n        \"Programming Language :: Python :: Implementation :: CPython\",\n        \"Programming Language :: Python :: Implementation :: PyPy\",\n        \"Development Status :: 4 - Beta\",\n    ],\n)\n", "target": 1}
{"idx": 951, "func": "import operator\nfrom functools import partial\nfrom typing import TYPE_CHECKING, Any, Dict, Iterable, Optional, Tuple\n\nfrom pypika import Table\nfrom pypika.functions import Upper\nfrom pypika.terms import BasicCriterion, Criterion, Equality, Term, ValueWrapper\n\nfrom tortoise.fields import Field\nfrom tortoise.fields.relational import BackwardFKRelation, ManyToManyFieldInstance\n\nif TYPE_CHECKING:  # pragma: nocoverage\n    from tortoise.models import Model\n\n##############################################################################\n# Encoders\n# Should be type: (Any, instance: \"Model\", field: Field) -> type:\n##############################################################################\n\n\ndef list_encoder(values: Iterable[Any], instance: \"Model\", field: Field) -> list:\n    \"\"\"Encodes an iterable of a given field into a database-compatible format.\"\"\"\n    return [field.to_db_value(element, instance) for element in values]\n\n\ndef related_list_encoder(values: Iterable[Any], instance: \"Model\", field: Field) -> list:\n    return [\n        field.to_db_value(element.pk if hasattr(element, \"pk\") else element, instance)\n        for element in values\n    ]\n\n\ndef bool_encoder(value: Any, instance: \"Model\", field: Field) -> bool:\n    return bool(value)\n\n\ndef string_encoder(value: Any, instance: \"Model\", field: Field) -> str:\n    return str(value)\n\n\n##############################################################################\n# Operators\n# Should be type: (field: Term, value: Any) -> Criterion:\n##############################################################################\n\n\ndef is_in(field: Term, value: Any) -> Criterion:\n    if value:\n        return field.isin(value)\n    # SQL has no False, so we return 1=0\n    return BasicCriterion(Equality.eq, ValueWrapper(1), ValueWrapper(0))\n\n\ndef not_in(field: Term, value: Any) -> Criterion:\n    if value:\n        return field.notin(value) | field.isnull()\n    # SQL has no True, so we return 1=1\n    return BasicCriterion(Equality.eq, ValueWrapper(1), ValueWrapper(1))\n\n\ndef between_and(field: Term, value: Tuple[Any, Any]) -> Criterion:\n    return field.between(value[0], value[1])\n\n\ndef not_equal(field: Term, value: Any) -> Criterion:\n    return field.ne(value) | field.isnull()\n\n\ndef is_null(field: Term, value: Any) -> Criterion:\n    if value:\n        return field.isnull()\n    return field.notnull()\n\n\ndef not_null(field: Term, value: Any) -> Criterion:\n    if value:\n        return field.notnull()\n    return field.isnull()\n\n\ndef contains(field: Term, value: str) -> Criterion:\n    return field.like(f\"%{value}%\")\n\n\ndef starts_with(field: Term, value: str) -> Criterion:\n    return field.like(f\"{value}%\")\n\n\ndef ends_with(field: Term, value: str) -> Criterion:\n    return field.like(f\"%{value}\")\n\n\ndef insensitive_exact(field: Term, value: str) -> Criterion:\n    return Upper(field).eq(Upper(f\"{value}\"))\n\n\ndef insensitive_contains(field: Term, value: str) -> Criterion:\n    return Upper(field).like(Upper(f\"%{value}%\"))\n\n\ndef insensitive_starts_with(field: Term, value: str) -> Criterion:\n    return Upper(field).like(Upper(f\"{value}%\"))\n\n\ndef insensitive_ends_with(field: Term, value: str) -> Criterion:\n    return Upper(field).like(Upper(f\"%{value}\"))\n\n\n##############################################################################\n# Filter resolvers\n##############################################################################\n\n\ndef get_m2m_filters(field_name: str, field: ManyToManyFieldInstance) -> Dict[str, dict]:\n    target_table_pk = field.related_model._meta.pk\n    return {\n        field_name: {\n            \"field\": field.forward_key,\n            \"backward_key\": field.backward_key,\n            \"operator\": operator.eq,\n            \"table\": Table(field.through),\n            \"value_encoder\": target_table_pk.to_db_value,\n        },\n        f\"{field_name}__not\": {\n            \"field\": field.forward_key,\n            \"backward_key\": field.backward_key,\n            \"operator\": not_equal,\n            \"table\": Table(field.through),\n            \"value_encoder\": target_table_pk.to_db_value,\n        },\n        f\"{field_name}__in\": {\n            \"field\": field.forward_key,\n            \"backward_key\": field.backward_key,\n            \"operator\": is_in,\n            \"table\": Table(field.through),\n            \"value_encoder\": partial(related_list_encoder, field=target_table_pk),\n        },\n        f\"{field_name}__not_in\": {\n            \"field\": field.forward_key,\n            \"backward_key\": field.backward_key,\n            \"operator\": not_in,\n            \"table\": Table(field.through),\n            \"value_encoder\": partial(related_list_encoder, field=target_table_pk),\n        },\n    }\n\n\ndef get_backward_fk_filters(field_name: str, field: BackwardFKRelation) -> Dict[str, dict]:\n    target_table_pk = field.related_model._meta.pk\n    return {\n        field_name: {\n            \"field\": field.related_model._meta.pk_attr,\n            \"backward_key\": field.relation_field,\n            \"operator\": operator.eq,\n            \"table\": Table(field.related_model._meta.db_table),\n            \"value_encoder\": target_table_pk.to_db_value,\n        },\n        f\"{field_name}__not\": {\n            \"field\": field.related_model._meta.pk_attr,\n            \"backward_key\": field.relation_field,\n            \"operator\": not_equal,\n            \"table\": Table(field.related_model._meta.db_table),\n            \"value_encoder\": target_table_pk.to_db_value,\n        },\n        f\"{field_name}__in\": {\n            \"field\": field.related_model._meta.pk_attr,\n            \"backward_key\": field.relation_field,\n            \"operator\": is_in,\n            \"table\": Table(field.related_model._meta.db_table),\n            \"value_encoder\": partial(related_list_encoder, field=target_table_pk),\n        },\n        f\"{field_name}__not_in\": {\n            \"field\": field.related_model._meta.pk_attr,\n            \"backward_key\": field.relation_field,\n            \"operator\": not_in,\n            \"table\": Table(field.related_model._meta.db_table),\n            \"value_encoder\": partial(related_list_encoder, field=target_table_pk),\n        },\n    }\n\n\ndef get_filters_for_field(\n    field_name: str, field: Optional[Field], source_field: str\n) -> Dict[str, dict]:\n    if isinstance(field, ManyToManyFieldInstance):\n        return get_m2m_filters(field_name, field)\n    if isinstance(field, BackwardFKRelation):\n        return get_backward_fk_filters(field_name, field)\n    actual_field_name = field_name\n    if field_name == \"pk\" and field:\n        actual_field_name = field.model_field_name\n    return {\n        field_name: {\n            \"field\": actual_field_name,\n            \"source_field\": source_field,\n            \"operator\": operator.eq,\n        },\n        f\"{field_name}__not\": {\n            \"field\": actual_field_name,\n            \"source_field\": source_field,\n            \"operator\": not_equal,\n        },\n        f\"{field_name}__in\": {\n            \"field\": actual_field_name,\n            \"source_field\": source_field,\n            \"operator\": is_in,\n            \"value_encoder\": list_encoder,\n        },\n        f\"{field_name}__not_in\": {\n            \"field\": actual_field_name,\n            \"source_field\": source_field,\n            \"operator\": not_in,\n            \"value_encoder\": list_encoder,\n        },\n        f\"{field_name}__isnull\": {\n            \"field\": actual_field_name,\n            \"source_field\": source_field,\n            \"operator\": is_null,\n            \"value_encoder\": bool_encoder,\n        },\n        f\"{field_name}__not_isnull\": {\n            \"field\": actual_field_name,\n            \"source_field\": source_field,\n            \"operator\": not_null,\n            \"value_encoder\": bool_encoder,\n        },\n        f\"{field_name}__gte\": {\n            \"field\": actual_field_name,\n            \"source_field\": source_field,\n            \"operator\": operator.ge,\n        },\n        f\"{field_name}__lte\": {\n            \"field\": actual_field_name,\n            \"source_field\": source_field,\n            \"operator\": operator.le,\n        },\n        f\"{field_name}__gt\": {\n            \"field\": actual_field_name,\n            \"source_field\": source_field,\n            \"operator\": operator.gt,\n        },\n        f\"{field_name}__lt\": {\n            \"field\": actual_field_name,\n            \"source_field\": source_field,\n            \"operator\": operator.lt,\n        },\n        f\"{field_name}__range\": {\n            \"field\": actual_field_name,\n            \"source_field\": source_field,\n            \"operator\": between_and,\n            \"value_encoder\": list_encoder,\n        },\n        f\"{field_name}__contains\": {\n            \"field\": actual_field_name,\n            \"source_field\": source_field,\n            \"operator\": contains,\n            \"value_encoder\": string_encoder,\n        },\n        f\"{field_name}__startswith\": {\n            \"field\": actual_field_name,\n            \"source_field\": source_field,\n            \"operator\": starts_with,\n            \"value_encoder\": string_encoder,\n        },\n        f\"{field_name}__endswith\": {\n            \"field\": actual_field_name,\n            \"source_field\": source_field,\n            \"operator\": ends_with,\n            \"value_encoder\": string_encoder,\n        },\n        f\"{field_name}__iexact\": {\n            \"field\": actual_field_name,\n            \"source_field\": source_field,\n            \"operator\": insensitive_exact,\n            \"value_encoder\": string_encoder,\n        },\n        f\"{field_name}__icontains\": {\n            \"field\": actual_field_name,\n            \"source_field\": source_field,\n            \"operator\": insensitive_contains,\n            \"value_encoder\": string_encoder,\n        },\n        f\"{field_name}__istartswith\": {\n            \"field\": actual_field_name,\n            \"source_field\": source_field,\n            \"operator\": insensitive_starts_with,\n            \"value_encoder\": string_encoder,\n        },\n        f\"{field_name}__iendswith\": {\n            \"field\": actual_field_name,\n            \"source_field\": source_field,\n            \"operator\": insensitive_ends_with,\n            \"value_encoder\": string_encoder,\n        },\n    }\n", "target": 1}
{"idx": 952, "func": "# Copyright (C) 2016 JWCrypto Project Contributors - see LICENSE file\n\nimport abc\nimport os\nimport struct\nfrom binascii import hexlify, unhexlify\n\nfrom cryptography.exceptions import InvalidSignature\nfrom cryptography.hazmat.backends import default_backend\nfrom cryptography.hazmat.primitives import constant_time, hashes, hmac\nfrom cryptography.hazmat.primitives.asymmetric import ec\nfrom cryptography.hazmat.primitives.asymmetric import padding\nfrom cryptography.hazmat.primitives.asymmetric import utils as ec_utils\nfrom cryptography.hazmat.primitives.ciphers import Cipher, algorithms, modes\nfrom cryptography.hazmat.primitives.kdf.concatkdf import ConcatKDFHash\nfrom cryptography.hazmat.primitives.kdf.pbkdf2 import PBKDF2HMAC\nfrom cryptography.hazmat.primitives.padding import PKCS7\n\nimport six\n\nfrom jwcrypto.common import InvalidCEKeyLength\nfrom jwcrypto.common import InvalidJWAAlgorithm\nfrom jwcrypto.common import InvalidJWEKeyLength\nfrom jwcrypto.common import InvalidJWEKeyType\nfrom jwcrypto.common import InvalidJWEOperation\nfrom jwcrypto.common import base64url_decode, base64url_encode\nfrom jwcrypto.common import json_decode\nfrom jwcrypto.jwk import JWK\n\n# Implements RFC 7518 - JSON Web Algorithms (JWA)\n\n\n@six.add_metaclass(abc.ABCMeta)\nclass JWAAlgorithm(object):\n\n    @abc.abstractproperty\n    def name(self):\n        \"\"\"The algorithm Name\"\"\"\n        pass\n\n    @abc.abstractproperty\n    def description(self):\n        \"\"\"A short description\"\"\"\n        pass\n\n    @abc.abstractproperty\n    def keysize(self):\n        \"\"\"The actual/recommended/minimum key size\"\"\"\n        pass\n\n    @abc.abstractproperty\n    def algorithm_usage_location(self):\n        \"\"\"One of 'alg', 'enc' or 'JWK'\"\"\"\n        pass\n\n    @abc.abstractproperty\n    def algorithm_use(self):\n        \"\"\"One of 'sig', 'kex', 'enc'\"\"\"\n        pass\n\n\ndef _bitsize(x):\n    return len(x) * 8\n\n\ndef _inbytes(x):\n    return x // 8\n\n\ndef _randombits(x):\n    if x % 8 != 0:\n        raise ValueError(\"lenght must be a multiple of 8\")\n    return os.urandom(_inbytes(x))\n\n\n# Note: the number of bits should be a multiple of 16\ndef _encode_int(n, bits):\n    e = '{:x}'.format(n)\n    ilen = ((bits + 7) // 8) * 2  # number of bytes rounded up times 2 bytes\n    return unhexlify(e.rjust(ilen, '0')[:ilen])\n\n\ndef _decode_int(n):\n    return int(hexlify(n), 16)\n\n\nclass _RawJWS(object):\n\n    def sign(self, key, payload):\n        raise NotImplementedError\n\n    def verify(self, key, payload, signature):\n        raise NotImplementedError\n\n\nclass _RawHMAC(_RawJWS):\n\n    def __init__(self, hashfn):\n        self.backend = default_backend()\n        self.hashfn = hashfn\n\n    def _hmac_setup(self, key, payload):\n        h = hmac.HMAC(key, self.hashfn, backend=self.backend)\n        h.update(payload)\n        return h\n\n    def sign(self, key, payload):\n        skey = base64url_decode(key.get_op_key('sign'))\n        h = self._hmac_setup(skey, payload)\n        return h.finalize()\n\n    def verify(self, key, payload, signature):\n        vkey = base64url_decode(key.get_op_key('verify'))\n        h = self._hmac_setup(vkey, payload)\n        h.verify(signature)\n\n\nclass _RawRSA(_RawJWS):\n    def __init__(self, padfn, hashfn):\n        self.padfn = padfn\n        self.hashfn = hashfn\n\n    def sign(self, key, payload):\n        skey = key.get_op_key('sign')\n        signer = skey.signer(self.padfn, self.hashfn)\n        signer.update(payload)\n        return signer.finalize()\n\n    def verify(self, key, payload, signature):\n        pkey = key.get_op_key('verify')\n        verifier = pkey.verifier(signature, self.padfn, self.hashfn)\n        verifier.update(payload)\n        verifier.verify()\n\n\nclass _RawEC(_RawJWS):\n    def __init__(self, curve, hashfn):\n        self._curve = curve\n        self.hashfn = hashfn\n\n    @property\n    def curve(self):\n        return self._curve\n\n    def sign(self, key, payload):\n        skey = key.get_op_key('sign', self._curve)\n        signer = skey.signer(ec.ECDSA(self.hashfn))\n        signer.update(payload)\n        signature = signer.finalize()\n        r, s = ec_utils.decode_rfc6979_signature(signature)\n        l = key.get_curve(self._curve).key_size\n        return _encode_int(r, l) + _encode_int(s, l)\n\n    def verify(self, key, payload, signature):\n        pkey = key.get_op_key('verify', self._curve)\n        r = signature[:len(signature) // 2]\n        s = signature[len(signature) // 2:]\n        enc_signature = ec_utils.encode_rfc6979_signature(\n            int(hexlify(r), 16), int(hexlify(s), 16))\n        verifier = pkey.verifier(enc_signature, ec.ECDSA(self.hashfn))\n        verifier.update(payload)\n        verifier.verify()\n\n\nclass _RawNone(_RawJWS):\n\n    def sign(self, key, payload):\n        return ''\n\n    def verify(self, key, payload, signature):\n        raise InvalidSignature('The \"none\" signature cannot be verified')\n\n\nclass _HS256(_RawHMAC, JWAAlgorithm):\n\n    name = \"HS256\"\n    description = \"HMAC using SHA-256\"\n    keysize = 256\n    algorithm_usage_location = 'alg'\n    algorithm_use = 'sig'\n\n    def __init__(self):\n        super(_HS256, self).__init__(hashes.SHA256())\n\n\nclass _HS384(_RawHMAC, JWAAlgorithm):\n\n    name = \"HS384\"\n    description = \"HMAC using SHA-384\"\n    keysize = 384\n    algorithm_usage_location = 'alg'\n    algorithm_use = 'sig'\n\n    def __init__(self):\n        super(_HS384, self).__init__(hashes.SHA384())\n\n\nclass _HS512(_RawHMAC, JWAAlgorithm):\n\n    name = \"HS512\"\n    description = \"HMAC using SHA-512\"\n    keysize = 512\n    algorithm_usage_location = 'alg'\n    algorithm_use = 'sig'\n\n    def __init__(self):\n        super(_HS512, self).__init__(hashes.SHA512())\n\n\nclass _RS256(_RawRSA, JWAAlgorithm):\n\n    name = \"RS256\"\n    description = \"RSASSA-PKCS1-v1_5 using SHA-256\"\n    keysize = 2048\n    algorithm_usage_location = 'alg'\n    algorithm_use = 'sig'\n\n    def __init__(self):\n        super(_RS256, self).__init__(padding.PKCS1v15(), hashes.SHA256())\n\n\nclass _RS384(_RawRSA, JWAAlgorithm):\n\n    name = \"RS384\"\n    description = \"RSASSA-PKCS1-v1_5 using SHA-384\"\n    keysize = 2048\n    algorithm_usage_location = 'alg'\n    algorithm_use = 'sig'\n\n    def __init__(self):\n        super(_RS384, self).__init__(padding.PKCS1v15(), hashes.SHA384())\n\n\nclass _RS512(_RawRSA, JWAAlgorithm):\n\n    name = \"RS512\"\n    description = \"RSASSA-PKCS1-v1_5 using SHA-512\"\n    keysize = 2048\n    algorithm_usage_location = 'alg'\n    algorithm_use = 'sig'\n\n    def __init__(self):\n        super(_RS512, self).__init__(padding.PKCS1v15(), hashes.SHA512())\n\n\nclass _ES256(_RawEC, JWAAlgorithm):\n\n    name = \"ES256\"\n    description = \"ECDSA using P-256 and SHA-256\"\n    keysize = 256\n    algorithm_usage_location = 'alg'\n    algorithm_use = 'sig'\n\n    def __init__(self):\n        super(_ES256, self).__init__('P-256', hashes.SHA256())\n\n\nclass _ES384(_RawEC, JWAAlgorithm):\n\n    name = \"ES384\"\n    description = \"ECDSA using P-384 and SHA-384\"\n    keysize = 384\n    algorithm_usage_location = 'alg'\n    algorithm_use = 'sig'\n\n    def __init__(self):\n        super(_ES384, self).__init__('P-384', hashes.SHA384())\n\n\nclass _ES512(_RawEC, JWAAlgorithm):\n\n    name = \"ES512\"\n    description = \"ECDSA using P-521 and SHA-512\"\n    keysize = 512\n    algorithm_usage_location = 'alg'\n    algorithm_use = 'sig'\n\n    def __init__(self):\n        super(_ES512, self).__init__('P-521', hashes.SHA512())\n\n\nclass _PS256(_RawRSA, JWAAlgorithm):\n\n    name = \"PS256\"\n    description = \"RSASSA-PSS using SHA-256 and MGF1 with SHA-256\"\n    keysize = 2048\n    algorithm_usage_location = 'alg'\n    algorithm_use = 'sig'\n\n    def __init__(self):\n        padfn = padding.PSS(padding.MGF1(hashes.SHA256()),\n                            hashes.SHA256.digest_size)\n        super(_PS256, self).__init__(padfn, hashes.SHA256())\n\n\nclass _PS384(_RawRSA, JWAAlgorithm):\n\n    name = \"PS384\"\n    description = \"RSASSA-PSS using SHA-384 and MGF1 with SHA-384\"\n    keysize = 2048\n    algorithm_usage_location = 'alg'\n    algorithm_use = 'sig'\n\n    def __init__(self):\n        padfn = padding.PSS(padding.MGF1(hashes.SHA384()),\n                            hashes.SHA384.digest_size)\n        super(_PS384, self).__init__(padfn, hashes.SHA384())\n\n\nclass _PS512(_RawRSA, JWAAlgorithm):\n\n    name = \"PS512\"\n    description = \"RSASSA-PSS using SHA-512 and MGF1 with SHA-512\"\n    keysize = 2048\n    algorithm_usage_location = 'alg'\n    algorithm_use = 'sig'\n\n    def __init__(self):\n        padfn = padding.PSS(padding.MGF1(hashes.SHA512()),\n                            hashes.SHA512.digest_size)\n        super(_PS512, self).__init__(padfn, hashes.SHA512())\n\n\nclass _None(_RawNone, JWAAlgorithm):\n\n    name = \"none\"\n    description = \"No digital signature or MAC performed\"\n    keysize = 0\n    algorithm_usage_location = 'alg'\n    algorithm_use = 'sig'\n\n\nclass _RawKeyMgmt(object):\n\n    def wrap(self, key, bitsize, cek, headers):\n        raise NotImplementedError\n\n    def unwrap(self, key, bitsize, ek, headers):\n        raise NotImplementedError\n\n\nclass _RSA(_RawKeyMgmt):\n\n    def __init__(self, padfn):\n        self.padfn = padfn\n\n    def _check_key(self, key):\n        if not isinstance(key, JWK):\n            raise ValueError('key is not a JWK object')\n        if key.key_type != 'RSA':\n            raise InvalidJWEKeyType('RSA', key.key_type)\n\n    # FIXME: get key size and insure > 2048 bits\n    def wrap(self, key, bitsize, cek, headers):\n        self._check_key(key)\n        if not cek:\n            cek = _randombits(bitsize)\n        rk = key.get_op_key('wrapKey')\n        ek = rk.encrypt(cek, self.padfn)\n        return {'cek': cek, 'ek': ek}\n\n    def unwrap(self, key, bitsize, ek, headers):\n        self._check_key(key)\n        rk = key.get_op_key('decrypt')\n        cek = rk.decrypt(ek, self.padfn)\n        if _bitsize(cek) != bitsize:\n            raise InvalidJWEKeyLength(bitsize, _bitsize(cek))\n        return cek\n\n\nclass _Rsa15(_RSA, JWAAlgorithm):\n\n    name = 'RSA1_5'\n    description = \"RSAES-PKCS1-v1_5\"\n    keysize = 2048\n    algorithm_usage_location = 'alg'\n    algorithm_use = 'kex'\n\n    def __init__(self):\n        super(_Rsa15, self).__init__(padding.PKCS1v15())\n\n\nclass _RsaOaep(_RSA, JWAAlgorithm):\n\n    name = 'RSA-OAEP'\n    description = \"RSAES OAEP using default parameters\"\n    keysize = 2048\n    algorithm_usage_location = 'alg'\n    algorithm_use = 'kex'\n\n    def __init__(self):\n        super(_RsaOaep, self).__init__(\n            padding.OAEP(padding.MGF1(hashes.SHA1()),\n                         hashes.SHA1(), None))\n\n\nclass _RsaOaep256(_RSA, JWAAlgorithm):  # noqa: ignore=N801\n\n    name = 'RSA-OAEP-256'\n    description = \"RSAES OAEP using SHA-256 and MGF1 with SHA-256\"\n    keysize = 2048\n    algorithm_usage_location = 'alg'\n    algorithm_use = 'kex'\n\n    def __init__(self):\n        super(_RsaOaep256, self).__init__(\n            padding.OAEP(padding.MGF1(hashes.SHA256()),\n                         hashes.SHA256(), None))\n\n\nclass _AesKw(_RawKeyMgmt):\n\n    keysize = None\n\n    def __init__(self):\n        self.backend = default_backend()\n\n    def _get_key(self, key, op):\n        if not isinstance(key, JWK):\n            raise ValueError('key is not a JWK object')\n        if key.key_type != 'oct':\n            raise InvalidJWEKeyType('oct', key.key_type)\n        rk = base64url_decode(key.get_op_key(op))\n        if _bitsize(rk) != self.keysize:\n            raise InvalidJWEKeyLength(self.keysize, _bitsize(rk))\n        return rk\n\n    def wrap(self, key, bitsize, cek, headers):\n        rk = self._get_key(key, 'encrypt')\n        if not cek:\n            cek = _randombits(bitsize)\n\n        # Implement RFC 3394 Key Unwrap - 2.2.2\n        # TODO: Use cryptography once issue #1733 is resolved\n        iv = 'a6a6a6a6a6a6a6a6'\n        a = unhexlify(iv)\n        r = [cek[i:i + 8] for i in range(0, len(cek), 8)]\n        n = len(r)\n        for j in range(0, 6):\n            for i in range(0, n):\n                e = Cipher(algorithms.AES(rk), modes.ECB(),\n                           backend=self.backend).encryptor()\n                b = e.update(a + r[i]) + e.finalize()\n                a = _encode_int(_decode_int(b[:8]) ^ ((n * j) + i + 1), 64)\n                r[i] = b[-8:]\n        ek = a\n        for i in range(0, n):\n            ek += r[i]\n        return {'cek': cek, 'ek': ek}\n\n    def unwrap(self, key, bitsize, ek, headers):\n        rk = self._get_key(key, 'decrypt')\n\n        # Implement RFC 3394 Key Unwrap - 2.2.3\n        # TODO: Use cryptography once issue #1733 is resolved\n        iv = 'a6a6a6a6a6a6a6a6'\n        aiv = unhexlify(iv)\n\n        r = [ek[i:i + 8] for i in range(0, len(ek), 8)]\n        a = r.pop(0)\n        n = len(r)\n        for j in range(5, -1, -1):\n            for i in range(n - 1, -1, -1):\n                da = _decode_int(a)\n                atr = _encode_int((da ^ ((n * j) + i + 1)), 64) + r[i]\n                d = Cipher(algorithms.AES(rk), modes.ECB(),\n                           backend=self.backend).decryptor()\n                b = d.update(atr) + d.finalize()\n                a = b[:8]\n                r[i] = b[-8:]\n\n        if a != aiv:\n            raise RuntimeError('Decryption Failed')\n\n        cek = b''.join(r)\n        if _bitsize(cek) != bitsize:\n            raise InvalidJWEKeyLength(bitsize, _bitsize(cek))\n        return cek\n\n\nclass _A128KW(_AesKw, JWAAlgorithm):\n\n    name = 'A128KW'\n    description = \"AES Key Wrap using 128-bit key\"\n    keysize = 128\n    algorithm_usage_location = 'alg'\n    algorithm_use = 'kex'\n\n\nclass _A192KW(_AesKw, JWAAlgorithm):\n\n    name = 'A192KW'\n    description = \"AES Key Wrap using 192-bit key\"\n    keysize = 192\n    algorithm_usage_location = 'alg'\n    algorithm_use = 'kex'\n\n\nclass _A256KW(_AesKw, JWAAlgorithm):\n\n    name = 'A256KW'\n    description = \"AES Key Wrap using 256-bit key\"\n    keysize = 256\n    algorithm_usage_location = 'alg'\n    algorithm_use = 'kex'\n\n\nclass _AesGcmKw(_RawKeyMgmt):\n\n    keysize = None\n\n    def __init__(self):\n        self.backend = default_backend()\n\n    def _get_key(self, key, op):\n        if not isinstance(key, JWK):\n            raise ValueError('key is not a JWK object')\n        if key.key_type != 'oct':\n            raise InvalidJWEKeyType('oct', key.key_type)\n        rk = base64url_decode(key.get_op_key(op))\n        if _bitsize(rk) != self.keysize:\n            raise InvalidJWEKeyLength(self.keysize, _bitsize(rk))\n        return rk\n\n    def wrap(self, key, bitsize, cek, headers):\n        rk = self._get_key(key, 'encrypt')\n        if not cek:\n            cek = _randombits(bitsize)\n\n        iv = _randombits(96)\n        cipher = Cipher(algorithms.AES(rk), modes.GCM(iv),\n                        backend=self.backend)\n        encryptor = cipher.encryptor()\n        ek = encryptor.update(cek) + encryptor.finalize()\n\n        tag = encryptor.tag\n        return {'cek': cek, 'ek': ek,\n                'header': {'iv': base64url_encode(iv),\n                           'tag': base64url_encode(tag)}}\n\n    def unwrap(self, key, bitsize, ek, headers):\n        rk = self._get_key(key, 'decrypt')\n\n        if 'iv' not in headers:\n            raise ValueError('Invalid Header, missing \"iv\" parameter')\n        iv = base64url_decode(headers['iv'])\n        if 'tag' not in headers:\n            raise ValueError('Invalid Header, missing \"tag\" parameter')\n        tag = base64url_decode(headers['tag'])\n\n        cipher = Cipher(algorithms.AES(rk), modes.GCM(iv, tag),\n                        backend=self.backend)\n        decryptor = cipher.decryptor()\n        cek = decryptor.update(ek) + decryptor.finalize()\n        if _bitsize(cek) != bitsize:\n            raise InvalidJWEKeyLength(bitsize, _bitsize(cek))\n        return cek\n\n\nclass _A128GcmKw(_AesGcmKw, JWAAlgorithm):\n\n    name = 'A128GCMKW'\n    description = \"Key wrapping with AES GCM using 128-bit key\"\n    keysize = 128\n    algorithm_usage_location = 'alg'\n    algorithm_use = 'kex'\n\n\nclass _A192GcmKw(_AesGcmKw, JWAAlgorithm):\n\n    name = 'A192GCMKW'\n    description = \"Key wrapping with AES GCM using 192-bit key\"\n    keysize = 192\n    algorithm_usage_location = 'alg'\n    algorithm_use = 'kex'\n\n\nclass _A256GcmKw(_AesGcmKw, JWAAlgorithm):\n\n    name = 'A256GCMKW'\n    description = \"Key wrapping with AES GCM using 256-bit key\"\n    keysize = 256\n    algorithm_usage_location = 'alg'\n    algorithm_use = 'kex'\n\n\nclass _Pbes2HsAesKw(_RawKeyMgmt):\n\n    name = None\n    keysize = None\n    hashsize = None\n\n    def __init__(self):\n        self.backend = default_backend()\n        self.aeskwmap = {128: _A128KW, 192: _A192KW, 256: _A256KW}\n\n    def _get_key(self, alg, key, p2s, p2c):\n        if isinstance(key, bytes):\n            plain = key\n        else:\n            plain = key.encode('utf8')\n        salt = bytes(self.name.encode('utf8')) + b'\\x00' + p2s\n\n        if self.hashsize == 256:\n            hashalg = hashes.SHA256()\n        elif self.hashsize == 384:\n            hashalg = hashes.SHA384()\n        elif self.hashsize == 512:\n            hashalg = hashes.SHA512()\n        else:\n            raise ValueError('Unknown Hash Size')\n\n        kdf = PBKDF2HMAC(algorithm=hashalg, length=_inbytes(self.keysize),\n                         salt=salt, iterations=p2c, backend=self.backend)\n        rk = kdf.derive(plain)\n        if _bitsize(rk) != self.keysize:\n            raise InvalidJWEKeyLength(self.keysize, len(rk))\n        return JWK(kty=\"oct\", use=\"enc\", k=base64url_encode(rk))\n\n    def wrap(self, key, bitsize, cek, headers):\n        p2s = _randombits(128)\n        p2c = 8192\n        kek = self._get_key(headers['alg'], key, p2s, p2c)\n\n        aeskw = self.aeskwmap[self.keysize]()\n        ret = aeskw.wrap(kek, bitsize, cek, headers)\n        ret['header'] = {'p2s': base64url_encode(p2s), 'p2c': p2c}\n        return ret\n\n    def unwrap(self, key, bitsize, ek, headers):\n        if 'p2s' not in headers:\n            raise ValueError('Invalid Header, missing \"p2s\" parameter')\n        if 'p2c' not in headers:\n            raise ValueError('Invalid Header, missing \"p2c\" parameter')\n        p2s = base64url_decode(headers['p2s'])\n        p2c = headers['p2c']\n        kek = self._get_key(headers['alg'], key, p2s, p2c)\n\n        aeskw = self.aeskwmap[self.keysize]()\n        return aeskw.unwrap(kek, bitsize, ek, headers)\n\n\nclass _Pbes2Hs256A128Kw(_Pbes2HsAesKw, JWAAlgorithm):\n\n    name = 'PBES2-HS256+A128KW'\n    description = 'PBES2 with HMAC SHA-256 and \"A128KW\" wrapping'\n    keysize = 128\n    algorithm_usage_location = 'alg'\n    algorithm_use = 'kex'\n    hashsize = 256\n\n\nclass _Pbes2Hs384A192Kw(_Pbes2HsAesKw, JWAAlgorithm):\n\n    name = 'PBES2-HS384+A192KW'\n    description = 'PBES2 with HMAC SHA-384 and \"A192KW\" wrapping'\n    keysize = 192\n    algorithm_usage_location = 'alg'\n    algorithm_use = 'kex'\n    hashsize = 384\n\n\nclass _Pbes2Hs512A256Kw(_Pbes2HsAesKw, JWAAlgorithm):\n\n    name = 'PBES2-HS512+A256KW'\n    description = 'PBES2 with HMAC SHA-512 and \"A256KW\" wrapping'\n    keysize = 256\n    algorithm_usage_location = 'alg'\n    algorithm_use = 'kex'\n    hashsize = 512\n\n\nclass _Direct(_RawKeyMgmt, JWAAlgorithm):\n\n    name = 'dir'\n    description = \"Direct use of a shared symmetric key\"\n    keysize = 128\n    algorithm_usage_location = 'alg'\n    algorithm_use = 'kex'\n\n    def _check_key(self, key):\n        if not isinstance(key, JWK):\n            raise ValueError('key is not a JWK object')\n        if key.key_type != 'oct':\n            raise InvalidJWEKeyType('oct', key.key_type)\n\n    def wrap(self, key, bitsize, cek, headers):\n        self._check_key(key)\n        if cek:\n            return (cek, None)\n        k = base64url_decode(key.get_op_key('encrypt'))\n        if _bitsize(k) != bitsize:\n            raise InvalidCEKeyLength(bitsize, _bitsize(k))\n        return {'cek': k}\n\n    def unwrap(self, key, bitsize, ek, headers):\n        self._check_key(key)\n        if ek != b'':\n            raise ValueError('Invalid Encryption Key.')\n        cek = base64url_decode(key.get_op_key('decrypt'))\n        if _bitsize(cek) != bitsize:\n            raise InvalidJWEKeyLength(bitsize, _bitsize(cek))\n        return cek\n\n\nclass _EcdhEs(_RawKeyMgmt):\n\n    name = 'ECDH-ES'\n    description = \"ECDH-ES using Concat KDF\"\n    algorithm_usage_location = 'alg'\n    algorithm_use = 'kex'\n    keysize = None\n\n    def __init__(self):\n        self.backend = default_backend()\n        self.aeskwmap = {128: _A128KW, 192: _A192KW, 256: _A256KW}\n\n    def _check_key(self, key):\n        if not isinstance(key, JWK):\n            raise ValueError('key is not a JWK object')\n        if key.key_type != 'EC':\n            raise InvalidJWEKeyType('EC', key.key_type)\n\n    def _derive(self, privkey, pubkey, alg, bitsize, headers):\n        # OtherInfo is defined in NIST SP 56A 5.8.1.2.1\n\n        # AlgorithmID\n        otherinfo = struct.pack('>I', len(alg))\n        otherinfo += bytes(alg.encode('utf8'))\n\n        # PartyUInfo\n        apu = base64url_decode(headers['apu']) if 'apu' in headers else b''\n        otherinfo += struct.pack('>I', len(apu))\n        otherinfo += apu\n\n        # PartyVInfo\n        apv = base64url_decode(headers['apv']) if 'apv' in headers else b''\n        otherinfo += struct.pack('>I', len(apv))\n        otherinfo += apv\n\n        # SuppPubInfo\n        otherinfo += struct.pack('>I', bitsize)\n\n        # no SuppPrivInfo\n\n        shared_key = privkey.exchange(ec.ECDH(), pubkey)\n        ckdf = ConcatKDFHash(algorithm=hashes.SHA256(),\n                             length=_inbytes(bitsize),\n                             otherinfo=otherinfo,\n                             backend=self.backend)\n        return ckdf.derive(shared_key)\n\n    def wrap(self, key, bitsize, cek, headers):\n        self._check_key(key)\n        if self.keysize is None:\n            if cek is not None:\n                raise InvalidJWEOperation('ECDH-ES cannot use an existing CEK')\n            alg = headers['enc']\n        else:\n            bitsize = self.keysize\n            alg = headers['alg']\n\n        epk = JWK.generate(kty=key.key_type, crv=key.key_curve)\n        dk = self._derive(epk.get_op_key('unwrapKey'),\n                          key.get_op_key('wrapKey'),\n                          alg, bitsize, headers)\n\n        if self.keysize is None:\n            ret = {'cek': dk}\n        else:\n            aeskw = self.aeskwmap[bitsize]()\n            kek = JWK(kty=\"oct\", use=\"enc\", k=base64url_encode(dk))\n            ret = aeskw.wrap(kek, bitsize, cek, headers)\n\n        ret['header'] = {'epk': json_decode(epk.export_public())}\n        return ret\n\n    def unwrap(self, key, bitsize, ek, headers):\n        if 'epk' not in headers:\n            raise ValueError('Invalid Header, missing \"epk\" parameter')\n        self._check_key(key)\n        if self.keysize is None:\n            alg = headers['enc']\n        else:\n            bitsize = self.keysize\n            alg = headers['alg']\n\n        epk = JWK(**headers['epk'])\n        dk = self._derive(key.get_op_key('unwrapKey'),\n                          epk.get_op_key('wrapKey'),\n                          alg, bitsize, headers)\n        if self.keysize is None:\n            return dk\n        else:\n            aeskw = self.aeskwmap[bitsize]()\n            kek = JWK(kty=\"oct\", use=\"enc\", k=base64url_encode(dk))\n            cek = aeskw.unwrap(kek, bitsize, ek, headers)\n            return cek\n\n\nclass _EcdhEsAes128Kw(_EcdhEs, JWAAlgorithm):\n\n    name = 'ECDH-ES+A128KW'\n    description = 'ECDH-ES using Concat KDF and \"A128KW\" wrapping'\n    keysize = 128\n    algorithm_usage_location = 'alg'\n    algorithm_use = 'kex'\n\n\nclass _EcdhEsAes192Kw(_EcdhEs, JWAAlgorithm):\n\n    name = 'ECDH-ES+A192KW'\n    description = 'ECDH-ES using Concat KDF and \"A192KW\" wrapping'\n    keysize = 192\n    algorithm_usage_location = 'alg'\n    algorithm_use = 'kex'\n\n\nclass _EcdhEsAes256Kw(_EcdhEs, JWAAlgorithm):\n\n    name = 'ECDH-ES+A256KW'\n    description = 'ECDH-ES using Concat KDF and \"A128KW\" wrapping'\n    keysize = 256\n    algorithm_usage_location = 'alg'\n    algorithm_use = 'kex'\n\n\nclass _RawJWE(object):\n\n    def encrypt(self, k, a, m):\n        raise NotImplementedError\n\n    def decrypt(self, k, a, iv, e, t):\n        raise NotImplementedError\n\n\nclass _AesCbcHmacSha2(_RawJWE):\n\n    keysize = None\n\n    def __init__(self, hashfn):\n        self.backend = default_backend()\n        self.hashfn = hashfn\n        self.blocksize = algorithms.AES.block_size\n        self.wrap_key_size = self.keysize * 2\n\n    def _mac(self, k, a, iv, e):\n        al = _encode_int(_bitsize(a), 64)\n        h = hmac.HMAC(k, self.hashfn, backend=self.backend)\n        h.update(a)\n        h.update(iv)\n        h.update(e)\n        h.update(al)\n        m = h.finalize()\n        return m[:_inbytes(self.keysize)]\n\n    # RFC 7518 - 5.2.2\n    def encrypt(self, k, a, m):\n        \"\"\" Encrypt according to the selected encryption and hashing\n        functions.\n\n        :param k: Encryption key (optional)\n        :param a: Additional Authentication Data\n        :param m: Plaintext\n\n        Returns a dictionary with the computed data.\n        \"\"\"\n        hkey = k[:_inbytes(self.keysize)]\n        ekey = k[_inbytes(self.keysize):]\n\n        # encrypt\n        iv = _randombits(self.blocksize)\n        cipher = Cipher(algorithms.AES(ekey), modes.CBC(iv),\n                        backend=self.backend)\n        encryptor = cipher.encryptor()\n        padder = PKCS7(self.blocksize).padder()\n        padded_data = padder.update(m) + padder.finalize()\n        e = encryptor.update(padded_data) + encryptor.finalize()\n\n        # mac\n        t = self._mac(hkey, a, iv, e)\n\n        return (iv, e, t)\n\n    def decrypt(self, k, a, iv, e, t):\n        \"\"\" Decrypt according to the selected encryption and hashing\n        functions.\n        :param k: Encryption key (optional)\n        :param a: Additional Authenticated Data\n        :param iv: Initialization Vector\n        :param e: Ciphertext\n        :param t: Authentication Tag\n\n        Returns plaintext or raises an error\n        \"\"\"\n        hkey = k[:_inbytes(self.keysize)]\n        dkey = k[_inbytes(self.keysize):]\n\n        # verify mac\n        if not constant_time.bytes_eq(t, self._mac(hkey, a, iv, e)):\n            raise InvalidSignature('Failed to verify MAC')\n\n        # decrypt\n        cipher = Cipher(algorithms.AES(dkey), modes.CBC(iv),\n                        backend=self.backend)\n        decryptor = cipher.decryptor()\n        d = decryptor.update(e) + decryptor.finalize()\n        unpadder = PKCS7(self.blocksize).unpadder()\n        return unpadder.update(d) + unpadder.finalize()\n\n\nclass _A128CbcHs256(_AesCbcHmacSha2, JWAAlgorithm):\n\n    name = 'A128CBC-HS256'\n    description = \"AES_128_CBC_HMAC_SHA_256 authenticated\"\n    keysize = 128\n    algorithm_usage_location = 'enc'\n    algorithm_use = 'enc'\n\n    def __init__(self):\n        super(_A128CbcHs256, self).__init__(hashes.SHA256())\n\n\nclass _A192CbcHs384(_AesCbcHmacSha2, JWAAlgorithm):\n\n    name = 'A192CBC-HS384'\n    description = \"AES_192_CBC_HMAC_SHA_384 authenticated\"\n    keysize = 192\n    algorithm_usage_location = 'enc'\n    algorithm_use = 'enc'\n\n    def __init__(self):\n        super(_A192CbcHs384, self).__init__(hashes.SHA384())\n\n\nclass _A256CbcHs512(_AesCbcHmacSha2, JWAAlgorithm):\n\n    name = 'A256CBC-HS512'\n    description = \"AES_256_CBC_HMAC_SHA_512 authenticated\"\n    keysize = 256\n    algorithm_usage_location = 'enc'\n    algorithm_use = 'enc'\n\n    def __init__(self):\n        super(_A256CbcHs512, self).__init__(hashes.SHA512())\n\n\nclass _AesGcm(_RawJWE):\n\n    keysize = None\n\n    def __init__(self):\n        self.backend = default_backend()\n        self.wrap_key_size = self.keysize\n\n    # RFC 7518 - 5.3\n    def encrypt(self, k, a, m):\n        \"\"\" Encrypt accoriding to the selected encryption and hashing\n        functions.\n\n        :param k: Encryption key (optional)\n        :param a: Additional Authentication Data\n        :param m: Plaintext\n\n        Returns a dictionary with the computed data.\n        \"\"\"\n        iv = _randombits(96)\n        cipher = Cipher(algorithms.AES(k), modes.GCM(iv),\n                        backend=self.backend)\n        encryptor = cipher.encryptor()\n        encryptor.authenticate_additional_data(a)\n        e = encryptor.update(m) + encryptor.finalize()\n\n        return (iv, e, encryptor.tag)\n\n    def decrypt(self, k, a, iv, e, t):\n        \"\"\" Decrypt accoriding to the selected encryption and hashing\n        functions.\n        :param k: Encryption key (optional)\n        :param a: Additional Authenticated Data\n        :param iv: Initialization Vector\n        :param e: Ciphertext\n        :param t: Authentication Tag\n\n        Returns plaintext or raises an error\n        \"\"\"\n        cipher = Cipher(algorithms.AES(k), modes.GCM(iv, t),\n                        backend=self.backend)\n        decryptor = cipher.decryptor()\n        decryptor.authenticate_additional_data(a)\n        return decryptor.update(e) + decryptor.finalize()\n\n\nclass _A128Gcm(_AesGcm, JWAAlgorithm):\n\n    name = 'A128GCM'\n    description = \"AES GCM using 128-bit key\"\n    keysize = 128\n    algorithm_usage_location = 'enc'\n    algorithm_use = 'enc'\n\n\nclass _A192Gcm(_AesGcm, JWAAlgorithm):\n\n    name = 'A192GCM'\n    description = \"AES GCM using 192-bit key\"\n    keysize = 192\n    algorithm_usage_location = 'enc'\n    algorithm_use = 'enc'\n\n\nclass _A256Gcm(_AesGcm, JWAAlgorithm):\n\n    name = 'A256GCM'\n    description = \"AES GCM using 256-bit key\"\n    keysize = 256\n    algorithm_usage_location = 'enc'\n    algorithm_use = 'enc'\n\n\nclass JWA(object):\n    \"\"\"JWA Signing Algorithms.\n\n    This class provides access to all JWA algorithms.\n    \"\"\"\n\n    algorithms_registry = {\n        'HS256': _HS256,\n        'HS384': _HS384,\n        'HS512': _HS512,\n        'RS256': _RS256,\n        'RS384': _RS384,\n        'RS512': _RS512,\n        'ES256': _ES256,\n        'ES384': _ES384,\n        'ES512': _ES512,\n        'PS256': _PS256,\n        'PS384': _PS384,\n        'PS512': _PS512,\n        'none': _None,\n        'RSA1_5': _Rsa15,\n        'RSA-OAEP': _RsaOaep,\n        'RSA-OAEP-256': _RsaOaep256,\n        'A128KW': _A128KW,\n        'A192KW': _A192KW,\n        'A256KW': _A256KW,\n        'dir': _Direct,\n        'ECDH-ES': _EcdhEs,\n        'ECDH-ES+A128KW': _EcdhEsAes128Kw,\n        'ECDH-ES+A192KW': _EcdhEsAes192Kw,\n        'ECDH-ES+A256KW': _EcdhEsAes256Kw,\n        'A128GCMKW': _A128GcmKw,\n        'A192GCMKW': _A192GcmKw,\n        'A256GCMKW': _A256GcmKw,\n        'PBES2-HS256+A128KW': _Pbes2Hs256A128Kw,\n        'PBES2-HS384+A192KW': _Pbes2Hs384A192Kw,\n        'PBES2-HS512+A256KW': _Pbes2Hs512A256Kw,\n        'A128CBC-HS256': _A128CbcHs256,\n        'A192CBC-HS384': _A192CbcHs384,\n        'A256CBC-HS512': _A256CbcHs512,\n        'A128GCM': _A128Gcm,\n        'A192GCM': _A192Gcm,\n        'A256GCM': _A256Gcm\n    }\n\n    @classmethod\n    def instantiate_alg(cls, name, use=None):\n        alg = cls.algorithms_registry[name]\n        if use is not None and alg.algorithm_use != use:\n            raise KeyError\n        return alg()\n\n    @classmethod\n    def signing_alg(cls, name):\n        try:\n            return cls.instantiate_alg(name, use='sig')\n        except KeyError:\n            raise InvalidJWAAlgorithm(\n                '%s is not a valid Signign algorithm name' % name)\n\n    @classmethod\n    def keymgmt_alg(cls, name):\n        try:\n            return cls.instantiate_alg(name, use='kex')\n        except KeyError:\n            raise InvalidJWAAlgorithm(\n                '%s is not a valid Key Management algorithm name' % name)\n\n    @classmethod\n    def encryption_alg(cls, name):\n        try:\n            return cls.instantiate_alg(name, use='enc')\n        except KeyError:\n            raise InvalidJWAAlgorithm(\n                '%s is not a valid Encryption algorithm name' % name)\n", "target": 1}
{"idx": 953, "func": "from __future__ import absolute_import\nfrom typing import Any, Optional, Tuple, List, Set, Iterable, Mapping, Callable, Dict\n\nfrom django.utils.translation import ugettext as _\nfrom django.conf import settings\nfrom django.db import transaction\nfrom django.http import HttpRequest, HttpResponse\n\nfrom zerver.lib.request import JsonableError, REQ, has_request_variables\nfrom zerver.decorator import authenticated_json_post_view, \\\n    authenticated_json_view, \\\n    get_user_profile_by_email, require_realm_admin, to_non_negative_int\nfrom zerver.lib.actions import bulk_remove_subscriptions, \\\n    do_change_subscription_property, internal_prep_message, \\\n    create_streams_if_needed, gather_subscriptions, subscribed_to_stream, \\\n    bulk_add_subscriptions, do_send_messages, get_subscriber_emails, do_rename_stream, \\\n    do_deactivate_stream, do_make_stream_public, do_add_default_stream, \\\n    do_change_stream_description, do_get_streams, do_make_stream_private, \\\n    do_remove_default_stream, get_topic_history_for_stream\nfrom zerver.lib.response import json_success, json_error, json_response\nfrom zerver.lib.validator import check_string, check_list, check_dict, \\\n    check_bool, check_variable_type\nfrom zerver.models import UserProfile, Stream, Realm, Subscription, \\\n    Recipient, get_recipient, get_stream, bulk_get_streams, \\\n    bulk_get_recipients, valid_stream_name, get_active_user_dicts_in_realm\n\nfrom collections import defaultdict\nimport ujson\nfrom six.moves import urllib\n\nimport six\nfrom typing import Text\n\ndef is_active_subscriber(user_profile, recipient):\n    # type: (UserProfile, Recipient) -> bool\n    return Subscription.objects.filter(user_profile=user_profile,\n                                       recipient=recipient,\n                                       active=True).exists()\n\ndef list_to_streams(streams_raw, user_profile, autocreate=False):\n    # type: (Iterable[Mapping[str, Any]], UserProfile, Optional[bool]) -> Tuple[List[Stream], List[Stream]]\n    \"\"\"Converts list of dicts to a list of Streams, validating input in the process\n\n    For each stream name, we validate it to ensure it meets our\n    requirements for a proper stream name: that is, that it is shorter\n    than Stream.MAX_NAME_LENGTH characters and passes\n    valid_stream_name.\n\n    This function in autocreate mode should be atomic: either an exception will be raised\n    during a precheck, or all the streams specified will have been created if applicable.\n\n    @param streams_raw The list of stream dictionaries to process;\n      names should already be stripped of whitespace by the caller.\n    @param user_profile The user for whom we are retreiving the streams\n    @param autocreate Whether we should create streams if they don't already exist\n    \"\"\"\n    # Validate all streams, getting extant ones, then get-or-creating the rest.\n\n    stream_set = set(stream_dict[\"name\"] for stream_dict in streams_raw)\n\n    for stream_name in stream_set:\n        # Stream names should already have been stripped by the\n        # caller, but it makes sense to verify anyway.\n        assert stream_name == stream_name.strip()\n        if len(stream_name) > Stream.MAX_NAME_LENGTH:\n            raise JsonableError(_(\"Stream name (%s) too long.\") % (stream_name,))\n        if not valid_stream_name(stream_name):\n            raise JsonableError(_(\"Invalid stream name (%s).\") % (stream_name,))\n\n    existing_streams = [] # type: List[Stream]\n    missing_stream_dicts = [] # type: List[Mapping[str, Any]]\n    existing_stream_map = bulk_get_streams(user_profile.realm, stream_set)\n\n    for stream_dict in streams_raw:\n        stream_name = stream_dict[\"name\"]\n        stream = existing_stream_map.get(stream_name.lower())\n        if stream is None:\n            missing_stream_dicts.append(stream_dict)\n        else:\n            existing_streams.append(stream)\n\n    if len(missing_stream_dicts) == 0:\n        # This is the happy path for callers who expected all of these\n        # streams to exist already.\n        created_streams = [] # type: List[Stream]\n    else:\n        # autocreate=True path starts here\n        if not user_profile.can_create_streams():\n            raise JsonableError(_('User cannot create streams.'))\n        elif not autocreate:\n            raise JsonableError(_(\"Stream(s) (%s) do not exist\") % \", \".join(\n                stream_dict[\"name\"] for stream_dict in missing_stream_dicts))\n\n        # We already filtered out existing streams, so dup_streams\n        # will normally be an empty list below, but we protect against somebody\n        # else racing to create the same stream.  (This is not an entirely\n        # paranoid approach, since often on Zulip two people will discuss\n        # creating a new stream, and both people eagerly do it.)\n        created_streams, dup_streams = create_streams_if_needed(realm=user_profile.realm,\n                                                                stream_dicts=missing_stream_dicts)\n        existing_streams += dup_streams\n\n    return existing_streams, created_streams\n\nclass PrincipalError(JsonableError):\n    def __init__(self, principal, status_code=403):\n        # type: (Text, int) -> None\n        self.principal = principal # type: Text\n        self.status_code = status_code # type: int\n\n    def to_json_error_msg(self):\n        # type: () -> Text\n        return (\"User not authorized to execute queries on behalf of '%s'\"\n                % (self.principal,))\n\ndef principal_to_user_profile(agent, principal):\n    # type: (UserProfile, Text) -> UserProfile\n    principal_doesnt_exist = False\n    try:\n        principal_user_profile = get_user_profile_by_email(principal)\n    except UserProfile.DoesNotExist:\n        principal_doesnt_exist = True\n\n    if (principal_doesnt_exist or\n            agent.realm != principal_user_profile.realm):\n        # We have to make sure we don't leak information about which users\n        # are registered for Zulip in a different realm.  We could do\n        # something a little more clever and check the domain part of the\n        # principal to maybe give a better error message\n        raise PrincipalError(principal)\n\n    return principal_user_profile\n\n@require_realm_admin\ndef deactivate_stream_backend(request, user_profile, stream_id):\n    # type: (HttpRequest, UserProfile, int) -> HttpResponse\n    target = get_and_validate_stream_by_id(stream_id, user_profile.realm)\n\n    if target.invite_only and not subscribed_to_stream(user_profile, target):\n        return json_error(_('Cannot administer invite-only streams this way'))\n\n    do_deactivate_stream(target)\n    return json_success()\n\n@require_realm_admin\n@has_request_variables\ndef add_default_stream(request, user_profile, stream_name=REQ()):\n    # type: (HttpRequest, UserProfile, Text) -> HttpResponse\n    do_add_default_stream(user_profile.realm, stream_name)\n    return json_success()\n\n@require_realm_admin\n@has_request_variables\ndef remove_default_stream(request, user_profile, stream_name=REQ()):\n    # type: (HttpRequest, UserProfile, Text) -> HttpResponse\n    do_remove_default_stream(user_profile.realm, stream_name)\n    return json_success()\n\n@require_realm_admin\n@has_request_variables\ndef update_stream_backend(request, user_profile, stream_id,\n                          description=REQ(validator=check_string, default=None),\n                          is_private=REQ(validator=check_bool, default=None),\n                          new_name=REQ(validator=check_string, default=None)):\n    # type: (HttpRequest, UserProfile, int, Optional[Text], Optional[bool], Optional[Text]) -> HttpResponse\n    stream = get_and_validate_stream_by_id(stream_id, user_profile.realm)\n    stream_name = stream.name\n\n    if description is not None:\n        do_change_stream_description(user_profile.realm, stream_name, description)\n    if stream_name is not None and new_name is not None:\n        do_rename_stream(user_profile.realm, stream_name, new_name)\n    if is_private is not None:\n        if is_private:\n            do_make_stream_private(user_profile.realm, stream_name)\n        else:\n            do_make_stream_public(user_profile, user_profile.realm, stream_name)\n    return json_success()\n\ndef list_subscriptions_backend(request, user_profile):\n    # type: (HttpRequest, UserProfile) -> HttpResponse\n    return json_success({\"subscriptions\": gather_subscriptions(user_profile)[0]})\n\nFuncKwargPair = Tuple[Callable[..., HttpResponse], Dict[str, Iterable[Any]]]\n\n@has_request_variables\ndef update_subscriptions_backend(request, user_profile,\n                                 delete=REQ(validator=check_list(check_string), default=[]),\n                                 add=REQ(validator=check_list(check_dict([('name', check_string)])), default=[])):\n    # type: (HttpRequest, UserProfile, Iterable[Text], Iterable[Mapping[str, Any]]) -> HttpResponse\n    if not add and not delete:\n        return json_error(_('Nothing to do. Specify at least one of \"add\" or \"delete\".'))\n\n    method_kwarg_pairs = [\n        (add_subscriptions_backend, dict(streams_raw=add)),\n        (remove_subscriptions_backend, dict(streams_raw=delete))\n    ] # type: List[FuncKwargPair]\n    return compose_views(request, user_profile, method_kwarg_pairs)\n\ndef compose_views(request, user_profile, method_kwarg_pairs):\n    # type: (HttpRequest, UserProfile, List[FuncKwargPair]) -> HttpResponse\n    '''\n    This takes a series of view methods from method_kwarg_pairs and calls\n    them in sequence, and it smushes all the json results into a single\n    response when everything goes right.  (This helps clients avoid extra\n    latency hops.)  It rolls back the transaction when things go wrong in\n    any one of the composed methods.\n\n    TODO: Move this a utils-like module if we end up using it more widely.\n    '''\n\n    json_dict = {} # type: Dict[str, Any]\n    with transaction.atomic():\n        for method, kwargs in method_kwarg_pairs:\n            response = method(request, user_profile, **kwargs)\n            if response.status_code != 200:\n                raise JsonableError(response.content)\n            json_dict.update(ujson.loads(response.content))\n    return json_success(json_dict)\n\n@authenticated_json_post_view\ndef json_remove_subscriptions(request, user_profile):\n    # type: (HttpRequest, UserProfile) -> HttpResponse\n    return remove_subscriptions_backend(request, user_profile)\n\n@has_request_variables\ndef remove_subscriptions_backend(request, user_profile,\n                                 streams_raw = REQ(\"subscriptions\", validator=check_list(check_string)),\n                                 principals = REQ(validator=check_list(check_string), default=None)):\n    # type: (HttpRequest, UserProfile, Iterable[Text], Optional[Iterable[Text]]) -> HttpResponse\n\n    removing_someone_else = principals and \\\n        set(principals) != set((user_profile.email,))\n    if removing_someone_else and not user_profile.is_realm_admin:\n        # You can only unsubscribe other people from a stream if you are a realm\n        # admin.\n        return json_error(_(\"This action requires administrative rights\"))\n\n    streams_as_dict = []\n    for stream_name in streams_raw:\n        streams_as_dict.append({\"name\": stream_name.strip()})\n\n    streams, __ = list_to_streams(streams_as_dict, user_profile)\n\n    for stream in streams:\n        if removing_someone_else and stream.invite_only and \\\n                not subscribed_to_stream(user_profile, stream):\n            # Even as an admin, you can't remove other people from an\n            # invite-only stream you're not on.\n            return json_error(_(\"Cannot administer invite-only streams this way\"))\n\n    if principals:\n        people_to_unsub = set(principal_to_user_profile(\n            user_profile, principal) for principal in principals)\n    else:\n        people_to_unsub = set([user_profile])\n\n    result = dict(removed=[], not_subscribed=[]) # type: Dict[str, List[Text]]\n    (removed, not_subscribed) = bulk_remove_subscriptions(people_to_unsub, streams)\n\n    for (subscriber, stream) in removed:\n        result[\"removed\"].append(stream.name)\n    for (subscriber, stream) in not_subscribed:\n        result[\"not_subscribed\"].append(stream.name)\n\n    return json_success(result)\n\ndef filter_stream_authorization(user_profile, streams):\n    # type: (UserProfile, Iterable[Stream]) -> Tuple[List[Stream], List[Stream]]\n    streams_subscribed = set() # type: Set[int]\n    recipients_map = bulk_get_recipients(Recipient.STREAM, [stream.id for stream in streams])\n    subs = Subscription.objects.filter(user_profile=user_profile,\n                                       recipient__in=list(recipients_map.values()),\n                                       active=True)\n\n    for sub in subs:\n        streams_subscribed.add(sub.recipient.type_id)\n\n    unauthorized_streams = [] # type: List[Stream]\n    for stream in streams:\n        # The user is authorized for his own streams\n        if stream.id in streams_subscribed:\n            continue\n\n        # The user is not authorized for invite_only streams\n        if stream.invite_only:\n            unauthorized_streams.append(stream)\n\n    authorized_streams = [stream for stream in streams if\n                          stream.id not in set(stream.id for stream in unauthorized_streams)]\n    return authorized_streams, unauthorized_streams\n\n@has_request_variables\ndef add_subscriptions_backend(request, user_profile,\n                              streams_raw = REQ(\"subscriptions\",\n                                                validator=check_list(check_dict([('name', check_string)]))),\n                              invite_only = REQ(validator=check_bool, default=False),\n                              announce = REQ(validator=check_bool, default=False),\n                              principals = REQ(validator=check_list(check_string), default=None),\n                              authorization_errors_fatal = REQ(validator=check_bool, default=True)):\n    # type: (HttpRequest, UserProfile, Iterable[Mapping[str, Text]], bool, bool, Optional[List[Text]], bool) -> HttpResponse\n    stream_dicts = []\n    for stream_dict in streams_raw:\n        stream_dict_copy = {} # type: Dict[str, Any]\n        for field in stream_dict:\n            stream_dict_copy[field] = stream_dict[field]\n        # Strip the stream name here.\n        stream_dict_copy['name'] = stream_dict_copy['name'].strip()\n        stream_dict_copy[\"invite_only\"] = invite_only\n        stream_dicts.append(stream_dict_copy)\n\n    # Validation of the streams arguments, including enforcement of\n    # can_create_streams policy and valid_stream_name policy is inside\n    # list_to_streams.\n    existing_streams, created_streams = \\\n        list_to_streams(stream_dicts, user_profile, autocreate=True)\n    authorized_streams, unauthorized_streams = \\\n        filter_stream_authorization(user_profile, existing_streams)\n    if len(unauthorized_streams) > 0 and authorization_errors_fatal:\n        return json_error(_(\"Unable to access stream (%s).\") % unauthorized_streams[0].name)\n    # Newly created streams are also authorized for the creator\n    streams = authorized_streams + created_streams\n\n    if principals is not None:\n        if user_profile.realm.is_zephyr_mirror_realm and not all(stream.invite_only for stream in streams):\n            return json_error(_(\"You can only invite other Zephyr mirroring users to invite-only streams.\"))\n        subscribers = set(principal_to_user_profile(user_profile, principal) for principal in principals)\n    else:\n        subscribers = set([user_profile])\n\n    (subscribed, already_subscribed) = bulk_add_subscriptions(streams, subscribers)\n\n    result = dict(subscribed=defaultdict(list), already_subscribed=defaultdict(list)) # type: Dict[str, Any]\n    for (subscriber, stream) in subscribed:\n        result[\"subscribed\"][subscriber.email].append(stream.name)\n    for (subscriber, stream) in already_subscribed:\n        result[\"already_subscribed\"][subscriber.email].append(stream.name)\n\n    private_streams = dict((stream.name, stream.invite_only) for stream in streams)\n    bots = dict((subscriber.email, subscriber.is_bot) for subscriber in subscribers)\n\n    # Inform the user if someone else subscribed them to stuff,\n    # or if a new stream was created with the \"announce\" option.\n    notifications = []\n    if principals and result[\"subscribed\"]:\n        for email, subscriptions in six.iteritems(result[\"subscribed\"]):\n            if email == user_profile.email:\n                # Don't send a Zulip if you invited yourself.\n                continue\n            if bots[email]:\n                # Don't send invitation Zulips to bots\n                continue\n\n            if len(subscriptions) == 1:\n                msg = (\"Hi there!  We thought you'd like to know that %s just \"\n                       \"subscribed you to the%s stream #**%s**.\"\n                       % (user_profile.full_name,\n                          \" **invite-only**\" if private_streams[subscriptions[0]] else \"\",\n                          subscriptions[0],\n                          ))\n            else:\n                msg = (\"Hi there!  We thought you'd like to know that %s just \"\n                       \"subscribed you to the following streams: \\n\\n\"\n                       % (user_profile.full_name,))\n                for stream in subscriptions:\n                    msg += \"* #**%s**%s\\n\" % (\n                        stream,\n                        \" (**invite-only**)\" if private_streams[stream] else \"\")\n\n            if len([s for s in subscriptions if not private_streams[s]]) > 0:\n                msg += \"\\nYou can see historical content on a non-invite-only stream by narrowing to it.\"\n            notifications.append(internal_prep_message(\n                user_profile.realm, settings.NOTIFICATION_BOT,\n                \"private\", email, \"\", msg))\n\n    if announce and len(created_streams) > 0:\n        notifications_stream = user_profile.realm.notifications_stream\n        if notifications_stream is not None:\n            if len(created_streams) > 1:\n                stream_msg = \"the following streams: %s\" % (\", \".join('#**%s**' % s.name for s in created_streams))\n            else:\n                stream_msg = \"a new stream #**%s**.\" % created_streams[0].name\n            msg = (\"%s just created %s\" % (user_profile.full_name, stream_msg))\n            notifications.append(\n                internal_prep_message(user_profile.realm, settings.NOTIFICATION_BOT,\n                                      \"stream\",\n                                      notifications_stream.name, \"Streams\", msg))\n        else:\n            msg = (\"Hi there!  %s just created a new stream #**%s**.\"\n                   % (user_profile.full_name, created_streams[0].name))\n            for realm_user_dict in get_active_user_dicts_in_realm(user_profile.realm):\n                # Don't announce to yourself or to people you explicitly added\n                # (who will get the notification above instead).\n                if realm_user_dict['email'] in principals or realm_user_dict['email'] == user_profile.email:\n                    continue\n                notifications.append(internal_prep_message(\n                    user_profile.realm, settings.NOTIFICATION_BOT,\n                    \"private\",\n                    realm_user_dict['email'], \"\", msg))\n\n    if len(notifications) > 0:\n        do_send_messages(notifications)\n\n    result[\"subscribed\"] = dict(result[\"subscribed\"])\n    result[\"already_subscribed\"] = dict(result[\"already_subscribed\"])\n    if not authorization_errors_fatal:\n        result[\"unauthorized\"] = [stream.name for stream in unauthorized_streams]\n    return json_success(result)\n\n@has_request_variables\ndef get_subscribers_backend(request, user_profile,\n                            stream_id=REQ('stream', converter=to_non_negative_int)):\n    # type: (HttpRequest, UserProfile, int) -> HttpResponse\n    stream = get_and_validate_stream_by_id(stream_id, user_profile.realm)\n    subscribers = get_subscriber_emails(stream, user_profile)\n\n    return json_success({'subscribers': subscribers})\n\n# By default, lists all streams that the user has access to --\n# i.e. public streams plus invite-only streams that the user is on\n@has_request_variables\ndef get_streams_backend(request, user_profile,\n                        include_public=REQ(validator=check_bool, default=True),\n                        include_subscribed=REQ(validator=check_bool, default=True),\n                        include_all_active=REQ(validator=check_bool, default=False),\n                        include_default=REQ(validator=check_bool, default=False)):\n    # type: (HttpRequest, UserProfile, bool, bool, bool, bool) -> HttpResponse\n\n    streams = do_get_streams(user_profile, include_public=include_public,\n                             include_subscribed=include_subscribed,\n                             include_all_active=include_all_active,\n                             include_default=include_default)\n    return json_success({\"streams\": streams})\n\n@has_request_variables\ndef get_topics_backend(request, user_profile,\n                       stream_id=REQ(converter=to_non_negative_int)):\n    # type: (HttpRequest, UserProfile, int) -> HttpResponse\n    stream = get_and_validate_stream_by_id(stream_id, user_profile.realm)\n\n    if stream.realm_id != user_profile.realm_id:\n        return json_error(_(\"Invalid stream id\"))\n\n    recipient = get_recipient(Recipient.STREAM, stream.id)\n\n    if not stream.is_public():\n        if not is_active_subscriber(user_profile=user_profile,\n                                    recipient=recipient):\n            return json_error(_(\"Invalid stream id\"))\n\n    result = get_topic_history_for_stream(\n        user_profile=user_profile,\n        recipient=recipient,\n    )\n\n    # Our data structure here is a list of tuples of\n    # (topic name, unread count), and it's reverse chronological,\n    # so the most recent topic is the first element of the list.\n    return json_success(dict(topics=result))\n\n\n@authenticated_json_post_view\n@has_request_variables\ndef json_stream_exists(request, user_profile, stream=REQ(),\n                       autosubscribe=REQ(default=False)):\n    # type: (HttpRequest, UserProfile, Text, bool) -> HttpResponse\n    if not valid_stream_name(stream):\n        return json_error(_(\"Invalid characters in stream name\"))\n    try:\n        stream_id = Stream.objects.get(realm=user_profile.realm, name=stream).id\n    except Stream.DoesNotExist:\n        stream_id = None\n    return stream_exists_backend(request, user_profile, stream_id, autosubscribe)\n\ndef stream_exists_backend(request, user_profile, stream_id, autosubscribe):\n    # type: (HttpRequest, UserProfile, int, bool) -> HttpResponse\n    try:\n        stream = get_and_validate_stream_by_id(stream_id, user_profile.realm)\n    except JsonableError:\n        stream = None\n    result = {\"exists\": bool(stream)}\n    if stream is not None:\n        recipient = get_recipient(Recipient.STREAM, stream.id)\n        if autosubscribe:\n            bulk_add_subscriptions([stream], [user_profile])\n        result[\"subscribed\"] = is_active_subscriber(\n            user_profile=user_profile,\n            recipient=recipient)\n\n        return json_success(result) # results are ignored for HEAD requests\n    return json_response(data=result, status=404)\n\ndef get_and_validate_stream_by_id(stream_id, realm):\n    # type: (int, Realm) -> Stream\n    try:\n        stream = Stream.objects.get(pk=stream_id, realm_id=realm.id)\n    except Stream.DoesNotExist:\n        raise JsonableError(_(\"Invalid stream id\"))\n    return stream\n\n@has_request_variables\ndef json_get_stream_id(request, user_profile, stream=REQ()):\n    # type: (HttpRequest, UserProfile, Text) -> HttpResponse\n    try:\n        stream_id = Stream.objects.get(realm=user_profile.realm, name=stream).id\n    except Stream.DoesNotExist:\n        return json_error(_(\"No such stream name\"))\n    return json_success({'stream_id': stream_id})\n\ndef get_subscription_or_die(stream_name, user_profile):\n    # type: (Text, UserProfile) -> Subscription\n    stream = get_stream(stream_name, user_profile.realm)\n    if not stream:\n        raise JsonableError(_(\"Invalid stream %s\") % (stream_name,))\n    recipient = get_recipient(Recipient.STREAM, stream.id)\n    subscription = Subscription.objects.filter(user_profile=user_profile,\n                                               recipient=recipient, active=True)\n\n    if not subscription.exists():\n        raise JsonableError(_(\"Not subscribed to stream %s\") % (stream_name,))\n\n    return subscription\n\n@authenticated_json_view\n@has_request_variables\ndef json_subscription_property(request, user_profile, subscription_data=REQ(\n        validator=check_list(\n            check_dict([(\"stream\", check_string),\n                        (\"property\", check_string),\n                        (\"value\", check_variable_type(\n                            [check_string, check_bool]))])))):\n    # type: (HttpRequest, UserProfile, List[Dict[str, Any]]) -> HttpResponse\n    \"\"\"\n    This is the entry point to changing subscription properties. This\n    is a bulk endpoint: requestors always provide a subscription_data\n    list containing dictionaries for each stream of interest.\n\n    Requests are of the form:\n\n    [{\"stream\": \"devel\", \"property\": \"in_home_view\", \"value\": False},\n     {\"stream\": \"devel\", \"property\": \"color\", \"value\": \"#c2c2c2\"}]\n    \"\"\"\n    if request.method != \"POST\":\n        return json_error(_(\"Invalid verb\"))\n\n    property_converters = {\"color\": check_string, \"in_home_view\": check_bool,\n                           \"desktop_notifications\": check_bool,\n                           \"audible_notifications\": check_bool,\n                           \"pin_to_top\": check_bool}\n    response_data = []\n\n    for change in subscription_data:\n        stream_name = change[\"stream\"]\n        property = change[\"property\"]\n        value = change[\"value\"]\n\n        if property not in property_converters:\n            return json_error(_(\"Unknown subscription property: %s\") % (property,))\n\n        sub = get_subscription_or_die(stream_name, user_profile)[0]\n\n        property_conversion = property_converters[property](property, value)\n        if property_conversion:\n            return json_error(property_conversion)\n\n        do_change_subscription_property(user_profile, sub, stream_name,\n                                        property, value)\n\n        response_data.append({'stream': stream_name,\n                              'property': property,\n                              'value': value})\n\n    return json_success({\"subscription_data\": response_data})\n", "target": 1}
{"idx": 954, "func": "from django.db import models\n\ntry:\n    from django.contrib.auth.models import AbstractUser, UserManager\nexcept ImportError:\n    from django.db.models import Model as AbstractUser\n\n\nclass CustomUser(AbstractUser):\n    extra_field = models.CharField(max_length=2)\n    new_username_field = models.CharField('userid', unique=True, max_length=20)\n\n    USERNAME_FIELD = 'new_username_field'\n\n    def save(self, *args, **kwargs):\n        self.new_username_field = self.username\n        super(CustomUser, self).save(*args, **kwargs)\n\n\nclass PhoneNumberUser(CustomUser):\n    phone_number = models.CharField(max_length=11, default=\"+15555555\")\n\n\nclass NoUsernameUser(models.Model):\n    \"\"\"User model without a \"username\" field for authentication\n    backend testing\n    \"\"\"\n    pass\n", "target": 0}
{"idx": 955, "func": "##############################################################################\n#\n# Copyright (c) 2001, 2002 Zope Foundation and Contributors.\n# All Rights Reserved.\n#\n# This software is subject to the provisions of the Zope Public License,\n# Version 2.1 (ZPL).  A copy of the ZPL should accompany this distribution.\n# THIS SOFTWARE IS PROVIDED \"AS IS\" AND ANY AND ALL EXPRESS OR IMPLIED\n# WARRANTIES ARE DISCLAIMED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\n# WARRANTIES OF TITLE, MERCHANTABILITY, AGAINST INFRINGEMENT, AND FITNESS\n# FOR A PARTICULAR PURPOSE.\n#\n##############################################################################\n\"\"\"HTTP Request Parser\n\nThis server uses asyncore to accept connections and do initial\nprocessing but threads to do work.\n\"\"\"\nimport re\nfrom io import BytesIO\n\nfrom waitress.buffers import OverflowableBuffer\nfrom waitress.compat import tostr, unquote_bytes_to_wsgi, urlparse\nfrom waitress.receiver import ChunkedReceiver, FixedStreamReceiver\nfrom waitress.utilities import (\n    BadRequest,\n    RequestEntityTooLarge,\n    RequestHeaderFieldsTooLarge,\n    find_double_newline,\n)\n\n\nclass ParsingError(Exception):\n    pass\n\n\nclass HTTPRequestParser(object):\n    \"\"\"A structure that collects the HTTP request.\n\n    Once the stream is completed, the instance is passed to\n    a server task constructor.\n    \"\"\"\n\n    completed = False  # Set once request is completed.\n    empty = False  # Set if no request was made.\n    expect_continue = False  # client sent \"Expect: 100-continue\" header\n    headers_finished = False  # True when headers have been read\n    header_plus = b\"\"\n    chunked = False\n    content_length = 0\n    header_bytes_received = 0\n    body_bytes_received = 0\n    body_rcv = None\n    version = \"1.0\"\n    error = None\n    connection_close = False\n\n    # Other attributes: first_line, header, headers, command, uri, version,\n    # path, query, fragment\n\n    def __init__(self, adj):\n        \"\"\"\n        adj is an Adjustments object.\n        \"\"\"\n        # headers is a mapping containing keys translated to uppercase\n        # with dashes turned into underscores.\n        self.headers = {}\n        self.adj = adj\n\n    def received(self, data):\n        \"\"\"\n        Receives the HTTP stream for one request.  Returns the number of\n        bytes consumed.  Sets the completed flag once both the header and the\n        body have been received.\n        \"\"\"\n        if self.completed:\n            return 0  # Can't consume any more.\n\n        datalen = len(data)\n        br = self.body_rcv\n        if br is None:\n            # In header.\n            max_header = self.adj.max_request_header_size\n\n            s = self.header_plus + data\n            index = find_double_newline(s)\n            consumed = 0\n\n            if index >= 0:\n                # If the headers have ended, and we also have part of the body\n                # message in data we still want to validate we aren't going\n                # over our limit for received headers.\n                self.header_bytes_received += index\n                consumed = datalen - (len(s) - index)\n            else:\n                self.header_bytes_received += datalen\n                consumed = datalen\n\n            # If the first line + headers is over the max length, we return a\n            # RequestHeaderFieldsTooLarge error rather than continuing to\n            # attempt to parse the headers.\n            if self.header_bytes_received >= max_header:\n                self.parse_header(b\"GET / HTTP/1.0\\r\\n\")\n                self.error = RequestHeaderFieldsTooLarge(\n                    \"exceeds max_header of %s\" % max_header\n                )\n                self.completed = True\n                return consumed\n\n            if index >= 0:\n                # Header finished.\n                header_plus = s[:index]\n\n                # Remove preceeding blank lines. This is suggested by\n                # https://tools.ietf.org/html/rfc7230#section-3.5 to support\n                # clients sending an extra CR LF after another request when\n                # using HTTP pipelining\n                header_plus = header_plus.lstrip()\n\n                if not header_plus:\n                    self.empty = True\n                    self.completed = True\n                else:\n                    try:\n                        self.parse_header(header_plus)\n                    except ParsingError as e:\n                        self.error = BadRequest(e.args[0])\n                        self.completed = True\n                    else:\n                        if self.body_rcv is None:\n                            # no content-length header and not a t-e: chunked\n                            # request\n                            self.completed = True\n                        if self.content_length > 0:\n                            max_body = self.adj.max_request_body_size\n                            # we won't accept this request if the content-length\n                            # is too large\n                            if self.content_length >= max_body:\n                                self.error = RequestEntityTooLarge(\n                                    \"exceeds max_body of %s\" % max_body\n                                )\n                                self.completed = True\n                self.headers_finished = True\n                return consumed\n\n            # Header not finished yet.\n            self.header_plus = s\n            return datalen\n        else:\n            # In body.\n            consumed = br.received(data)\n            self.body_bytes_received += consumed\n            max_body = self.adj.max_request_body_size\n            if self.body_bytes_received >= max_body:\n                # this will only be raised during t-e: chunked requests\n                self.error = RequestEntityTooLarge(\"exceeds max_body of %s\" % max_body)\n                self.completed = True\n            elif br.error:\n                # garbage in chunked encoding input probably\n                self.error = br.error\n                self.completed = True\n            elif br.completed:\n                # The request (with the body) is ready to use.\n                self.completed = True\n                if self.chunked:\n                    # We've converted the chunked transfer encoding request\n                    # body into a normal request body, so we know its content\n                    # length; set the header here.  We already popped the\n                    # TRANSFER_ENCODING header in parse_header, so this will\n                    # appear to the client to be an entirely non-chunked HTTP\n                    # request with a valid content-length.\n                    self.headers[\"CONTENT_LENGTH\"] = str(br.__len__())\n\n            return consumed\n\n    def parse_header(self, header_plus):\n        \"\"\"\n        Parses the header_plus block of text (the headers plus the\n        first line of the request).\n        \"\"\"\n        index = header_plus.find(b\"\\r\\n\")\n        if index >= 0:\n            first_line = header_plus[:index].rstrip()\n            header = header_plus[index + 2 :]\n        else:\n            raise ParsingError(\"HTTP message header invalid\")\n\n        if b\"\\r\" in first_line or b\"\\n\" in first_line:\n            raise ParsingError(\"Bare CR or LF found in HTTP message\")\n\n        self.first_line = first_line  # for testing\n\n        lines = get_header_lines(header)\n\n        headers = self.headers\n        for line in lines:\n            index = line.find(b\":\")\n            if index > 0:\n                key = line[:index]\n\n                if key != key.strip():\n                    raise ParsingError(\"Invalid whitespace after field-name\")\n\n                if b\"_\" in key:\n                    continue\n                value = line[index + 1 :].strip()\n                key1 = tostr(key.upper().replace(b\"-\", b\"_\"))\n                # If a header already exists, we append subsequent values\n                # seperated by a comma. Applications already need to handle\n                # the comma seperated values, as HTTP front ends might do\n                # the concatenation for you (behavior specified in RFC2616).\n                try:\n                    headers[key1] += tostr(b\", \" + value)\n                except KeyError:\n                    headers[key1] = tostr(value)\n            # else there's garbage in the headers?\n\n        # command, uri, version will be bytes\n        command, uri, version = crack_first_line(first_line)\n        version = tostr(version)\n        command = tostr(command)\n        self.command = command\n        self.version = version\n        (\n            self.proxy_scheme,\n            self.proxy_netloc,\n            self.path,\n            self.query,\n            self.fragment,\n        ) = split_uri(uri)\n        self.url_scheme = self.adj.url_scheme\n        connection = headers.get(\"CONNECTION\", \"\")\n\n        if version == \"1.0\":\n            if connection.lower() != \"keep-alive\":\n                self.connection_close = True\n\n        if version == \"1.1\":\n            # since the server buffers data from chunked transfers and clients\n            # never need to deal with chunked requests, downstream clients\n            # should not see the HTTP_TRANSFER_ENCODING header; we pop it\n            # here\n            te = headers.pop(\"TRANSFER_ENCODING\", \"\")\n            if te.lower() == \"chunked\":\n                self.chunked = True\n                buf = OverflowableBuffer(self.adj.inbuf_overflow)\n                self.body_rcv = ChunkedReceiver(buf)\n            expect = headers.get(\"EXPECT\", \"\").lower()\n            self.expect_continue = expect == \"100-continue\"\n            if connection.lower() == \"close\":\n                self.connection_close = True\n\n        if not self.chunked:\n            try:\n                cl = int(headers.get(\"CONTENT_LENGTH\", 0))\n            except ValueError:\n                raise ParsingError(\"Content-Length is invalid\")\n\n            self.content_length = cl\n            if cl > 0:\n                buf = OverflowableBuffer(self.adj.inbuf_overflow)\n                self.body_rcv = FixedStreamReceiver(cl, buf)\n\n    def get_body_stream(self):\n        body_rcv = self.body_rcv\n        if body_rcv is not None:\n            return body_rcv.getfile()\n        else:\n            return BytesIO()\n\n    def close(self):\n        body_rcv = self.body_rcv\n        if body_rcv is not None:\n            body_rcv.getbuf().close()\n\n\ndef split_uri(uri):\n    # urlsplit handles byte input by returning bytes on py3, so\n    # scheme, netloc, path, query, and fragment are bytes\n\n    scheme = netloc = path = query = fragment = b\"\"\n\n    # urlsplit below will treat this as a scheme-less netloc, thereby losing\n    # the original intent of the request. Here we shamelessly stole 4 lines of\n    # code from the CPython stdlib to parse out the fragment and query but\n    # leave the path alone. See\n    # https://github.com/python/cpython/blob/8c9e9b0cd5b24dfbf1424d1f253d02de80e8f5ef/Lib/urllib/parse.py#L465-L468\n    # and https://github.com/Pylons/waitress/issues/260\n\n    if uri[:2] == b\"//\":\n        path = uri\n\n        if b\"#\" in path:\n            path, fragment = path.split(b\"#\", 1)\n\n        if b\"?\" in path:\n            path, query = path.split(b\"?\", 1)\n    else:\n        try:\n            scheme, netloc, path, query, fragment = urlparse.urlsplit(uri)\n        except UnicodeError:\n            raise ParsingError(\"Bad URI\")\n\n    return (\n        tostr(scheme),\n        tostr(netloc),\n        unquote_bytes_to_wsgi(path),\n        tostr(query),\n        tostr(fragment),\n    )\n\n\ndef get_header_lines(header):\n    \"\"\"\n    Splits the header into lines, putting multi-line headers together.\n    \"\"\"\n    r = []\n    lines = header.split(b\"\\r\\n\")\n    for line in lines:\n        if b\"\\r\" in line or b\"\\n\" in line:\n            raise ParsingError('Bare CR or LF found in header line \"%s\"' % tostr(line))\n\n        if line.startswith((b\" \", b\"\\t\")):\n            if not r:\n                # https://corte.si/posts/code/pathod/pythonservers/index.html\n                raise ParsingError('Malformed header line \"%s\"' % tostr(line))\n            r[-1] += line\n        else:\n            r.append(line)\n    return r\n\n\nfirst_line_re = re.compile(\n    b\"([^ ]+) \"\n    b\"((?:[^ :?#]+://[^ ?#/]*(?:[0-9]{1,5})?)?[^ ]+)\"\n    b\"(( HTTP/([0-9.]+))$|$)\"\n)\n\n\ndef crack_first_line(line):\n    m = first_line_re.match(line)\n    if m is not None and m.end() == len(line):\n        if m.group(3):\n            version = m.group(5)\n        else:\n            version = b\"\"\n        method = m.group(1)\n\n        # the request methods that are currently defined are all uppercase:\n        # https://www.iana.org/assignments/http-methods/http-methods.xhtml and\n        # the request method is case sensitive according to\n        # https://tools.ietf.org/html/rfc7231#section-4.1\n\n        # By disallowing anything but uppercase methods we save poor\n        # unsuspecting souls from sending lowercase HTTP methods to waitress\n        # and having the request complete, while servers like nginx drop the\n        # request onto the floor.\n        if method != method.upper():\n            raise ParsingError('Malformed HTTP method \"%s\"' % tostr(method))\n        uri = m.group(2)\n        return method, uri, version\n    else:\n        return b\"\", b\"\", b\"\"\n", "target": 0}
{"idx": 956, "func": "# (c) 2012-2014, Michael DeHaan <michael.dehaan@gmail.com>\n#\n# This file is part of Ansible\n#\n# Ansible is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# Ansible is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.\n\nimport os\n\nfrom ansible import utils\nimport ansible.constants as C\nimport ansible.utils.template as template\nfrom ansible import errors\nfrom ansible.runner.return_data import ReturnData\nimport base64\nimport json\nimport stat\nimport tempfile\nimport pipes\n\n## fixes https://github.com/ansible/ansible/issues/3518\n# http://mypy.pythonblogs.com/12_mypy/archive/1253_workaround_for_python_bug_ascii_codec_cant_encode_character_uxa0_in_position_111_ordinal_not_in_range128.html\nimport sys\nreload(sys)\nsys.setdefaultencoding(\"utf8\")\n\n\nclass ActionModule(object):\n\n    def __init__(self, runner):\n        self.runner = runner\n\n    def run(self, conn, tmp_path, module_name, module_args, inject, complex_args=None, **kwargs):\n        ''' handler for file transfer operations '''\n\n        # load up options\n        options = {}\n        if complex_args:\n            options.update(complex_args)\n        options.update(utils.parse_kv(module_args))\n        source  = options.get('src', None)\n        content = options.get('content', None)\n        dest    = options.get('dest', None)\n        raw     = utils.boolean(options.get('raw', 'no'))\n        force   = utils.boolean(options.get('force', 'yes'))\n\n        # content with newlines is going to be escaped to safely load in yaml\n        # now we need to unescape it so that the newlines are evaluated properly\n        # when writing the file to disk\n        if content:\n            if isinstance(content, unicode):\n                try:\n                    content = content.decode('unicode-escape')\n                except UnicodeDecodeError:\n                    pass\n\n        if (source is None and content is None and not 'first_available_file' in inject) or dest is None:\n            result=dict(failed=True, msg=\"src (or content) and dest are required\")\n            return ReturnData(conn=conn, result=result)\n        elif (source is not None or 'first_available_file' in inject) and content is not None:\n            result=dict(failed=True, msg=\"src and content are mutually exclusive\")\n            return ReturnData(conn=conn, result=result)\n\n        # Check if the source ends with a \"/\"\n        source_trailing_slash = False\n        if source:\n            source_trailing_slash = source.endswith(\"/\")\n\n        # Define content_tempfile in case we set it after finding content populated.\n        content_tempfile = None\n\n        # If content is defined make a temp file and write the content into it.\n        if content is not None:\n            try:\n                # If content comes to us as a dict it should be decoded json.\n                # We need to encode it back into a string to write it out.\n                if type(content) is dict:\n                    content_tempfile = self._create_content_tempfile(json.dumps(content))\n                else:\n                    content_tempfile = self._create_content_tempfile(content)\n                source = content_tempfile\n            except Exception, err:\n                result = dict(failed=True, msg=\"could not write content temp file: %s\" % err)\n                return ReturnData(conn=conn, result=result)\n        # if we have first_available_file in our vars\n        # look up the files and use the first one we find as src\n        elif 'first_available_file' in inject:\n            found = False\n            for fn in inject.get('first_available_file'):\n                fn_orig = fn\n                fnt = template.template(self.runner.basedir, fn, inject)\n                fnd = utils.path_dwim(self.runner.basedir, fnt)\n                if not os.path.exists(fnd) and '_original_file' in inject:\n                    fnd = utils.path_dwim_relative(inject['_original_file'], 'files', fnt, self.runner.basedir, check=False)\n                if os.path.exists(fnd):\n                    source = fnd\n                    found = True\n                    break\n            if not found:\n                results = dict(failed=True, msg=\"could not find src in first_available_file list\")\n                return ReturnData(conn=conn, result=results)\n        else:\n            source = template.template(self.runner.basedir, source, inject)\n            if '_original_file' in inject:\n                source = utils.path_dwim_relative(inject['_original_file'], 'files', source, self.runner.basedir)\n            else:\n                source = utils.path_dwim(self.runner.basedir, source)\n\n        # A list of source file tuples (full_path, relative_path) which will try to copy to the destination\n        source_files = []\n\n        # If source is a directory populate our list else source is a file and translate it to a tuple.\n        if os.path.isdir(source):\n            # Get the amount of spaces to remove to get the relative path.\n            if source_trailing_slash:\n                sz = len(source) + 1\n            else:\n                sz = len(source.rsplit('/', 1)[0]) + 1\n\n            # Walk the directory and append the file tuples to source_files.\n            for base_path, sub_folders, files in os.walk(source):\n                for file in files:\n                    full_path = os.path.join(base_path, file)\n                    rel_path = full_path[sz:]\n                    source_files.append((full_path, rel_path))\n\n            # If it's recursive copy, destination is always a dir,\n            # explicitly mark it so (note - copy module relies on this).\n            if not dest.endswith(\"/\"):\n                dest += \"/\"\n        else:\n            source_files.append((source, os.path.basename(source)))\n\n        changed = False\n        diffs = []\n        module_result = {\"changed\": False}\n\n        # A register for if we executed a module.\n        # Used to cut down on command calls when not recursive.\n        module_executed = False\n\n        # Tell _execute_module to delete the file if there is one file.\n        delete_remote_tmp = (len(source_files) == 1)\n\n        # If this is a recursive action create a tmp_path that we can share as the _exec_module create is too late.\n        if not delete_remote_tmp:\n            if \"-tmp-\" not in tmp_path:\n                tmp_path = self.runner._make_tmp_path(conn)\n\n        for source_full, source_rel in source_files:\n            # Generate the MD5 hash of the local file.\n            local_md5 = utils.md5(source_full)\n\n            # If local_md5 is not defined we can't find the file so we should fail out.\n            if local_md5 is None:\n                result = dict(failed=True, msg=\"could not find src=%s\" % source_full)\n                return ReturnData(conn=conn, result=result)\n\n            # This is kind of optimization - if user told us destination is\n            # dir, do path manipulation right away, otherwise we still check\n            # for dest being a dir via remote call below.\n            if dest.endswith(\"/\"):\n                dest_file = os.path.join(dest, source_rel)\n            else:\n                dest_file = dest\n\n            # Attempt to get the remote MD5 Hash.\n            remote_md5 = self.runner._remote_md5(conn, tmp_path, dest_file)\n\n            if remote_md5 == '3':\n                # The remote_md5 was executed on a directory.\n                if content is not None:\n                    # If source was defined as content remove the temporary file and fail out.\n                    self._remove_tempfile_if_content_defined(content, content_tempfile)\n                    result = dict(failed=True, msg=\"can not use content with a dir as dest\")\n                    return ReturnData(conn=conn, result=result)\n                else:\n                    # Append the relative source location to the destination and retry remote_md5.\n                    dest_file = os.path.join(dest, source_rel)\n                    remote_md5 = self.runner._remote_md5(conn, tmp_path, dest_file)\n\n            if remote_md5 != '1' and not force:\n                # remote_file does not exist so continue to next iteration.\n                continue\n\n            if local_md5 != remote_md5:\n                # The MD5 hashes don't match and we will change or error out.\n                changed = True\n\n                # Create a tmp_path if missing only if this is not recursive.\n                # If this is recursive we already have a tmp_path.\n                if delete_remote_tmp:\n                    if \"-tmp-\" not in tmp_path:\n                        tmp_path = self.runner._make_tmp_path(conn)\n\n                if self.runner.diff and not raw:\n                    diff = self._get_diff_data(conn, tmp_path, inject, dest_file, source_full)\n                else:\n                    diff = {}\n\n                if self.runner.noop_on_check(inject):\n                    self._remove_tempfile_if_content_defined(content, content_tempfile)\n                    diffs.append(diff)\n                    changed = True\n                    module_result = dict(changed=True)\n                    continue\n\n                # Define a remote directory that we will copy the file to.\n                tmp_src = tmp_path + 'source'\n\n                if not raw:\n                    conn.put_file(source_full, tmp_src)\n                else:\n                    conn.put_file(source_full, dest_file)\n\n                # We have copied the file remotely and no longer require our content_tempfile\n                self._remove_tempfile_if_content_defined(content, content_tempfile)\n\n                # fix file permissions when the copy is done as a different user\n                if self.runner.sudo and self.runner.sudo_user != 'root' and not raw:\n                    self.runner._low_level_exec_command(conn, \"chmod a+r %s\" % tmp_src, tmp_path)\n\n                if raw:\n                    # Continue to next iteration if raw is defined.\n                    continue\n\n                # Run the copy module\n\n                # src and dest here come after original and override them\n                # we pass dest only to make sure it includes trailing slash in case of recursive copy\n                module_args_tmp = \"%s src=%s dest=%s original_basename=%s\" % (module_args,\n                                  pipes.quote(tmp_src), pipes.quote(dest), pipes.quote(source_rel))\n\n                if self.runner.no_log:\n                    module_args_tmp = \"%s NO_LOG=True\" % module_args_tmp\n\n                module_return = self.runner._execute_module(conn, tmp_path, 'copy', module_args_tmp, inject=inject, complex_args=complex_args, delete_remote_tmp=delete_remote_tmp)\n                module_executed = True\n\n            else:\n                # no need to transfer the file, already correct md5, but still need to call\n                # the file module in case we want to change attributes\n                self._remove_tempfile_if_content_defined(content, content_tempfile)\n\n                if raw:\n                    # Continue to next iteration if raw is defined.\n                    # self.runner._remove_tmp_path(conn, tmp_path)\n                    continue\n\n                tmp_src = tmp_path + source_rel\n\n                # Build temporary module_args.\n                module_args_tmp = \"%s src=%s original_basename=%s\" % (module_args,\n                                  pipes.quote(tmp_src), pipes.quote(source_rel))\n                if self.runner.noop_on_check(inject):\n                    module_args_tmp = \"%s CHECKMODE=True\" % module_args_tmp\n                if self.runner.no_log:\n                    module_args_tmp = \"%s NO_LOG=True\" % module_args_tmp\n\n                # Execute the file module.\n                module_return = self.runner._execute_module(conn, tmp_path, 'file', module_args_tmp, inject=inject, complex_args=complex_args, delete_remote_tmp=delete_remote_tmp)\n                module_executed = True\n\n            module_result = module_return.result\n            if not module_result.get('md5sum'):\n                module_result['md5sum'] = local_md5\n            if module_result.get('failed') == True:\n                return module_return\n            if module_result.get('changed') == True:\n                changed = True\n\n        # Delete tmp_path if we were recursive or if we did not execute a module.\n        if (not C.DEFAULT_KEEP_REMOTE_FILES and not delete_remote_tmp) \\\n            or (not C.DEFAULT_KEEP_REMOTE_FILES and delete_remote_tmp and not module_executed):\n            self.runner._remove_tmp_path(conn, tmp_path)\n\n        # the file module returns the file path as 'path', but \n        # the copy module uses 'dest', so add it if it's not there\n        if 'path' in module_result and 'dest' not in module_result:\n            module_result['dest'] = module_result['path']\n\n        # TODO: Support detailed status/diff for multiple files\n        if len(source_files) == 1:\n            result = module_result\n        else:\n            result = dict(dest=dest, src=source, changed=changed)\n        if len(diffs) == 1:\n            return ReturnData(conn=conn, result=result, diff=diffs[0])\n        else:\n            return ReturnData(conn=conn, result=result)\n\n    def _create_content_tempfile(self, content):\n        ''' Create a tempfile containing defined content '''\n        fd, content_tempfile = tempfile.mkstemp()\n        f = os.fdopen(fd, 'w')\n        try:\n            f.write(content)\n        except Exception, err:\n            os.remove(content_tempfile)\n            raise Exception(err)\n        finally:\n            f.close()\n        return content_tempfile\n\n    def _get_diff_data(self, conn, tmp, inject, destination, source):\n        peek_result = self.runner._execute_module(conn, tmp, 'file', \"path=%s diff_peek=1\" % destination, inject=inject, persist_files=True)\n\n        if not peek_result.is_successful():\n            return {}\n\n        diff = {}\n        if peek_result.result['state'] == 'absent':\n            diff['before'] = ''\n        elif peek_result.result['appears_binary']:\n            diff['dst_binary'] = 1\n        elif peek_result.result['size'] > utils.MAX_FILE_SIZE_FOR_DIFF:\n            diff['dst_larger'] = utils.MAX_FILE_SIZE_FOR_DIFF\n        else:\n            dest_result = self.runner._execute_module(conn, tmp, 'slurp', \"path=%s\" % destination, inject=inject, persist_files=True)\n            if 'content' in dest_result.result:\n                dest_contents = dest_result.result['content']\n                if dest_result.result['encoding'] == 'base64':\n                    dest_contents = base64.b64decode(dest_contents)\n                else:\n                    raise Exception(\"unknown encoding, failed: %s\" % dest_result.result)\n                diff['before_header'] = destination\n                diff['before'] = dest_contents\n\n        src = open(source)\n        src_contents = src.read(8192)\n        st = os.stat(source)\n        if \"\\x00\" in src_contents:\n            diff['src_binary'] = 1\n        elif st[stat.ST_SIZE] > utils.MAX_FILE_SIZE_FOR_DIFF:\n            diff['src_larger'] = utils.MAX_FILE_SIZE_FOR_DIFF\n        else:\n            src.seek(0)\n            diff['after_header'] = source\n            diff['after'] = src.read()\n\n        return diff\n\n    def _remove_tempfile_if_content_defined(self, content, content_tempfile):\n        if content is not None:\n            os.remove(content_tempfile)\n\n    \n    def _result_key_merge(self, options, results):\n        # add keys to file module results to mimic copy\n        if 'path' in results.result and 'dest' not in results.result:\n            results.result['dest'] = results.result['path']\n            del results.result['path']\n        return results\n", "target": 1}
{"idx": 957, "func": "import re\nimport warnings\nfrom typing import TYPE_CHECKING, Awaitable, Callable, Tuple, Type, TypeVar\n\nfrom .web_exceptions import HTTPMove, HTTPPermanentRedirect\nfrom .web_request import Request\nfrom .web_response import StreamResponse\nfrom .web_urldispatcher import SystemRoute\n\n__all__ = (\n    \"middleware\",\n    \"normalize_path_middleware\",\n)\n\nif TYPE_CHECKING:  # pragma: no cover\n    from .web_app import Application\n\n_Func = TypeVar(\"_Func\")\n\n\nasync def _check_request_resolves(request: Request, path: str) -> Tuple[bool, Request]:\n    alt_request = request.clone(rel_url=path)\n\n    match_info = await request.app.router.resolve(alt_request)\n    alt_request._match_info = match_info  # type: ignore[assignment]\n\n    if match_info.http_exception is None:\n        return True, alt_request\n\n    return False, request\n\n\ndef middleware(f: _Func) -> _Func:\n    warnings.warn(\n        \"Middleware decorator is deprecated since 4.0 \"\n        \"and its behaviour is default, \"\n        \"you can simply remove this decorator.\",\n        DeprecationWarning,\n        stacklevel=2,\n    )\n    return f\n\n\n_Handler = Callable[[Request], Awaitable[StreamResponse]]\n_Middleware = Callable[[Request, _Handler], Awaitable[StreamResponse]]\n\n\ndef normalize_path_middleware(\n    *,\n    append_slash: bool = True,\n    remove_slash: bool = False,\n    merge_slashes: bool = True,\n    redirect_class: Type[HTTPMove] = HTTPPermanentRedirect,\n) -> _Middleware:\n    \"\"\"\n    Middleware factory which produces a middleware that normalizes\n    the path of a request. By normalizing it means:\n\n        - Add or remove a trailing slash to the path.\n        - Double slashes are replaced by one.\n\n    The middleware returns as soon as it finds a path that resolves\n    correctly. The order if both merge and append/remove are enabled is\n        1) merge slashes\n        2) append/remove slash\n        3) both merge slashes and append/remove slash.\n    If the path resolves with at least one of those conditions, it will\n    redirect to the new path.\n\n    Only one of `append_slash` and `remove_slash` can be enabled. If both\n    are `True` the factory will raise an assertion error\n\n    If `append_slash` is `True` the middleware will append a slash when\n    needed. If a resource is defined with trailing slash and the request\n    comes without it, it will append it automatically.\n\n    If `remove_slash` is `True`, `append_slash` must be `False`. When enabled\n    the middleware will remove trailing slashes and redirect if the resource\n    is defined\n\n    If merge_slashes is True, merge multiple consecutive slashes in the\n    path into one.\n    \"\"\"\n\n    correct_configuration = not (append_slash and remove_slash)\n    assert correct_configuration, \"Cannot both remove and append slash\"\n\n    async def impl(request: Request, handler: _Handler) -> StreamResponse:\n        if isinstance(request.match_info.route, SystemRoute):\n            paths_to_check = []\n            if \"?\" in request.raw_path:\n                path, query = request.raw_path.split(\"?\", 1)\n                query = \"?\" + query\n            else:\n                query = \"\"\n                path = request.raw_path\n\n            if merge_slashes:\n                paths_to_check.append(re.sub(\"//+\", \"/\", path))\n            if append_slash and not request.path.endswith(\"/\"):\n                paths_to_check.append(path + \"/\")\n            if remove_slash and request.path.endswith(\"/\"):\n                paths_to_check.append(path[:-1])\n            if merge_slashes and append_slash:\n                paths_to_check.append(re.sub(\"//+\", \"/\", path + \"/\"))\n            if merge_slashes and remove_slash and path.endswith(\"/\"):\n                merged_slashes = re.sub(\"//+\", \"/\", path)\n                paths_to_check.append(merged_slashes[:-1])\n\n            for path in paths_to_check:\n                path = re.sub(\"^//+\", \"/\", path)  # SECURITY: GHSA-v6wp-4m6f-gcjg\n                resolves, request = await _check_request_resolves(request, path)\n                if resolves:\n                    raise redirect_class(request.raw_path + query)\n\n        return await handler(request)\n\n    return impl\n\n\ndef _fix_request_current_app(app: \"Application\") -> _Middleware:\n    async def impl(request: Request, handler: _Handler) -> StreamResponse:\n        with request.match_info.set_current_app(app):\n            return await handler(request)\n\n    return impl\n", "target": 0}
{"idx": 958, "func": "#!/usr/bin/env python2\n# vim:fileencoding=utf-8\n# License: GPLv3 Copyright: 2015, Kovid Goyal <kovid at kovidgoyal.net>\n\nfrom __future__ import absolute_import, division, print_function, unicode_literals\n\nimport cPickle\nimport hashlib\nimport random\nimport shutil\nimport sys\nimport zipfile\nfrom json import load as load_json_file\nfrom threading import Lock\n\nfrom calibre import as_unicode\nfrom calibre.customize.ui import available_input_formats\nfrom calibre.db.view import sanitize_sort_field_name\nfrom calibre.srv.ajax import search_result\nfrom calibre.srv.errors import (\n    BookNotFound, HTTPBadRequest, HTTPForbidden, HTTPNotFound\n)\nfrom calibre.srv.metadata import (\n    book_as_json, categories_as_json, categories_settings, icon_map\n)\nfrom calibre.srv.routes import endpoint, json\nfrom calibre.srv.utils import get_library_data, get_use_roman\nfrom calibre.utils.config import prefs, tweaks\nfrom calibre.utils.icu import sort_key, numeric_sort_key\nfrom calibre.utils.localization import get_lang\nfrom calibre.utils.search_query_parser import ParseException\n\nPOSTABLE = frozenset({'GET', 'POST', 'HEAD'})\n\n\n@endpoint('', auth_required=False)\ndef index(ctx, rd):\n    return lopen(P('content-server/index-generated.html'), 'rb')\n\n\n@endpoint('/calibre.appcache', auth_required=False, cache_control='no-cache')\ndef appcache(ctx, rd):\n    return lopen(P('content-server/calibre.appcache'), 'rb')\n\n\n@endpoint('/robots.txt', auth_required=False)\ndef robots(ctx, rd):\n    return b'User-agent: *\\nDisallow: /'\n\n\n@endpoint('/ajax-setup', auth_required=False, cache_control='no-cache', postprocess=json)\ndef ajax_setup(ctx, rd):\n    auto_reload_port = getattr(rd.opts, 'auto_reload_port', 0)\n    return {\n        'auto_reload_port': max(0, auto_reload_port),\n        'allow_console_print': bool(getattr(rd.opts, 'allow_console_print', False)),\n        'ajax_timeout': rd.opts.ajax_timeout,\n    }\n\n\nprint_lock = Lock()\n\n\n@endpoint('/console-print', methods=('POST', ))\ndef console_print(ctx, rd):\n    if not getattr(rd.opts, 'allow_console_print', False):\n        raise HTTPForbidden('console printing is not allowed')\n    with print_lock:\n        print(rd.remote_addr, end=' ')\n        shutil.copyfileobj(rd.request_body_file, sys.stdout)\n    return ''\n\n\ndef get_basic_query_data(ctx, rd):\n    db, library_id, library_map, default_library = get_library_data(ctx, rd)\n    skeys = db.field_metadata.sortable_field_keys()\n    sorts, orders = [], []\n    for x in rd.query.get('sort', '').split(','):\n        if x:\n            s, o = x.rpartition('.')[::2]\n            if o and not s:\n                s, o = o, ''\n            if o not in ('asc', 'desc'):\n                o = 'asc'\n            if s.startswith('_'):\n                s = '#' + s[1:]\n            s = sanitize_sort_field_name(db.field_metadata, s)\n            if s in skeys:\n                sorts.append(s), orders.append(o)\n    if not sorts:\n        sorts, orders = ['timestamp'], ['desc']\n    return library_id, db, sorts, orders, rd.query.get('vl') or ''\n\n\n_cached_translations = None\n\n\ndef get_translations():\n    global _cached_translations\n    if _cached_translations is None:\n        _cached_translations = False\n        with zipfile.ZipFile(\n            P('content-server/locales.zip', allow_user_override=False), 'r'\n        ) as zf:\n            names = set(zf.namelist())\n            lang = get_lang()\n            if lang not in names:\n                xlang = lang.split('_')[0].lower()\n                if xlang in names:\n                    lang = xlang\n            if lang in names:\n                _cached_translations = load_json_file(zf.open(lang, 'r'))\n    return _cached_translations\n\n\ndef custom_list_template():\n    ans = getattr(custom_list_template, 'ans', None)\n    if ans is None:\n        ans = {\n            'thumbnail': True,\n            'thumbnail_height': 140,\n            'height': 'auto',\n            'comments_fields': ['comments'],\n            'lines': [\n                _('<b>{title}</b> by {authors}'),\n                _('{series_index} of <i>{series}</i>') + '|||{rating}',\n                '{tags}',\n                _('Date: {timestamp}') + '|||' + _('Published: {pubdate}') + '|||' + _('Publisher: {publisher}'),\n                '',\n            ]\n        }\n        custom_list_template.ans = ans\n    return ans\n\n\ndef basic_interface_data(ctx, rd):\n    ans = {\n        'username': rd.username,\n        'output_format': prefs['output_format'].upper(),\n        'input_formats': {x.upper(): True\n                          for x in available_input_formats()},\n        'gui_pubdate_display_format': tweaks['gui_pubdate_display_format'],\n        'gui_timestamp_display_format': tweaks['gui_timestamp_display_format'],\n        'gui_last_modified_display_format': tweaks['gui_last_modified_display_format'],\n        'use_roman_numerals_for_series_number': get_use_roman(),\n        'translations': get_translations(),\n        'icon_map': icon_map(),\n        'icon_path': ctx.url_for('/icon', which=''),\n        'custom_list_template': getattr(ctx, 'custom_list_template', None) or custom_list_template(),\n        'num_per_page': rd.opts.num_per_page,\n    }\n    ans['library_map'], ans['default_library_id'] = ctx.library_info(rd)\n    return ans\n\n\n@endpoint('/interface-data/update', postprocess=json)\ndef update_interface_data(ctx, rd):\n    '''\n    Return the interface data needed for the server UI\n    '''\n    return basic_interface_data(ctx, rd)\n\n\ndef get_field_list(db):\n    fieldlist = list(db.pref('book_display_fields', ()))\n    names = frozenset([x[0] for x in fieldlist])\n    available = frozenset(db.field_metadata.displayable_field_keys())\n    for field in available:\n        if field not in names:\n            fieldlist.append((field, True))\n    return [f for f, d in fieldlist if d and f in available]\n\n\ndef get_library_init_data(ctx, rd, db, num, sorts, orders, vl):\n    ans = {}\n    with db.safe_read_lock:\n        try:\n            ans['search_result'] = search_result(\n                ctx, rd, db,\n                rd.query.get('search', ''), num, 0, ','.join(sorts),\n                ','.join(orders), vl\n            )\n        except ParseException:\n            ans['search_result'] = search_result(\n                ctx, rd, db, '', num, 0, ','.join(sorts), ','.join(orders), vl\n            )\n        sf = db.field_metadata.ui_sortable_field_keys()\n        sf.pop('ondevice', None)\n        ans['sortable_fields'] = sorted(\n            ((sanitize_sort_field_name(db.field_metadata, k), v)\n             for k, v in sf.iteritems()),\n            key=lambda (field, name): sort_key(name)\n        )\n        ans['field_metadata'] = db.field_metadata.all_metadata()\n        ans['virtual_libraries'] = db._pref('virtual_libraries', {})\n        ans['book_display_fields'] = get_field_list(db)\n        mdata = ans['metadata'] = {}\n        try:\n            extra_books = set(\n                int(x) for x in rd.query.get('extra_books', '').split(',')\n            )\n        except Exception:\n            extra_books = ()\n        for coll in (ans['search_result']['book_ids'], extra_books):\n            for book_id in coll:\n                if book_id not in mdata:\n                    data = book_as_json(db, book_id)\n                    if data is not None:\n                        mdata[book_id] = data\n    return ans\n\n\n@endpoint('/interface-data/books-init', postprocess=json)\ndef books(ctx, rd):\n    '''\n    Get data to create list of books\n\n    Optional: ?num=50&sort=timestamp.desc&library_id=<default library>\n              &search=''&extra_books=''&vl=''\n    '''\n    ans = {}\n    try:\n        num = int(rd.query.get('num', rd.opts.num_per_page))\n    except Exception:\n        raise HTTPNotFound('Invalid number of books: %r' % rd.query.get('num'))\n    library_id, db, sorts, orders, vl = get_basic_query_data(ctx, rd)\n    ans = get_library_init_data(ctx, rd, db, num, sorts, orders, vl)\n    ans['library_id'] = library_id\n    return ans\n\n\n@endpoint('/interface-data/init', postprocess=json)\ndef interface_data(ctx, rd):\n    '''\n    Return the data needed to create the server UI as well as a list of books.\n\n    Optional: ?num=50&sort=timestamp.desc&library_id=<default library>\n              &search=''&extra_books=''&vl=''\n    '''\n    ans = basic_interface_data(ctx, rd)\n    ud = {}\n    if rd.username:\n        # Override session data with stored values for the authenticated user,\n        # if any\n        ud = ctx.user_manager.get_session_data(rd.username)\n        lid = ud.get('library_id')\n        if lid and lid in ans['library_map']:\n            rd.query.set('library_id', lid)\n        usort = ud.get('sort')\n        if usort:\n            rd.query.set('sort', usort)\n    ans['library_id'], db, sorts, orders, vl = get_basic_query_data(ctx, rd)\n    ans['user_session_data'] = ud\n    try:\n        num = int(rd.query.get('num', rd.opts.num_per_page))\n    except Exception:\n        raise HTTPNotFound('Invalid number of books: %r' % rd.query.get('num'))\n    ans.update(get_library_init_data(ctx, rd, db, num, sorts, orders, vl))\n    return ans\n\n\n@endpoint('/interface-data/more-books', postprocess=json, methods=POSTABLE)\ndef more_books(ctx, rd):\n    '''\n    Get more results from the specified search-query, which must\n    be specified as JSON in the request body.\n\n    Optional: ?num=50&library_id=<default library>\n    '''\n    db, library_id = get_library_data(ctx, rd)[:2]\n\n    try:\n        num = int(rd.query.get('num', rd.opts.num_per_page))\n    except Exception:\n        raise HTTPNotFound('Invalid number of books: %r' % rd.query.get('num'))\n    try:\n        search_query = load_json_file(rd.request_body_file)\n        query, offset, sorts, orders, vl = search_query['query'], search_query[\n            'offset'\n        ], search_query['sort'], search_query['sort_order'], search_query['vl']\n    except KeyError as err:\n        raise HTTPBadRequest('Search query missing key: %s' % as_unicode(err))\n    except Exception as err:\n        raise HTTPBadRequest('Invalid query: %s' % as_unicode(err))\n    ans = {}\n    with db.safe_read_lock:\n        ans['search_result'] = search_result(\n            ctx, rd, db, query, num, offset, sorts, orders, vl\n        )\n        mdata = ans['metadata'] = {}\n        for book_id in ans['search_result']['book_ids']:\n            data = book_as_json(db, book_id)\n            if data is not None:\n                mdata[book_id] = data\n\n    return ans\n\n\n@endpoint('/interface-data/set-session-data', postprocess=json, methods=POSTABLE)\ndef set_session_data(ctx, rd):\n    '''\n    Store session data persistently so that it is propagated automatically to\n    new logged in clients\n    '''\n    if rd.username:\n        try:\n            new_data = load_json_file(rd.request_body_file)\n            if not isinstance(new_data, dict):\n                raise Exception('session data must be a dict')\n        except Exception as err:\n            raise HTTPBadRequest('Invalid data: %s' % as_unicode(err))\n        ud = ctx.user_manager.get_session_data(rd.username)\n        ud.update(new_data)\n        ctx.user_manager.set_session_data(rd.username, ud)\n\n\n@endpoint('/interface-data/get-books', postprocess=json)\ndef get_books(ctx, rd):\n    '''\n    Get books for the specified query\n\n    Optional: ?library_id=<default library>&num=50&sort=timestamp.desc&search=''&vl=''\n    '''\n    library_id, db, sorts, orders, vl = get_basic_query_data(ctx, rd)\n    try:\n        num = int(rd.query.get('num', rd.opts.num_per_page))\n    except Exception:\n        raise HTTPNotFound('Invalid number of books: %r' % rd.query.get('num'))\n    searchq = rd.query.get('search', '')\n    db = get_library_data(ctx, rd)[0]\n    ans = {}\n    mdata = ans['metadata'] = {}\n    with db.safe_read_lock:\n        try:\n            ans['search_result'] = search_result(\n                ctx, rd, db, searchq, num, 0, ','.join(sorts), ','.join(orders), vl\n            )\n        except ParseException as err:\n            # This must not be translated as it is used by the front end to\n            # detect invalid search expressions\n            raise HTTPBadRequest('Invalid search expression: %s' % as_unicode(err))\n        for book_id in ans['search_result']['book_ids']:\n            data = book_as_json(db, book_id)\n            if data is not None:\n                mdata[book_id] = data\n    return ans\n\n\n@endpoint('/interface-data/book-metadata/{book_id=0}', postprocess=json)\ndef book_metadata(ctx, rd, book_id):\n    '''\n    Get metadata for the specified book. If no book_id is specified, return metadata for a random book.\n\n    Optional: ?library_id=<default library>&vl=<virtual library>\n    '''\n    library_id, db, sorts, orders, vl = get_basic_query_data(ctx, rd)\n\n    if not book_id:\n        all_ids = ctx.allowed_book_ids(rd, db)\n        book_id = random.choice(tuple(all_ids))\n    elif not ctx.has_id(rd, db, book_id):\n        raise BookNotFound(book_id, db)\n    data = book_as_json(db, book_id)\n    if data is None:\n        raise BookNotFound(book_id, db)\n    data['id'] = book_id  # needed for random book view (when book_id=0)\n    return data\n\n\n@endpoint('/interface-data/tag-browser')\ndef tag_browser(ctx, rd):\n    '''\n    Get the Tag Browser serialized as JSON\n    Optional: ?library_id=<default library>&sort_tags_by=name&partition_method=first letter\n              &collapse_at=25&dont_collapse=&hide_empty_categories=&vl=''\n    '''\n    db, library_id = get_library_data(ctx, rd)[:2]\n    opts = categories_settings(rd.query, db)\n    vl = rd.query.get('vl') or ''\n    etag = cPickle.dumps([db.last_modified().isoformat(), rd.username, library_id, vl, list(opts)], -1)\n    etag = hashlib.sha1(etag).hexdigest()\n\n    def generate():\n        return json(ctx, rd, tag_browser, categories_as_json(ctx, rd, db, opts, vl))\n\n    return rd.etagged_dynamic_response(etag, generate)\n\n\n@endpoint('/interface-data/field-names/{field}', postprocess=json)\ndef field_names(ctx, rd, field):\n    '''\n    Get a list of all names for the specified field\n    Optional: ?library_id=<default library>\n    '''\n    db, library_id = get_library_data(ctx, rd)[:2]\n    return tuple(sorted(db.all_field_names(field), key=numeric_sort_key))\n", "target": 0}
{"idx": 959, "func": "# coding: utf-8\n\n# Need not unicode_literals\nfrom __future__ import division, absolute_import\n\nimport io\nimport re\nimport codecs\nimport json\nimport yaml\nfrom urllib.request import urlopen\nfrom yaml import SafeLoader\n\nimport csv\nfrom csv import register_dialect, Dialect, QUOTE_MINIMAL\nfrom typing import List, Optional, Dict, Union, Sequence\n\n\nclass CrLfDialect(Dialect):\n    delimiter = ','\n    quotechar = '\"'\n    doublequote = True\n    skipinitialspace = True\n    lineterminator = '\\r\\n'\n    quoting = QUOTE_MINIMAL\nregister_dialect(\"crlf\", CrLfDialect)\n\n\nclass LfDialect(Dialect):\n    delimiter = ','\n    quotechar = '\"'\n    doublequote = True\n    skipinitialspace = True\n    lineterminator = '\\n'\n    quoting = QUOTE_MINIMAL\nregister_dialect(\"lf\", LfDialect)\n\n\nclass MyDumper(yaml.SafeDumper):\n    def increase_indent(self, flow=False, indentless=False):\n        return super(MyDumper, self).increase_indent(flow, False)\n\n\ndef construct_yaml_str(self, node):\n    return self.construct_scalar(node)\n\nSafeLoader.add_constructor(u'tag:yaml.org,2002:str', construct_yaml_str)\n\n\ndef replace_keys(d, keymap, force_snake_case):\n    \"\"\"\n    :param dict d:\n    :param Dict[unicode, unicode] keymap:\n    :param bool force_snake_case:\n    :rtype: Dict[unicode, unicode]\n    \"\"\"\n    return {\n        to_snake(keymap.get(k, k)) if force_snake_case else keymap.get(k, k):\n            v for k, v in d.items()\n        }\n\n\ndef to_snake(value):\n    \"\"\"For key of dictionary\n\n    :param unicode value:\n    :rtype: unicode\n    \"\"\"\n    return re.sub(r'((?<!^)[A-Z])', \"_\\\\1\", value.strip('<>-')).lower().replace(\"-\", \"_\")\n\n\ndef load_json(json_str):\n    \"\"\"\n    :param unicode json_str:\n    :rtype: dict | list\n    \"\"\"\n    return json.loads(json_str)\n\n\ndef load_jsonf(fpath, encoding):\n    \"\"\"\n    :param unicode fpath:\n    :param unicode encoding:\n    :rtype: dict | list\n    \"\"\"\n    with codecs.open(fpath, encoding=encoding) as f:\n        return json.load(f)\n\n\ndef load_yaml(yaml_str):\n    \"\"\"\n    :param unicode yaml_str:\n    :rtype: dict | list\n    \"\"\"\n    return yaml.safe_load(yaml_str)\n\n\ndef load_yamlf(fpath, encoding):\n    \"\"\"\n    :param unicode fpath:\n    :param unicode encoding:\n    :rtype: dict | list\n    \"\"\"\n    with codecs.open(fpath, encoding=encoding) as f:\n        return yaml.safe_load(f)\n\n\ndef load_csvf(fpath, fieldnames, encoding):\n    \"\"\"\n    :param unicode fpath:\n    :param Optional[list[unicode]] fieldnames:\n    :param unicode encoding:\n    :rtype: List[dict]\n    \"\"\"\n    with open(fpath, mode='r', encoding=encoding) as f:\n        snippet = f.read(8192)\n        f.seek(0)\n\n        dialect = csv.Sniffer().sniff(snippet)\n        dialect.skipinitialspace = True\n        return list(csv.DictReader(f, fieldnames=fieldnames, dialect=dialect))\n\n\ndef load_json_url(url):\n    \"\"\"\n    :param unicode url:\n    :rtype: dict | list\n    \"\"\"\n    return json.loads(urlopen(url).read())\n\n\ndef dump_csv(data, fieldnames, with_header=False, crlf=False):\n    \"\"\"\n    :param List[dict] data:\n    :param List[unicode] fieldnames:\n    :param bool with_header:\n    :param bool crlf:\n    :rtype: unicode\n    \"\"\"\n    def force_str(v):\n        # XXX: Double quotation behaves strangely... so replace (why?)\n        return dump_json(v).replace('\"', \"'\") if isinstance(v, (dict, list)) else v\n\n    with io.StringIO() as sio:\n        dialect = 'crlf' if crlf else 'lf'\n        writer = csv.DictWriter(sio, fieldnames=fieldnames, dialect=dialect, extrasaction='ignore')\n        if with_header:\n            writer.writeheader()\n        for x in data:\n            writer.writerow({k: force_str(v) for k, v in x.items()})\n        sio.seek(0)\n        return sio.read()\n\n\ndef save_csvf(data: list, fieldnames: Sequence[str], fpath: str, encoding: str, with_header=False, crlf=False) -> str:\n    \"\"\"\n    :param data:\n    :param fieldnames:\n    :param fpath: write path\n    :param encoding: encoding\n    :param with_header:\n    :param crlf:\n    :rtype: written path\n    \"\"\"\n    with codecs.open(fpath, mode='w', encoding=encoding) as f:\n        f.write(dump_csv(data, fieldnames, with_header=with_header, crlf=crlf))\n        return fpath\n\n\ndef dump_json(data, indent=None):\n    \"\"\"\n    :param list | dict data:\n    :param Optional[int] indent:\n    :rtype: unicode\n    \"\"\"\n    return json.dumps(data,\n                      indent=indent,\n                      ensure_ascii=False,\n                      sort_keys=True,\n                      separators=(',', ': '))\n\n\ndef dump_yaml(data):\n    \"\"\"\n    :param list | dict data:\n    :rtype: unicode\n    \"\"\"\n    return yaml.dump(data,\n                     indent=2,\n                     encoding=None,\n                     allow_unicode=True,\n                     default_flow_style=False,\n                     Dumper=MyDumper)\n\n\ndef save_yamlf(data: Union[list, dict], fpath: str, encoding: str) -> str:\n    \"\"\"\n    :param data: list | dict data\n    :param fpath: write path\n    :param encoding: encoding\n    :rtype: written path\n    \"\"\"\n    with codecs.open(fpath, mode='w', encoding=encoding) as f:\n        f.write(dump_yaml(data))\n        return fpath\n", "target": 0}
{"idx": 960, "func": "#!/usr/bin/python -tt\n\n# This program is free software; you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation; either version 2 of the License, or\n# (at your option) any later version.\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program; if not, write to the Free Software Foundation,\n# Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA.\n# copyright 2006 Duke University\n# author seth vidal\n\n# sync all or the newest packages from a repo to the local path\n# TODO:\n#     have it print out list of changes\n#     make it work with mirrorlists (silly, really)\n#     man page/more useful docs\n#     deal nicely with a package changing but not changing names (ie: replacement)\n\n# criteria\n# if a package is not the same and smaller then reget it\n# if a package is not the same and larger, delete it and get it again\n# always replace metadata files if they're not the same.\n\n\n\n\n\nimport os\nimport sys\nimport shutil\nimport stat\n\nfrom optparse import OptionParser\nfrom urlparse import urljoin\n\nfrom yumutils.i18n import _\n\nimport yum\nimport yum.Errors\nfrom yum.packageSack import ListPackageSack\nimport rpmUtils.arch\nimport logging\nfrom urlgrabber.progress import TextMeter, TextMultiFileMeter\nimport urlgrabber\n\nclass RepoSync(yum.YumBase):\n    def __init__(self, opts):\n        yum.YumBase.__init__(self)\n        self.logger = logging.getLogger('yum.verbose.reposync')\n        self.opts = opts\n\ndef localpkgs(directory):\n    names = os.listdir(directory)\n\n    cache = {}\n    for name in names:\n        fn = os.path.join(directory, name)\n        try:\n            st = os.lstat(fn)\n        except os.error:\n            continue\n        if stat.S_ISDIR(st.st_mode):\n            subcache = localpkgs(fn)\n            for pkg in subcache.keys():\n                cache[pkg] = subcache[pkg]\n        elif stat.S_ISREG(st.st_mode) and name.endswith(\".rpm\"):\n            cache[name] = {'path': fn, 'size': st.st_size, 'device': st.st_dev}\n    return cache\n\ndef is_subpath(path, root):\n    root = os.path.realpath(root)\n    path = os.path.realpath(os.path.join(root, path))\n    # join() is used below to ensure root ends with a slash\n    return path.startswith(os.path.join(root, ''))\n\ndef parseArgs():\n    usage = _(\"\"\"\n    Reposync is used to synchronize a remote yum repository to a local \n    directory using yum to retrieve the packages.\n    \n    %s [options]\n    \"\"\") % sys.argv[0]\n\n    parser = OptionParser(usage=usage)\n    parser.add_option(\"-c\", \"--config\", default='/etc/yum.conf',\n        help=_('config file to use (defaults to /etc/yum.conf)'))\n    parser.add_option(\"-a\", \"--arch\", default=None,\n        help=_('act as if running the specified arch (default: current arch, note: does not override $releasever. x86_64 is a superset for i*86.)'))\n    parser.add_option(\"--source\", default=False, dest=\"source\", action=\"store_true\",\n                      help=_('operate on source packages'))\n    parser.add_option(\"-r\", \"--repoid\", default=[], action='append',\n        help=_(\"specify repo ids to query, can be specified multiple times (default is all enabled)\"))\n    parser.add_option(\"-e\", \"--cachedir\",\n        help=_(\"directory in which to store metadata\"))\n    parser.add_option(\"-t\", \"--tempcache\", default=False, action=\"store_true\",\n        help=_(\"Use a temp dir for storing/accessing yum-cache\"))\n    parser.add_option(\"-d\", \"--delete\", default=False, action=\"store_true\",\n        help=_(\"delete local packages no longer present in repository\"))\n    parser.add_option(\"-p\", \"--download_path\", dest='destdir',\n        default=os.getcwd(), help=_(\"Path to download packages to: defaults to current dir\"))\n    parser.add_option(\"--norepopath\", dest='norepopath', default=False, action=\"store_true\",\n        help=_(\"Don't add the reponame to the download path. Can only be used when syncing a single repository (default is to add the reponame)\"))\n    parser.add_option(\"-g\", \"--gpgcheck\", default=False, action=\"store_true\",\n        help=_(\"Remove packages that fail GPG signature checking after downloading\"))\n    parser.add_option(\"-u\", \"--urls\", default=False, action=\"store_true\",\n        help=_(\"Just list urls of what would be downloaded, don't download\"))\n    parser.add_option(\"-n\", \"--newest-only\", dest='newest', default=False, action=\"store_true\",\n        help=_(\"Download only newest packages per-repo\"))\n    parser.add_option(\"-q\", \"--quiet\", default=False, action=\"store_true\",\n        help=_(\"Output as little as possible\"))\n    parser.add_option(\"-l\", \"--plugins\", default=False, action=\"store_true\",\n        help=_(\"enable yum plugin support\"))\n    parser.add_option(\"-m\", \"--downloadcomps\", default=False, action=\"store_true\",\n        help=_(\"also download comps.xml\"))\n    parser.add_option(\"\", \"--download-metadata\", dest=\"downloadmd\",\n        default=False, action=\"store_true\",\n        help=_(\"download all the non-default metadata\"))\n    parser.add_option(\"\", \"--allow-path-traversal\", default=False,\n        action=\"store_true\",\n        help=_(\"Allow packages stored outside their repo directory to be synced \"\n               \"(UNSAFE, USE WITH CAUTION!)\"))\n    (opts, args) = parser.parse_args()\n    return (opts, args)\n\n\ndef main():\n    (opts, dummy) = parseArgs()\n\n    if not os.path.exists(opts.destdir) and not opts.urls:\n        try:\n            os.makedirs(opts.destdir)\n        except OSError, e:\n            print >> sys.stderr, _(\"Error: Cannot create destination dir %s\") % opts.destdir\n            sys.exit(1)\n\n    if not os.access(opts.destdir, os.W_OK) and not opts.urls:\n        print >> sys.stderr, _(\"Error: Cannot write to  destination dir %s\") % opts.destdir\n        sys.exit(1)\n\n    my = RepoSync(opts=opts)\n    my.doConfigSetup(fn=opts.config, init_plugins=opts.plugins)\n\n    # Force unprivileged users to have a private temporary cachedir\n    # if they've not given an explicit cachedir\n    if os.getuid() != 0 and not opts.cachedir:\n        opts.tempcache = True\n\n    if opts.tempcache:\n        if not my.setCacheDir(force=True, reuse=False):\n            print >> sys.stderr, _(\"Error: Could not make cachedir, exiting\")\n            sys.exit(50)\n        my.conf.uid = 1 # force locking of user cache\n    elif opts.cachedir:\n        my.repos.setCacheDir(opts.cachedir)\n\n    # Lock if they've not given an explicit cachedir\n    if not opts.cachedir:\n        try:\n            my.doLock()\n        except yum.Errors.LockError, e:\n            print >> sys.stderr, _(\"Error: %s\") % e\n            sys.exit(50)\n\n    #  Use progress bar display when downloading repo metadata\n    # and package files ... needs to be setup before .repos (ie. RHN/etc.).\n    if not opts.quiet:\n        my.repos.setProgressBar(TextMeter(fo=sys.stdout), TextMultiFileMeter(fo=sys.stdout))\n    my.doRepoSetup()\n\n    if len(opts.repoid) > 0:\n        myrepos = []\n\n        # find the ones we want\n        for glob in opts.repoid:\n            add_repos = my.repos.findRepos(glob)\n            if not add_repos:\n                print >> sys.stderr, _(\"Warning: cannot find repository %s\") % glob\n                continue\n            myrepos.extend(add_repos)\n\n        if not myrepos:\n            print >> sys.stderr, _(\"No repositories found\")\n            sys.exit(1)\n\n        # disable them all\n        for repo in my.repos.repos.values():\n            repo.disable()\n\n        # enable the ones we like\n        for repo in myrepos:\n            repo.enable()\n\n    # --norepopath can only be sensibly used with a single repository:\n    if len(my.repos.listEnabled()) > 1 and opts.norepopath:\n        print >> sys.stderr, _(\"Error: Can't use --norepopath with multiple repositories\")\n        sys.exit(1)\n\n    try:\n        arches = rpmUtils.arch.getArchList(opts.arch)\n        if opts.source:\n            arches += ['src']\n        my.doSackSetup(arches)\n    except yum.Errors.RepoError, e:\n        print >> sys.stderr, _(\"Error setting up repositories: %s\") % e\n        # maybe this shouldn't be entirely fatal\n        sys.exit(1)\n\n    exit_code = 0\n    for repo in my.repos.listEnabled():\n        reposack = ListPackageSack(my.pkgSack.returnPackages(repoid=repo.id))\n\n        if opts.newest:\n            download_list = reposack.returnNewestByNameArch()\n        else:\n            download_list = list(reposack)\n\n        if opts.norepopath:\n            local_repo_path = opts.destdir\n        else:\n            local_repo_path = opts.destdir + '/' + repo.id\n\n        # Ensure we don't traverse out of local_repo_path by dropping any\n        # packages whose remote_path is absolute or contains up-level\n        # references (unless explicitly allowed).\n        # See RHBZ#1600221 for details.\n        if not opts.allow_path_traversal:\n            newlist = []\n            skipped = False\n            for pkg in download_list:\n                if is_subpath(pkg.remote_path, local_repo_path):\n                    newlist.append(pkg)\n                    continue\n                my.logger.warning(\n                    _('WARNING: skipping package %s: remote path \"%s\" not '\n                      'within repodir, unsafe to mirror locally')\n                    % (pkg, pkg.remote_path)\n                )\n                skipped = True\n            if skipped:\n                my.logger.info(\n                    _('You can enable unsafe remote paths by using '\n                      '--allow-path-traversal (see reposync(1) for details)')\n                )\n            download_list = newlist\n\n        if opts.delete and os.path.exists(local_repo_path):\n            current_pkgs = localpkgs(local_repo_path)\n\n            download_set = {}\n            for pkg in download_list:\n                rpmname = os.path.basename(pkg.remote_path)\n                download_set[rpmname] = 1\n\n            for pkg in current_pkgs:\n                if pkg in download_set:\n                    continue\n\n                if not opts.quiet:\n                    my.logger.info(\"Removing obsolete %s\", pkg)\n                os.unlink(current_pkgs[pkg]['path'])\n\n        if opts.downloadcomps or opts.downloadmd:\n\n            if not os.path.exists(local_repo_path):\n                try:\n                    os.makedirs(local_repo_path)\n                except IOError, e:\n                    my.logger.error(\"Could not make repo subdir: %s\" % e)\n                    my.closeRpmDB()\n                    sys.exit(1)\n\n            if opts.downloadcomps:\n                wanted_types = ['group']\n\n            if opts.downloadmd:\n                wanted_types = repo.repoXML.fileTypes()\n\n            for ftype in repo.repoXML.fileTypes():\n                if ftype in ['primary', 'primary_db', 'filelists',\n                             'filelists_db', 'other', 'other_db']:\n                    continue\n                if ftype not in wanted_types:\n                    continue\n\n                try:\n                    resultfile = repo.retrieveMD(ftype)\n                    basename = os.path.basename(resultfile)\n                    if ftype == 'group' and opts.downloadcomps: # for compat with how --downloadcomps saved the comps file always as comps.xml\n                        basename = 'comps.xml'\n                    shutil.copyfile(resultfile, \"%s/%s\" % (local_repo_path, basename))\n                except yum.Errors.RepoMDError, e:\n                    if not opts.quiet:\n                        my.logger.error(\"Unable to fetch metadata: %s\" % e)\n\n        remote_size = 0\n        if not opts.urls:\n            for pkg in download_list:\n                local = os.path.join(local_repo_path, pkg.remote_path)\n                sz = int(pkg.returnSimple('packagesize'))\n                if os.path.exists(local) and os.path.getsize(local) == sz:\n                    continue\n                remote_size += sz\n\n        if hasattr(urlgrabber.progress, 'text_meter_total_size'):\n            urlgrabber.progress.text_meter_total_size(remote_size)\n\n        download_list.sort(key=lambda pkg: pkg.name)\n        if opts.urls:\n            for pkg in download_list:\n                local = os.path.join(local_repo_path, pkg.remote_path)\n                if not (os.path.exists(local) and my.verifyPkg(local, pkg, False)):\n                    print urljoin(pkg.repo.urls[0], pkg.remote_path)\n            continue\n\n        # create dest dir\n        if not os.path.exists(local_repo_path):\n            os.makedirs(local_repo_path)\n\n        # set localpaths\n        for pkg in download_list:\n            pkg.localpath = os.path.join(local_repo_path, pkg.remote_path)\n            pkg.repo.copy_local = True\n            pkg.repo.cache = 0\n            localdir = os.path.dirname(pkg.localpath)\n            if not os.path.exists(localdir):\n                os.makedirs(localdir)\n\n        # use downloader from YumBase\n        probs = my.downloadPkgs(download_list)\n        if probs:\n            exit_code = 1\n            for key in probs:\n                for error in probs[key]:\n                    my.logger.error('%s: %s', key, error)\n\n        if opts.gpgcheck:\n            for pkg in download_list:\n                result, error = my.sigCheckPkg(pkg)\n                if result != 0:\n                    rpmfn = os.path.basename(pkg.remote_path)\n                    if result == 1:\n                        my.logger.warning('Removing %s, due to missing GPG key.' % rpmfn)\n                    elif result == 2:\n                        my.logger.warning('Removing %s due to failed signature check.' % rpmfn)\n                    else:\n                        my.logger.warning('Removing %s due to failed signature check: %s' % rpmfn)\n                    os.unlink(pkg.localpath)\n                    exit_code = 1\n                    continue\n\n    my.closeRpmDB()\n    sys.exit(exit_code)\n\nif __name__ == \"__main__\":\n    main()\n", "target": 0}
{"idx": 961, "func": "\"\"\"Header value parser implementing various email-related RFC parsing rules.\n\nThe parsing methods defined in this module implement various email related\nparsing rules.  Principal among them is RFC 5322, which is the followon\nto RFC 2822 and primarily a clarification of the former.  It also implements\nRFC 2047 encoded word decoding.\n\nRFC 5322 goes to considerable trouble to maintain backward compatibility with\nRFC 822 in the parse phase, while cleaning up the structure on the generation\nphase.  This parser supports correct RFC 5322 generation by tagging white space\nas folding white space only when folding is allowed in the non-obsolete rule\nsets.  Actually, the parser is even more generous when accepting input than RFC\n5322 mandates, following the spirit of Postel's Law, which RFC 5322 encourages.\nWhere possible deviations from the standard are annotated on the 'defects'\nattribute of tokens that deviate.\n\nThe general structure of the parser follows RFC 5322, and uses its terminology\nwhere there is a direct correspondence.  Where the implementation requires a\nsomewhat different structure than that used by the formal grammar, new terms\nthat mimic the closest existing terms are used.  Thus, it really helps to have\na copy of RFC 5322 handy when studying this code.\n\nInput to the parser is a string that has already been unfolded according to\nRFC 5322 rules.  According to the RFC this unfolding is the very first step, and\nthis parser leaves the unfolding step to a higher level message parser, which\nwill have already detected the line breaks that need unfolding while\ndetermining the beginning and end of each header.\n\nThe output of the parser is a TokenList object, which is a list subclass.  A\nTokenList is a recursive data structure.  The terminal nodes of the structure\nare Terminal objects, which are subclasses of str.  These do not correspond\ndirectly to terminal objects in the formal grammar, but are instead more\npractical higher level combinations of true terminals.\n\nAll TokenList and Terminal objects have a 'value' attribute, which produces the\nsemantically meaningful value of that part of the parse subtree.  The value of\nall whitespace tokens (no matter how many sub-tokens they may contain) is a\nsingle space, as per the RFC rules.  This includes 'CFWS', which is herein\nincluded in the general class of whitespace tokens.  There is one exception to\nthe rule that whitespace tokens are collapsed into single spaces in values: in\nthe value of a 'bare-quoted-string' (a quoted-string with no leading or\ntrailing whitespace), any whitespace that appeared between the quotation marks\nis preserved in the returned value.  Note that in all Terminal strings quoted\npairs are turned into their unquoted values.\n\nAll TokenList and Terminal objects also have a string value, which attempts to\nbe a \"canonical\" representation of the RFC-compliant form of the substring that\nproduced the parsed subtree, including minimal use of quoted pair quoting.\nWhitespace runs are not collapsed.\n\nComment tokens also have a 'content' attribute providing the string found\nbetween the parens (including any nested comments) with whitespace preserved.\n\nAll TokenList and Terminal objects have a 'defects' attribute which is a\npossibly empty list all of the defects found while creating the token.  Defects\nmay appear on any token in the tree, and a composite list of all defects in the\nsubtree is available through the 'all_defects' attribute of any node.  (For\nTerminal notes x.defects == x.all_defects.)\n\nEach object in a parse tree is called a 'token', and each has a 'token_type'\nattribute that gives the name from the RFC 5322 grammar that it represents.\nNot all RFC 5322 nodes are produced, and there is one non-RFC 5322 node that\nmay be produced: 'ptext'.  A 'ptext' is a string of printable ascii characters.\nIt is returned in place of lists of (ctext/quoted-pair) and\n(qtext/quoted-pair).\n\nXXX: provide complete list of token types.\n\"\"\"\n\nimport re\nimport sys\nimport urllib   # For urllib.parse.unquote\nfrom string import hexdigits\nfrom operator import itemgetter\nfrom email import _encoded_words as _ew\nfrom email import errors\nfrom email import utils\n\n#\n# Useful constants and functions\n#\n\nWSP = set(' \\t')\nCFWS_LEADER = WSP | set('(')\nSPECIALS = set(r'()<>@,:;.\\\"[]')\nATOM_ENDS = SPECIALS | WSP\nDOT_ATOM_ENDS = ATOM_ENDS - set('.')\n# '.', '\"', and '(' do not end phrases in order to support obs-phrase\nPHRASE_ENDS = SPECIALS - set('.\"(')\nTSPECIALS = (SPECIALS | set('/?=')) - set('.')\nTOKEN_ENDS = TSPECIALS | WSP\nASPECIALS = TSPECIALS | set(\"*'%\")\nATTRIBUTE_ENDS = ASPECIALS | WSP\nEXTENDED_ATTRIBUTE_ENDS = ATTRIBUTE_ENDS - set('%')\n\ndef quote_string(value):\n    return '\"'+str(value).replace('\\\\', '\\\\\\\\').replace('\"', r'\\\"')+'\"'\n\n# Match a RFC 2047 word, looks like =?utf-8?q?someword?=\nrfc2047_matcher = re.compile(r'''\n   =\\?            # literal =?\n   [^?]*          # charset\n   \\?             # literal ?\n   [qQbB]         # literal 'q' or 'b', case insensitive\n   \\?             # literal ?\n  .*?             # encoded word\n  \\?=             # literal ?=\n''', re.VERBOSE | re.MULTILINE)\n\n\n#\n# TokenList and its subclasses\n#\n\nclass TokenList(list):\n\n    token_type = None\n    syntactic_break = True\n    ew_combine_allowed = True\n\n    def __init__(self, *args, **kw):\n        super().__init__(*args, **kw)\n        self.defects = []\n\n    def __str__(self):\n        return ''.join(str(x) for x in self)\n\n    def __repr__(self):\n        return '{}({})'.format(self.__class__.__name__,\n                             super().__repr__())\n\n    @property\n    def value(self):\n        return ''.join(x.value for x in self if x.value)\n\n    @property\n    def all_defects(self):\n        return sum((x.all_defects for x in self), self.defects)\n\n    def startswith_fws(self):\n        return self[0].startswith_fws()\n\n    @property\n    def as_ew_allowed(self):\n        \"\"\"True if all top level tokens of this part may be RFC2047 encoded.\"\"\"\n        return all(part.as_ew_allowed for part in self)\n\n    @property\n    def comments(self):\n        comments = []\n        for token in self:\n            comments.extend(token.comments)\n        return comments\n\n    def fold(self, *, policy):\n        return _refold_parse_tree(self, policy=policy)\n\n    def pprint(self, indent=''):\n        print(self.ppstr(indent=indent))\n\n    def ppstr(self, indent=''):\n        return '\\n'.join(self._pp(indent=indent))\n\n    def _pp(self, indent=''):\n        yield '{}{}/{}('.format(\n            indent,\n            self.__class__.__name__,\n            self.token_type)\n        for token in self:\n            if not hasattr(token, '_pp'):\n                yield (indent + '    !! invalid element in token '\n                                        'list: {!r}'.format(token))\n            else:\n                yield from token._pp(indent+'    ')\n        if self.defects:\n            extra = ' Defects: {}'.format(self.defects)\n        else:\n            extra = ''\n        yield '{}){}'.format(indent, extra)\n\n\nclass WhiteSpaceTokenList(TokenList):\n\n    @property\n    def value(self):\n        return ' '\n\n    @property\n    def comments(self):\n        return [x.content for x in self if x.token_type=='comment']\n\n\nclass UnstructuredTokenList(TokenList):\n    token_type = 'unstructured'\n\n\nclass Phrase(TokenList):\n    token_type = 'phrase'\n\nclass Word(TokenList):\n    token_type = 'word'\n\n\nclass CFWSList(WhiteSpaceTokenList):\n    token_type = 'cfws'\n\n\nclass Atom(TokenList):\n    token_type = 'atom'\n\n\nclass Token(TokenList):\n    token_type = 'token'\n    encode_as_ew = False\n\n\nclass EncodedWord(TokenList):\n    token_type = 'encoded-word'\n    cte = None\n    charset = None\n    lang = None\n\n\nclass QuotedString(TokenList):\n\n    token_type = 'quoted-string'\n\n    @property\n    def content(self):\n        for x in self:\n            if x.token_type == 'bare-quoted-string':\n                return x.value\n\n    @property\n    def quoted_value(self):\n        res = []\n        for x in self:\n            if x.token_type == 'bare-quoted-string':\n                res.append(str(x))\n            else:\n                res.append(x.value)\n        return ''.join(res)\n\n    @property\n    def stripped_value(self):\n        for token in self:\n            if token.token_type == 'bare-quoted-string':\n                return token.value\n\n\nclass BareQuotedString(QuotedString):\n\n    token_type = 'bare-quoted-string'\n\n    def __str__(self):\n        return quote_string(''.join(str(x) for x in self))\n\n    @property\n    def value(self):\n        return ''.join(str(x) for x in self)\n\n\nclass Comment(WhiteSpaceTokenList):\n\n    token_type = 'comment'\n\n    def __str__(self):\n        return ''.join(sum([\n                            [\"(\"],\n                            [self.quote(x) for x in self],\n                            [\")\"],\n                            ], []))\n\n    def quote(self, value):\n        if value.token_type == 'comment':\n            return str(value)\n        return str(value).replace('\\\\', '\\\\\\\\').replace(\n                                  '(', r'\\(').replace(\n                                  ')', r'\\)')\n\n    @property\n    def content(self):\n        return ''.join(str(x) for x in self)\n\n    @property\n    def comments(self):\n        return [self.content]\n\nclass AddressList(TokenList):\n\n    token_type = 'address-list'\n\n    @property\n    def addresses(self):\n        return [x for x in self if x.token_type=='address']\n\n    @property\n    def mailboxes(self):\n        return sum((x.mailboxes\n                    for x in self if x.token_type=='address'), [])\n\n    @property\n    def all_mailboxes(self):\n        return sum((x.all_mailboxes\n                    for x in self if x.token_type=='address'), [])\n\n\nclass Address(TokenList):\n\n    token_type = 'address'\n\n    @property\n    def display_name(self):\n        if self[0].token_type == 'group':\n            return self[0].display_name\n\n    @property\n    def mailboxes(self):\n        if self[0].token_type == 'mailbox':\n            return [self[0]]\n        elif self[0].token_type == 'invalid-mailbox':\n            return []\n        return self[0].mailboxes\n\n    @property\n    def all_mailboxes(self):\n        if self[0].token_type == 'mailbox':\n            return [self[0]]\n        elif self[0].token_type == 'invalid-mailbox':\n            return [self[0]]\n        return self[0].all_mailboxes\n\nclass MailboxList(TokenList):\n\n    token_type = 'mailbox-list'\n\n    @property\n    def mailboxes(self):\n        return [x for x in self if x.token_type=='mailbox']\n\n    @property\n    def all_mailboxes(self):\n        return [x for x in self\n            if x.token_type in ('mailbox', 'invalid-mailbox')]\n\n\nclass GroupList(TokenList):\n\n    token_type = 'group-list'\n\n    @property\n    def mailboxes(self):\n        if not self or self[0].token_type != 'mailbox-list':\n            return []\n        return self[0].mailboxes\n\n    @property\n    def all_mailboxes(self):\n        if not self or self[0].token_type != 'mailbox-list':\n            return []\n        return self[0].all_mailboxes\n\n\nclass Group(TokenList):\n\n    token_type = \"group\"\n\n    @property\n    def mailboxes(self):\n        if self[2].token_type != 'group-list':\n            return []\n        return self[2].mailboxes\n\n    @property\n    def all_mailboxes(self):\n        if self[2].token_type != 'group-list':\n            return []\n        return self[2].all_mailboxes\n\n    @property\n    def display_name(self):\n        return self[0].display_name\n\n\nclass NameAddr(TokenList):\n\n    token_type = 'name-addr'\n\n    @property\n    def display_name(self):\n        if len(self) == 1:\n            return None\n        return self[0].display_name\n\n    @property\n    def local_part(self):\n        return self[-1].local_part\n\n    @property\n    def domain(self):\n        return self[-1].domain\n\n    @property\n    def route(self):\n        return self[-1].route\n\n    @property\n    def addr_spec(self):\n        return self[-1].addr_spec\n\n\nclass AngleAddr(TokenList):\n\n    token_type = 'angle-addr'\n\n    @property\n    def local_part(self):\n        for x in self:\n            if x.token_type == 'addr-spec':\n                return x.local_part\n\n    @property\n    def domain(self):\n        for x in self:\n            if x.token_type == 'addr-spec':\n                return x.domain\n\n    @property\n    def route(self):\n        for x in self:\n            if x.token_type == 'obs-route':\n                return x.domains\n\n    @property\n    def addr_spec(self):\n        for x in self:\n            if x.token_type == 'addr-spec':\n                if x.local_part:\n                    return x.addr_spec\n                else:\n                    return quote_string(x.local_part) + x.addr_spec\n        else:\n            return '<>'\n\n\nclass ObsRoute(TokenList):\n\n    token_type = 'obs-route'\n\n    @property\n    def domains(self):\n        return [x.domain for x in self if x.token_type == 'domain']\n\n\nclass Mailbox(TokenList):\n\n    token_type = 'mailbox'\n\n    @property\n    def display_name(self):\n        if self[0].token_type == 'name-addr':\n            return self[0].display_name\n\n    @property\n    def local_part(self):\n        return self[0].local_part\n\n    @property\n    def domain(self):\n        return self[0].domain\n\n    @property\n    def route(self):\n        if self[0].token_type == 'name-addr':\n            return self[0].route\n\n    @property\n    def addr_spec(self):\n        return self[0].addr_spec\n\n\nclass InvalidMailbox(TokenList):\n\n    token_type = 'invalid-mailbox'\n\n    @property\n    def display_name(self):\n        return None\n\n    local_part = domain = route = addr_spec = display_name\n\n\nclass Domain(TokenList):\n\n    token_type = 'domain'\n    as_ew_allowed = False\n\n    @property\n    def domain(self):\n        return ''.join(super().value.split())\n\n\nclass DotAtom(TokenList):\n    token_type = 'dot-atom'\n\n\nclass DotAtomText(TokenList):\n    token_type = 'dot-atom-text'\n    as_ew_allowed = True\n\n\nclass NoFoldLiteral(TokenList):\n    token_type = 'no-fold-literal'\n    as_ew_allowed = False\n\n\nclass AddrSpec(TokenList):\n\n    token_type = 'addr-spec'\n    as_ew_allowed = False\n\n    @property\n    def local_part(self):\n        return self[0].local_part\n\n    @property\n    def domain(self):\n        if len(self) < 3:\n            return None\n        return self[-1].domain\n\n    @property\n    def value(self):\n        if len(self) < 3:\n            return self[0].value\n        return self[0].value.rstrip()+self[1].value+self[2].value.lstrip()\n\n    @property\n    def addr_spec(self):\n        nameset = set(self.local_part)\n        if len(nameset) > len(nameset-DOT_ATOM_ENDS):\n            lp = quote_string(self.local_part)\n        else:\n            lp = self.local_part\n        if self.domain is not None:\n            return lp + '@' + self.domain\n        return lp\n\n\nclass ObsLocalPart(TokenList):\n\n    token_type = 'obs-local-part'\n    as_ew_allowed = False\n\n\nclass DisplayName(Phrase):\n\n    token_type = 'display-name'\n    ew_combine_allowed = False\n\n    @property\n    def display_name(self):\n        res = TokenList(self)\n        if res[0].token_type == 'cfws':\n            res.pop(0)\n        else:\n            if res[0][0].token_type == 'cfws':\n                res[0] = TokenList(res[0][1:])\n        if res[-1].token_type == 'cfws':\n            res.pop()\n        else:\n            if res[-1][-1].token_type == 'cfws':\n                res[-1] = TokenList(res[-1][:-1])\n        return res.value\n\n    @property\n    def value(self):\n        quote = False\n        if self.defects:\n            quote = True\n        else:\n            for x in self:\n                if x.token_type == 'quoted-string':\n                    quote = True\n        if quote:\n            pre = post = ''\n            if self[0].token_type=='cfws' or self[0][0].token_type=='cfws':\n                pre = ' '\n            if self[-1].token_type=='cfws' or self[-1][-1].token_type=='cfws':\n                post = ' '\n            return pre+quote_string(self.display_name)+post\n        else:\n            return super().value\n\n\nclass LocalPart(TokenList):\n\n    token_type = 'local-part'\n    as_ew_allowed = False\n\n    @property\n    def value(self):\n        if self[0].token_type == \"quoted-string\":\n            return self[0].quoted_value\n        else:\n            return self[0].value\n\n    @property\n    def local_part(self):\n        # Strip whitespace from front, back, and around dots.\n        res = [DOT]\n        last = DOT\n        last_is_tl = False\n        for tok in self[0] + [DOT]:\n            if tok.token_type == 'cfws':\n                continue\n            if (last_is_tl and tok.token_type == 'dot' and\n                    last[-1].token_type == 'cfws'):\n                res[-1] = TokenList(last[:-1])\n            is_tl = isinstance(tok, TokenList)\n            if (is_tl and last.token_type == 'dot' and\n                    tok[0].token_type == 'cfws'):\n                res.append(TokenList(tok[1:]))\n            else:\n                res.append(tok)\n            last = res[-1]\n            last_is_tl = is_tl\n        res = TokenList(res[1:-1])\n        return res.value\n\n\nclass DomainLiteral(TokenList):\n\n    token_type = 'domain-literal'\n    as_ew_allowed = False\n\n    @property\n    def domain(self):\n        return ''.join(super().value.split())\n\n    @property\n    def ip(self):\n        for x in self:\n            if x.token_type == 'ptext':\n                return x.value\n\n\nclass MIMEVersion(TokenList):\n\n    token_type = 'mime-version'\n    major = None\n    minor = None\n\n\nclass Parameter(TokenList):\n\n    token_type = 'parameter'\n    sectioned = False\n    extended = False\n    charset = 'us-ascii'\n\n    @property\n    def section_number(self):\n        # Because the first token, the attribute (name) eats CFWS, the second\n        # token is always the section if there is one.\n        return self[1].number if self.sectioned else 0\n\n    @property\n    def param_value(self):\n        # This is part of the \"handle quoted extended parameters\" hack.\n        for token in self:\n            if token.token_type == 'value':\n                return token.stripped_value\n            if token.token_type == 'quoted-string':\n                for token in token:\n                    if token.token_type == 'bare-quoted-string':\n                        for token in token:\n                            if token.token_type == 'value':\n                                return token.stripped_value\n        return ''\n\n\nclass InvalidParameter(Parameter):\n\n    token_type = 'invalid-parameter'\n\n\nclass Attribute(TokenList):\n\n    token_type = 'attribute'\n\n    @property\n    def stripped_value(self):\n        for token in self:\n            if token.token_type.endswith('attrtext'):\n                return token.value\n\nclass Section(TokenList):\n\n    token_type = 'section'\n    number = None\n\n\nclass Value(TokenList):\n\n    token_type = 'value'\n\n    @property\n    def stripped_value(self):\n        token = self[0]\n        if token.token_type == 'cfws':\n            token = self[1]\n        if token.token_type.endswith(\n                ('quoted-string', 'attribute', 'extended-attribute')):\n            return token.stripped_value\n        return self.value\n\n\nclass MimeParameters(TokenList):\n\n    token_type = 'mime-parameters'\n    syntactic_break = False\n\n    @property\n    def params(self):\n        # The RFC specifically states that the ordering of parameters is not\n        # guaranteed and may be reordered by the transport layer.  So we have\n        # to assume the RFC 2231 pieces can come in any order.  However, we\n        # output them in the order that we first see a given name, which gives\n        # us a stable __str__.\n        params = {}  # Using order preserving dict from Python 3.7+\n        for token in self:\n            if not token.token_type.endswith('parameter'):\n                continue\n            if token[0].token_type != 'attribute':\n                continue\n            name = token[0].value.strip()\n            if name not in params:\n                params[name] = []\n            params[name].append((token.section_number, token))\n        for name, parts in params.items():\n            parts = sorted(parts, key=itemgetter(0))\n            first_param = parts[0][1]\n            charset = first_param.charset\n            # Our arbitrary error recovery is to ignore duplicate parameters,\n            # to use appearance order if there are duplicate rfc 2231 parts,\n            # and to ignore gaps.  This mimics the error recovery of get_param.\n            if not first_param.extended and len(parts) > 1:\n                if parts[1][0] == 0:\n                    parts[1][1].defects.append(errors.InvalidHeaderDefect(\n                        'duplicate parameter name; duplicate(s) ignored'))\n                    parts = parts[:1]\n                # Else assume the *0* was missing...note that this is different\n                # from get_param, but we registered a defect for this earlier.\n            value_parts = []\n            i = 0\n            for section_number, param in parts:\n                if section_number != i:\n                    # We could get fancier here and look for a complete\n                    # duplicate extended parameter and ignore the second one\n                    # seen.  But we're not doing that.  The old code didn't.\n                    if not param.extended:\n                        param.defects.append(errors.InvalidHeaderDefect(\n                            'duplicate parameter name; duplicate ignored'))\n                        continue\n                    else:\n                        param.defects.append(errors.InvalidHeaderDefect(\n                            \"inconsistent RFC2231 parameter numbering\"))\n                i += 1\n                value = param.param_value\n                if param.extended:\n                    try:\n                        value = urllib.parse.unquote_to_bytes(value)\n                    except UnicodeEncodeError:\n                        # source had surrogate escaped bytes.  What we do now\n                        # is a bit of an open question.  I'm not sure this is\n                        # the best choice, but it is what the old algorithm did\n                        value = urllib.parse.unquote(value, encoding='latin-1')\n                    else:\n                        try:\n                            value = value.decode(charset, 'surrogateescape')\n                        except LookupError:\n                            # XXX: there should really be a custom defect for\n                            # unknown character set to make it easy to find,\n                            # because otherwise unknown charset is a silent\n                            # failure.\n                            value = value.decode('us-ascii', 'surrogateescape')\n                        if utils._has_surrogates(value):\n                            param.defects.append(errors.UndecodableBytesDefect())\n                value_parts.append(value)\n            value = ''.join(value_parts)\n            yield name, value\n\n    def __str__(self):\n        params = []\n        for name, value in self.params:\n            if value:\n                params.append('{}={}'.format(name, quote_string(value)))\n            else:\n                params.append(name)\n        params = '; '.join(params)\n        return ' ' + params if params else ''\n\n\nclass ParameterizedHeaderValue(TokenList):\n\n    # Set this false so that the value doesn't wind up on a new line even\n    # if it and the parameters would fit there but not on the first line.\n    syntactic_break = False\n\n    @property\n    def params(self):\n        for token in reversed(self):\n            if token.token_type == 'mime-parameters':\n                return token.params\n        return {}\n\n\nclass ContentType(ParameterizedHeaderValue):\n    token_type = 'content-type'\n    as_ew_allowed = False\n    maintype = 'text'\n    subtype = 'plain'\n\n\nclass ContentDisposition(ParameterizedHeaderValue):\n    token_type = 'content-disposition'\n    as_ew_allowed = False\n    content_disposition = None\n\n\nclass ContentTransferEncoding(TokenList):\n    token_type = 'content-transfer-encoding'\n    as_ew_allowed = False\n    cte = '7bit'\n\n\nclass HeaderLabel(TokenList):\n    token_type = 'header-label'\n    as_ew_allowed = False\n\n\nclass MsgID(TokenList):\n    token_type = 'msg-id'\n    as_ew_allowed = False\n\n    def fold(self, policy):\n        # message-id tokens may not be folded.\n        return str(self) + policy.linesep\n\nclass MessageID(MsgID):\n    token_type = 'message-id'\n\n\nclass Header(TokenList):\n    token_type = 'header'\n\n\n#\n# Terminal classes and instances\n#\n\nclass Terminal(str):\n\n    as_ew_allowed = True\n    ew_combine_allowed = True\n    syntactic_break = True\n\n    def __new__(cls, value, token_type):\n        self = super().__new__(cls, value)\n        self.token_type = token_type\n        self.defects = []\n        return self\n\n    def __repr__(self):\n        return \"{}({})\".format(self.__class__.__name__, super().__repr__())\n\n    def pprint(self):\n        print(self.__class__.__name__ + '/' + self.token_type)\n\n    @property\n    def all_defects(self):\n        return list(self.defects)\n\n    def _pp(self, indent=''):\n        return [\"{}{}/{}({}){}\".format(\n            indent,\n            self.__class__.__name__,\n            self.token_type,\n            super().__repr__(),\n            '' if not self.defects else ' {}'.format(self.defects),\n            )]\n\n    def pop_trailing_ws(self):\n        # This terminates the recursion.\n        return None\n\n    @property\n    def comments(self):\n        return []\n\n    def __getnewargs__(self):\n        return(str(self), self.token_type)\n\n\nclass WhiteSpaceTerminal(Terminal):\n\n    @property\n    def value(self):\n        return ' '\n\n    def startswith_fws(self):\n        return True\n\n\nclass ValueTerminal(Terminal):\n\n    @property\n    def value(self):\n        return self\n\n    def startswith_fws(self):\n        return False\n\n\nclass EWWhiteSpaceTerminal(WhiteSpaceTerminal):\n\n    @property\n    def value(self):\n        return ''\n\n    def __str__(self):\n        return ''\n\n\n# XXX these need to become classes and used as instances so\n# that a program can't change them in a parse tree and screw\n# up other parse trees.  Maybe should have  tests for that, too.\nDOT = ValueTerminal('.', 'dot')\nListSeparator = ValueTerminal(',', 'list-separator')\nRouteComponentMarker = ValueTerminal('@', 'route-component-marker')\n\n#\n# Parser\n#\n\n# Parse strings according to RFC822/2047/2822/5322 rules.\n#\n# This is a stateless parser.  Each get_XXX function accepts a string and\n# returns either a Terminal or a TokenList representing the RFC object named\n# by the method and a string containing the remaining unparsed characters\n# from the input.  Thus a parser method consumes the next syntactic construct\n# of a given type and returns a token representing the construct plus the\n# unparsed remainder of the input string.\n#\n# For example, if the first element of a structured header is a 'phrase',\n# then:\n#\n#     phrase, value = get_phrase(value)\n#\n# returns the complete phrase from the start of the string value, plus any\n# characters left in the string after the phrase is removed.\n\n_wsp_splitter = re.compile(r'([{}]+)'.format(''.join(WSP))).split\n_non_atom_end_matcher = re.compile(r\"[^{}]+\".format(\n    re.escape(''.join(ATOM_ENDS)))).match\n_non_printable_finder = re.compile(r\"[\\x00-\\x20\\x7F]\").findall\n_non_token_end_matcher = re.compile(r\"[^{}]+\".format(\n    re.escape(''.join(TOKEN_ENDS)))).match\n_non_attribute_end_matcher = re.compile(r\"[^{}]+\".format(\n    re.escape(''.join(ATTRIBUTE_ENDS)))).match\n_non_extended_attribute_end_matcher = re.compile(r\"[^{}]+\".format(\n    re.escape(''.join(EXTENDED_ATTRIBUTE_ENDS)))).match\n\ndef _validate_xtext(xtext):\n    \"\"\"If input token contains ASCII non-printables, register a defect.\"\"\"\n\n    non_printables = _non_printable_finder(xtext)\n    if non_printables:\n        xtext.defects.append(errors.NonPrintableDefect(non_printables))\n    if utils._has_surrogates(xtext):\n        xtext.defects.append(errors.UndecodableBytesDefect(\n            \"Non-ASCII characters found in header token\"))\n\ndef _get_ptext_to_endchars(value, endchars):\n    \"\"\"Scan printables/quoted-pairs until endchars and return unquoted ptext.\n\n    This function turns a run of qcontent, ccontent-without-comments, or\n    dtext-with-quoted-printables into a single string by unquoting any\n    quoted printables.  It returns the string, the remaining value, and\n    a flag that is True iff there were any quoted printables decoded.\n\n    \"\"\"\n    fragment, *remainder = _wsp_splitter(value, 1)\n    vchars = []\n    escape = False\n    had_qp = False\n    for pos in range(len(fragment)):\n        if fragment[pos] == '\\\\':\n            if escape:\n                escape = False\n                had_qp = True\n            else:\n                escape = True\n                continue\n        if escape:\n            escape = False\n        elif fragment[pos] in endchars:\n            break\n        vchars.append(fragment[pos])\n    else:\n        pos = pos + 1\n    return ''.join(vchars), ''.join([fragment[pos:]] + remainder), had_qp\n\ndef get_fws(value):\n    \"\"\"FWS = 1*WSP\n\n    This isn't the RFC definition.  We're using fws to represent tokens where\n    folding can be done, but when we are parsing the *un*folding has already\n    been done so we don't need to watch out for CRLF.\n\n    \"\"\"\n    newvalue = value.lstrip()\n    fws = WhiteSpaceTerminal(value[:len(value)-len(newvalue)], 'fws')\n    return fws, newvalue\n\ndef get_encoded_word(value):\n    \"\"\" encoded-word = \"=?\" charset \"?\" encoding \"?\" encoded-text \"?=\"\n\n    \"\"\"\n    ew = EncodedWord()\n    if not value.startswith('=?'):\n        raise errors.HeaderParseError(\n            \"expected encoded word but found {}\".format(value))\n    tok, *remainder = value[2:].split('?=', 1)\n    if tok == value[2:]:\n        raise errors.HeaderParseError(\n            \"expected encoded word but found {}\".format(value))\n    remstr = ''.join(remainder)\n    if len(remstr) > 1 and remstr[0] in hexdigits and remstr[1] in hexdigits:\n        # The ? after the CTE was followed by an encoded word escape (=XX).\n        rest, *remainder = remstr.split('?=', 1)\n        tok = tok + '?=' + rest\n    if len(tok.split()) > 1:\n        ew.defects.append(errors.InvalidHeaderDefect(\n            \"whitespace inside encoded word\"))\n    ew.cte = value\n    value = ''.join(remainder)\n    try:\n        text, charset, lang, defects = _ew.decode('=?' + tok + '?=')\n    except ValueError:\n        raise errors.HeaderParseError(\n            \"encoded word format invalid: '{}'\".format(ew.cte))\n    ew.charset = charset\n    ew.lang = lang\n    ew.defects.extend(defects)\n    while text:\n        if text[0] in WSP:\n            token, text = get_fws(text)\n            ew.append(token)\n            continue\n        chars, *remainder = _wsp_splitter(text, 1)\n        vtext = ValueTerminal(chars, 'vtext')\n        _validate_xtext(vtext)\n        ew.append(vtext)\n        text = ''.join(remainder)\n    # Encoded words should be followed by a WS\n    if value and value[0] not in WSP:\n        ew.defects.append(errors.InvalidHeaderDefect(\n            \"missing trailing whitespace after encoded-word\"))\n    return ew, value\n\ndef get_unstructured(value):\n    \"\"\"unstructured = (*([FWS] vchar) *WSP) / obs-unstruct\n       obs-unstruct = *((*LF *CR *(obs-utext) *LF *CR)) / FWS)\n       obs-utext = %d0 / obs-NO-WS-CTL / LF / CR\n\n       obs-NO-WS-CTL is control characters except WSP/CR/LF.\n\n    So, basically, we have printable runs, plus control characters or nulls in\n    the obsolete syntax, separated by whitespace.  Since RFC 2047 uses the\n    obsolete syntax in its specification, but requires whitespace on either\n    side of the encoded words, I can see no reason to need to separate the\n    non-printable-non-whitespace from the printable runs if they occur, so we\n    parse this into xtext tokens separated by WSP tokens.\n\n    Because an 'unstructured' value must by definition constitute the entire\n    value, this 'get' routine does not return a remaining value, only the\n    parsed TokenList.\n\n    \"\"\"\n    # XXX: but what about bare CR and LF?  They might signal the start or\n    # end of an encoded word.  YAGNI for now, since our current parsers\n    # will never send us strings with bare CR or LF.\n\n    unstructured = UnstructuredTokenList()\n    while value:\n        if value[0] in WSP:\n            token, value = get_fws(value)\n            unstructured.append(token)\n            continue\n        if value.startswith('=?'):\n            try:\n                token, value = get_encoded_word(value)\n            except errors.HeaderParseError:\n                # XXX: Need to figure out how to register defects when\n                # appropriate here.\n                pass\n            else:\n                have_ws = True\n                if len(unstructured) > 0:\n                    if unstructured[-1].token_type != 'fws':\n                        unstructured.defects.append(errors.InvalidHeaderDefect(\n                            \"missing whitespace before encoded word\"))\n                        have_ws = False\n                if have_ws and len(unstructured) > 1:\n                    if unstructured[-2].token_type == 'encoded-word':\n                        unstructured[-1] = EWWhiteSpaceTerminal(\n                            unstructured[-1], 'fws')\n                unstructured.append(token)\n                continue\n        tok, *remainder = _wsp_splitter(value, 1)\n        # Split in the middle of an atom if there is a rfc2047 encoded word\n        # which does not have WSP on both sides. The defect will be registered\n        # the next time through the loop.\n        if rfc2047_matcher.search(tok):\n            tok, *remainder = value.partition('=?')\n        vtext = ValueTerminal(tok, 'vtext')\n        _validate_xtext(vtext)\n        unstructured.append(vtext)\n        value = ''.join(remainder)\n    return unstructured\n\ndef get_qp_ctext(value):\n    r\"\"\"ctext = <printable ascii except \\ ( )>\n\n    This is not the RFC ctext, since we are handling nested comments in comment\n    and unquoting quoted-pairs here.  We allow anything except the '()'\n    characters, but if we find any ASCII other than the RFC defined printable\n    ASCII, a NonPrintableDefect is added to the token's defects list.  Since\n    quoted pairs are converted to their unquoted values, what is returned is\n    a 'ptext' token.  In this case it is a WhiteSpaceTerminal, so it's value\n    is ' '.\n\n    \"\"\"\n    ptext, value, _ = _get_ptext_to_endchars(value, '()')\n    ptext = WhiteSpaceTerminal(ptext, 'ptext')\n    _validate_xtext(ptext)\n    return ptext, value\n\ndef get_qcontent(value):\n    \"\"\"qcontent = qtext / quoted-pair\n\n    We allow anything except the DQUOTE character, but if we find any ASCII\n    other than the RFC defined printable ASCII, a NonPrintableDefect is\n    added to the token's defects list.  Any quoted pairs are converted to their\n    unquoted values, so what is returned is a 'ptext' token.  In this case it\n    is a ValueTerminal.\n\n    \"\"\"\n    ptext, value, _ = _get_ptext_to_endchars(value, '\"')\n    ptext = ValueTerminal(ptext, 'ptext')\n    _validate_xtext(ptext)\n    return ptext, value\n\ndef get_atext(value):\n    \"\"\"atext = <matches _atext_matcher>\n\n    We allow any non-ATOM_ENDS in atext, but add an InvalidATextDefect to\n    the token's defects list if we find non-atext characters.\n    \"\"\"\n    m = _non_atom_end_matcher(value)\n    if not m:\n        raise errors.HeaderParseError(\n            \"expected atext but found '{}'\".format(value))\n    atext = m.group()\n    value = value[len(atext):]\n    atext = ValueTerminal(atext, 'atext')\n    _validate_xtext(atext)\n    return atext, value\n\ndef get_bare_quoted_string(value):\n    \"\"\"bare-quoted-string = DQUOTE *([FWS] qcontent) [FWS] DQUOTE\n\n    A quoted-string without the leading or trailing white space.  Its\n    value is the text between the quote marks, with whitespace\n    preserved and quoted pairs decoded.\n    \"\"\"\n    if value[0] != '\"':\n        raise errors.HeaderParseError(\n            \"expected '\\\"' but found '{}'\".format(value))\n    bare_quoted_string = BareQuotedString()\n    value = value[1:]\n    if value and value[0] == '\"':\n        token, value = get_qcontent(value)\n        bare_quoted_string.append(token)\n    while value and value[0] != '\"':\n        if value[0] in WSP:\n            token, value = get_fws(value)\n        elif value[:2] == '=?':\n            try:\n                token, value = get_encoded_word(value)\n                bare_quoted_string.defects.append(errors.InvalidHeaderDefect(\n                    \"encoded word inside quoted string\"))\n            except errors.HeaderParseError:\n                token, value = get_qcontent(value)\n        else:\n            token, value = get_qcontent(value)\n        bare_quoted_string.append(token)\n    if not value:\n        bare_quoted_string.defects.append(errors.InvalidHeaderDefect(\n            \"end of header inside quoted string\"))\n        return bare_quoted_string, value\n    return bare_quoted_string, value[1:]\n\ndef get_comment(value):\n    \"\"\"comment = \"(\" *([FWS] ccontent) [FWS] \")\"\n       ccontent = ctext / quoted-pair / comment\n\n    We handle nested comments here, and quoted-pair in our qp-ctext routine.\n    \"\"\"\n    if value and value[0] != '(':\n        raise errors.HeaderParseError(\n            \"expected '(' but found '{}'\".format(value))\n    comment = Comment()\n    value = value[1:]\n    while value and value[0] != \")\":\n        if value[0] in WSP:\n            token, value = get_fws(value)\n        elif value[0] == '(':\n            token, value = get_comment(value)\n        else:\n            token, value = get_qp_ctext(value)\n        comment.append(token)\n    if not value:\n        comment.defects.append(errors.InvalidHeaderDefect(\n            \"end of header inside comment\"))\n        return comment, value\n    return comment, value[1:]\n\ndef get_cfws(value):\n    \"\"\"CFWS = (1*([FWS] comment) [FWS]) / FWS\n\n    \"\"\"\n    cfws = CFWSList()\n    while value and value[0] in CFWS_LEADER:\n        if value[0] in WSP:\n            token, value = get_fws(value)\n        else:\n            token, value = get_comment(value)\n        cfws.append(token)\n    return cfws, value\n\ndef get_quoted_string(value):\n    \"\"\"quoted-string = [CFWS] <bare-quoted-string> [CFWS]\n\n    'bare-quoted-string' is an intermediate class defined by this\n    parser and not by the RFC grammar.  It is the quoted string\n    without any attached CFWS.\n    \"\"\"\n    quoted_string = QuotedString()\n    if value and value[0] in CFWS_LEADER:\n        token, value = get_cfws(value)\n        quoted_string.append(token)\n    token, value = get_bare_quoted_string(value)\n    quoted_string.append(token)\n    if value and value[0] in CFWS_LEADER:\n        token, value = get_cfws(value)\n        quoted_string.append(token)\n    return quoted_string, value\n\ndef get_atom(value):\n    \"\"\"atom = [CFWS] 1*atext [CFWS]\n\n    An atom could be an rfc2047 encoded word.\n    \"\"\"\n    atom = Atom()\n    if value and value[0] in CFWS_LEADER:\n        token, value = get_cfws(value)\n        atom.append(token)\n    if value and value[0] in ATOM_ENDS:\n        raise errors.HeaderParseError(\n            \"expected atom but found '{}'\".format(value))\n    if value.startswith('=?'):\n        try:\n            token, value = get_encoded_word(value)\n        except errors.HeaderParseError:\n            # XXX: need to figure out how to register defects when\n            # appropriate here.\n            token, value = get_atext(value)\n    else:\n        token, value = get_atext(value)\n    atom.append(token)\n    if value and value[0] in CFWS_LEADER:\n        token, value = get_cfws(value)\n        atom.append(token)\n    return atom, value\n\ndef get_dot_atom_text(value):\n    \"\"\" dot-text = 1*atext *(\".\" 1*atext)\n\n    \"\"\"\n    dot_atom_text = DotAtomText()\n    if not value or value[0] in ATOM_ENDS:\n        raise errors.HeaderParseError(\"expected atom at a start of \"\n            \"dot-atom-text but found '{}'\".format(value))\n    while value and value[0] not in ATOM_ENDS:\n        token, value = get_atext(value)\n        dot_atom_text.append(token)\n        if value and value[0] == '.':\n            dot_atom_text.append(DOT)\n            value = value[1:]\n    if dot_atom_text[-1] is DOT:\n        raise errors.HeaderParseError(\"expected atom at end of dot-atom-text \"\n            \"but found '{}'\".format('.'+value))\n    return dot_atom_text, value\n\ndef get_dot_atom(value):\n    \"\"\" dot-atom = [CFWS] dot-atom-text [CFWS]\n\n    Any place we can have a dot atom, we could instead have an rfc2047 encoded\n    word.\n    \"\"\"\n    dot_atom = DotAtom()\n    if value[0] in CFWS_LEADER:\n        token, value = get_cfws(value)\n        dot_atom.append(token)\n    if value.startswith('=?'):\n        try:\n            token, value = get_encoded_word(value)\n        except errors.HeaderParseError:\n            # XXX: need to figure out how to register defects when\n            # appropriate here.\n            token, value = get_dot_atom_text(value)\n    else:\n        token, value = get_dot_atom_text(value)\n    dot_atom.append(token)\n    if value and value[0] in CFWS_LEADER:\n        token, value = get_cfws(value)\n        dot_atom.append(token)\n    return dot_atom, value\n\ndef get_word(value):\n    \"\"\"word = atom / quoted-string\n\n    Either atom or quoted-string may start with CFWS.  We have to peel off this\n    CFWS first to determine which type of word to parse.  Afterward we splice\n    the leading CFWS, if any, into the parsed sub-token.\n\n    If neither an atom or a quoted-string is found before the next special, a\n    HeaderParseError is raised.\n\n    The token returned is either an Atom or a QuotedString, as appropriate.\n    This means the 'word' level of the formal grammar is not represented in the\n    parse tree; this is because having that extra layer when manipulating the\n    parse tree is more confusing than it is helpful.\n\n    \"\"\"\n    if value[0] in CFWS_LEADER:\n        leader, value = get_cfws(value)\n    else:\n        leader = None\n    if not value:\n        raise errors.HeaderParseError(\n            \"Expected 'atom' or 'quoted-string' but found nothing.\")\n    if value[0]=='\"':\n        token, value = get_quoted_string(value)\n    elif value[0] in SPECIALS:\n        raise errors.HeaderParseError(\"Expected 'atom' or 'quoted-string' \"\n                                      \"but found '{}'\".format(value))\n    else:\n        token, value = get_atom(value)\n    if leader is not None:\n        token[:0] = [leader]\n    return token, value\n\ndef get_phrase(value):\n    \"\"\" phrase = 1*word / obs-phrase\n        obs-phrase = word *(word / \".\" / CFWS)\n\n    This means a phrase can be a sequence of words, periods, and CFWS in any\n    order as long as it starts with at least one word.  If anything other than\n    words is detected, an ObsoleteHeaderDefect is added to the token's defect\n    list.  We also accept a phrase that starts with CFWS followed by a dot;\n    this is registered as an InvalidHeaderDefect, since it is not supported by\n    even the obsolete grammar.\n\n    \"\"\"\n    phrase = Phrase()\n    try:\n        token, value = get_word(value)\n        phrase.append(token)\n    except errors.HeaderParseError:\n        phrase.defects.append(errors.InvalidHeaderDefect(\n            \"phrase does not start with word\"))\n    while value and value[0] not in PHRASE_ENDS:\n        if value[0]=='.':\n            phrase.append(DOT)\n            phrase.defects.append(errors.ObsoleteHeaderDefect(\n                \"period in 'phrase'\"))\n            value = value[1:]\n        else:\n            try:\n                token, value = get_word(value)\n            except errors.HeaderParseError:\n                if value[0] in CFWS_LEADER:\n                    token, value = get_cfws(value)\n                    phrase.defects.append(errors.ObsoleteHeaderDefect(\n                        \"comment found without atom\"))\n                else:\n                    raise\n            phrase.append(token)\n    return phrase, value\n\ndef get_local_part(value):\n    \"\"\" local-part = dot-atom / quoted-string / obs-local-part\n\n    \"\"\"\n    local_part = LocalPart()\n    leader = None\n    if value[0] in CFWS_LEADER:\n        leader, value = get_cfws(value)\n    if not value:\n        raise errors.HeaderParseError(\n            \"expected local-part but found '{}'\".format(value))\n    try:\n        token, value = get_dot_atom(value)\n    except errors.HeaderParseError:\n        try:\n            token, value = get_word(value)\n        except errors.HeaderParseError:\n            if value[0] != '\\\\' and value[0] in PHRASE_ENDS:\n                raise\n            token = TokenList()\n    if leader is not None:\n        token[:0] = [leader]\n    local_part.append(token)\n    if value and (value[0]=='\\\\' or value[0] not in PHRASE_ENDS):\n        obs_local_part, value = get_obs_local_part(str(local_part) + value)\n        if obs_local_part.token_type == 'invalid-obs-local-part':\n            local_part.defects.append(errors.InvalidHeaderDefect(\n                \"local-part is not dot-atom, quoted-string, or obs-local-part\"))\n        else:\n            local_part.defects.append(errors.ObsoleteHeaderDefect(\n                \"local-part is not a dot-atom (contains CFWS)\"))\n        local_part[0] = obs_local_part\n    try:\n        local_part.value.encode('ascii')\n    except UnicodeEncodeError:\n        local_part.defects.append(errors.NonASCIILocalPartDefect(\n                \"local-part contains non-ASCII characters)\"))\n    return local_part, value\n\ndef get_obs_local_part(value):\n    \"\"\" obs-local-part = word *(\".\" word)\n    \"\"\"\n    obs_local_part = ObsLocalPart()\n    last_non_ws_was_dot = False\n    while value and (value[0]=='\\\\' or value[0] not in PHRASE_ENDS):\n        if value[0] == '.':\n            if last_non_ws_was_dot:\n                obs_local_part.defects.append(errors.InvalidHeaderDefect(\n                    \"invalid repeated '.'\"))\n            obs_local_part.append(DOT)\n            last_non_ws_was_dot = True\n            value = value[1:]\n            continue\n        elif value[0]=='\\\\':\n            obs_local_part.append(ValueTerminal(value[0],\n                                                'misplaced-special'))\n            value = value[1:]\n            obs_local_part.defects.append(errors.InvalidHeaderDefect(\n                \"'\\\\' character outside of quoted-string/ccontent\"))\n            last_non_ws_was_dot = False\n            continue\n        if obs_local_part and obs_local_part[-1].token_type != 'dot':\n            obs_local_part.defects.append(errors.InvalidHeaderDefect(\n                \"missing '.' between words\"))\n        try:\n            token, value = get_word(value)\n            last_non_ws_was_dot = False\n        except errors.HeaderParseError:\n            if value[0] not in CFWS_LEADER:\n                raise\n            token, value = get_cfws(value)\n        obs_local_part.append(token)\n    if (obs_local_part[0].token_type == 'dot' or\n            obs_local_part[0].token_type=='cfws' and\n            obs_local_part[1].token_type=='dot'):\n        obs_local_part.defects.append(errors.InvalidHeaderDefect(\n            \"Invalid leading '.' in local part\"))\n    if (obs_local_part[-1].token_type == 'dot' or\n            obs_local_part[-1].token_type=='cfws' and\n            obs_local_part[-2].token_type=='dot'):\n        obs_local_part.defects.append(errors.InvalidHeaderDefect(\n            \"Invalid trailing '.' in local part\"))\n    if obs_local_part.defects:\n        obs_local_part.token_type = 'invalid-obs-local-part'\n    return obs_local_part, value\n\ndef get_dtext(value):\n    r\"\"\" dtext = <printable ascii except \\ [ ]> / obs-dtext\n        obs-dtext = obs-NO-WS-CTL / quoted-pair\n\n    We allow anything except the excluded characters, but if we find any\n    ASCII other than the RFC defined printable ASCII, a NonPrintableDefect is\n    added to the token's defects list.  Quoted pairs are converted to their\n    unquoted values, so what is returned is a ptext token, in this case a\n    ValueTerminal.  If there were quoted-printables, an ObsoleteHeaderDefect is\n    added to the returned token's defect list.\n\n    \"\"\"\n    ptext, value, had_qp = _get_ptext_to_endchars(value, '[]')\n    ptext = ValueTerminal(ptext, 'ptext')\n    if had_qp:\n        ptext.defects.append(errors.ObsoleteHeaderDefect(\n            \"quoted printable found in domain-literal\"))\n    _validate_xtext(ptext)\n    return ptext, value\n\ndef _check_for_early_dl_end(value, domain_literal):\n    if value:\n        return False\n    domain_literal.append(errors.InvalidHeaderDefect(\n        \"end of input inside domain-literal\"))\n    domain_literal.append(ValueTerminal(']', 'domain-literal-end'))\n    return True\n\ndef get_domain_literal(value):\n    \"\"\" domain-literal = [CFWS] \"[\" *([FWS] dtext) [FWS] \"]\" [CFWS]\n\n    \"\"\"\n    domain_literal = DomainLiteral()\n    if value[0] in CFWS_LEADER:\n        token, value = get_cfws(value)\n        domain_literal.append(token)\n    if not value:\n        raise errors.HeaderParseError(\"expected domain-literal\")\n    if value[0] != '[':\n        raise errors.HeaderParseError(\"expected '[' at start of domain-literal \"\n                \"but found '{}'\".format(value))\n    value = value[1:]\n    if _check_for_early_dl_end(value, domain_literal):\n        return domain_literal, value\n    domain_literal.append(ValueTerminal('[', 'domain-literal-start'))\n    if value[0] in WSP:\n        token, value = get_fws(value)\n        domain_literal.append(token)\n    token, value = get_dtext(value)\n    domain_literal.append(token)\n    if _check_for_early_dl_end(value, domain_literal):\n        return domain_literal, value\n    if value[0] in WSP:\n        token, value = get_fws(value)\n        domain_literal.append(token)\n    if _check_for_early_dl_end(value, domain_literal):\n        return domain_literal, value\n    if value[0] != ']':\n        raise errors.HeaderParseError(\"expected ']' at end of domain-literal \"\n                \"but found '{}'\".format(value))\n    domain_literal.append(ValueTerminal(']', 'domain-literal-end'))\n    value = value[1:]\n    if value and value[0] in CFWS_LEADER:\n        token, value = get_cfws(value)\n        domain_literal.append(token)\n    return domain_literal, value\n\ndef get_domain(value):\n    \"\"\" domain = dot-atom / domain-literal / obs-domain\n        obs-domain = atom *(\".\" atom))\n\n    \"\"\"\n    domain = Domain()\n    leader = None\n    if value[0] in CFWS_LEADER:\n        leader, value = get_cfws(value)\n    if not value:\n        raise errors.HeaderParseError(\n            \"expected domain but found '{}'\".format(value))\n    if value[0] == '[':\n        token, value = get_domain_literal(value)\n        if leader is not None:\n            token[:0] = [leader]\n        domain.append(token)\n        return domain, value\n    try:\n        token, value = get_dot_atom(value)\n    except errors.HeaderParseError:\n        token, value = get_atom(value)\n    if leader is not None:\n        token[:0] = [leader]\n    domain.append(token)\n    if value and value[0] == '.':\n        domain.defects.append(errors.ObsoleteHeaderDefect(\n            \"domain is not a dot-atom (contains CFWS)\"))\n        if domain[0].token_type == 'dot-atom':\n            domain[:] = domain[0]\n        while value and value[0] == '.':\n            domain.append(DOT)\n            token, value = get_atom(value[1:])\n            domain.append(token)\n    return domain, value\n\ndef get_addr_spec(value):\n    \"\"\" addr-spec = local-part \"@\" domain\n\n    \"\"\"\n    addr_spec = AddrSpec()\n    token, value = get_local_part(value)\n    addr_spec.append(token)\n    if not value or value[0] != '@':\n        addr_spec.defects.append(errors.InvalidHeaderDefect(\n            \"addr-spec local part with no domain\"))\n        return addr_spec, value\n    addr_spec.append(ValueTerminal('@', 'address-at-symbol'))\n    token, value = get_domain(value[1:])\n    addr_spec.append(token)\n    return addr_spec, value\n\ndef get_obs_route(value):\n    \"\"\" obs-route = obs-domain-list \":\"\n        obs-domain-list = *(CFWS / \",\") \"@\" domain *(\",\" [CFWS] [\"@\" domain])\n\n        Returns an obs-route token with the appropriate sub-tokens (that is,\n        there is no obs-domain-list in the parse tree).\n    \"\"\"\n    obs_route = ObsRoute()\n    while value and (value[0]==',' or value[0] in CFWS_LEADER):\n        if value[0] in CFWS_LEADER:\n            token, value = get_cfws(value)\n            obs_route.append(token)\n        elif value[0] == ',':\n            obs_route.append(ListSeparator)\n            value = value[1:]\n    if not value or value[0] != '@':\n        raise errors.HeaderParseError(\n            \"expected obs-route domain but found '{}'\".format(value))\n    obs_route.append(RouteComponentMarker)\n    token, value = get_domain(value[1:])\n    obs_route.append(token)\n    while value and value[0]==',':\n        obs_route.append(ListSeparator)\n        value = value[1:]\n        if not value:\n            break\n        if value[0] in CFWS_LEADER:\n            token, value = get_cfws(value)\n            obs_route.append(token)\n        if value[0] == '@':\n            obs_route.append(RouteComponentMarker)\n            token, value = get_domain(value[1:])\n            obs_route.append(token)\n    if not value:\n        raise errors.HeaderParseError(\"end of header while parsing obs-route\")\n    if value[0] != ':':\n        raise errors.HeaderParseError( \"expected ':' marking end of \"\n            \"obs-route but found '{}'\".format(value))\n    obs_route.append(ValueTerminal(':', 'end-of-obs-route-marker'))\n    return obs_route, value[1:]\n\ndef get_angle_addr(value):\n    \"\"\" angle-addr = [CFWS] \"<\" addr-spec \">\" [CFWS] / obs-angle-addr\n        obs-angle-addr = [CFWS] \"<\" obs-route addr-spec \">\" [CFWS]\n\n    \"\"\"\n    angle_addr = AngleAddr()\n    if value[0] in CFWS_LEADER:\n        token, value = get_cfws(value)\n        angle_addr.append(token)\n    if not value or value[0] != '<':\n        raise errors.HeaderParseError(\n            \"expected angle-addr but found '{}'\".format(value))\n    angle_addr.append(ValueTerminal('<', 'angle-addr-start'))\n    value = value[1:]\n    # Although it is not legal per RFC5322, SMTP uses '<>' in certain\n    # circumstances.\n    if value[0] == '>':\n        angle_addr.append(ValueTerminal('>', 'angle-addr-end'))\n        angle_addr.defects.append(errors.InvalidHeaderDefect(\n            \"null addr-spec in angle-addr\"))\n        value = value[1:]\n        return angle_addr, value\n    try:\n        token, value = get_addr_spec(value)\n    except errors.HeaderParseError:\n        try:\n            token, value = get_obs_route(value)\n            angle_addr.defects.append(errors.ObsoleteHeaderDefect(\n                \"obsolete route specification in angle-addr\"))\n        except errors.HeaderParseError:\n            raise errors.HeaderParseError(\n                \"expected addr-spec or obs-route but found '{}'\".format(value))\n        angle_addr.append(token)\n        token, value = get_addr_spec(value)\n    angle_addr.append(token)\n    if value and value[0] == '>':\n        value = value[1:]\n    else:\n        angle_addr.defects.append(errors.InvalidHeaderDefect(\n            \"missing trailing '>' on angle-addr\"))\n    angle_addr.append(ValueTerminal('>', 'angle-addr-end'))\n    if value and value[0] in CFWS_LEADER:\n        token, value = get_cfws(value)\n        angle_addr.append(token)\n    return angle_addr, value\n\ndef get_display_name(value):\n    \"\"\" display-name = phrase\n\n    Because this is simply a name-rule, we don't return a display-name\n    token containing a phrase, but rather a display-name token with\n    the content of the phrase.\n\n    \"\"\"\n    display_name = DisplayName()\n    token, value = get_phrase(value)\n    display_name.extend(token[:])\n    display_name.defects = token.defects[:]\n    return display_name, value\n\n\ndef get_name_addr(value):\n    \"\"\" name-addr = [display-name] angle-addr\n\n    \"\"\"\n    name_addr = NameAddr()\n    # Both the optional display name and the angle-addr can start with cfws.\n    leader = None\n    if value[0] in CFWS_LEADER:\n        leader, value = get_cfws(value)\n        if not value:\n            raise errors.HeaderParseError(\n                \"expected name-addr but found '{}'\".format(leader))\n    if value[0] != '<':\n        if value[0] in PHRASE_ENDS:\n            raise errors.HeaderParseError(\n                \"expected name-addr but found '{}'\".format(value))\n        token, value = get_display_name(value)\n        if not value:\n            raise errors.HeaderParseError(\n                \"expected name-addr but found '{}'\".format(token))\n        if leader is not None:\n            token[0][:0] = [leader]\n            leader = None\n        name_addr.append(token)\n    token, value = get_angle_addr(value)\n    if leader is not None:\n        token[:0] = [leader]\n    name_addr.append(token)\n    return name_addr, value\n\ndef get_mailbox(value):\n    \"\"\" mailbox = name-addr / addr-spec\n\n    \"\"\"\n    # The only way to figure out if we are dealing with a name-addr or an\n    # addr-spec is to try parsing each one.\n    mailbox = Mailbox()\n    try:\n        token, value = get_name_addr(value)\n    except errors.HeaderParseError:\n        try:\n            token, value = get_addr_spec(value)\n        except errors.HeaderParseError:\n            raise errors.HeaderParseError(\n                \"expected mailbox but found '{}'\".format(value))\n    if any(isinstance(x, errors.InvalidHeaderDefect)\n                       for x in token.all_defects):\n        mailbox.token_type = 'invalid-mailbox'\n    mailbox.append(token)\n    return mailbox, value\n\ndef get_invalid_mailbox(value, endchars):\n    \"\"\" Read everything up to one of the chars in endchars.\n\n    This is outside the formal grammar.  The InvalidMailbox TokenList that is\n    returned acts like a Mailbox, but the data attributes are None.\n\n    \"\"\"\n    invalid_mailbox = InvalidMailbox()\n    while value and value[0] not in endchars:\n        if value[0] in PHRASE_ENDS:\n            invalid_mailbox.append(ValueTerminal(value[0],\n                                                 'misplaced-special'))\n            value = value[1:]\n        else:\n            token, value = get_phrase(value)\n            invalid_mailbox.append(token)\n    return invalid_mailbox, value\n\ndef get_mailbox_list(value):\n    \"\"\" mailbox-list = (mailbox *(\",\" mailbox)) / obs-mbox-list\n        obs-mbox-list = *([CFWS] \",\") mailbox *(\",\" [mailbox / CFWS])\n\n    For this routine we go outside the formal grammar in order to improve error\n    handling.  We recognize the end of the mailbox list only at the end of the\n    value or at a ';' (the group terminator).  This is so that we can turn\n    invalid mailboxes into InvalidMailbox tokens and continue parsing any\n    remaining valid mailboxes.  We also allow all mailbox entries to be null,\n    and this condition is handled appropriately at a higher level.\n\n    \"\"\"\n    mailbox_list = MailboxList()\n    while value and value[0] != ';':\n        try:\n            token, value = get_mailbox(value)\n            mailbox_list.append(token)\n        except errors.HeaderParseError:\n            leader = None\n            if value[0] in CFWS_LEADER:\n                leader, value = get_cfws(value)\n                if not value or value[0] in ',;':\n                    mailbox_list.append(leader)\n                    mailbox_list.defects.append(errors.ObsoleteHeaderDefect(\n                        \"empty element in mailbox-list\"))\n                else:\n                    token, value = get_invalid_mailbox(value, ',;')\n                    if leader is not None:\n                        token[:0] = [leader]\n                    mailbox_list.append(token)\n                    mailbox_list.defects.append(errors.InvalidHeaderDefect(\n                        \"invalid mailbox in mailbox-list\"))\n            elif value[0] == ',':\n                mailbox_list.defects.append(errors.ObsoleteHeaderDefect(\n                    \"empty element in mailbox-list\"))\n            else:\n                token, value = get_invalid_mailbox(value, ',;')\n                if leader is not None:\n                    token[:0] = [leader]\n                mailbox_list.append(token)\n                mailbox_list.defects.append(errors.InvalidHeaderDefect(\n                    \"invalid mailbox in mailbox-list\"))\n        if value and value[0] not in ',;':\n            # Crap after mailbox; treat it as an invalid mailbox.\n            # The mailbox info will still be available.\n            mailbox = mailbox_list[-1]\n            mailbox.token_type = 'invalid-mailbox'\n            token, value = get_invalid_mailbox(value, ',;')\n            mailbox.extend(token)\n            mailbox_list.defects.append(errors.InvalidHeaderDefect(\n                \"invalid mailbox in mailbox-list\"))\n        if value and value[0] == ',':\n            mailbox_list.append(ListSeparator)\n            value = value[1:]\n    return mailbox_list, value\n\n\ndef get_group_list(value):\n    \"\"\" group-list = mailbox-list / CFWS / obs-group-list\n        obs-group-list = 1*([CFWS] \",\") [CFWS]\n\n    \"\"\"\n    group_list = GroupList()\n    if not value:\n        group_list.defects.append(errors.InvalidHeaderDefect(\n            \"end of header before group-list\"))\n        return group_list, value\n    leader = None\n    if value and value[0] in CFWS_LEADER:\n        leader, value = get_cfws(value)\n        if not value:\n            # This should never happen in email parsing, since CFWS-only is a\n            # legal alternative to group-list in a group, which is the only\n            # place group-list appears.\n            group_list.defects.append(errors.InvalidHeaderDefect(\n                \"end of header in group-list\"))\n            group_list.append(leader)\n            return group_list, value\n        if value[0] == ';':\n            group_list.append(leader)\n            return group_list, value\n    token, value = get_mailbox_list(value)\n    if len(token.all_mailboxes)==0:\n        if leader is not None:\n            group_list.append(leader)\n        group_list.extend(token)\n        group_list.defects.append(errors.ObsoleteHeaderDefect(\n            \"group-list with empty entries\"))\n        return group_list, value\n    if leader is not None:\n        token[:0] = [leader]\n    group_list.append(token)\n    return group_list, value\n\ndef get_group(value):\n    \"\"\" group = display-name \":\" [group-list] \";\" [CFWS]\n\n    \"\"\"\n    group = Group()\n    token, value = get_display_name(value)\n    if not value or value[0] != ':':\n        raise errors.HeaderParseError(\"expected ':' at end of group \"\n            \"display name but found '{}'\".format(value))\n    group.append(token)\n    group.append(ValueTerminal(':', 'group-display-name-terminator'))\n    value = value[1:]\n    if value and value[0] == ';':\n        group.append(ValueTerminal(';', 'group-terminator'))\n        return group, value[1:]\n    token, value = get_group_list(value)\n    group.append(token)\n    if not value:\n        group.defects.append(errors.InvalidHeaderDefect(\n            \"end of header in group\"))\n    elif value[0] != ';':\n        raise errors.HeaderParseError(\n            \"expected ';' at end of group but found {}\".format(value))\n    group.append(ValueTerminal(';', 'group-terminator'))\n    value = value[1:]\n    if value and value[0] in CFWS_LEADER:\n        token, value = get_cfws(value)\n        group.append(token)\n    return group, value\n\ndef get_address(value):\n    \"\"\" address = mailbox / group\n\n    Note that counter-intuitively, an address can be either a single address or\n    a list of addresses (a group).  This is why the returned Address object has\n    a 'mailboxes' attribute which treats a single address as a list of length\n    one.  When you need to differentiate between to two cases, extract the single\n    element, which is either a mailbox or a group token.\n\n    \"\"\"\n    # The formal grammar isn't very helpful when parsing an address.  mailbox\n    # and group, especially when allowing for obsolete forms, start off very\n    # similarly.  It is only when you reach one of @, <, or : that you know\n    # what you've got.  So, we try each one in turn, starting with the more\n    # likely of the two.  We could perhaps make this more efficient by looking\n    # for a phrase and then branching based on the next character, but that\n    # would be a premature optimization.\n    address = Address()\n    try:\n        token, value = get_group(value)\n    except errors.HeaderParseError:\n        try:\n            token, value = get_mailbox(value)\n        except errors.HeaderParseError:\n            raise errors.HeaderParseError(\n                \"expected address but found '{}'\".format(value))\n    address.append(token)\n    return address, value\n\ndef get_address_list(value):\n    \"\"\" address_list = (address *(\",\" address)) / obs-addr-list\n        obs-addr-list = *([CFWS] \",\") address *(\",\" [address / CFWS])\n\n    We depart from the formal grammar here by continuing to parse until the end\n    of the input, assuming the input to be entirely composed of an\n    address-list.  This is always true in email parsing, and allows us\n    to skip invalid addresses to parse additional valid ones.\n\n    \"\"\"\n    address_list = AddressList()\n    while value:\n        try:\n            token, value = get_address(value)\n            address_list.append(token)\n        except errors.HeaderParseError as err:\n            leader = None\n            if value[0] in CFWS_LEADER:\n                leader, value = get_cfws(value)\n                if not value or value[0] == ',':\n                    address_list.append(leader)\n                    address_list.defects.append(errors.ObsoleteHeaderDefect(\n                        \"address-list entry with no content\"))\n                else:\n                    token, value = get_invalid_mailbox(value, ',')\n                    if leader is not None:\n                        token[:0] = [leader]\n                    address_list.append(Address([token]))\n                    address_list.defects.append(errors.InvalidHeaderDefect(\n                        \"invalid address in address-list\"))\n            elif value[0] == ',':\n                address_list.defects.append(errors.ObsoleteHeaderDefect(\n                    \"empty element in address-list\"))\n            else:\n                token, value = get_invalid_mailbox(value, ',')\n                if leader is not None:\n                    token[:0] = [leader]\n                address_list.append(Address([token]))\n                address_list.defects.append(errors.InvalidHeaderDefect(\n                    \"invalid address in address-list\"))\n        if value and value[0] != ',':\n            # Crap after address; treat it as an invalid mailbox.\n            # The mailbox info will still be available.\n            mailbox = address_list[-1][0]\n            mailbox.token_type = 'invalid-mailbox'\n            token, value = get_invalid_mailbox(value, ',')\n            mailbox.extend(token)\n            address_list.defects.append(errors.InvalidHeaderDefect(\n                \"invalid address in address-list\"))\n        if value:  # Must be a , at this point.\n            address_list.append(ValueTerminal(',', 'list-separator'))\n            value = value[1:]\n    return address_list, value\n\n\ndef get_no_fold_literal(value):\n    \"\"\" no-fold-literal = \"[\" *dtext \"]\"\n    \"\"\"\n    no_fold_literal = NoFoldLiteral()\n    if not value:\n        raise errors.HeaderParseError(\n            \"expected no-fold-literal but found '{}'\".format(value))\n    if value[0] != '[':\n        raise errors.HeaderParseError(\n            \"expected '[' at the start of no-fold-literal \"\n            \"but found '{}'\".format(value))\n    no_fold_literal.append(ValueTerminal('[', 'no-fold-literal-start'))\n    value = value[1:]\n    token, value = get_dtext(value)\n    no_fold_literal.append(token)\n    if not value or value[0] != ']':\n        raise errors.HeaderParseError(\n            \"expected ']' at the end of no-fold-literal \"\n            \"but found '{}'\".format(value))\n    no_fold_literal.append(ValueTerminal(']', 'no-fold-literal-end'))\n    return no_fold_literal, value[1:]\n\ndef get_msg_id(value):\n    \"\"\"msg-id = [CFWS] \"<\" id-left '@' id-right  \">\" [CFWS]\n       id-left = dot-atom-text / obs-id-left\n       id-right = dot-atom-text / no-fold-literal / obs-id-right\n       no-fold-literal = \"[\" *dtext \"]\"\n    \"\"\"\n    msg_id = MsgID()\n    if value[0] in CFWS_LEADER:\n        token, value = get_cfws(value)\n        msg_id.append(token)\n    if not value or value[0] != '<':\n        raise errors.HeaderParseError(\n            \"expected msg-id but found '{}'\".format(value))\n    msg_id.append(ValueTerminal('<', 'msg-id-start'))\n    value = value[1:]\n    # Parse id-left.\n    try:\n        token, value = get_dot_atom_text(value)\n    except errors.HeaderParseError:\n        try:\n            # obs-id-left is same as local-part of add-spec.\n            token, value = get_obs_local_part(value)\n            msg_id.defects.append(errors.ObsoleteHeaderDefect(\n                \"obsolete id-left in msg-id\"))\n        except errors.HeaderParseError:\n            raise errors.HeaderParseError(\n                \"expected dot-atom-text or obs-id-left\"\n                \" but found '{}'\".format(value))\n    msg_id.append(token)\n    if not value or value[0] != '@':\n        msg_id.defects.append(errors.InvalidHeaderDefect(\n            \"msg-id with no id-right\"))\n        # Even though there is no id-right, if the local part\n        # ends with `>` let's just parse it too and return\n        # along with the defect.\n        if value and value[0] == '>':\n            msg_id.append(ValueTerminal('>', 'msg-id-end'))\n            value = value[1:]\n        return msg_id, value\n    msg_id.append(ValueTerminal('@', 'address-at-symbol'))\n    value = value[1:]\n    # Parse id-right.\n    try:\n        token, value = get_dot_atom_text(value)\n    except errors.HeaderParseError:\n        try:\n            token, value = get_no_fold_literal(value)\n        except errors.HeaderParseError as e:\n            try:\n                token, value = get_domain(value)\n                msg_id.defects.append(errors.ObsoleteHeaderDefect(\n                    \"obsolete id-right in msg-id\"))\n            except errors.HeaderParseError:\n                raise errors.HeaderParseError(\n                    \"expected dot-atom-text, no-fold-literal or obs-id-right\"\n                    \" but found '{}'\".format(value))\n    msg_id.append(token)\n    if value and value[0] == '>':\n        value = value[1:]\n    else:\n        msg_id.defects.append(errors.InvalidHeaderDefect(\n            \"missing trailing '>' on msg-id\"))\n    msg_id.append(ValueTerminal('>', 'msg-id-end'))\n    if value and value[0] in CFWS_LEADER:\n        token, value = get_cfws(value)\n        msg_id.append(token)\n    return msg_id, value\n\n\ndef parse_message_id(value):\n    \"\"\"message-id      =   \"Message-ID:\" msg-id CRLF\n    \"\"\"\n    message_id = MessageID()\n    try:\n        token, value = get_msg_id(value)\n    except errors.HeaderParseError:\n        message_id.defects.append(errors.InvalidHeaderDefect(\n            \"Expected msg-id but found {!r}\".format(value)))\n    message_id.append(token)\n    return message_id\n\n#\n# XXX: As I begin to add additional header parsers, I'm realizing we probably\n# have two level of parser routines: the get_XXX methods that get a token in\n# the grammar, and parse_XXX methods that parse an entire field value.  So\n# get_address_list above should really be a parse_ method, as probably should\n# be get_unstructured.\n#\n\ndef parse_mime_version(value):\n    \"\"\" mime-version = [CFWS] 1*digit [CFWS] \".\" [CFWS] 1*digit [CFWS]\n\n    \"\"\"\n    # The [CFWS] is implicit in the RFC 2045 BNF.\n    # XXX: This routine is a bit verbose, should factor out a get_int method.\n    mime_version = MIMEVersion()\n    if not value:\n        mime_version.defects.append(errors.HeaderMissingRequiredValue(\n            \"Missing MIME version number (eg: 1.0)\"))\n        return mime_version\n    if value[0] in CFWS_LEADER:\n        token, value = get_cfws(value)\n        mime_version.append(token)\n        if not value:\n            mime_version.defects.append(errors.HeaderMissingRequiredValue(\n                \"Expected MIME version number but found only CFWS\"))\n    digits = ''\n    while value and value[0] != '.' and value[0] not in CFWS_LEADER:\n        digits += value[0]\n        value = value[1:]\n    if not digits.isdigit():\n        mime_version.defects.append(errors.InvalidHeaderDefect(\n            \"Expected MIME major version number but found {!r}\".format(digits)))\n        mime_version.append(ValueTerminal(digits, 'xtext'))\n    else:\n        mime_version.major = int(digits)\n        mime_version.append(ValueTerminal(digits, 'digits'))\n    if value and value[0] in CFWS_LEADER:\n        token, value = get_cfws(value)\n        mime_version.append(token)\n    if not value or value[0] != '.':\n        if mime_version.major is not None:\n            mime_version.defects.append(errors.InvalidHeaderDefect(\n                \"Incomplete MIME version; found only major number\"))\n        if value:\n            mime_version.append(ValueTerminal(value, 'xtext'))\n        return mime_version\n    mime_version.append(ValueTerminal('.', 'version-separator'))\n    value = value[1:]\n    if value and value[0] in CFWS_LEADER:\n        token, value = get_cfws(value)\n        mime_version.append(token)\n    if not value:\n        if mime_version.major is not None:\n            mime_version.defects.append(errors.InvalidHeaderDefect(\n                \"Incomplete MIME version; found only major number\"))\n        return mime_version\n    digits = ''\n    while value and value[0] not in CFWS_LEADER:\n        digits += value[0]\n        value = value[1:]\n    if not digits.isdigit():\n        mime_version.defects.append(errors.InvalidHeaderDefect(\n            \"Expected MIME minor version number but found {!r}\".format(digits)))\n        mime_version.append(ValueTerminal(digits, 'xtext'))\n    else:\n        mime_version.minor = int(digits)\n        mime_version.append(ValueTerminal(digits, 'digits'))\n    if value and value[0] in CFWS_LEADER:\n        token, value = get_cfws(value)\n        mime_version.append(token)\n    if value:\n        mime_version.defects.append(errors.InvalidHeaderDefect(\n            \"Excess non-CFWS text after MIME version\"))\n        mime_version.append(ValueTerminal(value, 'xtext'))\n    return mime_version\n\ndef get_invalid_parameter(value):\n    \"\"\" Read everything up to the next ';'.\n\n    This is outside the formal grammar.  The InvalidParameter TokenList that is\n    returned acts like a Parameter, but the data attributes are None.\n\n    \"\"\"\n    invalid_parameter = InvalidParameter()\n    while value and value[0] != ';':\n        if value[0] in PHRASE_ENDS:\n            invalid_parameter.append(ValueTerminal(value[0],\n                                                   'misplaced-special'))\n            value = value[1:]\n        else:\n            token, value = get_phrase(value)\n            invalid_parameter.append(token)\n    return invalid_parameter, value\n\ndef get_ttext(value):\n    \"\"\"ttext = <matches _ttext_matcher>\n\n    We allow any non-TOKEN_ENDS in ttext, but add defects to the token's\n    defects list if we find non-ttext characters.  We also register defects for\n    *any* non-printables even though the RFC doesn't exclude all of them,\n    because we follow the spirit of RFC 5322.\n\n    \"\"\"\n    m = _non_token_end_matcher(value)\n    if not m:\n        raise errors.HeaderParseError(\n            \"expected ttext but found '{}'\".format(value))\n    ttext = m.group()\n    value = value[len(ttext):]\n    ttext = ValueTerminal(ttext, 'ttext')\n    _validate_xtext(ttext)\n    return ttext, value\n\ndef get_token(value):\n    \"\"\"token = [CFWS] 1*ttext [CFWS]\n\n    The RFC equivalent of ttext is any US-ASCII chars except space, ctls, or\n    tspecials.  We also exclude tabs even though the RFC doesn't.\n\n    The RFC implies the CFWS but is not explicit about it in the BNF.\n\n    \"\"\"\n    mtoken = Token()\n    if value and value[0] in CFWS_LEADER:\n        token, value = get_cfws(value)\n        mtoken.append(token)\n    if value and value[0] in TOKEN_ENDS:\n        raise errors.HeaderParseError(\n            \"expected token but found '{}'\".format(value))\n    token, value = get_ttext(value)\n    mtoken.append(token)\n    if value and value[0] in CFWS_LEADER:\n        token, value = get_cfws(value)\n        mtoken.append(token)\n    return mtoken, value\n\ndef get_attrtext(value):\n    \"\"\"attrtext = 1*(any non-ATTRIBUTE_ENDS character)\n\n    We allow any non-ATTRIBUTE_ENDS in attrtext, but add defects to the\n    token's defects list if we find non-attrtext characters.  We also register\n    defects for *any* non-printables even though the RFC doesn't exclude all of\n    them, because we follow the spirit of RFC 5322.\n\n    \"\"\"\n    m = _non_attribute_end_matcher(value)\n    if not m:\n        raise errors.HeaderParseError(\n            \"expected attrtext but found {!r}\".format(value))\n    attrtext = m.group()\n    value = value[len(attrtext):]\n    attrtext = ValueTerminal(attrtext, 'attrtext')\n    _validate_xtext(attrtext)\n    return attrtext, value\n\ndef get_attribute(value):\n    \"\"\" [CFWS] 1*attrtext [CFWS]\n\n    This version of the BNF makes the CFWS explicit, and as usual we use a\n    value terminal for the actual run of characters.  The RFC equivalent of\n    attrtext is the token characters, with the subtraction of '*', \"'\", and '%'.\n    We include tab in the excluded set just as we do for token.\n\n    \"\"\"\n    attribute = Attribute()\n    if value and value[0] in CFWS_LEADER:\n        token, value = get_cfws(value)\n        attribute.append(token)\n    if value and value[0] in ATTRIBUTE_ENDS:\n        raise errors.HeaderParseError(\n            \"expected token but found '{}'\".format(value))\n    token, value = get_attrtext(value)\n    attribute.append(token)\n    if value and value[0] in CFWS_LEADER:\n        token, value = get_cfws(value)\n        attribute.append(token)\n    return attribute, value\n\ndef get_extended_attrtext(value):\n    \"\"\"attrtext = 1*(any non-ATTRIBUTE_ENDS character plus '%')\n\n    This is a special parsing routine so that we get a value that\n    includes % escapes as a single string (which we decode as a single\n    string later).\n\n    \"\"\"\n    m = _non_extended_attribute_end_matcher(value)\n    if not m:\n        raise errors.HeaderParseError(\n            \"expected extended attrtext but found {!r}\".format(value))\n    attrtext = m.group()\n    value = value[len(attrtext):]\n    attrtext = ValueTerminal(attrtext, 'extended-attrtext')\n    _validate_xtext(attrtext)\n    return attrtext, value\n\ndef get_extended_attribute(value):\n    \"\"\" [CFWS] 1*extended_attrtext [CFWS]\n\n    This is like the non-extended version except we allow % characters, so that\n    we can pick up an encoded value as a single string.\n\n    \"\"\"\n    # XXX: should we have an ExtendedAttribute TokenList?\n    attribute = Attribute()\n    if value and value[0] in CFWS_LEADER:\n        token, value = get_cfws(value)\n        attribute.append(token)\n    if value and value[0] in EXTENDED_ATTRIBUTE_ENDS:\n        raise errors.HeaderParseError(\n            \"expected token but found '{}'\".format(value))\n    token, value = get_extended_attrtext(value)\n    attribute.append(token)\n    if value and value[0] in CFWS_LEADER:\n        token, value = get_cfws(value)\n        attribute.append(token)\n    return attribute, value\n\ndef get_section(value):\n    \"\"\" '*' digits\n\n    The formal BNF is more complicated because leading 0s are not allowed.  We\n    check for that and add a defect.  We also assume no CFWS is allowed between\n    the '*' and the digits, though the RFC is not crystal clear on that.\n    The caller should already have dealt with leading CFWS.\n\n    \"\"\"\n    section = Section()\n    if not value or value[0] != '*':\n        raise errors.HeaderParseError(\"Expected section but found {}\".format(\n                                        value))\n    section.append(ValueTerminal('*', 'section-marker'))\n    value = value[1:]\n    if not value or not value[0].isdigit():\n        raise errors.HeaderParseError(\"Expected section number but \"\n                                      \"found {}\".format(value))\n    digits = ''\n    while value and value[0].isdigit():\n        digits += value[0]\n        value = value[1:]\n    if digits[0] == '0' and digits != '0':\n        section.defects.append(errors.InvalidHeaderError(\n                \"section number has an invalid leading 0\"))\n    section.number = int(digits)\n    section.append(ValueTerminal(digits, 'digits'))\n    return section, value\n\n\ndef get_value(value):\n    \"\"\" quoted-string / attribute\n\n    \"\"\"\n    v = Value()\n    if not value:\n        raise errors.HeaderParseError(\"Expected value but found end of string\")\n    leader = None\n    if value[0] in CFWS_LEADER:\n        leader, value = get_cfws(value)\n    if not value:\n        raise errors.HeaderParseError(\"Expected value but found \"\n                                      \"only {}\".format(leader))\n    if value[0] == '\"':\n        token, value = get_quoted_string(value)\n    else:\n        token, value = get_extended_attribute(value)\n    if leader is not None:\n        token[:0] = [leader]\n    v.append(token)\n    return v, value\n\ndef get_parameter(value):\n    \"\"\" attribute [section] [\"*\"] [CFWS] \"=\" value\n\n    The CFWS is implied by the RFC but not made explicit in the BNF.  This\n    simplified form of the BNF from the RFC is made to conform with the RFC BNF\n    through some extra checks.  We do it this way because it makes both error\n    recovery and working with the resulting parse tree easier.\n    \"\"\"\n    # It is possible CFWS would also be implicitly allowed between the section\n    # and the 'extended-attribute' marker (the '*') , but we've never seen that\n    # in the wild and we will therefore ignore the possibility.\n    param = Parameter()\n    token, value = get_attribute(value)\n    param.append(token)\n    if not value or value[0] == ';':\n        param.defects.append(errors.InvalidHeaderDefect(\"Parameter contains \"\n            \"name ({}) but no value\".format(token)))\n        return param, value\n    if value[0] == '*':\n        try:\n            token, value = get_section(value)\n            param.sectioned = True\n            param.append(token)\n        except errors.HeaderParseError:\n            pass\n        if not value:\n            raise errors.HeaderParseError(\"Incomplete parameter\")\n        if value[0] == '*':\n            param.append(ValueTerminal('*', 'extended-parameter-marker'))\n            value = value[1:]\n            param.extended = True\n    if value[0] != '=':\n        raise errors.HeaderParseError(\"Parameter not followed by '='\")\n    param.append(ValueTerminal('=', 'parameter-separator'))\n    value = value[1:]\n    leader = None\n    if value and value[0] in CFWS_LEADER:\n        token, value = get_cfws(value)\n        param.append(token)\n    remainder = None\n    appendto = param\n    if param.extended and value and value[0] == '\"':\n        # Now for some serious hackery to handle the common invalid case of\n        # double quotes around an extended value.  We also accept (with defect)\n        # a value marked as encoded that isn't really.\n        qstring, remainder = get_quoted_string(value)\n        inner_value = qstring.stripped_value\n        semi_valid = False\n        if param.section_number == 0:\n            if inner_value and inner_value[0] == \"'\":\n                semi_valid = True\n            else:\n                token, rest = get_attrtext(inner_value)\n                if rest and rest[0] == \"'\":\n                    semi_valid = True\n        else:\n            try:\n                token, rest = get_extended_attrtext(inner_value)\n            except:\n                pass\n            else:\n                if not rest:\n                    semi_valid = True\n        if semi_valid:\n            param.defects.append(errors.InvalidHeaderDefect(\n                \"Quoted string value for extended parameter is invalid\"))\n            param.append(qstring)\n            for t in qstring:\n                if t.token_type == 'bare-quoted-string':\n                    t[:] = []\n                    appendto = t\n                    break\n            value = inner_value\n        else:\n            remainder = None\n            param.defects.append(errors.InvalidHeaderDefect(\n                \"Parameter marked as extended but appears to have a \"\n                \"quoted string value that is non-encoded\"))\n    if value and value[0] == \"'\":\n        token = None\n    else:\n        token, value = get_value(value)\n    if not param.extended or param.section_number > 0:\n        if not value or value[0] != \"'\":\n            appendto.append(token)\n            if remainder is not None:\n                assert not value, value\n                value = remainder\n            return param, value\n        param.defects.append(errors.InvalidHeaderDefect(\n            \"Apparent initial-extended-value but attribute \"\n            \"was not marked as extended or was not initial section\"))\n    if not value:\n        # Assume the charset/lang is missing and the token is the value.\n        param.defects.append(errors.InvalidHeaderDefect(\n            \"Missing required charset/lang delimiters\"))\n        appendto.append(token)\n        if remainder is None:\n            return param, value\n    else:\n        if token is not None:\n            for t in token:\n                if t.token_type == 'extended-attrtext':\n                    break\n            t.token_type == 'attrtext'\n            appendto.append(t)\n            param.charset = t.value\n        if value[0] != \"'\":\n            raise errors.HeaderParseError(\"Expected RFC2231 char/lang encoding \"\n                                          \"delimiter, but found {!r}\".format(value))\n        appendto.append(ValueTerminal(\"'\", 'RFC2231-delimiter'))\n        value = value[1:]\n        if value and value[0] != \"'\":\n            token, value = get_attrtext(value)\n            appendto.append(token)\n            param.lang = token.value\n            if not value or value[0] != \"'\":\n                raise errors.HeaderParseError(\"Expected RFC2231 char/lang encoding \"\n                                  \"delimiter, but found {}\".format(value))\n        appendto.append(ValueTerminal(\"'\", 'RFC2231-delimiter'))\n        value = value[1:]\n    if remainder is not None:\n        # Treat the rest of value as bare quoted string content.\n        v = Value()\n        while value:\n            if value[0] in WSP:\n                token, value = get_fws(value)\n            elif value[0] == '\"':\n                token = ValueTerminal('\"', 'DQUOTE')\n                value = value[1:]\n            else:\n                token, value = get_qcontent(value)\n            v.append(token)\n        token = v\n    else:\n        token, value = get_value(value)\n    appendto.append(token)\n    if remainder is not None:\n        assert not value, value\n        value = remainder\n    return param, value\n\ndef parse_mime_parameters(value):\n    \"\"\" parameter *( \";\" parameter )\n\n    That BNF is meant to indicate this routine should only be called after\n    finding and handling the leading ';'.  There is no corresponding rule in\n    the formal RFC grammar, but it is more convenient for us for the set of\n    parameters to be treated as its own TokenList.\n\n    This is 'parse' routine because it consumes the remaining value, but it\n    would never be called to parse a full header.  Instead it is called to\n    parse everything after the non-parameter value of a specific MIME header.\n\n    \"\"\"\n    mime_parameters = MimeParameters()\n    while value:\n        try:\n            token, value = get_parameter(value)\n            mime_parameters.append(token)\n        except errors.HeaderParseError as err:\n            leader = None\n            if value[0] in CFWS_LEADER:\n                leader, value = get_cfws(value)\n            if not value:\n                mime_parameters.append(leader)\n                return mime_parameters\n            if value[0] == ';':\n                if leader is not None:\n                    mime_parameters.append(leader)\n                mime_parameters.defects.append(errors.InvalidHeaderDefect(\n                    \"parameter entry with no content\"))\n            else:\n                token, value = get_invalid_parameter(value)\n                if leader:\n                    token[:0] = [leader]\n                mime_parameters.append(token)\n                mime_parameters.defects.append(errors.InvalidHeaderDefect(\n                    \"invalid parameter {!r}\".format(token)))\n        if value and value[0] != ';':\n            # Junk after the otherwise valid parameter.  Mark it as\n            # invalid, but it will have a value.\n            param = mime_parameters[-1]\n            param.token_type = 'invalid-parameter'\n            token, value = get_invalid_parameter(value)\n            param.extend(token)\n            mime_parameters.defects.append(errors.InvalidHeaderDefect(\n                \"parameter with invalid trailing text {!r}\".format(token)))\n        if value:\n            # Must be a ';' at this point.\n            mime_parameters.append(ValueTerminal(';', 'parameter-separator'))\n            value = value[1:]\n    return mime_parameters\n\ndef _find_mime_parameters(tokenlist, value):\n    \"\"\"Do our best to find the parameters in an invalid MIME header\n\n    \"\"\"\n    while value and value[0] != ';':\n        if value[0] in PHRASE_ENDS:\n            tokenlist.append(ValueTerminal(value[0], 'misplaced-special'))\n            value = value[1:]\n        else:\n            token, value = get_phrase(value)\n            tokenlist.append(token)\n    if not value:\n        return\n    tokenlist.append(ValueTerminal(';', 'parameter-separator'))\n    tokenlist.append(parse_mime_parameters(value[1:]))\n\ndef parse_content_type_header(value):\n    \"\"\" maintype \"/\" subtype *( \";\" parameter )\n\n    The maintype and substype are tokens.  Theoretically they could\n    be checked against the official IANA list + x-token, but we\n    don't do that.\n    \"\"\"\n    ctype = ContentType()\n    recover = False\n    if not value:\n        ctype.defects.append(errors.HeaderMissingRequiredValue(\n            \"Missing content type specification\"))\n        return ctype\n    try:\n        token, value = get_token(value)\n    except errors.HeaderParseError:\n        ctype.defects.append(errors.InvalidHeaderDefect(\n            \"Expected content maintype but found {!r}\".format(value)))\n        _find_mime_parameters(ctype, value)\n        return ctype\n    ctype.append(token)\n    # XXX: If we really want to follow the formal grammar we should make\n    # mantype and subtype specialized TokenLists here.  Probably not worth it.\n    if not value or value[0] != '/':\n        ctype.defects.append(errors.InvalidHeaderDefect(\n            \"Invalid content type\"))\n        if value:\n            _find_mime_parameters(ctype, value)\n        return ctype\n    ctype.maintype = token.value.strip().lower()\n    ctype.append(ValueTerminal('/', 'content-type-separator'))\n    value = value[1:]\n    try:\n        token, value = get_token(value)\n    except errors.HeaderParseError:\n        ctype.defects.append(errors.InvalidHeaderDefect(\n            \"Expected content subtype but found {!r}\".format(value)))\n        _find_mime_parameters(ctype, value)\n        return ctype\n    ctype.append(token)\n    ctype.subtype = token.value.strip().lower()\n    if not value:\n        return ctype\n    if value[0] != ';':\n        ctype.defects.append(errors.InvalidHeaderDefect(\n            \"Only parameters are valid after content type, but \"\n            \"found {!r}\".format(value)))\n        # The RFC requires that a syntactically invalid content-type be treated\n        # as text/plain.  Perhaps we should postel this, but we should probably\n        # only do that if we were checking the subtype value against IANA.\n        del ctype.maintype, ctype.subtype\n        _find_mime_parameters(ctype, value)\n        return ctype\n    ctype.append(ValueTerminal(';', 'parameter-separator'))\n    ctype.append(parse_mime_parameters(value[1:]))\n    return ctype\n\ndef parse_content_disposition_header(value):\n    \"\"\" disposition-type *( \";\" parameter )\n\n    \"\"\"\n    disp_header = ContentDisposition()\n    if not value:\n        disp_header.defects.append(errors.HeaderMissingRequiredValue(\n            \"Missing content disposition\"))\n        return disp_header\n    try:\n        token, value = get_token(value)\n    except errors.HeaderParseError:\n        disp_header.defects.append(errors.InvalidHeaderDefect(\n            \"Expected content disposition but found {!r}\".format(value)))\n        _find_mime_parameters(disp_header, value)\n        return disp_header\n    disp_header.append(token)\n    disp_header.content_disposition = token.value.strip().lower()\n    if not value:\n        return disp_header\n    if value[0] != ';':\n        disp_header.defects.append(errors.InvalidHeaderDefect(\n            \"Only parameters are valid after content disposition, but \"\n            \"found {!r}\".format(value)))\n        _find_mime_parameters(disp_header, value)\n        return disp_header\n    disp_header.append(ValueTerminal(';', 'parameter-separator'))\n    disp_header.append(parse_mime_parameters(value[1:]))\n    return disp_header\n\ndef parse_content_transfer_encoding_header(value):\n    \"\"\" mechanism\n\n    \"\"\"\n    # We should probably validate the values, since the list is fixed.\n    cte_header = ContentTransferEncoding()\n    if not value:\n        cte_header.defects.append(errors.HeaderMissingRequiredValue(\n            \"Missing content transfer encoding\"))\n        return cte_header\n    try:\n        token, value = get_token(value)\n    except errors.HeaderParseError:\n        cte_header.defects.append(errors.InvalidHeaderDefect(\n            \"Expected content transfer encoding but found {!r}\".format(value)))\n    else:\n        cte_header.append(token)\n        cte_header.cte = token.value.strip().lower()\n    if not value:\n        return cte_header\n    while value:\n        cte_header.defects.append(errors.InvalidHeaderDefect(\n            \"Extra text after content transfer encoding\"))\n        if value[0] in PHRASE_ENDS:\n            cte_header.append(ValueTerminal(value[0], 'misplaced-special'))\n            value = value[1:]\n        else:\n            token, value = get_phrase(value)\n            cte_header.append(token)\n    return cte_header\n\n\n#\n# Header folding\n#\n# Header folding is complex, with lots of rules and corner cases.  The\n# following code does its best to obey the rules and handle the corner\n# cases, but you can be sure there are few bugs:)\n#\n# This folder generally canonicalizes as it goes, preferring the stringified\n# version of each token.  The tokens contain information that supports the\n# folder, including which tokens can be encoded in which ways.\n#\n# Folded text is accumulated in a simple list of strings ('lines'), each\n# one of which should be less than policy.max_line_length ('maxlen').\n#\n\ndef _steal_trailing_WSP_if_exists(lines):\n    wsp = ''\n    if lines and lines[-1] and lines[-1][-1] in WSP:\n        wsp = lines[-1][-1]\n        lines[-1] = lines[-1][:-1]\n    return wsp\n\ndef _refold_parse_tree(parse_tree, *, policy):\n    \"\"\"Return string of contents of parse_tree folded according to RFC rules.\n\n    \"\"\"\n    # max_line_length 0/None means no limit, ie: infinitely long.\n    maxlen = policy.max_line_length or sys.maxsize\n    encoding = 'utf-8' if policy.utf8 else 'us-ascii'\n    lines = ['']\n    last_ew = None\n    wrap_as_ew_blocked = 0\n    want_encoding = False\n    end_ew_not_allowed = Terminal('', 'wrap_as_ew_blocked')\n    parts = list(parse_tree)\n    while parts:\n        part = parts.pop(0)\n        if part is end_ew_not_allowed:\n            wrap_as_ew_blocked -= 1\n            continue\n        tstr = str(part)\n        try:\n            tstr.encode(encoding)\n            charset = encoding\n        except UnicodeEncodeError:\n            if any(isinstance(x, errors.UndecodableBytesDefect)\n                   for x in part.all_defects):\n                charset = 'unknown-8bit'\n            else:\n                # If policy.utf8 is false this should really be taken from a\n                # 'charset' property on the policy.\n                charset = 'utf-8'\n            want_encoding = True\n        if part.token_type == 'mime-parameters':\n            # Mime parameter folding (using RFC2231) is extra special.\n            _fold_mime_parameters(part, lines, maxlen, encoding)\n            continue\n        if want_encoding and not wrap_as_ew_blocked:\n            if not part.as_ew_allowed:\n                want_encoding = False\n                last_ew = None\n                if part.syntactic_break:\n                    encoded_part = part.fold(policy=policy)[:-len(policy.linesep)]\n                    if policy.linesep not in encoded_part:\n                        # It fits on a single line\n                        if len(encoded_part) > maxlen - len(lines[-1]):\n                            # But not on this one, so start a new one.\n                            newline = _steal_trailing_WSP_if_exists(lines)\n                            # XXX what if encoded_part has no leading FWS?\n                            lines.append(newline)\n                        lines[-1] += encoded_part\n                        continue\n                # Either this is not a major syntactic break, so we don't\n                # want it on a line by itself even if it fits, or it\n                # doesn't fit on a line by itself.  Either way, fall through\n                # to unpacking the subparts and wrapping them.\n            if not hasattr(part, 'encode'):\n                # It's not a Terminal, do each piece individually.\n                parts = list(part) + parts\n            else:\n                # It's a terminal, wrap it as an encoded word, possibly\n                # combining it with previously encoded words if allowed.\n                last_ew = _fold_as_ew(tstr, lines, maxlen, last_ew,\n                                      part.ew_combine_allowed, charset)\n            want_encoding = False\n            continue\n        if len(tstr) <= maxlen - len(lines[-1]):\n            lines[-1] += tstr\n            continue\n        # This part is too long to fit.  The RFC wants us to break at\n        # \"major syntactic breaks\", so unless we don't consider this\n        # to be one, check if it will fit on the next line by itself.\n        if (part.syntactic_break and\n                len(tstr) + 1 <= maxlen):\n            newline = _steal_trailing_WSP_if_exists(lines)\n            if newline or part.startswith_fws():\n                lines.append(newline + tstr)\n                last_ew = None\n                continue\n        if not hasattr(part, 'encode'):\n            # It's not a terminal, try folding the subparts.\n            newparts = list(part)\n            if not part.as_ew_allowed:\n                wrap_as_ew_blocked += 1\n                newparts.append(end_ew_not_allowed)\n            parts = newparts + parts\n            continue\n        if part.as_ew_allowed and not wrap_as_ew_blocked:\n            # It doesn't need CTE encoding, but encode it anyway so we can\n            # wrap it.\n            parts.insert(0, part)\n            want_encoding = True\n            continue\n        # We can't figure out how to wrap, it, so give up.\n        newline = _steal_trailing_WSP_if_exists(lines)\n        if newline or part.startswith_fws():\n            lines.append(newline + tstr)\n        else:\n            # We can't fold it onto the next line either...\n            lines[-1] += tstr\n    return policy.linesep.join(lines) + policy.linesep\n\ndef _fold_as_ew(to_encode, lines, maxlen, last_ew, ew_combine_allowed, charset):\n    \"\"\"Fold string to_encode into lines as encoded word, combining if allowed.\n    Return the new value for last_ew, or None if ew_combine_allowed is False.\n\n    If there is already an encoded word in the last line of lines (indicated by\n    a non-None value for last_ew) and ew_combine_allowed is true, decode the\n    existing ew, combine it with to_encode, and re-encode.  Otherwise, encode\n    to_encode.  In either case, split to_encode as necessary so that the\n    encoded segments fit within maxlen.\n\n    \"\"\"\n    if last_ew is not None and ew_combine_allowed:\n        to_encode = str(\n            get_unstructured(lines[-1][last_ew:] + to_encode))\n        lines[-1] = lines[-1][:last_ew]\n    if to_encode[0] in WSP:\n        # We're joining this to non-encoded text, so don't encode\n        # the leading blank.\n        leading_wsp = to_encode[0]\n        to_encode = to_encode[1:]\n        if (len(lines[-1]) == maxlen):\n            lines.append(_steal_trailing_WSP_if_exists(lines))\n        lines[-1] += leading_wsp\n    trailing_wsp = ''\n    if to_encode[-1] in WSP:\n        # Likewise for the trailing space.\n        trailing_wsp = to_encode[-1]\n        to_encode = to_encode[:-1]\n    new_last_ew = len(lines[-1]) if last_ew is None else last_ew\n\n    encode_as = 'utf-8' if charset == 'us-ascii' else charset\n\n    # The RFC2047 chrome takes up 7 characters plus the length\n    # of the charset name.\n    chrome_len = len(encode_as) + 7\n\n    if (chrome_len + 1) >= maxlen:\n        raise errors.HeaderParseError(\n            \"max_line_length is too small to fit an encoded word\")\n\n    while to_encode:\n        remaining_space = maxlen - len(lines[-1])\n        text_space = remaining_space - chrome_len\n        if text_space <= 0:\n            lines.append(' ')\n            continue\n\n        to_encode_word = to_encode[:text_space]\n        encoded_word = _ew.encode(to_encode_word, charset=encode_as)\n        excess = len(encoded_word) - remaining_space\n        while excess > 0:\n            # Since the chunk to encode is guaranteed to fit into less than 100 characters,\n            # shrinking it by one at a time shouldn't take long.\n            to_encode_word = to_encode_word[:-1]\n            encoded_word = _ew.encode(to_encode_word, charset=encode_as)\n            excess = len(encoded_word) - remaining_space\n        lines[-1] += encoded_word\n        to_encode = to_encode[len(to_encode_word):]\n\n        if to_encode:\n            lines.append(' ')\n            new_last_ew = len(lines[-1])\n    lines[-1] += trailing_wsp\n    return new_last_ew if ew_combine_allowed else None\n\ndef _fold_mime_parameters(part, lines, maxlen, encoding):\n    \"\"\"Fold TokenList 'part' into the 'lines' list as mime parameters.\n\n    Using the decoded list of parameters and values, format them according to\n    the RFC rules, including using RFC2231 encoding if the value cannot be\n    expressed in 'encoding' and/or the parameter+value is too long to fit\n    within 'maxlen'.\n\n    \"\"\"\n    # Special case for RFC2231 encoding: start from decoded values and use\n    # RFC2231 encoding iff needed.\n    #\n    # Note that the 1 and 2s being added to the length calculations are\n    # accounting for the possibly-needed spaces and semicolons we'll be adding.\n    #\n    for name, value in part.params:\n        # XXX What if this ';' puts us over maxlen the first time through the\n        # loop?  We should split the header value onto a newline in that case,\n        # but to do that we need to recognize the need earlier or reparse the\n        # header, so I'm going to ignore that bug for now.  It'll only put us\n        # one character over.\n        if not lines[-1].rstrip().endswith(';'):\n            lines[-1] += ';'\n        charset = encoding\n        error_handler = 'strict'\n        try:\n            value.encode(encoding)\n            encoding_required = False\n        except UnicodeEncodeError:\n            encoding_required = True\n            if utils._has_surrogates(value):\n                charset = 'unknown-8bit'\n                error_handler = 'surrogateescape'\n            else:\n                charset = 'utf-8'\n        if encoding_required:\n            encoded_value = urllib.parse.quote(\n                value, safe='', errors=error_handler)\n            tstr = \"{}*={}''{}\".format(name, charset, encoded_value)\n        else:\n            tstr = '{}={}'.format(name, quote_string(value))\n        if len(lines[-1]) + len(tstr) + 1 < maxlen:\n            lines[-1] = lines[-1] + ' ' + tstr\n            continue\n        elif len(tstr) + 2 <= maxlen:\n            lines.append(' ' + tstr)\n            continue\n        # We need multiple sections.  We are allowed to mix encoded and\n        # non-encoded sections, but we aren't going to.  We'll encode them all.\n        section = 0\n        extra_chrome = charset + \"''\"\n        while value:\n            chrome_len = len(name) + len(str(section)) + 3 + len(extra_chrome)\n            if maxlen <= chrome_len + 3:\n                # We need room for the leading blank, the trailing semicolon,\n                # and at least one character of the value.  If we don't\n                # have that, we'd be stuck, so in that case fall back to\n                # the RFC standard width.\n                maxlen = 78\n            splitpoint = maxchars = maxlen - chrome_len - 2\n            while True:\n                partial = value[:splitpoint]\n                encoded_value = urllib.parse.quote(\n                    partial, safe='', errors=error_handler)\n                if len(encoded_value) <= maxchars:\n                    break\n                splitpoint -= 1\n            lines.append(\" {}*{}*={}{}\".format(\n                name, section, extra_chrome, encoded_value))\n            extra_chrome = ''\n            section += 1\n            value = value[splitpoint:]\n            if value:\n                lines[-1] += ';'\n", "target": 1}
{"idx": 962, "func": "# Copyright (C) 2013, Red Hat, Inc.\n# All rights reserved.\n#\n# Permission is hereby granted, free of charge, to any person obtaining a copy\n# of this software and associated documentation files (the \"Software\"), to deal\n# in the Software without restriction, including without limitation the rights\n# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n# copies of the Software, and to permit persons to whom the Software is\n# furnished to do so, subject to the following conditions:\n#\n# The above copyright notice and this permission notice shall be included in\n# all copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n# THE SOFTWARE.\n\nimport io\nimport logging\nimport select\nimport socket\nimport struct\nimport sys\nimport time\n\ntry:  # Python 3.x\n    import http.client as httplib\n    import urllib.parse as urlparse\nexcept ImportError:  # Python 2.x\n    import httplib\n    import urlparse\n\nimport kdcproxy.codec as codec\nfrom kdcproxy.config import MetaResolver\n\n\nclass HTTPException(Exception):\n\n    def __init__(self, code, msg, headers=[]):\n        headers = list(filter(lambda h: h[0] != 'Content-Length', headers))\n\n        if 'Content-Type' not in dict(headers):\n            headers.append(('Content-Type', 'text/plain; charset=utf-8'))\n\n        if sys.version_info.major == 3 and isinstance(msg, str):\n            msg = bytes(msg, \"utf-8\")\n\n        headers.append(('Content-Length', str(len(msg))))\n\n        super(HTTPException, self).__init__(code, msg, headers)\n        self.code = code\n        self.message = msg\n        self.headers = headers\n\n    def __str__(self):\n        return \"%d %s\" % (self.code, httplib.responses[self.code])\n\n\nclass Application:\n    SOCKTYPES = {\n        \"tcp\": socket.SOCK_STREAM,\n        \"udp\": socket.SOCK_DGRAM,\n    }\n\n    def __init__(self):\n        self.__resolver = MetaResolver()\n\n    def __await_reply(self, pr, rsocks, wsocks, timeout):\n        extra = 0\n        read_buffers = {}\n        while (timeout + extra) > time.time():\n            if not wsocks and not rsocks:\n                break\n\n            r, w, x = select.select(rsocks, wsocks, rsocks + wsocks,\n                                    (timeout + extra) - time.time())\n            for sock in x:\n                sock.close()\n                try:\n                    rsocks.remove(sock)\n                except ValueError:\n                    pass\n                try:\n                    wsocks.remove(sock)\n                except ValueError:\n                    pass\n\n            for sock in w:\n                try:\n                    if self.sock_type(sock) == socket.SOCK_DGRAM:\n                        # If we proxy over UDP, remove the 4-byte length\n                        # prefix since it is TCP only.\n                        sock.sendall(pr.request[4:])\n                    else:\n                        sock.sendall(pr.request)\n                        extra = 10  # New connections get 10 extra seconds\n                except Exception:\n                    logging.exception('Error in recv() of %s', sock)\n                    continue\n                rsocks.append(sock)\n                wsocks.remove(sock)\n\n            for sock in r:\n                try:\n                    reply = self.__handle_recv(sock, read_buffers)\n                except Exception:\n                    logging.exception('Error in recv() of %s', sock)\n                    if self.sock_type(sock) == socket.SOCK_STREAM:\n                        # Remove broken TCP socket from readers\n                        rsocks.remove(sock)\n                else:\n                    if reply is not None:\n                        return reply\n\n        return None\n\n    def __handle_recv(self, sock, read_buffers):\n        if self.sock_type(sock) == socket.SOCK_DGRAM:\n            # For UDP sockets, recv() returns an entire datagram\n            # package. KDC sends one datagram as reply.\n            reply = sock.recv(1048576)\n            # If we proxy over UDP, we will be missing the 4-byte\n            # length prefix. So add it.\n            reply = struct.pack(\"!I\", len(reply)) + reply\n            return reply\n        else:\n            # TCP is a different story. The reply must be buffered\n            # until the full answer is accumulated.\n            buf = read_buffers.get(sock)\n            part = sock.recv(1048576)\n            if buf is None:\n                if len(part) > 4:\n                    # got enough data in the initial package. Now check\n                    # if we got the full package in the first run.\n                    (length, ) = struct.unpack(\"!I\", part[0:4])\n                    if length + 4 == len(part):\n                        return part\n                read_buffers[sock] = buf = io.BytesIO()\n\n            if part:\n                # data received, accumulate it in a buffer\n                buf.write(part)\n                return None\n            else:\n                # EOF received\n                read_buffers.pop(sock)\n                reply = buf.getvalue()\n                return reply\n\n    def __filter_addr(self, addr):\n        if addr[0] not in (socket.AF_INET, socket.AF_INET6):\n            return False\n\n        if addr[1] not in (socket.SOCK_STREAM, socket.SOCK_DGRAM):\n            return False\n\n        if addr[2] not in (socket.IPPROTO_TCP, socket.IPPROTO_UDP):\n            return False\n\n        return True\n\n    def sock_type(self, sock):\n        try:\n            return sock.type & ~socket.SOCK_NONBLOCK\n        except AttributeError:\n            return sock.type\n\n    def __call__(self, env, start_response):\n        try:\n            # Validate the method\n            method = env[\"REQUEST_METHOD\"].upper()\n            if method != \"POST\":\n                raise HTTPException(405, \"Method not allowed (%s).\" % method)\n\n            # Parse the request\n            try:\n                length = int(env[\"CONTENT_LENGTH\"])\n            except AttributeError:\n                length = -1\n            try:\n                pr = codec.decode(env[\"wsgi.input\"].read(length))\n            except codec.ParsingError as e:\n                raise HTTPException(400, e.message)\n\n            # Find the remote proxy\n            servers = self.__resolver.lookup(\n                pr.realm,\n                kpasswd=isinstance(pr, codec.KPASSWDProxyRequest)\n            )\n            if not servers:\n                raise HTTPException(503, \"Can't find remote (%s).\" % pr)\n\n            # Contact the remote server\n            reply = None\n            wsocks = []\n            rsocks = []\n            for server in map(urlparse.urlparse, servers):\n                # Enforce valid, supported URIs\n                scheme = server.scheme.lower().split(\"+\", 1)\n                if scheme[0] not in (\"kerberos\", \"kpasswd\"):\n                    continue\n                if len(scheme) > 1 and scheme[1] not in (\"tcp\", \"udp\"):\n                    continue\n\n                # Do the DNS lookup\n                try:\n                    port = server.port\n                    if port is None:\n                        port = scheme[0]\n                    addrs = socket.getaddrinfo(server.hostname, port)\n                except socket.gaierror:\n                    continue\n\n                # Sort addresses so that we get TCP first.\n                #\n                # Stick a None address on the end so we can get one\n                # more attempt after all servers have been contacted.\n                addrs = tuple(sorted(filter(self.__filter_addr, addrs)))\n                for addr in addrs + (None,):\n                    if addr is not None:\n                        # Bypass unspecified socktypes\n                        if (len(scheme) > 1\n                                and addr[1] != self.SOCKTYPES[scheme[1]]):\n                            continue\n\n                        # Create the socket\n                        sock = socket.socket(*addr[:3])\n                        sock.setblocking(0)\n\n                        # Connect\n                        try:\n                            # In Python 2.x, non-blocking connect() throws\n                            # socket.error() with errno == EINPROGRESS. In\n                            # Python 3.x, it throws io.BlockingIOError().\n                            sock.connect(addr[4])\n                        except socket.error as e:\n                            if e.errno != 115:  # errno != EINPROGRESS\n                                sock.close()\n                                continue\n                        except io.BlockingIOError:\n                            pass\n                        wsocks.append(sock)\n\n                    # Resend packets to UDP servers\n                    for sock in tuple(rsocks):\n                        if self.sock_type(sock) == socket.SOCK_DGRAM:\n                            wsocks.append(sock)\n                            rsocks.remove(sock)\n\n                    # Call select()\n                    timeout = time.time() + (15 if addr is None else 2)\n                    reply = self.__await_reply(pr, rsocks, wsocks, timeout)\n                    if reply is not None:\n                        break\n\n                if reply is not None:\n                    break\n\n            for sock in rsocks + wsocks:\n                sock.close()\n\n            if reply is None:\n                raise HTTPException(503, \"Remote unavailable (%s).\" % pr)\n\n            # Return the result to the client\n            raise HTTPException(200, codec.encode(reply),\n                                [(\"Content-Type\", \"application/kerberos\")])\n        except HTTPException as e:\n            start_response(str(e), e.headers)\n            return [e.message]\n\napplication = Application()\n", "target": 1}
{"idx": 963, "func": "# -*- coding: utf-8 -*-\n'''\nTCP transport classes\n\nWire protocol: \"len(payload) msgpack({'head': SOMEHEADER, 'body': SOMEBODY})\"\n\n'''\n\n# Import Python Libs\nfrom __future__ import absolute_import\nimport logging\nimport msgpack\nimport socket\nimport os\nimport weakref\nimport time\nimport traceback\nimport errno\n\n# Import Salt Libs\nimport salt.crypt\nimport salt.utils\nimport salt.utils.verify\nimport salt.utils.event\nimport salt.utils.async\nimport salt.payload\nimport salt.exceptions\nimport salt.transport.frame\nimport salt.transport.ipc\nimport salt.transport.client\nimport salt.transport.server\nimport salt.transport.mixins.auth\nimport salt.ext.six as six\nfrom salt.exceptions import SaltReqTimeoutError, SaltClientError\nfrom salt.transport import iter_transport_opts\n\n# Import Tornado Libs\nimport tornado\nimport tornado.tcpserver\nimport tornado.gen\nimport tornado.concurrent\nimport tornado.tcpclient\nimport tornado.netutil\n\n# pylint: disable=import-error,no-name-in-module\nif six.PY2:\n    import urlparse\nelse:\n    import urllib.parse as urlparse\n# pylint: enable=import-error,no-name-in-module\n\n# Import third party libs\ntry:\n    from Cryptodome.Cipher import PKCS1_OAEP\nexcept ImportError:\n    from Crypto.Cipher import PKCS1_OAEP\n\nif six.PY3 and salt.utils.is_windows():\n    USE_LOAD_BALANCER = True\nelse:\n    USE_LOAD_BALANCER = False\n\nif USE_LOAD_BALANCER:\n    import threading\n    import multiprocessing\n    import errno\n    import tornado.util\n    from salt.utils.process import SignalHandlingMultiprocessingProcess\n\nlog = logging.getLogger(__name__)\n\n\ndef _set_tcp_keepalive(sock, opts):\n    '''\n    Ensure that TCP keepalives are set for the socket.\n    '''\n    if hasattr(socket, 'SO_KEEPALIVE'):\n        if opts.get('tcp_keepalive', False):\n            sock.setsockopt(socket.SOL_SOCKET, socket.SO_KEEPALIVE, 1)\n            if hasattr(socket, 'SOL_TCP'):\n                if hasattr(socket, 'TCP_KEEPIDLE'):\n                    tcp_keepalive_idle = opts.get('tcp_keepalive_idle', -1)\n                    if tcp_keepalive_idle > 0:\n                        sock.setsockopt(\n                            socket.SOL_TCP, socket.TCP_KEEPIDLE,\n                            int(tcp_keepalive_idle))\n                if hasattr(socket, 'TCP_KEEPCNT'):\n                    tcp_keepalive_cnt = opts.get('tcp_keepalive_cnt', -1)\n                    if tcp_keepalive_cnt > 0:\n                        sock.setsockopt(\n                            socket.SOL_TCP, socket.TCP_KEEPCNT,\n                            int(tcp_keepalive_cnt))\n                if hasattr(socket, 'TCP_KEEPINTVL'):\n                    tcp_keepalive_intvl = opts.get('tcp_keepalive_intvl', -1)\n                    if tcp_keepalive_intvl > 0:\n                        sock.setsockopt(\n                            socket.SOL_TCP, socket.TCP_KEEPINTVL,\n                            int(tcp_keepalive_intvl))\n            if hasattr(socket, 'SIO_KEEPALIVE_VALS'):\n                # Windows doesn't support TCP_KEEPIDLE, TCP_KEEPCNT, nor\n                # TCP_KEEPINTVL. Instead, it has its own proprietary\n                # SIO_KEEPALIVE_VALS.\n                tcp_keepalive_idle = opts.get('tcp_keepalive_idle', -1)\n                tcp_keepalive_intvl = opts.get('tcp_keepalive_intvl', -1)\n                # Windows doesn't support changing something equivalent to\n                # TCP_KEEPCNT.\n                if tcp_keepalive_idle > 0 or tcp_keepalive_intvl > 0:\n                    # Windows defaults may be found by using the link below.\n                    # Search for 'KeepAliveTime' and 'KeepAliveInterval'.\n                    # https://technet.microsoft.com/en-us/library/bb726981.aspx#EDAA\n                    # If one value is set and the other isn't, we still need\n                    # to send both values to SIO_KEEPALIVE_VALS and they both\n                    # need to be valid. So in that case, use the Windows\n                    # default.\n                    if tcp_keepalive_idle <= 0:\n                        tcp_keepalive_idle = 7200\n                    if tcp_keepalive_intvl <= 0:\n                        tcp_keepalive_intvl = 1\n                    # The values expected are in milliseconds, so multiply by\n                    # 1000.\n                    sock.ioctl(socket.SIO_KEEPALIVE_VALS, (\n                        1, int(tcp_keepalive_idle * 1000),\n                        int(tcp_keepalive_intvl * 1000)))\n        else:\n            sock.setsockopt(socket.SOL_SOCKET, socket.SO_KEEPALIVE, 0)\n\n\nif USE_LOAD_BALANCER:\n    class LoadBalancerServer(SignalHandlingMultiprocessingProcess):\n        '''\n        Raw TCP server which runs in its own process and will listen\n        for incoming connections. Each incoming connection will be\n        sent via multiprocessing queue to the workers.\n        Since the queue is shared amongst workers, only one worker will\n        handle a given connection.\n        '''\n        # TODO: opts!\n        # Based on default used in tornado.netutil.bind_sockets()\n        backlog = 128\n\n        def __init__(self, opts, socket_queue, log_queue=None):\n            super(LoadBalancerServer, self).__init__(log_queue=log_queue)\n            self.opts = opts\n            self.socket_queue = socket_queue\n            self._socket = None\n\n        # __setstate__ and __getstate__ are only used on Windows.\n        # We do this so that __init__ will be invoked on Windows in the child\n        # process so that a register_after_fork() equivalent will work on\n        # Windows.\n        def __setstate__(self, state):\n            self._is_child = True\n            self.__init__(\n                state['opts'],\n                state['socket_queue'],\n                log_queue=state['log_queue']\n            )\n\n        def __getstate__(self):\n            return {'opts': self.opts,\n                    'socket_queue': self.socket_queue,\n                    'log_queue': self.log_queue}\n\n        def close(self):\n            if self._socket is not None:\n                self._socket.shutdown(socket.SHUT_RDWR)\n                self._socket.close()\n                self._socket = None\n\n        def __del__(self):\n            self.close()\n\n        def run(self):\n            '''\n            Start the load balancer\n            '''\n            self._socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n            self._socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n            _set_tcp_keepalive(self._socket, self.opts)\n            self._socket.setblocking(1)\n            self._socket.bind((self.opts['interface'], int(self.opts['ret_port'])))\n            self._socket.listen(self.backlog)\n\n            while True:\n                try:\n                    # Wait for a connection to occur since the socket is\n                    # blocking.\n                    connection, address = self._socket.accept()\n                    # Wait for a free slot to be available to put\n                    # the connection into.\n                    # Sockets are picklable on Windows in Python 3.\n                    self.socket_queue.put((connection, address), True, None)\n                except socket.error as e:\n                    # ECONNABORTED indicates that there was a connection\n                    # but it was closed while still in the accept queue.\n                    # (observed on FreeBSD).\n                    if tornado.util.errno_from_exception(e) == errno.ECONNABORTED:\n                        continue\n                    raise\n\n\n# TODO: move serial down into message library\nclass AsyncTCPReqChannel(salt.transport.client.ReqChannel):\n    '''\n    Encapsulate sending routines to tcp.\n\n    Note: this class returns a singleton\n    '''\n    # This class is only a singleton per minion/master pair\n    # mapping of io_loop -> {key -> channel}\n    instance_map = weakref.WeakKeyDictionary()\n\n    def __new__(cls, opts, **kwargs):\n        '''\n        Only create one instance of channel per __key()\n        '''\n        # do we have any mapping for this io_loop\n        io_loop = kwargs.get('io_loop') or tornado.ioloop.IOLoop.current()\n        if io_loop not in cls.instance_map:\n            cls.instance_map[io_loop] = weakref.WeakValueDictionary()\n        loop_instance_map = cls.instance_map[io_loop]\n\n        key = cls.__key(opts, **kwargs)\n        obj = loop_instance_map.get(key)\n        if obj is None:\n            log.debug('Initializing new AsyncTCPReqChannel for {0}'.format(key))\n            # we need to make a local variable for this, as we are going to store\n            # it in a WeakValueDictionary-- which will remove the item if no one\n            # references it-- this forces a reference while we return to the caller\n            obj = object.__new__(cls)\n            obj.__singleton_init__(opts, **kwargs)\n            loop_instance_map[key] = obj\n        else:\n            log.debug('Re-using AsyncTCPReqChannel for {0}'.format(key))\n        return obj\n\n    @classmethod\n    def __key(cls, opts, **kwargs):\n        if 'master_uri' in kwargs:\n            opts['master_uri'] = kwargs['master_uri']\n        return (opts['pki_dir'],     # where the keys are stored\n                opts['id'],          # minion ID\n                opts['master_uri'],\n                kwargs.get('crypt', 'aes'),  # TODO: use the same channel for crypt\n                )\n\n    # has to remain empty for singletons, since __init__ will *always* be called\n    def __init__(self, opts, **kwargs):\n        pass\n\n    # an init for the singleton instance to call\n    def __singleton_init__(self, opts, **kwargs):\n        self.opts = dict(opts)\n\n        self.serial = salt.payload.Serial(self.opts)\n\n        # crypt defaults to 'aes'\n        self.crypt = kwargs.get('crypt', 'aes')\n\n        self.io_loop = kwargs.get('io_loop') or tornado.ioloop.IOLoop.current()\n\n        if self.crypt != 'clear':\n            self.auth = salt.crypt.AsyncAuth(self.opts, io_loop=self.io_loop)\n\n        resolver = kwargs.get('resolver')\n\n        parse = urlparse.urlparse(self.opts['master_uri'])\n        host, port = parse.netloc.rsplit(':', 1)\n        self.master_addr = (host, int(port))\n        self._closing = False\n        self.message_client = SaltMessageClientPool(self.opts,\n                                                    args=(self.opts, host, int(port),),\n                                                    kwargs={'io_loop': self.io_loop, 'resolver': resolver})\n\n    def close(self):\n        if self._closing:\n            return\n        self._closing = True\n        self.message_client.close()\n\n    def __del__(self):\n        self.close()\n\n    def _package_load(self, load):\n        return {\n            'enc': self.crypt,\n            'load': load,\n        }\n\n    @tornado.gen.coroutine\n    def crypted_transfer_decode_dictentry(self, load, dictkey=None, tries=3, timeout=60):\n        if not self.auth.authenticated:\n            yield self.auth.authenticate()\n        ret = yield self.message_client.send(self._package_load(self.auth.crypticle.dumps(load)), timeout=timeout)\n        key = self.auth.get_keys()\n        cipher = PKCS1_OAEP.new(key)\n        aes = cipher.decrypt(ret['key'])\n        pcrypt = salt.crypt.Crypticle(self.opts, aes)\n        data = pcrypt.loads(ret[dictkey])\n        if six.PY3:\n            data = salt.transport.frame.decode_embedded_strs(data)\n        raise tornado.gen.Return(data)\n\n    @tornado.gen.coroutine\n    def _crypted_transfer(self, load, tries=3, timeout=60):\n        '''\n        In case of authentication errors, try to renegotiate authentication\n        and retry the method.\n        Indeed, we can fail too early in case of a master restart during a\n        minion state execution call\n        '''\n        @tornado.gen.coroutine\n        def _do_transfer():\n            data = yield self.message_client.send(self._package_load(self.auth.crypticle.dumps(load)),\n                                                  timeout=timeout,\n                                                  )\n            # we may not have always data\n            # as for example for saltcall ret submission, this is a blind\n            # communication, we do not subscribe to return events, we just\n            # upload the results to the master\n            if data:\n                data = self.auth.crypticle.loads(data)\n                if six.PY3:\n                    data = salt.transport.frame.decode_embedded_strs(data)\n            raise tornado.gen.Return(data)\n\n        if not self.auth.authenticated:\n            yield self.auth.authenticate()\n        try:\n            ret = yield _do_transfer()\n            raise tornado.gen.Return(ret)\n        except salt.crypt.AuthenticationError:\n            yield self.auth.authenticate()\n            ret = yield _do_transfer()\n            raise tornado.gen.Return(ret)\n\n    @tornado.gen.coroutine\n    def _uncrypted_transfer(self, load, tries=3, timeout=60):\n        ret = yield self.message_client.send(self._package_load(load), timeout=timeout)\n        raise tornado.gen.Return(ret)\n\n    @tornado.gen.coroutine\n    def send(self, load, tries=3, timeout=60, raw=False):\n        '''\n        Send a request, return a future which will complete when we send the message\n        '''\n        try:\n            if self.crypt == 'clear':\n                ret = yield self._uncrypted_transfer(load, tries=tries, timeout=timeout)\n            else:\n                ret = yield self._crypted_transfer(load, tries=tries, timeout=timeout)\n        except tornado.iostream.StreamClosedError:\n            # Convert to 'SaltClientError' so that clients can handle this\n            # exception more appropriately.\n            raise SaltClientError('Connection to master lost')\n        raise tornado.gen.Return(ret)\n\n\nclass AsyncTCPPubChannel(salt.transport.mixins.auth.AESPubClientMixin, salt.transport.client.AsyncPubChannel):\n    def __init__(self,\n                 opts,\n                 **kwargs):\n        self.opts = opts\n\n        self.serial = salt.payload.Serial(self.opts)\n\n        self.crypt = kwargs.get('crypt', 'aes')\n        self.io_loop = kwargs.get('io_loop') or tornado.ioloop.IOLoop.current()\n        self.connected = False\n        self._closing = False\n        self._reconnected = False\n        self.event = salt.utils.event.get_event(\n            'minion',\n            opts=self.opts,\n            listen=False\n        )\n\n    def close(self):\n        if self._closing:\n            return\n        self._closing = True\n        if hasattr(self, 'message_client'):\n            self.message_client.close()\n\n    def __del__(self):\n        self.close()\n\n    def _package_load(self, load):\n        return {\n            'enc': self.crypt,\n            'load': load,\n        }\n\n    @tornado.gen.coroutine\n    def send_id(self, tok, force_auth):\n        '''\n        Send the minion id to the master so that the master may better\n        track the connection state of the minion.\n        In case of authentication errors, try to renegotiate authentication\n        and retry the method.\n        '''\n        load = {'id': self.opts['id'], 'tok': tok}\n\n        @tornado.gen.coroutine\n        def _do_transfer():\n            msg = self._package_load(self.auth.crypticle.dumps(load))\n            package = salt.transport.frame.frame_msg(msg, header=None)\n            yield self.message_client.write_to_stream(package)\n            raise tornado.gen.Return(True)\n\n        if force_auth or not self.auth.authenticated:\n            count = 0\n            while count <= self.opts['tcp_authentication_retries'] or self.opts['tcp_authentication_retries'] < 0:\n                try:\n                    yield self.auth.authenticate()\n                    break\n                except SaltClientError as exc:\n                    log.debug(exc)\n                    count += 1\n        try:\n            ret = yield _do_transfer()\n            raise tornado.gen.Return(ret)\n        except salt.crypt.AuthenticationError:\n            yield self.auth.authenticate()\n            ret = yield _do_transfer()\n            raise tornado.gen.Return(ret)\n\n    @tornado.gen.coroutine\n    def connect_callback(self, result):\n        if self._closing:\n            return\n        # Force re-auth on reconnect since the master\n        # may have been restarted\n        yield self.send_id(self.tok, self._reconnected)\n        self.connected = True\n        self.event.fire_event(\n            {'master': self.opts['master']},\n            '__master_connected'\n        )\n        if self._reconnected:\n            # On reconnects, fire a master event to notify that the minion is\n            # available.\n            if self.opts.get('__role') == 'syndic':\n                data = 'Syndic {0} started at {1}'.format(\n                    self.opts['id'],\n                    time.asctime()\n                )\n                tag = salt.utils.event.tagify(\n                    [self.opts['id'], 'start'],\n                    'syndic'\n                )\n            else:\n                data = 'Minion {0} started at {1}'.format(\n                    self.opts['id'],\n                    time.asctime()\n                )\n                tag = salt.utils.event.tagify(\n                    [self.opts['id'], 'start'],\n                    'minion'\n                )\n            load = {'id': self.opts['id'],\n                    'cmd': '_minion_event',\n                    'pretag': None,\n                    'tok': self.tok,\n                    'data': data,\n                    'tag': tag}\n            req_channel = salt.utils.async.SyncWrapper(\n                AsyncTCPReqChannel, (self.opts,)\n            )\n            try:\n                req_channel.send(load, timeout=60)\n            except salt.exceptions.SaltReqTimeoutError:\n                log.info('fire_master failed: master could not be contacted. Request timed out.')\n            except Exception:\n                log.info('fire_master failed: {0}'.format(\n                    traceback.format_exc())\n                )\n        else:\n            self._reconnected = True\n\n    def disconnect_callback(self):\n        if self._closing:\n            return\n        self.connected = False\n        self.event.fire_event(\n            {'master': self.opts['master']},\n            '__master_disconnected'\n        )\n\n    @tornado.gen.coroutine\n    def connect(self):\n        try:\n            self.auth = salt.crypt.AsyncAuth(self.opts, io_loop=self.io_loop)\n            self.tok = self.auth.gen_token('salt')\n            if not self.auth.authenticated:\n                yield self.auth.authenticate()\n            if self.auth.authenticated:\n                self.message_client = SaltMessageClientPool(\n                    self.opts,\n                    args=(self.opts, self.opts['master_ip'], int(self.auth.creds['publish_port']),),\n                    kwargs={'io_loop': self.io_loop,\n                            'connect_callback': self.connect_callback,\n                            'disconnect_callback': self.disconnect_callback})\n                yield self.message_client.connect()  # wait for the client to be connected\n                self.connected = True\n        # TODO: better exception handling...\n        except KeyboardInterrupt:\n            raise\n        except Exception as exc:\n            if '-|RETRY|-' not in str(exc):\n                raise SaltClientError('Unable to sign_in to master: {0}'.format(exc))  # TODO: better error message\n\n    def on_recv(self, callback):\n        '''\n        Register an on_recv callback\n        '''\n        if callback is None:\n            return self.message_client.on_recv(callback)\n\n        @tornado.gen.coroutine\n        def wrap_callback(body):\n            if not isinstance(body, dict):\n                # TODO: For some reason we need to decode here for things\n                #       to work. Fix this.\n                body = msgpack.loads(body)\n                if six.PY3:\n                    body = salt.transport.frame.decode_embedded_strs(body)\n            ret = yield self._decode_payload(body)\n            callback(ret)\n        return self.message_client.on_recv(wrap_callback)\n\n\nclass TCPReqServerChannel(salt.transport.mixins.auth.AESReqServerMixin, salt.transport.server.ReqServerChannel):\n    # TODO: opts!\n    backlog = 5\n\n    def __init__(self, opts):\n        salt.transport.server.ReqServerChannel.__init__(self, opts)\n        self._socket = None\n\n    @property\n    def socket(self):\n        return self._socket\n\n    def close(self):\n        if self._socket is not None:\n            try:\n                self._socket.shutdown(socket.SHUT_RDWR)\n            except socket.error as exc:\n                if exc.errno == errno.ENOTCONN:\n                    # We may try to shutdown a socket which is already disconnected.\n                    # Ignore this condition and continue.\n                    pass\n                else:\n                    raise exc\n            self._socket.close()\n            self._socket = None\n\n    def __del__(self):\n        self.close()\n\n    def pre_fork(self, process_manager):\n        '''\n        Pre-fork we need to create the zmq router device\n        '''\n        salt.transport.mixins.auth.AESReqServerMixin.pre_fork(self, process_manager)\n        if USE_LOAD_BALANCER:\n            self.socket_queue = multiprocessing.Queue()\n            process_manager.add_process(\n                LoadBalancerServer, args=(self.opts, self.socket_queue)\n            )\n        elif not salt.utils.is_windows():\n            self._socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n            self._socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n            _set_tcp_keepalive(self._socket, self.opts)\n            self._socket.setblocking(0)\n            self._socket.bind((self.opts['interface'], int(self.opts['ret_port'])))\n\n    def post_fork(self, payload_handler, io_loop):\n        '''\n        After forking we need to create all of the local sockets to listen to the\n        router\n\n        payload_handler: function to call with your payloads\n        '''\n        self.payload_handler = payload_handler\n        self.io_loop = io_loop\n        self.serial = salt.payload.Serial(self.opts)\n        if USE_LOAD_BALANCER:\n            self.req_server = LoadBalancerWorker(self.socket_queue,\n                                                 self.handle_message,\n                                                 io_loop=self.io_loop,\n                                                 ssl_options=self.opts.get('ssl'))\n        else:\n            if salt.utils.is_windows():\n                self._socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n                self._socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n                _set_tcp_keepalive(self._socket, self.opts)\n                self._socket.setblocking(0)\n                self._socket.bind((self.opts['interface'], int(self.opts['ret_port'])))\n            self.req_server = SaltMessageServer(self.handle_message,\n                                                io_loop=self.io_loop,\n                                                ssl_options=self.opts.get('ssl'))\n            self.req_server.add_socket(self._socket)\n            self._socket.listen(self.backlog)\n        salt.transport.mixins.auth.AESReqServerMixin.post_fork(self, payload_handler, io_loop)\n\n    @tornado.gen.coroutine\n    def handle_message(self, stream, header, payload):\n        '''\n        Handle incoming messages from underylying tcp streams\n        '''\n        try:\n            try:\n                payload = self._decode_payload(payload)\n            except Exception:\n                stream.write(salt.transport.frame.frame_msg('bad load', header=header))\n                raise tornado.gen.Return()\n\n            # TODO helper functions to normalize payload?\n            if not isinstance(payload, dict) or not isinstance(payload.get('load'), dict):\n                yield stream.write(salt.transport.frame.frame_msg(\n                    'payload and load must be a dict', header=header))\n                raise tornado.gen.Return()\n\n            try:\n                id_ = payload['load'].get('id', '')\n                if '\\0' in id_:\n                    log.error('Payload contains an id with a null byte: %s', payload)\n                    stream.send(self.serial.dumps('bad load: id contains a null byte'))\n                    raise tornado.gen.Return()\n            except TypeError:\n                log.error('Payload contains non-string id: %s', payload)\n                stream.send(self.serial.dumps('bad load: id {0} is not a string'.format(id_)))\n                raise tornado.gen.Return()\n\n            # intercept the \"_auth\" commands, since the main daemon shouldn't know\n            # anything about our key auth\n            if payload['enc'] == 'clear' and payload.get('load', {}).get('cmd') == '_auth':\n                yield stream.write(salt.transport.frame.frame_msg(\n                    self._auth(payload['load']), header=header))\n                raise tornado.gen.Return()\n\n            # TODO: test\n            try:\n                ret, req_opts = yield self.payload_handler(payload)\n            except Exception as e:\n                # always attempt to return an error to the minion\n                stream.write('Some exception handling minion payload')\n                log.error('Some exception handling a payload from minion', exc_info=True)\n                stream.close()\n                raise tornado.gen.Return()\n\n            req_fun = req_opts.get('fun', 'send')\n            if req_fun == 'send_clear':\n                stream.write(salt.transport.frame.frame_msg(ret, header=header))\n            elif req_fun == 'send':\n                stream.write(salt.transport.frame.frame_msg(self.crypticle.dumps(ret), header=header))\n            elif req_fun == 'send_private':\n                stream.write(salt.transport.frame.frame_msg(self._encrypt_private(ret,\n                                                             req_opts['key'],\n                                                             req_opts['tgt'],\n                                                             ), header=header))\n            else:\n                log.error('Unknown req_fun {0}'.format(req_fun))\n                # always attempt to return an error to the minion\n                stream.write('Server-side exception handling payload')\n                stream.close()\n        except tornado.gen.Return:\n            raise\n        except tornado.iostream.StreamClosedError:\n            # Stream was closed. This could happen if the remote side\n            # closed the connection on its end (eg in a timeout or shutdown\n            # situation).\n            log.error('Connection was unexpectedly closed', exc_info=True)\n        except Exception as exc:  # pylint: disable=broad-except\n            # Absorb any other exceptions\n            log.error('Unexpected exception occurred: {0}'.format(exc), exc_info=True)\n\n        raise tornado.gen.Return()\n\n\nclass SaltMessageServer(tornado.tcpserver.TCPServer, object):\n    '''\n    Raw TCP server which will receive all of the TCP streams and re-assemble\n    messages that are sent through to us\n    '''\n    def __init__(self, message_handler, *args, **kwargs):\n        super(SaltMessageServer, self).__init__(*args, **kwargs)\n\n        self.clients = []\n        self.message_handler = message_handler\n\n    @tornado.gen.coroutine\n    def handle_stream(self, stream, address):\n        '''\n        Handle incoming streams and add messages to the incoming queue\n        '''\n        log.trace('Req client {0} connected'.format(address))\n        self.clients.append((stream, address))\n        unpacker = msgpack.Unpacker()\n        try:\n            while True:\n                wire_bytes = yield stream.read_bytes(4096, partial=True)\n                unpacker.feed(wire_bytes)\n                for framed_msg in unpacker:\n                    if six.PY3:\n                        framed_msg = salt.transport.frame.decode_embedded_strs(\n                            framed_msg\n                        )\n                    header = framed_msg['head']\n                    self.io_loop.spawn_callback(self.message_handler, stream, header, framed_msg['body'])\n\n        except tornado.iostream.StreamClosedError:\n            log.trace('req client disconnected {0}'.format(address))\n            self.clients.remove((stream, address))\n        except Exception as e:\n            log.trace('other master-side exception: {0}'.format(e))\n            self.clients.remove((stream, address))\n            stream.close()\n\n    def shutdown(self):\n        '''\n        Shutdown the whole server\n        '''\n        for item in self.clients:\n            client, address = item\n            client.close()\n            self.clients.remove(item)\n\n\nif USE_LOAD_BALANCER:\n    class LoadBalancerWorker(SaltMessageServer):\n        '''\n        This will receive TCP connections from 'LoadBalancerServer' via\n        a multiprocessing queue.\n        Since the queue is shared amongst workers, only one worker will handle\n        a given connection.\n        '''\n        def __init__(self, socket_queue, message_handler, *args, **kwargs):\n            super(LoadBalancerWorker, self).__init__(\n                message_handler, *args, **kwargs)\n            self.socket_queue = socket_queue\n\n            t = threading.Thread(target=self.socket_queue_thread)\n            t.start()\n\n        def socket_queue_thread(self):\n            try:\n                while True:\n                    client_socket, address = self.socket_queue.get(True, None)\n\n                    # 'self.io_loop' initialized in super class\n                    # 'tornado.tcpserver.TCPServer'.\n                    # 'self._handle_connection' defined in same super class.\n                    self.io_loop.spawn_callback(\n                        self._handle_connection, client_socket, address)\n            except (KeyboardInterrupt, SystemExit):\n                pass\n\n\nclass TCPClientKeepAlive(tornado.tcpclient.TCPClient):\n    '''\n    Override _create_stream() in TCPClient to enable keep alive support.\n    '''\n    def __init__(self, opts, resolver=None, io_loop=None):\n        self.opts = opts\n        super(TCPClientKeepAlive, self).__init__(\n            resolver=resolver, io_loop=io_loop)\n\n    def _create_stream(self, max_buffer_size, af, addr, **kwargs):  # pylint: disable=unused-argument\n        '''\n        Override _create_stream() in TCPClient.\n\n        Tornado 4.5 added the kwargs 'source_ip' and 'source_port'.\n        Due to this, use **kwargs to swallow these and any future\n        kwargs to maintain compatibility.\n        '''\n        # Always connect in plaintext; we'll convert to ssl if necessary\n        # after one connection has completed.\n        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        _set_tcp_keepalive(sock, self.opts)\n        stream = tornado.iostream.IOStream(\n            sock,\n            io_loop=self.io_loop,\n            max_buffer_size=max_buffer_size)\n        return stream.connect(addr)\n\n\nclass SaltMessageClientPool(salt.transport.MessageClientPool):\n    '''\n    Wrapper class of SaltMessageClient to avoid blocking waiting while writing data to socket.\n    '''\n    def __init__(self, opts, args=None, kwargs=None):\n        super(SaltMessageClientPool, self).__init__(SaltMessageClient, opts, args=args, kwargs=kwargs)\n\n    def __del__(self):\n        self.close()\n\n    def close(self):\n        for message_client in self.message_clients:\n            message_client.close()\n        self.message_clients = []\n\n    @tornado.gen.coroutine\n    def connect(self):\n        futures = []\n        for message_client in self.message_clients:\n            futures.append(message_client.connect())\n        for future in futures:\n            yield future\n        raise tornado.gen.Return(None)\n\n    def on_recv(self, *args, **kwargs):\n        for message_client in self.message_clients:\n            message_client.on_recv(*args, **kwargs)\n\n    def send(self, *args, **kwargs):\n        message_clients = sorted(self.message_clients, key=lambda x: len(x.send_queue))\n        return message_clients[0].send(*args, **kwargs)\n\n    def write_to_stream(self, *args, **kwargs):\n        message_clients = sorted(self.message_clients, key=lambda x: len(x.send_queue))\n        return message_clients[0]._stream.write(*args, **kwargs)\n\n\n# TODO consolidate with IPCClient\n# TODO: limit in-flight messages.\n# TODO: singleton? Something to not re-create the tcp connection so much\nclass SaltMessageClient(object):\n    '''\n    Low-level message sending client\n    '''\n    def __init__(self, opts, host, port, io_loop=None, resolver=None,\n                 connect_callback=None, disconnect_callback=None):\n        self.opts = opts\n        self.host = host\n        self.port = port\n        self.connect_callback = connect_callback\n        self.disconnect_callback = disconnect_callback\n\n        self.io_loop = io_loop or tornado.ioloop.IOLoop.current()\n\n        self._tcp_client = TCPClientKeepAlive(\n            opts, io_loop=self.io_loop, resolver=resolver)\n\n        self._mid = 1\n        self._max_messages = int((1 << 31) - 2)  # number of IDs before we wrap\n\n        # TODO: max queue size\n        self.send_queue = []  # queue of messages to be sent\n        self.send_future_map = {}  # mapping of request_id -> Future\n        self.send_timeout_map = {}  # request_id -> timeout_callback\n\n        self._read_until_future = None\n        self._on_recv = None\n        self._closing = False\n        self._connecting_future = self.connect()\n        self._stream_return_future = tornado.concurrent.Future()\n        self.io_loop.spawn_callback(self._stream_return)\n\n    # TODO: timeout inflight sessions\n    def close(self):\n        if self._closing:\n            return\n        self._closing = True\n        if hasattr(self, '_stream') and not self._stream.closed():\n            self._stream.close()\n            if self._read_until_future is not None:\n                # This will prevent this message from showing up:\n                # '[ERROR   ] Future exception was never retrieved:\n                # StreamClosedError'\n                # This happens because the logic is always waiting to read\n                # the next message and the associated read future is marked\n                # 'StreamClosedError' when the stream is closed.\n                self._read_until_future.exc_info()\n                if (not self._stream_return_future.done() and\n                        self.io_loop != tornado.ioloop.IOLoop.current(\n                            instance=False)):\n                    # If _stream_return() hasn't completed, it means the IO\n                    # Loop is stopped (such as when using\n                    # 'salt.utils.async.SyncWrapper'). Ensure that\n                    # _stream_return() completes by restarting the IO Loop.\n                    # This will prevent potential errors on shutdown.\n                    orig_loop = tornado.ioloop.IOLoop.current()\n                    self.io_loop.make_current()\n                    try:\n                        self.io_loop.add_future(\n                            self._stream_return_future,\n                            lambda future: self.io_loop.stop()\n                        )\n                        self.io_loop.start()\n                    finally:\n                        orig_loop.make_current()\n        self._tcp_client.close()\n        # Clear callback references to allow the object that they belong to\n        # to be deleted.\n        self.connect_callback = None\n        self.disconnect_callback = None\n\n    def __del__(self):\n        self.close()\n\n    def connect(self):\n        '''\n        Ask for this client to reconnect to the origin\n        '''\n        if hasattr(self, '_connecting_future') and not self._connecting_future.done():\n            future = self._connecting_future\n        else:\n            future = tornado.concurrent.Future()\n            self._connecting_future = future\n            self.io_loop.add_callback(self._connect)\n\n            # Add the callback only when a new future is created\n            if self.connect_callback is not None:\n                def handle_future(future):\n                    response = future.result()\n                    self.io_loop.add_callback(self.connect_callback, response)\n                future.add_done_callback(handle_future)\n\n        return future\n\n    # TODO: tcp backoff opts\n    @tornado.gen.coroutine\n    def _connect(self):\n        '''\n        Try to connect for the rest of time!\n        '''\n        while True:\n            if self._closing:\n                break\n            try:\n                self._stream = yield self._tcp_client.connect(self.host,\n                                                              self.port,\n                                                              ssl_options=self.opts.get('ssl'))\n                self._connecting_future.set_result(True)\n                break\n            except Exception as e:\n                yield tornado.gen.sleep(1)  # TODO: backoff\n                #self._connecting_future.set_exception(e)\n\n    @tornado.gen.coroutine\n    def _stream_return(self):\n        try:\n            while not self._closing and (\n                    not self._connecting_future.done() or\n                    self._connecting_future.result() is not True):\n                yield self._connecting_future\n            unpacker = msgpack.Unpacker()\n            while not self._closing:\n                try:\n                    self._read_until_future = self._stream.read_bytes(4096, partial=True)\n                    wire_bytes = yield self._read_until_future\n                    unpacker.feed(wire_bytes)\n                    for framed_msg in unpacker:\n                        if six.PY3:\n                            framed_msg = salt.transport.frame.decode_embedded_strs(\n                                framed_msg\n                            )\n                        header = framed_msg['head']\n                        body = framed_msg['body']\n                        message_id = header.get('mid')\n\n                        if message_id in self.send_future_map:\n                            self.send_future_map.pop(message_id).set_result(body)\n                            self.remove_message_timeout(message_id)\n                        else:\n                            if self._on_recv is not None:\n                                self.io_loop.spawn_callback(self._on_recv, header, body)\n                            else:\n                                log.error('Got response for message_id {0} that we are not tracking'.format(message_id))\n                except tornado.iostream.StreamClosedError as e:\n                    log.debug('tcp stream to {0}:{1} closed, unable to recv'.format(self.host, self.port))\n                    for future in six.itervalues(self.send_future_map):\n                        future.set_exception(e)\n                    self.send_future_map = {}\n                    if self._closing:\n                        return\n                    if self.disconnect_callback:\n                        self.disconnect_callback()\n                    # if the last connect finished, then we need to make a new one\n                    if self._connecting_future.done():\n                        self._connecting_future = self.connect()\n                    yield self._connecting_future\n                except TypeError:\n                    # This is an invalid transport\n                    if 'detect_mode' in self.opts:\n                        log.info('There was an error trying to use TCP transport; '\n                                 'attempting to fallback to another transport')\n                    else:\n                        raise SaltClientError\n                except Exception as e:\n                    log.error('Exception parsing response', exc_info=True)\n                    for future in six.itervalues(self.send_future_map):\n                        future.set_exception(e)\n                    self.send_future_map = {}\n                    if self._closing:\n                        return\n                    if self.disconnect_callback:\n                        self.disconnect_callback()\n                    # if the last connect finished, then we need to make a new one\n                    if self._connecting_future.done():\n                        self._connecting_future = self.connect()\n                    yield self._connecting_future\n        finally:\n            self._stream_return_future.set_result(True)\n\n    @tornado.gen.coroutine\n    def _stream_send(self):\n        while not self._connecting_future.done() or self._connecting_future.result() is not True:\n            yield self._connecting_future\n        while len(self.send_queue) > 0:\n            message_id, item = self.send_queue[0]\n            try:\n                yield self._stream.write(item)\n                del self.send_queue[0]\n            # if the connection is dead, lets fail this send, and make sure we\n            # attempt to reconnect\n            except tornado.iostream.StreamClosedError as e:\n                if message_id in self.send_future_map:\n                    self.send_future_map.pop(message_id).set_exception(e)\n                self.remove_message_timeout(message_id)\n                del self.send_queue[0]\n                if self._closing:\n                    return\n                if self.disconnect_callback:\n                    self.disconnect_callback()\n                # if the last connect finished, then we need to make a new one\n                if self._connecting_future.done():\n                    self._connecting_future = self.connect()\n                yield self._connecting_future\n\n    def _message_id(self):\n        wrap = False\n        while self._mid in self.send_future_map:\n            if self._mid >= self._max_messages:\n                if wrap:\n                    # this shouldn't ever happen, but just in case\n                    raise Exception('Unable to find available messageid')\n                self._mid = 1\n                wrap = True\n            else:\n                self._mid += 1\n\n        return self._mid\n\n    # TODO: return a message object which takes care of multiplexing?\n    def on_recv(self, callback):\n        '''\n        Register a callback for received messages (that we didn't initiate)\n        '''\n        if callback is None:\n            self._on_recv = callback\n        else:\n            def wrap_recv(header, body):\n                callback(body)\n            self._on_recv = wrap_recv\n\n    def remove_message_timeout(self, message_id):\n        if message_id not in self.send_timeout_map:\n            return\n        timeout = self.send_timeout_map.pop(message_id)\n        self.io_loop.remove_timeout(timeout)\n\n    def timeout_message(self, message_id):\n        if message_id in self.send_timeout_map:\n            del self.send_timeout_map[message_id]\n        if message_id in self.send_future_map:\n            self.send_future_map.pop(message_id).set_exception(\n                SaltReqTimeoutError('Message timed out')\n            )\n\n    def send(self, msg, timeout=None, callback=None, raw=False):\n        '''\n        Send given message, and return a future\n        '''\n        message_id = self._message_id()\n        header = {'mid': message_id}\n\n        future = tornado.concurrent.Future()\n        if callback is not None:\n            def handle_future(future):\n                response = future.result()\n                self.io_loop.add_callback(callback, response)\n            future.add_done_callback(handle_future)\n        # Add this future to the mapping\n        self.send_future_map[message_id] = future\n\n        if self.opts.get('detect_mode') is True:\n            timeout = 1\n\n        if timeout is not None:\n            send_timeout = self.io_loop.call_later(timeout, self.timeout_message, message_id)\n            self.send_timeout_map[message_id] = send_timeout\n\n        # if we don't have a send queue, we need to spawn the callback to do the sending\n        if len(self.send_queue) == 0:\n            self.io_loop.spawn_callback(self._stream_send)\n        self.send_queue.append((message_id, salt.transport.frame.frame_msg(msg, header=header)))\n        return future\n\n\nclass Subscriber(object):\n    '''\n    Client object for use with the TCP publisher server\n    '''\n    def __init__(self, stream, address):\n        self.stream = stream\n        self.address = address\n        self._closing = False\n        self._read_until_future = None\n        self.id_ = None\n\n    def close(self):\n        if self._closing:\n            return\n        self._closing = True\n        if not self.stream.closed():\n            self.stream.close()\n            if self._read_until_future is not None:\n                # This will prevent this message from showing up:\n                # '[ERROR   ] Future exception was never retrieved:\n                # StreamClosedError'\n                # This happens because the logic is always waiting to read\n                # the next message and the associated read future is marked\n                # 'StreamClosedError' when the stream is closed.\n                self._read_until_future.exc_info()\n\n    def __del__(self):\n        self.close()\n\n\nclass PubServer(tornado.tcpserver.TCPServer, object):\n    '''\n    TCP publisher\n    '''\n    def __init__(self, opts, io_loop=None):\n        super(PubServer, self).__init__(io_loop=io_loop, ssl_options=opts.get('ssl'))\n        self.opts = opts\n        self._closing = False\n        self.clients = set()\n        self.aes_funcs = salt.master.AESFuncs(self.opts)\n        self.present = {}\n        self.presence_events = False\n        if self.opts.get('presence_events', False):\n            tcp_only = True\n            for transport, _ in iter_transport_opts(self.opts):\n                if transport != 'tcp':\n                    tcp_only = False\n            if tcp_only:\n                # Only when the transport is TCP only, the presence events will\n                # be handled here. Otherwise, it will be handled in the\n                # 'Maintenance' process.\n                self.presence_events = True\n\n        if self.presence_events:\n            self.event = salt.utils.event.get_event(\n                'master',\n                opts=self.opts,\n                listen=False\n            )\n\n    def close(self):\n        if self._closing:\n            return\n        self._closing = True\n\n    def __del__(self):\n        self.close()\n\n    def _add_client_present(self, client):\n        id_ = client.id_\n        if id_ in self.present:\n            clients = self.present[id_]\n            clients.add(client)\n        else:\n            self.present[id_] = set([client])\n            if self.presence_events:\n                data = {'new': [id_],\n                        'lost': []}\n                self.event.fire_event(\n                    data,\n                    salt.utils.event.tagify('change', 'presence')\n                )\n                data = {'present': list(self.present.keys())}\n                self.event.fire_event(\n                    data,\n                    salt.utils.event.tagify('present', 'presence')\n                )\n\n    def _remove_client_present(self, client):\n        id_ = client.id_\n        if id_ is None or id_ not in self.present:\n            # This is possible if _remove_client_present() is invoked\n            # before the minion's id is validated.\n            return\n\n        clients = self.present[id_]\n        if client not in clients:\n            # Since _remove_client_present() is potentially called from\n            # _stream_read() and/or publish_payload(), it is possible for\n            # it to be called twice, in which case we will get here.\n            # This is not an abnormal case, so no logging is required.\n            return\n\n        clients.remove(client)\n        if len(clients) == 0:\n            del self.present[id_]\n            if self.presence_events:\n                data = {'new': [],\n                        'lost': [id_]}\n                self.event.fire_event(\n                    data,\n                    salt.utils.event.tagify('change', 'presence')\n                )\n                data = {'present': list(self.present.keys())}\n                self.event.fire_event(\n                    data,\n                    salt.utils.event.tagify('present', 'presence')\n                )\n\n    @tornado.gen.coroutine\n    def _stream_read(self, client):\n        unpacker = msgpack.Unpacker()\n        while not self._closing:\n            try:\n                client._read_until_future = client.stream.read_bytes(4096, partial=True)\n                wire_bytes = yield client._read_until_future\n                unpacker.feed(wire_bytes)\n                for framed_msg in unpacker:\n                    if six.PY3:\n                        framed_msg = salt.transport.frame.decode_embedded_strs(\n                            framed_msg\n                        )\n                    body = framed_msg['body']\n                    if body['enc'] != 'aes':\n                        # We only accept 'aes' encoded messages for 'id'\n                        continue\n                    crypticle = salt.crypt.Crypticle(self.opts, salt.master.SMaster.secrets['aes']['secret'].value)\n                    load = crypticle.loads(body['load'])\n                    if six.PY3:\n                        load = salt.transport.frame.decode_embedded_strs(load)\n                    if not self.aes_funcs.verify_minion(load['id'], load['tok']):\n                        continue\n                    client.id_ = load['id']\n                    self._add_client_present(client)\n            except tornado.iostream.StreamClosedError as e:\n                log.debug('tcp stream to {0} closed, unable to recv'.format(client.address))\n                client.close()\n                self._remove_client_present(client)\n                self.clients.discard(client)\n                break\n            except Exception as e:\n                log.error('Exception parsing response', exc_info=True)\n                continue\n\n    def handle_stream(self, stream, address):\n        log.trace('Subscriber at {0} connected'.format(address))\n        client = Subscriber(stream, address)\n        self.clients.add(client)\n        self.io_loop.spawn_callback(self._stream_read, client)\n\n    # TODO: ACK the publish through IPC\n    @tornado.gen.coroutine\n    def publish_payload(self, package, _):\n        log.debug('TCP PubServer sending payload: {0}'.format(package))\n        payload = salt.transport.frame.frame_msg(package['payload'])\n\n        to_remove = []\n        if 'topic_lst' in package:\n            topic_lst = package['topic_lst']\n            for topic in topic_lst:\n                if topic in self.present:\n                    # This will rarely be a list of more than 1 item. It will\n                    # be more than 1 item if the minion disconnects from the\n                    # master in an unclean manner (eg cable yank), then\n                    # restarts and the master is yet to detect the disconnect\n                    # via TCP keep-alive.\n                    for client in self.present[topic]:\n                        try:\n                            # Write the packed str\n                            f = client.stream.write(payload)\n                            self.io_loop.add_future(f, lambda f: True)\n                        except tornado.iostream.StreamClosedError:\n                            to_remove.append(client)\n                else:\n                    log.debug('Publish target {0} not connected'.format(topic))\n        else:\n            for client in self.clients:\n                try:\n                    # Write the packed str\n                    f = client.stream.write(payload)\n                    self.io_loop.add_future(f, lambda f: True)\n                except tornado.iostream.StreamClosedError:\n                    to_remove.append(client)\n        for client in to_remove:\n            log.debug('Subscriber at {0} has disconnected from publisher'.format(client.address))\n            client.close()\n            self._remove_client_present(client)\n            self.clients.discard(client)\n        log.trace('TCP PubServer finished publishing payload')\n\n\nclass TCPPubServerChannel(salt.transport.server.PubServerChannel):\n    # TODO: opts!\n    # Based on default used in tornado.netutil.bind_sockets()\n    backlog = 128\n\n    def __init__(self, opts):\n        self.opts = opts\n        self.serial = salt.payload.Serial(self.opts)  # TODO: in init?\n        self.io_loop = None\n\n    def __setstate__(self, state):\n        salt.master.SMaster.secrets = state['secrets']\n        self.__init__(state['opts'])\n\n    def __getstate__(self):\n        return {'opts': self.opts,\n                'secrets': salt.master.SMaster.secrets}\n\n    def _publish_daemon(self, log_queue=None):\n        '''\n        Bind to the interface specified in the configuration file\n        '''\n        salt.utils.appendproctitle(self.__class__.__name__)\n\n        if log_queue is not None:\n            salt.log.setup.set_multiprocessing_logging_queue(log_queue)\n        salt.log.setup.setup_multiprocessing_logging(log_queue)\n\n        # Check if io_loop was set outside\n        if self.io_loop is None:\n            self.io_loop = tornado.ioloop.IOLoop.current()\n\n        # Spin up the publisher\n        pub_server = PubServer(self.opts, io_loop=self.io_loop)\n        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n        _set_tcp_keepalive(sock, self.opts)\n        sock.setblocking(0)\n        sock.bind((self.opts['interface'], int(self.opts['publish_port'])))\n        sock.listen(self.backlog)\n        # pub_server will take ownership of the socket\n        pub_server.add_socket(sock)\n\n        # Set up Salt IPC server\n        if self.opts.get('ipc_mode', '') == 'tcp':\n            pull_uri = int(self.opts.get('tcp_master_publish_pull', 4514))\n        else:\n            pull_uri = os.path.join(self.opts['sock_dir'], 'publish_pull.ipc')\n\n        pull_sock = salt.transport.ipc.IPCMessageServer(\n            pull_uri,\n            io_loop=self.io_loop,\n            payload_handler=pub_server.publish_payload,\n        )\n\n        # Securely create socket\n        log.info('Starting the Salt Puller on {0}'.format(pull_uri))\n        old_umask = os.umask(0o177)\n        try:\n            pull_sock.start()\n        finally:\n            os.umask(old_umask)\n\n        # run forever\n        try:\n            self.io_loop.start()\n        except (KeyboardInterrupt, SystemExit):\n            salt.log.setup.shutdown_multiprocessing_logging()\n\n    def pre_fork(self, process_manager):\n        '''\n        Do anything necessary pre-fork. Since this is on the master side this will\n        primarily be used to create IPC channels and create our daemon process to\n        do the actual publishing\n        '''\n        kwargs = {}\n        if salt.utils.is_windows():\n            kwargs['log_queue'] = (\n                salt.log.setup.get_multiprocessing_logging_queue()\n            )\n\n        process_manager.add_process(self._publish_daemon, kwargs=kwargs)\n\n    def publish(self, load):\n        '''\n        Publish \"load\" to minions\n        '''\n        payload = {'enc': 'aes'}\n\n        crypticle = salt.crypt.Crypticle(self.opts, salt.master.SMaster.secrets['aes']['secret'].value)\n        payload['load'] = crypticle.dumps(load)\n        if self.opts['sign_pub_messages']:\n            master_pem_path = os.path.join(self.opts['pki_dir'], 'master.pem')\n            log.debug(\"Signing data packet\")\n            payload['sig'] = salt.crypt.sign_message(master_pem_path, payload['load'])\n        # Use the Salt IPC server\n        if self.opts.get('ipc_mode', '') == 'tcp':\n            pull_uri = int(self.opts.get('tcp_master_publish_pull', 4514))\n        else:\n            pull_uri = os.path.join(self.opts['sock_dir'], 'publish_pull.ipc')\n        # TODO: switch to the actual async interface\n        #pub_sock = salt.transport.ipc.IPCMessageClient(self.opts, io_loop=self.io_loop)\n        pub_sock = salt.utils.async.SyncWrapper(\n            salt.transport.ipc.IPCMessageClient,\n            (pull_uri,)\n        )\n        pub_sock.connect()\n\n        int_payload = {'payload': self.serial.dumps(payload)}\n\n        # add some targeting stuff for lists only (for now)\n        if load['tgt_type'] == 'list':\n            int_payload['topic_lst'] = load['tgt']\n        # Send it over IPC!\n        pub_sock.send(int_payload)\n", "target": 0}
{"idx": 964, "func": "# Based on local.py (c) 2012, Michael DeHaan <michael.dehaan@gmail.com>\n# and chroot.py     (c) 2013, Maykel Moya <mmoya@speedyrails.com>\n# and jail.py       (c) 2013, Michael Scherer <misc@zarb.org>\n# (c) 2015, Dagobert Michelsen <dam@baltic-online.de>\n# (c) 2015, Toshio Kuratomi <tkuratomi@ansible.com>\n#\n# This file is part of Ansible\n#\n# Ansible is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# Ansible is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.\nfrom __future__ import (absolute_import, division, print_function)\n__metaclass__ = type\n\nimport distutils.spawn\nimport traceback\nimport os\nimport subprocess\nfrom ansible import errors\nfrom ansible.callbacks import vvv\nimport ansible.constants as C\n\nBUFSIZE = 4096\n\nclass Connection(object):\n    ''' Local zone based connections '''\n\n    def _search_executable(self, executable):\n        cmd = distutils.spawn.find_executable(executable)\n        if not cmd:\n            raise errors.AnsibleError(\"%s command not found in PATH\") % executable\n        return cmd\n\n    def list_zones(self):\n        pipe = subprocess.Popen([self.zoneadm_cmd, 'list', '-ip'],\n                             cwd=self.runner.basedir,\n                             stdin=subprocess.PIPE,\n                             stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n\n        zones = []\n        for l in pipe.stdout.readlines():\n          # 1:work:running:/zones/work:3126dc59-9a07-4829-cde9-a816e4c5040e:native:shared\n          s = l.split(':')\n          if s[1] != 'global':\n            zones.append(s[1])\n\n        return zones\n\n    def get_zone_path(self):\n        #solaris10vm# zoneadm -z cswbuild list -p         \n        #-:cswbuild:installed:/zones/cswbuild:479f3c4b-d0c6-e97b-cd04-fd58f2c0238e:native:shared\n        pipe = subprocess.Popen([self.zoneadm_cmd, '-z', self.zone, 'list', '-p'],\n                             cwd=self.runner.basedir,\n                             stdin=subprocess.PIPE,\n                             stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n\n        #stdout, stderr = p.communicate()\n        path = pipe.stdout.readlines()[0].split(':')[3]\n        return path + '/root'\n        \n    def __init__(self, runner, host, port, *args, **kwargs):\n        self.zone = host\n        self.runner = runner\n        self.host = host\n        self.has_pipelining = False\n        self.become_methods_supported=C.BECOME_METHODS\n\n        if os.geteuid() != 0:\n            raise errors.AnsibleError(\"zone connection requires running as root\")\n\n        self.zoneadm_cmd = self._search_executable('zoneadm')\n        self.zlogin_cmd = self._search_executable('zlogin')\n        \n        if not self.zone in self.list_zones():\n            raise errors.AnsibleError(\"incorrect zone name %s\" % self.zone)\n\n\n        self.host = host\n        # port is unused, since this is local\n        self.port = port\n\n    def connect(self, port=None):\n        ''' connect to the zone; nothing to do here '''\n\n        vvv(\"THIS IS A LOCAL ZONE DIR\", host=self.zone)\n\n        return self\n\n    # a modifier\n    def _generate_cmd(self, executable, cmd):\n        if executable:\n            ### TODO: Why was \"-c\" removed from here? (vs jail.py)\n            local_cmd = [self.zlogin_cmd, self.zone, executable, cmd]\n        else:\n            local_cmd = '%s \"%s\" %s' % (self.zlogin_cmd, self.zone, cmd)\n        return local_cmd\n\n    def _buffered_exec_command(self, cmd, tmp_path, become_user=None, sudoable=False, executable=None, in_data=None, stdin=subprocess.PIPE):\n        ''' run a command on the zone.  This is only needed for implementing\n        put_file() get_file() so that we don't have to read the whole file\n        into memory.\n\n        compared to exec_command() it looses some niceties like being able to\n        return the process's exit code immediately.\n        '''\n\n        if sudoable and self.runner.become and self.runner.become_method not in self.become_methods_supported:\n            raise errors.AnsibleError(\"Internal Error: this module does not support running commands via %s\" % self.runner.become_method)\n\n        if in_data:\n            raise errors.AnsibleError(\"Internal Error: this module does not support optimized module pipelining\")\n\n        # We happily ignore privilege escalation\n        local_cmd = self._generate_cmd(executable, cmd)\n\n        vvv(\"EXEC %s\" % (local_cmd), host=self.zone)\n        p = subprocess.Popen(local_cmd, shell=isinstance(local_cmd, basestring),\n                             cwd=self.runner.basedir,\n                             stdin=stdin,\n                             stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n\n        return p\n\n    def exec_command(self, cmd, tmp_path, become_user=None, sudoable=False, executable=None, in_data=None):\n        ''' run a command on the zone '''\n\n        ### TODO: Why all the precautions not to specify /bin/sh? (vs jail.py)\n        if executable == '/bin/sh':\n          executable = None\n\n        p = self._buffered_exec_command(cmd, tmp_path, become_user, sudoable, executable, in_data)\n\n        stdout, stderr = p.communicate()\n        return (p.returncode, '', stdout, stderr)\n\n    def put_file(self, in_path, out_path):\n        ''' transfer a file from local to zone '''\n\n        vvv(\"PUT %s TO %s\" % (in_path, out_path), host=self.zone)\n\n        with open(in_path, 'rb') as in_file:\n            p = self._buffered_exec_command('dd of=%s' % out_path, None, stdin=in_file)\n            try:\n                stdout, stderr = p.communicate()\n            except:\n                traceback.print_exc()\n                raise errors.AnsibleError(\"failed to transfer file to %s\" % out_path)\n            if p.returncode != 0:\n                raise errors.AnsibleError(\"failed to transfer file to %s:\\n%s\\n%s\" % (out_path, stdout, stderr))\n\n    def fetch_file(self, in_path, out_path):\n        ''' fetch a file from zone to local '''\n\n        vvv(\"FETCH %s TO %s\" % (in_path, out_path), host=self.zone)\n\n\n        p = self._buffered_exec_command('dd if=%s bs=%s' % (in_path, BUFSIZE), None)\n\n        with open(out_path, 'wb+') as out_file:\n            try:\n                for chunk in p.stdout.read(BUFSIZE):\n                    out_file.write(chunk)\n            except:\n                traceback.print_exc()\n                raise errors.AnsibleError(\"failed to transfer file to %s\" % out_path)\n            stdout, stderr = p.communicate()\n            if p.returncode != 0:\n                raise errors.AnsibleError(\"failed to transfer file to %s:\\n%s\\n%s\" % (out_path, stdout, stderr))\n\n    def close(self):\n        ''' terminate the connection; nothing to do here '''\n        pass\n", "target": 0}
{"idx": 965, "func": "# vim: ft=python fileencoding=utf-8 sts=4 sw=4 et:\n\n# Copyright 2016-2018 Florian Bruhin (The Compiler) <mail@qutebrowser.org>\n#\n# This file is part of qutebrowser.\n#\n# qutebrowser is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# qutebrowser is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with qutebrowser.  If not, see <http://www.gnu.org/licenses/>.\n\n\"\"\"Base class for a wrapper over QWebView/QWebEngineView.\"\"\"\n\nimport enum\nimport itertools\n\nimport attr\nfrom PyQt5.QtCore import pyqtSignal, pyqtSlot, QUrl, QObject, QSizeF, Qt\nfrom PyQt5.QtGui import QIcon\nfrom PyQt5.QtWidgets import QWidget, QApplication, QDialog\nfrom PyQt5.QtPrintSupport import QPrintDialog\n\nimport pygments\nimport pygments.lexers\nimport pygments.formatters\n\nfrom qutebrowser.keyinput import modeman\nfrom qutebrowser.config import config\nfrom qutebrowser.utils import (utils, objreg, usertypes, log, qtutils,\n                               urlutils, message)\nfrom qutebrowser.misc import miscwidgets, objects\nfrom qutebrowser.browser import mouse, hints\nfrom qutebrowser.qt import sip\n\n\ntab_id_gen = itertools.count(0)\n\n\ndef create(win_id, private, parent=None):\n    \"\"\"Get a QtWebKit/QtWebEngine tab object.\n\n    Args:\n        win_id: The window ID where the tab will be shown.\n        private: Whether the tab is a private/off the record tab.\n        parent: The Qt parent to set.\n    \"\"\"\n    # Importing modules here so we don't depend on QtWebEngine without the\n    # argument and to avoid circular imports.\n    mode_manager = modeman.instance(win_id)\n    if objects.backend == usertypes.Backend.QtWebEngine:\n        from qutebrowser.browser.webengine import webenginetab\n        tab_class = webenginetab.WebEngineTab\n    else:\n        from qutebrowser.browser.webkit import webkittab\n        tab_class = webkittab.WebKitTab\n    return tab_class(win_id=win_id, mode_manager=mode_manager, private=private,\n                     parent=parent)\n\n\ndef init():\n    \"\"\"Initialize backend-specific modules.\"\"\"\n    if objects.backend == usertypes.Backend.QtWebEngine:\n        from qutebrowser.browser.webengine import webenginetab\n        webenginetab.init()\n\n\nclass WebTabError(Exception):\n\n    \"\"\"Base class for various errors.\"\"\"\n\n\nclass UnsupportedOperationError(WebTabError):\n\n    \"\"\"Raised when an operation is not supported with the given backend.\"\"\"\n\n\nTerminationStatus = enum.Enum('TerminationStatus', [\n    'normal',\n    'abnormal',  # non-zero exit status\n    'crashed',   # e.g. segfault\n    'killed',\n    'unknown',\n])\n\n\n@attr.s\nclass TabData:\n\n    \"\"\"A simple namespace with a fixed set of attributes.\n\n    Attributes:\n        keep_icon: Whether the (e.g. cloned) icon should not be cleared on page\n                   load.\n        inspector: The QWebInspector used for this webview.\n        viewing_source: Set if we're currently showing a source view.\n                        Only used when sources are shown via pygments.\n        open_target: Where to open the next link.\n                     Only used for QtWebKit.\n        override_target: Override for open_target for fake clicks (like hints).\n                         Only used for QtWebKit.\n        pinned: Flag to pin the tab.\n        fullscreen: Whether the tab has a video shown fullscreen currently.\n        netrc_used: Whether netrc authentication was performed.\n        input_mode: current input mode for the tab.\n    \"\"\"\n\n    keep_icon = attr.ib(False)\n    viewing_source = attr.ib(False)\n    inspector = attr.ib(None)\n    open_target = attr.ib(usertypes.ClickTarget.normal)\n    override_target = attr.ib(None)\n    pinned = attr.ib(False)\n    fullscreen = attr.ib(False)\n    netrc_used = attr.ib(False)\n    input_mode = attr.ib(usertypes.KeyMode.normal)\n\n    def should_show_icon(self):\n        return (config.val.tabs.favicons.show == 'always' or\n                config.val.tabs.favicons.show == 'pinned' and self.pinned)\n\n\nclass AbstractAction:\n\n    \"\"\"Attribute of AbstractTab for Qt WebActions.\n\n    Class attributes (overridden by subclasses):\n        action_class: The class actions are defined on (QWeb{Engine,}Page)\n        action_base: The type of the actions (QWeb{Engine,}Page.WebAction)\n    \"\"\"\n\n    action_class = None\n    action_base = None\n\n    def __init__(self, tab):\n        self._widget = None\n        self._tab = tab\n\n    def exit_fullscreen(self):\n        \"\"\"Exit the fullscreen mode.\"\"\"\n        raise NotImplementedError\n\n    def save_page(self):\n        \"\"\"Save the current page.\"\"\"\n        raise NotImplementedError\n\n    def run_string(self, name):\n        \"\"\"Run a webaction based on its name.\"\"\"\n        member = getattr(self.action_class, name, None)\n        if not isinstance(member, self.action_base):\n            raise WebTabError(\"{} is not a valid web action!\".format(name))\n        self._widget.triggerPageAction(member)\n\n    def show_source(self,\n                    pygments=False):  # pylint: disable=redefined-outer-name\n        \"\"\"Show the source of the current page in a new tab.\"\"\"\n        raise NotImplementedError\n\n    def _show_source_pygments(self):\n\n        def show_source_cb(source):\n            \"\"\"Show source as soon as it's ready.\"\"\"\n            # WORKAROUND for https://github.com/PyCQA/pylint/issues/491\n            # pylint: disable=no-member\n            lexer = pygments.lexers.HtmlLexer()\n            formatter = pygments.formatters.HtmlFormatter(\n                full=True, linenos='table')\n            # pylint: enable=no-member\n            highlighted = pygments.highlight(source, lexer, formatter)\n\n            tb = objreg.get('tabbed-browser', scope='window',\n                            window=self._tab.win_id)\n            new_tab = tb.tabopen(background=False, related=True)\n            new_tab.set_html(highlighted, self._tab.url())\n            new_tab.data.viewing_source = True\n\n        self._tab.dump_async(show_source_cb)\n\n\nclass AbstractPrinting:\n\n    \"\"\"Attribute of AbstractTab for printing the page.\"\"\"\n\n    def __init__(self, tab):\n        self._widget = None\n        self._tab = tab\n\n    def check_pdf_support(self):\n        raise NotImplementedError\n\n    def check_printer_support(self):\n        raise NotImplementedError\n\n    def check_preview_support(self):\n        raise NotImplementedError\n\n    def to_pdf(self, filename):\n        raise NotImplementedError\n\n    def to_printer(self, printer, callback=None):\n        \"\"\"Print the tab.\n\n        Args:\n            printer: The QPrinter to print to.\n            callback: Called with a boolean\n                      (True if printing succeeded, False otherwise)\n        \"\"\"\n        raise NotImplementedError\n\n    def show_dialog(self):\n        \"\"\"Print with a QPrintDialog.\"\"\"\n        self.check_printer_support()\n\n        def print_callback(ok):\n            \"\"\"Called when printing finished.\"\"\"\n            if not ok:\n                message.error(\"Printing failed!\")\n            diag.deleteLater()\n\n        def do_print():\n            \"\"\"Called when the dialog was closed.\"\"\"\n            self.to_printer(diag.printer(), print_callback)\n\n        diag = QPrintDialog(self._tab)\n        if utils.is_mac:\n            # For some reason we get a segfault when using open() on macOS\n            ret = diag.exec_()\n            if ret == QDialog.Accepted:\n                do_print()\n        else:\n            diag.open(do_print)\n\n\nclass AbstractSearch(QObject):\n\n    \"\"\"Attribute of AbstractTab for doing searches.\n\n    Attributes:\n        text: The last thing this view was searched for.\n        search_displayed: Whether we're currently displaying search results in\n                          this view.\n        _flags: The flags of the last search (needs to be set by subclasses).\n        _widget: The underlying WebView widget.\n    \"\"\"\n\n    def __init__(self, parent=None):\n        super().__init__(parent)\n        self._widget = None\n        self.text = None\n        self.search_displayed = False\n\n    def _is_case_sensitive(self, ignore_case):\n        \"\"\"Check if case-sensitivity should be used.\n\n        This assumes self.text is already set properly.\n\n        Arguments:\n            ignore_case: The ignore_case value from the config.\n        \"\"\"\n        mapping = {\n            'smart': not self.text.islower(),\n            'never': True,\n            'always': False,\n        }\n        return mapping[ignore_case]\n\n    def search(self, text, *, ignore_case='never', reverse=False,\n               result_cb=None):\n        \"\"\"Find the given text on the page.\n\n        Args:\n            text: The text to search for.\n            ignore_case: Search case-insensitively. ('always'/'never/'smart')\n            reverse: Reverse search direction.\n            result_cb: Called with a bool indicating whether a match was found.\n        \"\"\"\n        raise NotImplementedError\n\n    def clear(self):\n        \"\"\"Clear the current search.\"\"\"\n        raise NotImplementedError\n\n    def prev_result(self, *, result_cb=None):\n        \"\"\"Go to the previous result of the current search.\n\n        Args:\n            result_cb: Called with a bool indicating whether a match was found.\n        \"\"\"\n        raise NotImplementedError\n\n    def next_result(self, *, result_cb=None):\n        \"\"\"Go to the next result of the current search.\n\n        Args:\n            result_cb: Called with a bool indicating whether a match was found.\n        \"\"\"\n        raise NotImplementedError\n\n\nclass AbstractZoom(QObject):\n\n    \"\"\"Attribute of AbstractTab for controlling zoom.\n\n    Attributes:\n        _neighborlist: A NeighborList with the zoom levels.\n        _default_zoom_changed: Whether the zoom was changed from the default.\n    \"\"\"\n\n    def __init__(self, tab, parent=None):\n        super().__init__(parent)\n        self._tab = tab\n        self._widget = None\n        self._default_zoom_changed = False\n        self._init_neighborlist()\n        config.instance.changed.connect(self._on_config_changed)\n        self._zoom_factor = float(config.val.zoom.default) / 100\n\n        # # FIXME:qtwebengine is this needed?\n        # # For some reason, this signal doesn't get disconnected automatically\n        # # when the WebView is destroyed on older PyQt versions.\n        # # See https://github.com/qutebrowser/qutebrowser/issues/390\n        # self.destroyed.connect(functools.partial(\n        #     cfg.changed.disconnect, self.init_neighborlist))\n\n    @pyqtSlot(str)\n    def _on_config_changed(self, option):\n        if option in ['zoom.levels', 'zoom.default']:\n            if not self._default_zoom_changed:\n                factor = float(config.val.zoom.default) / 100\n                self.set_factor(factor)\n            self._init_neighborlist()\n\n    def _init_neighborlist(self):\n        \"\"\"Initialize self._neighborlist.\"\"\"\n        levels = config.val.zoom.levels\n        self._neighborlist = usertypes.NeighborList(\n            levels, mode=usertypes.NeighborList.Modes.edge)\n        self._neighborlist.fuzzyval = config.val.zoom.default\n\n    def offset(self, offset):\n        \"\"\"Increase/Decrease the zoom level by the given offset.\n\n        Args:\n            offset: The offset in the zoom level list.\n\n        Return:\n            The new zoom percentage.\n        \"\"\"\n        level = self._neighborlist.getitem(offset)\n        self.set_factor(float(level) / 100, fuzzyval=False)\n        return level\n\n    def _set_factor_internal(self, factor):\n        raise NotImplementedError\n\n    def set_factor(self, factor, *, fuzzyval=True):\n        \"\"\"Zoom to a given zoom factor.\n\n        Args:\n            factor: The zoom factor as float.\n            fuzzyval: Whether to set the NeighborLists fuzzyval.\n        \"\"\"\n        if fuzzyval:\n            self._neighborlist.fuzzyval = int(factor * 100)\n        if factor < 0:\n            raise ValueError(\"Can't zoom to factor {}!\".format(factor))\n\n        default_zoom_factor = float(config.val.zoom.default) / 100\n        self._default_zoom_changed = (factor != default_zoom_factor)\n\n        self._zoom_factor = factor\n        self._set_factor_internal(factor)\n\n    def factor(self):\n        return self._zoom_factor\n\n    def set_default(self):\n        self._set_factor_internal(float(config.val.zoom.default) / 100)\n\n    def set_current(self):\n        self._set_factor_internal(self._zoom_factor)\n\n\nclass AbstractCaret(QObject):\n\n    \"\"\"Attribute of AbstractTab for caret browsing.\n\n    Signals:\n        selection_toggled: Emitted when the selection was toggled.\n                           arg: Whether the selection is now active.\n    \"\"\"\n\n    selection_toggled = pyqtSignal(bool)\n\n    def __init__(self, tab, mode_manager, parent=None):\n        super().__init__(parent)\n        self._tab = tab\n        self._widget = None\n        self.selection_enabled = False\n        mode_manager.entered.connect(self._on_mode_entered)\n        mode_manager.left.connect(self._on_mode_left)\n\n    def _on_mode_entered(self, mode):\n        raise NotImplementedError\n\n    def _on_mode_left(self, mode):\n        raise NotImplementedError\n\n    def move_to_next_line(self, count=1):\n        raise NotImplementedError\n\n    def move_to_prev_line(self, count=1):\n        raise NotImplementedError\n\n    def move_to_next_char(self, count=1):\n        raise NotImplementedError\n\n    def move_to_prev_char(self, count=1):\n        raise NotImplementedError\n\n    def move_to_end_of_word(self, count=1):\n        raise NotImplementedError\n\n    def move_to_next_word(self, count=1):\n        raise NotImplementedError\n\n    def move_to_prev_word(self, count=1):\n        raise NotImplementedError\n\n    def move_to_start_of_line(self):\n        raise NotImplementedError\n\n    def move_to_end_of_line(self):\n        raise NotImplementedError\n\n    def move_to_start_of_next_block(self, count=1):\n        raise NotImplementedError\n\n    def move_to_start_of_prev_block(self, count=1):\n        raise NotImplementedError\n\n    def move_to_end_of_next_block(self, count=1):\n        raise NotImplementedError\n\n    def move_to_end_of_prev_block(self, count=1):\n        raise NotImplementedError\n\n    def move_to_start_of_document(self):\n        raise NotImplementedError\n\n    def move_to_end_of_document(self):\n        raise NotImplementedError\n\n    def toggle_selection(self):\n        raise NotImplementedError\n\n    def drop_selection(self):\n        raise NotImplementedError\n\n    def selection(self, callback):\n        raise NotImplementedError\n\n    def _follow_enter(self, tab):\n        \"\"\"Follow a link by faking an enter press.\"\"\"\n        if tab:\n            self._tab.key_press(Qt.Key_Enter, modifier=Qt.ControlModifier)\n        else:\n            self._tab.key_press(Qt.Key_Enter)\n\n    def follow_selected(self, *, tab=False):\n        raise NotImplementedError\n\n\nclass AbstractScroller(QObject):\n\n    \"\"\"Attribute of AbstractTab to manage scroll position.\"\"\"\n\n    perc_changed = pyqtSignal(int, int)\n\n    def __init__(self, tab, parent=None):\n        super().__init__(parent)\n        self._tab = tab\n        self._widget = None\n        self.perc_changed.connect(self._log_scroll_pos_change)\n\n    @pyqtSlot()\n    def _log_scroll_pos_change(self):\n        log.webview.vdebug(\"Scroll position changed to {}\".format(\n            self.pos_px()))\n\n    def _init_widget(self, widget):\n        self._widget = widget\n\n    def pos_px(self):\n        raise NotImplementedError\n\n    def pos_perc(self):\n        raise NotImplementedError\n\n    def to_perc(self, x=None, y=None):\n        raise NotImplementedError\n\n    def to_point(self, point):\n        raise NotImplementedError\n\n    def to_anchor(self, name):\n        raise NotImplementedError\n\n    def delta(self, x=0, y=0):\n        raise NotImplementedError\n\n    def delta_page(self, x=0, y=0):\n        raise NotImplementedError\n\n    def up(self, count=1):\n        raise NotImplementedError\n\n    def down(self, count=1):\n        raise NotImplementedError\n\n    def left(self, count=1):\n        raise NotImplementedError\n\n    def right(self, count=1):\n        raise NotImplementedError\n\n    def top(self):\n        raise NotImplementedError\n\n    def bottom(self):\n        raise NotImplementedError\n\n    def page_up(self, count=1):\n        raise NotImplementedError\n\n    def page_down(self, count=1):\n        raise NotImplementedError\n\n    def at_top(self):\n        raise NotImplementedError\n\n    def at_bottom(self):\n        raise NotImplementedError\n\n\nclass AbstractHistory:\n\n    \"\"\"The history attribute of a AbstractTab.\"\"\"\n\n    def __init__(self, tab):\n        self._tab = tab\n        self._history = None\n\n    def __len__(self):\n        return len(self._history)\n\n    def __iter__(self):\n        return iter(self._history.items())\n\n    def current_idx(self):\n        raise NotImplementedError\n\n    def back(self, count=1):\n        \"\"\"Go back in the tab's history.\"\"\"\n        idx = self.current_idx() - count\n        if idx >= 0:\n            self._go_to_item(self._item_at(idx))\n        else:\n            self._go_to_item(self._item_at(0))\n            raise WebTabError(\"At beginning of history.\")\n\n    def forward(self, count=1):\n        \"\"\"Go forward in the tab's history.\"\"\"\n        idx = self.current_idx() + count\n        if idx < len(self):\n            self._go_to_item(self._item_at(idx))\n        else:\n            self._go_to_item(self._item_at(len(self) - 1))\n            raise WebTabError(\"At end of history.\")\n\n    def can_go_back(self):\n        raise NotImplementedError\n\n    def can_go_forward(self):\n        raise NotImplementedError\n\n    def _item_at(self, i):\n        raise NotImplementedError\n\n    def _go_to_item(self, item):\n        raise NotImplementedError\n\n    def serialize(self):\n        \"\"\"Serialize into an opaque format understood by self.deserialize.\"\"\"\n        raise NotImplementedError\n\n    def deserialize(self, data):\n        \"\"\"Serialize from a format produced by self.serialize.\"\"\"\n        raise NotImplementedError\n\n    def load_items(self, items):\n        \"\"\"Deserialize from a list of WebHistoryItems.\"\"\"\n        raise NotImplementedError\n\n\nclass AbstractElements:\n\n    \"\"\"Finding and handling of elements on the page.\"\"\"\n\n    def __init__(self, tab):\n        self._widget = None\n        self._tab = tab\n\n    def find_css(self, selector, callback, *, only_visible=False):\n        \"\"\"Find all HTML elements matching a given selector async.\n\n        Args:\n            callback: The callback to be called when the search finished.\n            selector: The CSS selector to search for.\n            only_visible: Only show elements which are visible on screen.\n        \"\"\"\n        raise NotImplementedError\n\n    def find_id(self, elem_id, callback):\n        \"\"\"Find the HTML element with the given ID async.\n\n        Args:\n            callback: The callback to be called when the search finished.\n            elem_id: The ID to search for.\n        \"\"\"\n        raise NotImplementedError\n\n    def find_focused(self, callback):\n        \"\"\"Find the focused element on the page async.\n\n        Args:\n            callback: The callback to be called when the search finished.\n                      Called with a WebEngineElement or None.\n        \"\"\"\n        raise NotImplementedError\n\n    def find_at_pos(self, pos, callback):\n        \"\"\"Find the element at the given position async.\n\n        This is also called \"hit test\" elsewhere.\n\n        Args:\n            pos: The QPoint to get the element for.\n            callback: The callback to be called when the search finished.\n                      Called with a WebEngineElement or None.\n        \"\"\"\n        raise NotImplementedError\n\n\nclass AbstractAudio(QObject):\n\n    \"\"\"Handling of audio/muting for this tab.\"\"\"\n\n    muted_changed = pyqtSignal(bool)\n    recently_audible_changed = pyqtSignal(bool)\n\n    def __init__(self, parent=None):\n        super().__init__(parent)\n        self._widget = None\n\n    def set_muted(self, muted: bool):\n        \"\"\"Set this tab as muted or not.\"\"\"\n        raise NotImplementedError\n\n    def is_muted(self):\n        \"\"\"Whether this tab is muted.\"\"\"\n        raise NotImplementedError\n\n    def toggle_muted(self):\n        self.set_muted(not self.is_muted())\n\n    def is_recently_audible(self):\n        \"\"\"Whether this tab has had audio playing recently.\"\"\"\n        raise NotImplementedError\n\n\nclass AbstractTab(QWidget):\n\n    \"\"\"A wrapper over the given widget to hide its API and expose another one.\n\n    We use this to unify QWebView and QWebEngineView.\n\n    Attributes:\n        history: The AbstractHistory for the current tab.\n        registry: The ObjectRegistry associated with this tab.\n        private: Whether private browsing is turned on for this tab.\n\n        _load_status: loading status of this page\n                      Accessible via load_status() method.\n        _has_ssl_errors: Whether SSL errors happened.\n                         Needs to be set by subclasses.\n\n        for properties, see WebView/WebEngineView docs.\n\n    Signals:\n        See related Qt signals.\n\n        new_tab_requested: Emitted when a new tab should be opened with the\n                           given URL.\n        load_status_changed: The loading status changed\n        fullscreen_requested: Fullscreen display was requested by the page.\n                              arg: True if fullscreen should be turned on,\n                                   False if it should be turned off.\n        renderer_process_terminated: Emitted when the underlying renderer\n                                     process terminated.\n                                     arg 0: A TerminationStatus member.\n                                     arg 1: The exit code.\n        predicted_navigation: Emitted before we tell Qt to open a URL.\n    \"\"\"\n\n    window_close_requested = pyqtSignal()\n    link_hovered = pyqtSignal(str)\n    load_started = pyqtSignal()\n    load_progress = pyqtSignal(int)\n    load_finished = pyqtSignal(bool)\n    icon_changed = pyqtSignal(QIcon)\n    title_changed = pyqtSignal(str)\n    load_status_changed = pyqtSignal(str)\n    new_tab_requested = pyqtSignal(QUrl)\n    url_changed = pyqtSignal(QUrl)\n    shutting_down = pyqtSignal()\n    contents_size_changed = pyqtSignal(QSizeF)\n    add_history_item = pyqtSignal(QUrl, QUrl, str)  # url, requested url, title\n    fullscreen_requested = pyqtSignal(bool)\n    renderer_process_terminated = pyqtSignal(TerminationStatus, int)\n    predicted_navigation = pyqtSignal(QUrl)\n\n    def __init__(self, *, win_id, mode_manager, private, parent=None):\n        self.private = private\n        self.win_id = win_id\n        self.tab_id = next(tab_id_gen)\n        super().__init__(parent)\n\n        self.registry = objreg.ObjectRegistry()\n        tab_registry = objreg.get('tab-registry', scope='window',\n                                  window=win_id)\n        tab_registry[self.tab_id] = self\n        objreg.register('tab', self, registry=self.registry)\n\n        self.data = TabData()\n        self._layout = miscwidgets.WrapperLayout(self)\n        self._widget = None\n        self._progress = 0\n        self._has_ssl_errors = False\n        self._mode_manager = mode_manager\n        self._load_status = usertypes.LoadStatus.none\n        self._mouse_event_filter = mouse.MouseEventFilter(\n            self, parent=self)\n        self.backend = None\n\n        # FIXME:qtwebengine  Should this be public api via self.hints?\n        #                    Also, should we get it out of objreg?\n        hintmanager = hints.HintManager(win_id, self.tab_id, parent=self)\n        objreg.register('hintmanager', hintmanager, scope='tab',\n                        window=self.win_id, tab=self.tab_id)\n\n        self.predicted_navigation.connect(self._on_predicted_navigation)\n\n    def _set_widget(self, widget):\n        # pylint: disable=protected-access\n        self._widget = widget\n        self._layout.wrap(self, widget)\n        self.history._history = widget.history()\n        self.scroller._init_widget(widget)\n        self.caret._widget = widget\n        self.zoom._widget = widget\n        self.search._widget = widget\n        self.printing._widget = widget\n        self.action._widget = widget\n        self.elements._widget = widget\n        self.audio._widget = widget\n        self.settings._settings = widget.settings()\n\n        self._install_event_filter()\n        self.zoom.set_default()\n\n    def _install_event_filter(self):\n        raise NotImplementedError\n\n    def _set_load_status(self, val):\n        \"\"\"Setter for load_status.\"\"\"\n        if not isinstance(val, usertypes.LoadStatus):\n            raise TypeError(\"Type {} is no LoadStatus member!\".format(val))\n        log.webview.debug(\"load status for {}: {}\".format(repr(self), val))\n        self._load_status = val\n        self.load_status_changed.emit(val.name)\n\n    def event_target(self):\n        \"\"\"Return the widget events should be sent to.\"\"\"\n        raise NotImplementedError\n\n    def send_event(self, evt):\n        \"\"\"Send the given event to the underlying widget.\n\n        The event will be sent via QApplication.postEvent.\n        Note that a posted event may not be re-used in any way!\n        \"\"\"\n        # This only gives us some mild protection against re-using events, but\n        # it's certainly better than a segfault.\n        if getattr(evt, 'posted', False):\n            raise utils.Unreachable(\"Can't re-use an event which was already \"\n                                    \"posted!\")\n\n        recipient = self.event_target()\n        if recipient is None:\n            # https://github.com/qutebrowser/qutebrowser/issues/3888\n            log.webview.warning(\"Unable to find event target!\")\n            return\n\n        evt.posted = True\n        QApplication.postEvent(recipient, evt)\n\n    @pyqtSlot(QUrl)\n    def _on_predicted_navigation(self, url):\n        \"\"\"Adjust the title if we are going to visit an URL soon.\"\"\"\n        qtutils.ensure_valid(url)\n        url_string = url.toDisplayString()\n        log.webview.debug(\"Predicted navigation: {}\".format(url_string))\n        self.title_changed.emit(url_string)\n\n    @pyqtSlot(QUrl)\n    def _on_url_changed(self, url):\n        \"\"\"Update title when URL has changed and no title is available.\"\"\"\n        if url.isValid() and not self.title():\n            self.title_changed.emit(url.toDisplayString())\n        self.url_changed.emit(url)\n\n    @pyqtSlot()\n    def _on_load_started(self):\n        self._progress = 0\n        self._has_ssl_errors = False\n        self.data.viewing_source = False\n        self._set_load_status(usertypes.LoadStatus.loading)\n        self.load_started.emit()\n\n    @pyqtSlot(usertypes.NavigationRequest)\n    def _on_navigation_request(self, navigation):\n        \"\"\"Handle common acceptNavigationRequest code.\"\"\"\n        url = utils.elide(navigation.url.toDisplayString(), 100)\n        log.webview.debug(\"navigation request: url {}, type {}, is_main_frame \"\n                          \"{}\".format(url,\n                                      navigation.navigation_type,\n                                      navigation.is_main_frame))\n\n        if not navigation.url.isValid():\n            # Also a WORKAROUND for missing IDNA 2008 support in QUrl, see\n            # https://bugreports.qt.io/browse/QTBUG-60364\n\n            if navigation.navigation_type == navigation.Type.link_clicked:\n                msg = urlutils.get_errstring(navigation.url,\n                                             \"Invalid link clicked\")\n                message.error(msg)\n                self.data.open_target = usertypes.ClickTarget.normal\n\n            log.webview.debug(\"Ignoring invalid URL {} in \"\n                              \"acceptNavigationRequest: {}\".format(\n                                  navigation.url.toDisplayString(),\n                                  navigation.url.errorString()))\n            navigation.accepted = False\n\n    def handle_auto_insert_mode(self, ok):\n        \"\"\"Handle `input.insert_mode.auto_load` after loading finished.\"\"\"\n        if not config.val.input.insert_mode.auto_load or not ok:\n            return\n\n        cur_mode = self._mode_manager.mode\n        if cur_mode == usertypes.KeyMode.insert:\n            return\n\n        def _auto_insert_mode_cb(elem):\n            \"\"\"Called from JS after finding the focused element.\"\"\"\n            if elem is None:\n                log.webview.debug(\"No focused element!\")\n                return\n            if elem.is_editable():\n                modeman.enter(self.win_id, usertypes.KeyMode.insert,\n                              'load finished', only_if_normal=True)\n\n        self.elements.find_focused(_auto_insert_mode_cb)\n\n    @pyqtSlot(bool)\n    def _on_load_finished(self, ok):\n        if sip.isdeleted(self._widget):\n            # https://github.com/qutebrowser/qutebrowser/issues/3498\n            return\n\n        sess_manager = objreg.get('session-manager')\n        sess_manager.save_autosave()\n\n        if ok and not self._has_ssl_errors:\n            if self.url().scheme() == 'https':\n                self._set_load_status(usertypes.LoadStatus.success_https)\n            else:\n                self._set_load_status(usertypes.LoadStatus.success)\n        elif ok:\n            self._set_load_status(usertypes.LoadStatus.warn)\n        else:\n            self._set_load_status(usertypes.LoadStatus.error)\n\n        self.load_finished.emit(ok)\n\n        if not self.title():\n            self.title_changed.emit(self.url().toDisplayString())\n\n        self.zoom.set_current()\n\n    @pyqtSlot()\n    def _on_history_trigger(self):\n        \"\"\"Emit add_history_item when triggered by backend-specific signal.\"\"\"\n        raise NotImplementedError\n\n    @pyqtSlot(int)\n    def _on_load_progress(self, perc):\n        self._progress = perc\n        self.load_progress.emit(perc)\n\n    def url(self, requested=False):\n        raise NotImplementedError\n\n    def progress(self):\n        return self._progress\n\n    def load_status(self):\n        return self._load_status\n\n    def _openurl_prepare(self, url, *, predict=True):\n        qtutils.ensure_valid(url)\n        if predict:\n            self.predicted_navigation.emit(url)\n\n    def openurl(self, url, *, predict=True):\n        raise NotImplementedError\n\n    def reload(self, *, force=False):\n        raise NotImplementedError\n\n    def stop(self):\n        raise NotImplementedError\n\n    def clear_ssl_errors(self):\n        raise NotImplementedError\n\n    def key_press(self, key, modifier=Qt.NoModifier):\n        \"\"\"Send a fake key event to this tab.\"\"\"\n        raise NotImplementedError\n\n    def dump_async(self, callback, *, plain=False):\n        \"\"\"Dump the current page's html asynchronously.\n\n        The given callback will be called with the result when dumping is\n        complete.\n        \"\"\"\n        raise NotImplementedError\n\n    def run_js_async(self, code, callback=None, *, world=None):\n        \"\"\"Run javascript async.\n\n        The given callback will be called with the result when running JS is\n        complete.\n\n        Args:\n            code: The javascript code to run.\n            callback: The callback to call with the result, or None.\n            world: A world ID (int or usertypes.JsWorld member) to run the JS\n                   in the main world or in another isolated world.\n        \"\"\"\n        raise NotImplementedError\n\n    def shutdown(self):\n        raise NotImplementedError\n\n    def title(self):\n        raise NotImplementedError\n\n    def icon(self):\n        raise NotImplementedError\n\n    def set_html(self, html, base_url=QUrl()):\n        raise NotImplementedError\n\n    def networkaccessmanager(self):\n        \"\"\"Get the QNetworkAccessManager for this tab.\n\n        This is only implemented for QtWebKit.\n        For QtWebEngine, always returns None.\n        \"\"\"\n        raise NotImplementedError\n\n    def user_agent(self):\n        \"\"\"Get the user agent for this tab.\n\n        This is only implemented for QtWebKit.\n        For QtWebEngine, always returns None.\n        \"\"\"\n        raise NotImplementedError\n\n    def __repr__(self):\n        try:\n            url = utils.elide(self.url().toDisplayString(QUrl.EncodeUnicode),\n                              100)\n        except (AttributeError, RuntimeError) as exc:\n            url = '<{}>'.format(exc.__class__.__name__)\n        return utils.get_repr(self, tab_id=self.tab_id, url=url)\n\n    def is_deleted(self):\n        return sip.isdeleted(self._widget)\n", "target": 1}
{"idx": 966, "func": "#!/usr/bin/python\n# -*- coding: utf-8 -*-\n\n# Copyright: (c) 2019, Felix Fontein <felix@fontein.de>\n# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)\n\nfrom __future__ import absolute_import, division, print_function\n__metaclass__ = type\n\n\nDOCUMENTATION = r'''\n---\nmodule: x509_crl\nversion_added: '1.0.0'\nshort_description: Generate Certificate Revocation Lists (CRLs)\ndescription:\n    - This module allows one to (re)generate or update Certificate Revocation Lists (CRLs).\n    - Certificates on the revocation list can be either specified via serial number and (optionally) their issuer,\n      or as a path to a certificate file in PEM format.\nrequirements:\n    - cryptography >= 1.2\nauthor:\n    - Felix Fontein (@felixfontein)\noptions:\n    state:\n        description:\n            - Whether the CRL file should exist or not, taking action if the state is different from what is stated.\n        type: str\n        default: present\n        choices: [ absent, present ]\n\n    mode:\n        description:\n            - Defines how to process entries of existing CRLs.\n            - If set to C(generate), makes sure that the CRL has the exact set of revoked certificates\n              as specified in I(revoked_certificates).\n            - If set to C(update), makes sure that the CRL contains the revoked certificates from\n              I(revoked_certificates), but can also contain other revoked certificates. If the CRL file\n              already exists, all entries from the existing CRL will also be included in the new CRL.\n              When using C(update), you might be interested in setting I(ignore_timestamps) to C(yes).\n        type: str\n        default: generate\n        choices: [ generate, update ]\n\n    force:\n        description:\n            - Should the CRL be forced to be regenerated.\n        type: bool\n        default: no\n\n    backup:\n        description:\n            - Create a backup file including a timestamp so you can get the original\n              CRL back if you overwrote it with a new one by accident.\n        type: bool\n        default: no\n\n    path:\n        description:\n            - Remote absolute path where the generated CRL file should be created or is already located.\n        type: path\n        required: yes\n\n    format:\n        description:\n            - Whether the CRL file should be in PEM or DER format.\n            - If an existing CRL file does match everything but I(format), it will be converted to the correct format\n              instead of regenerated.\n        type: str\n        choices: [pem, der]\n        default: pem\n\n    privatekey_path:\n        description:\n            - Path to the CA's private key to use when signing the CRL.\n            - Either I(privatekey_path) or I(privatekey_content) must be specified if I(state) is C(present), but not both.\n        type: path\n\n    privatekey_content:\n        description:\n            - The content of the CA's private key to use when signing the CRL.\n            - Either I(privatekey_path) or I(privatekey_content) must be specified if I(state) is C(present), but not both.\n        type: str\n\n    privatekey_passphrase:\n        description:\n            - The passphrase for the I(privatekey_path).\n            - This is required if the private key is password protected.\n        type: str\n\n    issuer:\n        description:\n            - Key/value pairs that will be present in the issuer name field of the CRL.\n            - If you need to specify more than one value with the same key, use a list as value.\n            - Required if I(state) is C(present).\n        type: dict\n\n    last_update:\n        description:\n            - The point in time from which this CRL can be trusted.\n            - Time can be specified either as relative time or as absolute timestamp.\n            - Time will always be interpreted as UTC.\n            - Valid format is C([+-]timespec | ASN.1 TIME) where timespec can be an integer\n              + C([w | d | h | m | s]) (e.g. C(+32w1d2h).\n            - Note that if using relative time this module is NOT idempotent, except when\n              I(ignore_timestamps) is set to C(yes).\n        type: str\n        default: \"+0s\"\n\n    next_update:\n        description:\n            - \"The absolute latest point in time by which this I(issuer) is expected to have issued\n               another CRL. Many clients will treat a CRL as expired once I(next_update) occurs.\"\n            - Time can be specified either as relative time or as absolute timestamp.\n            - Time will always be interpreted as UTC.\n            - Valid format is C([+-]timespec | ASN.1 TIME) where timespec can be an integer\n              + C([w | d | h | m | s]) (e.g. C(+32w1d2h).\n            - Note that if using relative time this module is NOT idempotent, except when\n              I(ignore_timestamps) is set to C(yes).\n            - Required if I(state) is C(present).\n        type: str\n\n    digest:\n        description:\n            - Digest algorithm to be used when signing the CRL.\n        type: str\n        default: sha256\n\n    revoked_certificates:\n        description:\n            - List of certificates to be revoked.\n            - Required if I(state) is C(present).\n        type: list\n        elements: dict\n        suboptions:\n            path:\n                description:\n                    - Path to a certificate in PEM format.\n                    - The serial number and issuer will be extracted from the certificate.\n                    - Mutually exclusive with I(content) and I(serial_number). One of these three options\n                      must be specified.\n                type: path\n            content:\n                description:\n                    - Content of a certificate in PEM format.\n                    - The serial number and issuer will be extracted from the certificate.\n                    - Mutually exclusive with I(path) and I(serial_number). One of these three options\n                      must be specified.\n                type: str\n            serial_number:\n                description:\n                    - Serial number of the certificate.\n                    - Mutually exclusive with I(path) and I(content). One of these three options must\n                      be specified.\n                type: int\n            revocation_date:\n                description:\n                    - The point in time the certificate was revoked.\n                    - Time can be specified either as relative time or as absolute timestamp.\n                    - Time will always be interpreted as UTC.\n                    - Valid format is C([+-]timespec | ASN.1 TIME) where timespec can be an integer\n                      + C([w | d | h | m | s]) (e.g. C(+32w1d2h).\n                    - Note that if using relative time this module is NOT idempotent, except when\n                      I(ignore_timestamps) is set to C(yes).\n                type: str\n                default: \"+0s\"\n            issuer:\n                description:\n                    - The certificate's issuer.\n                    - \"Example: C(DNS:ca.example.org)\"\n                type: list\n                elements: str\n            issuer_critical:\n                description:\n                    - Whether the certificate issuer extension should be critical.\n                type: bool\n                default: no\n            reason:\n                description:\n                    - The value for the revocation reason extension.\n                type: str\n                choices:\n                    - unspecified\n                    - key_compromise\n                    - ca_compromise\n                    - affiliation_changed\n                    - superseded\n                    - cessation_of_operation\n                    - certificate_hold\n                    - privilege_withdrawn\n                    - aa_compromise\n                    - remove_from_crl\n            reason_critical:\n                description:\n                    - Whether the revocation reason extension should be critical.\n                type: bool\n                default: no\n            invalidity_date:\n                description:\n                    - The point in time it was known/suspected that the private key was compromised\n                      or that the certificate otherwise became invalid.\n                    - Time can be specified either as relative time or as absolute timestamp.\n                    - Time will always be interpreted as UTC.\n                    - Valid format is C([+-]timespec | ASN.1 TIME) where timespec can be an integer\n                      + C([w | d | h | m | s]) (e.g. C(+32w1d2h).\n                    - Note that if using relative time this module is NOT idempotent. This will NOT\n                      change when I(ignore_timestamps) is set to C(yes).\n                type: str\n            invalidity_date_critical:\n                description:\n                    - Whether the invalidity date extension should be critical.\n                type: bool\n                default: no\n\n    ignore_timestamps:\n        description:\n            - Whether the timestamps I(last_update), I(next_update) and I(revocation_date) (in\n              I(revoked_certificates)) should be ignored for idempotency checks. The timestamp\n              I(invalidity_date) in I(revoked_certificates) will never be ignored.\n            - Use this in combination with relative timestamps for these values to get idempotency.\n        type: bool\n        default: no\n\n    return_content:\n        description:\n            - If set to C(yes), will return the (current or generated) CRL's content as I(crl).\n        type: bool\n        default: no\n\nextends_documentation_fragment:\n    - files\n\nnotes:\n    - All ASN.1 TIME values should be specified following the YYYYMMDDHHMMSSZ pattern.\n    - Date specified should be UTC. Minutes and seconds are mandatory.\n'''\n\nEXAMPLES = r'''\n- name: Generate a CRL\n  community.crypto.x509_crl:\n    path: /etc/ssl/my-ca.crl\n    privatekey_path: /etc/ssl/private/my-ca.pem\n    issuer:\n      CN: My CA\n    last_update: \"+0s\"\n    next_update: \"+7d\"\n    revoked_certificates:\n      - serial_number: 1234\n        revocation_date: 20190331202428Z\n        issuer:\n          CN: My CA\n      - serial_number: 2345\n        revocation_date: 20191013152910Z\n        reason: affiliation_changed\n        invalidity_date: 20191001000000Z\n      - path: /etc/ssl/crt/revoked-cert.pem\n        revocation_date: 20191010010203Z\n'''\n\nRETURN = r'''\nfilename:\n    description: Path to the generated CRL\n    returned: changed or success\n    type: str\n    sample: /path/to/my-ca.crl\nbackup_file:\n    description: Name of backup file created.\n    returned: changed and if I(backup) is C(yes)\n    type: str\n    sample: /path/to/my-ca.crl.2019-03-09@11:22~\nprivatekey:\n    description: Path to the private CA key\n    returned: changed or success\n    type: str\n    sample: /path/to/my-ca.pem\nformat:\n    description:\n        - Whether the CRL is in PEM format (C(pem)) or in DER format (C(der)).\n    returned: success\n    type: str\n    sample: pem\nissuer:\n    description:\n        - The CRL's issuer.\n        - Note that for repeated values, only the last one will be returned.\n    returned: success\n    type: dict\n    sample: '{\"organizationName\": \"Ansible\", \"commonName\": \"ca.example.com\"}'\nissuer_ordered:\n    description: The CRL's issuer as an ordered list of tuples.\n    returned: success\n    type: list\n    elements: list\n    sample: '[[\"organizationName\", \"Ansible\"], [\"commonName\": \"ca.example.com\"]]'\nlast_update:\n    description: The point in time from which this CRL can be trusted as ASN.1 TIME.\n    returned: success\n    type: str\n    sample: 20190413202428Z\nnext_update:\n    description: The point in time from which a new CRL will be issued and the client has to check for it as ASN.1 TIME.\n    returned: success\n    type: str\n    sample: 20190413202428Z\ndigest:\n    description: The signature algorithm used to sign the CRL.\n    returned: success\n    type: str\n    sample: sha256WithRSAEncryption\nrevoked_certificates:\n    description: List of certificates to be revoked.\n    returned: success\n    type: list\n    elements: dict\n    contains:\n        serial_number:\n            description: Serial number of the certificate.\n            type: int\n            sample: 1234\n        revocation_date:\n            description: The point in time the certificate was revoked as ASN.1 TIME.\n            type: str\n            sample: 20190413202428Z\n        issuer:\n            description: The certificate's issuer.\n            type: list\n            elements: str\n            sample: '[\"DNS:ca.example.org\"]'\n        issuer_critical:\n            description: Whether the certificate issuer extension is critical.\n            type: bool\n            sample: no\n        reason:\n            description:\n                - The value for the revocation reason extension.\n                - One of C(unspecified), C(key_compromise), C(ca_compromise), C(affiliation_changed), C(superseded),\n                  C(cessation_of_operation), C(certificate_hold), C(privilege_withdrawn), C(aa_compromise), and\n                  C(remove_from_crl).\n            type: str\n            sample: key_compromise\n        reason_critical:\n            description: Whether the revocation reason extension is critical.\n            type: bool\n            sample: no\n        invalidity_date:\n            description: |\n                The point in time it was known/suspected that the private key was compromised\n                or that the certificate otherwise became invalid as ASN.1 TIME.\n            type: str\n            sample: 20190413202428Z\n        invalidity_date_critical:\n            description: Whether the invalidity date extension is critical.\n            type: bool\n            sample: no\ncrl:\n    description:\n        - The (current or generated) CRL's content.\n        - Will be the CRL itself if I(format) is C(pem), and Base64 of the\n          CRL if I(format) is C(der).\n    returned: if I(state) is C(present) and I(return_content) is C(yes)\n    type: str\n'''\n\n\nimport base64\nimport os\nimport traceback\n\nfrom distutils.version import LooseVersion\n\nfrom ansible.module_utils.basic import AnsibleModule, missing_required_lib\nfrom ansible.module_utils._text import to_native, to_text\n\nfrom ansible_collections.community.crypto.plugins.module_utils.io import (\n    write_file,\n)\n\nfrom ansible_collections.community.crypto.plugins.module_utils.crypto.basic import (\n    OpenSSLObjectError,\n    OpenSSLBadPassphraseError,\n)\n\nfrom ansible_collections.community.crypto.plugins.module_utils.crypto.support import (\n    OpenSSLObject,\n    load_privatekey,\n    load_certificate,\n    parse_name_field,\n    get_relative_time_option,\n    select_message_digest,\n)\n\nfrom ansible_collections.community.crypto.plugins.module_utils.crypto.cryptography_support import (\n    cryptography_get_name,\n    cryptography_name_to_oid,\n    cryptography_oid_to_name,\n    cryptography_serial_number_of_cert,\n)\n\nfrom ansible_collections.community.crypto.plugins.module_utils.crypto.cryptography_crl import (\n    REVOCATION_REASON_MAP,\n    TIMESTAMP_FORMAT,\n    cryptography_decode_revoked_certificate,\n    cryptography_dump_revoked,\n    cryptography_get_signature_algorithm_oid_from_crl,\n)\n\nfrom ansible_collections.community.crypto.plugins.module_utils.crypto.identify import (\n    identify_pem_format,\n)\n\nMINIMAL_CRYPTOGRAPHY_VERSION = '1.2'\n\nCRYPTOGRAPHY_IMP_ERR = None\ntry:\n    import cryptography\n    from cryptography import x509\n    from cryptography.hazmat.backends import default_backend\n    from cryptography.hazmat.primitives.serialization import Encoding\n    from cryptography.x509 import (\n        CertificateRevocationListBuilder,\n        RevokedCertificateBuilder,\n        NameAttribute,\n        Name,\n    )\n    CRYPTOGRAPHY_VERSION = LooseVersion(cryptography.__version__)\nexcept ImportError:\n    CRYPTOGRAPHY_IMP_ERR = traceback.format_exc()\n    CRYPTOGRAPHY_FOUND = False\nelse:\n    CRYPTOGRAPHY_FOUND = True\n\n\nclass CRLError(OpenSSLObjectError):\n    pass\n\n\nclass CRL(OpenSSLObject):\n\n    def __init__(self, module):\n        super(CRL, self).__init__(\n            module.params['path'],\n            module.params['state'],\n            module.params['force'],\n            module.check_mode\n        )\n\n        self.format = module.params['format']\n\n        self.update = module.params['mode'] == 'update'\n        self.ignore_timestamps = module.params['ignore_timestamps']\n        self.return_content = module.params['return_content']\n        self.crl_content = None\n\n        self.privatekey_path = module.params['privatekey_path']\n        self.privatekey_content = module.params['privatekey_content']\n        if self.privatekey_content is not None:\n            self.privatekey_content = self.privatekey_content.encode('utf-8')\n        self.privatekey_passphrase = module.params['privatekey_passphrase']\n\n        self.issuer = parse_name_field(module.params['issuer'])\n        self.issuer = [(entry[0], entry[1]) for entry in self.issuer if entry[1]]\n\n        self.last_update = get_relative_time_option(module.params['last_update'], 'last_update')\n        self.next_update = get_relative_time_option(module.params['next_update'], 'next_update')\n\n        self.digest = select_message_digest(module.params['digest'])\n        if self.digest is None:\n            raise CRLError('The digest \"{0}\" is not supported'.format(module.params['digest']))\n\n        self.revoked_certificates = []\n        for i, rc in enumerate(module.params['revoked_certificates']):\n            result = {\n                'serial_number': None,\n                'revocation_date': None,\n                'issuer': None,\n                'issuer_critical': False,\n                'reason': None,\n                'reason_critical': False,\n                'invalidity_date': None,\n                'invalidity_date_critical': False,\n            }\n            path_prefix = 'revoked_certificates[{0}].'.format(i)\n            if rc['path'] is not None or rc['content'] is not None:\n                # Load certificate from file or content\n                try:\n                    if rc['content'] is not None:\n                        rc['content'] = rc['content'].encode('utf-8')\n                    cert = load_certificate(rc['path'], content=rc['content'], backend='cryptography')\n                    result['serial_number'] = cryptography_serial_number_of_cert(cert)\n                except OpenSSLObjectError as e:\n                    if rc['content'] is not None:\n                        module.fail_json(\n                            msg='Cannot parse certificate from {0}content: {1}'.format(path_prefix, to_native(e))\n                        )\n                    else:\n                        module.fail_json(\n                            msg='Cannot read certificate \"{1}\" from {0}path: {2}'.format(path_prefix, rc['path'], to_native(e))\n                        )\n            else:\n                # Specify serial_number (and potentially issuer) directly\n                result['serial_number'] = rc['serial_number']\n            # All other options\n            if rc['issuer']:\n                result['issuer'] = [cryptography_get_name(issuer) for issuer in rc['issuer']]\n                result['issuer_critical'] = rc['issuer_critical']\n            result['revocation_date'] = get_relative_time_option(\n                rc['revocation_date'],\n                path_prefix + 'revocation_date'\n            )\n            if rc['reason']:\n                result['reason'] = REVOCATION_REASON_MAP[rc['reason']]\n                result['reason_critical'] = rc['reason_critical']\n            if rc['invalidity_date']:\n                result['invalidity_date'] = get_relative_time_option(\n                    rc['invalidity_date'],\n                    path_prefix + 'invalidity_date'\n                )\n                result['invalidity_date_critical'] = rc['invalidity_date_critical']\n            self.revoked_certificates.append(result)\n\n        self.module = module\n\n        self.backup = module.params['backup']\n        self.backup_file = None\n\n        try:\n            self.privatekey = load_privatekey(\n                path=self.privatekey_path,\n                content=self.privatekey_content,\n                passphrase=self.privatekey_passphrase,\n                backend='cryptography'\n            )\n        except OpenSSLBadPassphraseError as exc:\n            raise CRLError(exc)\n\n        self.crl = None\n        try:\n            with open(self.path, 'rb') as f:\n                data = f.read()\n            self.actual_format = 'pem' if identify_pem_format(data) else 'der'\n            if self.actual_format == 'pem':\n                self.crl = x509.load_pem_x509_crl(data, default_backend())\n                if self.return_content:\n                    self.crl_content = data\n            else:\n                self.crl = x509.load_der_x509_crl(data, default_backend())\n                if self.return_content:\n                    self.crl_content = base64.b64encode(data)\n        except Exception as dummy:\n            self.crl_content = None\n            self.actual_format = self.format\n\n    def remove(self):\n        if self.backup:\n            self.backup_file = self.module.backup_local(self.path)\n        super(CRL, self).remove(self.module)\n\n    def _compress_entry(self, entry):\n        if self.ignore_timestamps:\n            # Throw out revocation_date\n            return (\n                entry['serial_number'],\n                tuple(entry['issuer']) if entry['issuer'] is not None else None,\n                entry['issuer_critical'],\n                entry['reason'],\n                entry['reason_critical'],\n                entry['invalidity_date'],\n                entry['invalidity_date_critical'],\n            )\n        else:\n            return (\n                entry['serial_number'],\n                entry['revocation_date'],\n                tuple(entry['issuer']) if entry['issuer'] is not None else None,\n                entry['issuer_critical'],\n                entry['reason'],\n                entry['reason_critical'],\n                entry['invalidity_date'],\n                entry['invalidity_date_critical'],\n            )\n\n    def check(self, perms_required=True, ignore_conversion=True):\n        \"\"\"Ensure the resource is in its desired state.\"\"\"\n\n        state_and_perms = super(CRL, self).check(self.module, perms_required)\n\n        if not state_and_perms:\n            return False\n\n        if self.crl is None:\n            return False\n\n        if self.last_update != self.crl.last_update and not self.ignore_timestamps:\n            return False\n        if self.next_update != self.crl.next_update and not self.ignore_timestamps:\n            return False\n        if self.digest.name != self.crl.signature_hash_algorithm.name:\n            return False\n\n        want_issuer = [(cryptography_name_to_oid(entry[0]), entry[1]) for entry in self.issuer]\n        if want_issuer != [(sub.oid, sub.value) for sub in self.crl.issuer]:\n            return False\n\n        old_entries = [self._compress_entry(cryptography_decode_revoked_certificate(cert)) for cert in self.crl]\n        new_entries = [self._compress_entry(cert) for cert in self.revoked_certificates]\n        if self.update:\n            # We don't simply use a set so that duplicate entries are treated correctly\n            for entry in new_entries:\n                try:\n                    old_entries.remove(entry)\n                except ValueError:\n                    return False\n        else:\n            if old_entries != new_entries:\n                return False\n\n        if self.format != self.actual_format and not ignore_conversion:\n            return False\n\n        return True\n\n    def _generate_crl(self):\n        backend = default_backend()\n        crl = CertificateRevocationListBuilder()\n\n        try:\n            crl = crl.issuer_name(Name([\n                NameAttribute(cryptography_name_to_oid(entry[0]), to_text(entry[1]))\n                for entry in self.issuer\n            ]))\n        except ValueError as e:\n            raise CRLError(e)\n\n        crl = crl.last_update(self.last_update)\n        crl = crl.next_update(self.next_update)\n\n        if self.update and self.crl:\n            new_entries = set([self._compress_entry(entry) for entry in self.revoked_certificates])\n            for entry in self.crl:\n                decoded_entry = self._compress_entry(cryptography_decode_revoked_certificate(entry))\n                if decoded_entry not in new_entries:\n                    crl = crl.add_revoked_certificate(entry)\n        for entry in self.revoked_certificates:\n            revoked_cert = RevokedCertificateBuilder()\n            revoked_cert = revoked_cert.serial_number(entry['serial_number'])\n            revoked_cert = revoked_cert.revocation_date(entry['revocation_date'])\n            if entry['issuer'] is not None:\n                revoked_cert = revoked_cert.add_extension(\n                    x509.CertificateIssuer([\n                        cryptography_get_name(name) for name in entry['issuer']\n                    ]),\n                    entry['issuer_critical']\n                )\n            if entry['reason'] is not None:\n                revoked_cert = revoked_cert.add_extension(\n                    x509.CRLReason(entry['reason']),\n                    entry['reason_critical']\n                )\n            if entry['invalidity_date'] is not None:\n                revoked_cert = revoked_cert.add_extension(\n                    x509.InvalidityDate(entry['invalidity_date']),\n                    entry['invalidity_date_critical']\n                )\n            crl = crl.add_revoked_certificate(revoked_cert.build(backend))\n\n        self.crl = crl.sign(self.privatekey, self.digest, backend=backend)\n        if self.format == 'pem':\n            return self.crl.public_bytes(Encoding.PEM)\n        else:\n            return self.crl.public_bytes(Encoding.DER)\n\n    def generate(self):\n        result = None\n        if not self.check(perms_required=False, ignore_conversion=True) or self.force:\n            result = self._generate_crl()\n        elif not self.check(perms_required=False, ignore_conversion=False) and self.crl:\n            if self.format == 'pem':\n                result = self.crl.public_bytes(Encoding.PEM)\n            else:\n                result = self.crl.public_bytes(Encoding.DER)\n\n        if result is not None:\n            if self.return_content:\n                if self.format == 'pem':\n                    self.crl_content = result\n                else:\n                    self.crl_content = base64.b64encode(result)\n            if self.backup:\n                self.backup_file = self.module.backup_local(self.path)\n            write_file(self.module, result)\n            self.changed = True\n\n        file_args = self.module.load_file_common_arguments(self.module.params)\n        if self.module.set_fs_attributes_if_different(file_args, False):\n            self.changed = True\n\n    def dump(self, check_mode=False):\n        result = {\n            'changed': self.changed,\n            'filename': self.path,\n            'privatekey': self.privatekey_path,\n            'format': self.format,\n            'last_update': None,\n            'next_update': None,\n            'digest': None,\n            'issuer_ordered': None,\n            'issuer': None,\n            'revoked_certificates': [],\n        }\n        if self.backup_file:\n            result['backup_file'] = self.backup_file\n\n        if check_mode:\n            result['last_update'] = self.last_update.strftime(TIMESTAMP_FORMAT)\n            result['next_update'] = self.next_update.strftime(TIMESTAMP_FORMAT)\n            # result['digest'] = cryptography_oid_to_name(self.crl.signature_algorithm_oid)\n            result['digest'] = self.module.params['digest']\n            result['issuer_ordered'] = self.issuer\n            result['issuer'] = {}\n            for k, v in self.issuer:\n                result['issuer'][k] = v\n            result['revoked_certificates'] = []\n            for entry in self.revoked_certificates:\n                result['revoked_certificates'].append(cryptography_dump_revoked(entry))\n        elif self.crl:\n            result['last_update'] = self.crl.last_update.strftime(TIMESTAMP_FORMAT)\n            result['next_update'] = self.crl.next_update.strftime(TIMESTAMP_FORMAT)\n            result['digest'] = cryptography_oid_to_name(cryptography_get_signature_algorithm_oid_from_crl(self.crl))\n            issuer = []\n            for attribute in self.crl.issuer:\n                issuer.append([cryptography_oid_to_name(attribute.oid), attribute.value])\n            result['issuer_ordered'] = issuer\n            result['issuer'] = {}\n            for k, v in issuer:\n                result['issuer'][k] = v\n            result['revoked_certificates'] = []\n            for cert in self.crl:\n                entry = cryptography_decode_revoked_certificate(cert)\n                result['revoked_certificates'].append(cryptography_dump_revoked(entry))\n\n        if self.return_content:\n            result['crl'] = self.crl_content\n\n        return result\n\n\ndef main():\n    module = AnsibleModule(\n        argument_spec=dict(\n            state=dict(type='str', default='present', choices=['present', 'absent']),\n            mode=dict(type='str', default='generate', choices=['generate', 'update']),\n            force=dict(type='bool', default=False),\n            backup=dict(type='bool', default=False),\n            path=dict(type='path', required=True),\n            format=dict(type='str', default='pem', choices=['pem', 'der']),\n            privatekey_path=dict(type='path'),\n            privatekey_content=dict(type='str', no_log=True),\n            privatekey_passphrase=dict(type='str', no_log=True),\n            issuer=dict(type='dict'),\n            last_update=dict(type='str', default='+0s'),\n            next_update=dict(type='str'),\n            digest=dict(type='str', default='sha256'),\n            ignore_timestamps=dict(type='bool', default=False),\n            return_content=dict(type='bool', default=False),\n            revoked_certificates=dict(\n                type='list',\n                elements='dict',\n                options=dict(\n                    path=dict(type='path'),\n                    content=dict(type='str'),\n                    serial_number=dict(type='int'),\n                    revocation_date=dict(type='str', default='+0s'),\n                    issuer=dict(type='list', elements='str'),\n                    issuer_critical=dict(type='bool', default=False),\n                    reason=dict(\n                        type='str',\n                        choices=[\n                            'unspecified', 'key_compromise', 'ca_compromise', 'affiliation_changed',\n                            'superseded', 'cessation_of_operation', 'certificate_hold',\n                            'privilege_withdrawn', 'aa_compromise', 'remove_from_crl'\n                        ]\n                    ),\n                    reason_critical=dict(type='bool', default=False),\n                    invalidity_date=dict(type='str'),\n                    invalidity_date_critical=dict(type='bool', default=False),\n                ),\n                required_one_of=[['path', 'content', 'serial_number']],\n                mutually_exclusive=[['path', 'content', 'serial_number']],\n            ),\n        ),\n        required_if=[\n            ('state', 'present', ['privatekey_path', 'privatekey_content'], True),\n            ('state', 'present', ['issuer', 'next_update', 'revoked_certificates'], False),\n        ],\n        mutually_exclusive=(\n            ['privatekey_path', 'privatekey_content'],\n        ),\n        supports_check_mode=True,\n        add_file_common_args=True,\n    )\n\n    if not CRYPTOGRAPHY_FOUND:\n        module.fail_json(msg=missing_required_lib('cryptography >= {0}'.format(MINIMAL_CRYPTOGRAPHY_VERSION)),\n                         exception=CRYPTOGRAPHY_IMP_ERR)\n\n    try:\n        crl = CRL(module)\n\n        if module.params['state'] == 'present':\n            if module.check_mode:\n                result = crl.dump(check_mode=True)\n                result['changed'] = module.params['force'] or not crl.check() or not crl.check(ignore_conversion=False)\n                module.exit_json(**result)\n\n            crl.generate()\n        else:\n            if module.check_mode:\n                result = crl.dump(check_mode=True)\n                result['changed'] = os.path.exists(module.params['path'])\n                module.exit_json(**result)\n\n            crl.remove()\n\n        result = crl.dump()\n        module.exit_json(**result)\n    except OpenSSLObjectError as exc:\n        module.fail_json(msg=to_native(exc))\n\n\nif __name__ == \"__main__\":\n    main()\n", "target": 0}
{"idx": 967, "func": "from __future__ import unicode_literals\n\nimport calendar\nimport datetime\nimport re\nimport sys\ntry:\n    from urllib import parse as urllib_parse\nexcept ImportError:     # Python 2\n    import urllib as urllib_parse\n    import urlparse\n    urllib_parse.urlparse = urlparse.urlparse\n\n\nfrom email.utils import formatdate\n\nfrom django.utils.datastructures import MultiValueDict\nfrom django.utils.encoding import force_str, force_text\nfrom django.utils.functional import allow_lazy\nfrom django.utils import six\n\nETAG_MATCH = re.compile(r'(?:W/)?\"((?:\\\\.|[^\"])*)\"')\n\nMONTHS = 'jan feb mar apr may jun jul aug sep oct nov dec'.split()\n__D = r'(?P<day>\\d{2})'\n__D2 = r'(?P<day>[ \\d]\\d)'\n__M = r'(?P<mon>\\w{3})'\n__Y = r'(?P<year>\\d{4})'\n__Y2 = r'(?P<year>\\d{2})'\n__T = r'(?P<hour>\\d{2}):(?P<min>\\d{2}):(?P<sec>\\d{2})'\nRFC1123_DATE = re.compile(r'^\\w{3}, %s %s %s %s GMT$' % (__D, __M, __Y, __T))\nRFC850_DATE = re.compile(r'^\\w{6,9}, %s-%s-%s %s GMT$' % (__D, __M, __Y2, __T))\nASCTIME_DATE = re.compile(r'^\\w{3} %s %s %s %s$' % (__M, __D2, __T, __Y))\n\ndef urlquote(url, safe='/'):\n    \"\"\"\n    A version of Python's urllib.quote() function that can operate on unicode\n    strings. The url is first UTF-8 encoded before quoting. The returned string\n    can safely be used as part of an argument to a subsequent iri_to_uri() call\n    without double-quoting occurring.\n    \"\"\"\n    return force_text(urllib_parse.quote(force_str(url), force_str(safe)))\nurlquote = allow_lazy(urlquote, six.text_type)\n\ndef urlquote_plus(url, safe=''):\n    \"\"\"\n    A version of Python's urllib.quote_plus() function that can operate on\n    unicode strings. The url is first UTF-8 encoded before quoting. The\n    returned string can safely be used as part of an argument to a subsequent\n    iri_to_uri() call without double-quoting occurring.\n    \"\"\"\n    return force_text(urllib_parse.quote_plus(force_str(url), force_str(safe)))\nurlquote_plus = allow_lazy(urlquote_plus, six.text_type)\n\ndef urlunquote(quoted_url):\n    \"\"\"\n    A wrapper for Python's urllib.unquote() function that can operate on\n    the result of django.utils.http.urlquote().\n    \"\"\"\n    return force_text(urllib_parse.unquote(force_str(quoted_url)))\nurlunquote = allow_lazy(urlunquote, six.text_type)\n\ndef urlunquote_plus(quoted_url):\n    \"\"\"\n    A wrapper for Python's urllib.unquote_plus() function that can operate on\n    the result of django.utils.http.urlquote_plus().\n    \"\"\"\n    return force_text(urllib_parse.unquote_plus(force_str(quoted_url)))\nurlunquote_plus = allow_lazy(urlunquote_plus, six.text_type)\n\ndef urlencode(query, doseq=0):\n    \"\"\"\n    A version of Python's urllib.urlencode() function that can operate on\n    unicode strings. The parameters are first case to UTF-8 encoded strings and\n    then encoded as per normal.\n    \"\"\"\n    if isinstance(query, MultiValueDict):\n        query = query.lists()\n    elif hasattr(query, 'items'):\n        query = query.items()\n    return urllib_parse.urlencode(\n        [(force_str(k),\n         [force_str(i) for i in v] if isinstance(v, (list,tuple)) else force_str(v))\n            for k, v in query],\n        doseq)\n\ndef cookie_date(epoch_seconds=None):\n    \"\"\"\n    Formats the time to ensure compatibility with Netscape's cookie standard.\n\n    Accepts a floating point number expressed in seconds since the epoch, in\n    UTC - such as that outputted by time.time(). If set to None, defaults to\n    the current time.\n\n    Outputs a string in the format 'Wdy, DD-Mon-YYYY HH:MM:SS GMT'.\n    \"\"\"\n    rfcdate = formatdate(epoch_seconds)\n    return '%s-%s-%s GMT' % (rfcdate[:7], rfcdate[8:11], rfcdate[12:25])\n\ndef http_date(epoch_seconds=None):\n    \"\"\"\n    Formats the time to match the RFC1123 date format as specified by HTTP\n    RFC2616 section 3.3.1.\n\n    Accepts a floating point number expressed in seconds since the epoch, in\n    UTC - such as that outputted by time.time(). If set to None, defaults to\n    the current time.\n\n    Outputs a string in the format 'Wdy, DD Mon YYYY HH:MM:SS GMT'.\n    \"\"\"\n    rfcdate = formatdate(epoch_seconds)\n    return '%s GMT' % rfcdate[:25]\n\ndef parse_http_date(date):\n    \"\"\"\n    Parses a date format as specified by HTTP RFC2616 section 3.3.1.\n\n    The three formats allowed by the RFC are accepted, even if only the first\n    one is still in widespread use.\n\n    Returns an integer expressed in seconds since the epoch, in UTC.\n    \"\"\"\n    # emails.Util.parsedate does the job for RFC1123 dates; unfortunately\n    # RFC2616 makes it mandatory to support RFC850 dates too. So we roll\n    # our own RFC-compliant parsing.\n    for regex in RFC1123_DATE, RFC850_DATE, ASCTIME_DATE:\n        m = regex.match(date)\n        if m is not None:\n            break\n    else:\n        raise ValueError(\"%r is not in a valid HTTP date format\" % date)\n    try:\n        year = int(m.group('year'))\n        if year < 100:\n            if year < 70:\n                year += 2000\n            else:\n                year += 1900\n        month = MONTHS.index(m.group('mon').lower()) + 1\n        day = int(m.group('day'))\n        hour = int(m.group('hour'))\n        min = int(m.group('min'))\n        sec = int(m.group('sec'))\n        result = datetime.datetime(year, month, day, hour, min, sec)\n        return calendar.timegm(result.utctimetuple())\n    except Exception:\n        raise ValueError(\"%r is not a valid date\" % date)\n\ndef parse_http_date_safe(date):\n    \"\"\"\n    Same as parse_http_date, but returns None if the input is invalid.\n    \"\"\"\n    try:\n        return parse_http_date(date)\n    except Exception:\n        pass\n\n# Base 36 functions: useful for generating compact URLs\n\ndef base36_to_int(s):\n    \"\"\"\n    Converts a base 36 string to an ``int``. Raises ``ValueError` if the\n    input won't fit into an int.\n    \"\"\"\n    # To prevent overconsumption of server resources, reject any\n    # base36 string that is long than 13 base36 digits (13 digits\n    # is sufficient to base36-encode any 64-bit integer)\n    if len(s) > 13:\n        raise ValueError(\"Base36 input too large\")\n    value = int(s, 36)\n    # ... then do a final check that the value will fit into an int to avoid\n    # returning a long (#15067). The long type was removed in Python 3.\n    if not six.PY3 and value > sys.maxint:\n        raise ValueError(\"Base36 input too large\")\n    return value\n\ndef int_to_base36(i):\n    \"\"\"\n    Converts an integer to a base36 string\n    \"\"\"\n    digits = \"0123456789abcdefghijklmnopqrstuvwxyz\"\n    factor = 0\n    if i < 0:\n        raise ValueError(\"Negative base36 conversion input.\")\n    if not six.PY3:\n        if not isinstance(i, six.integer_types):\n            raise TypeError(\"Non-integer base36 conversion input.\")\n        if i > sys.maxint:\n            raise ValueError(\"Base36 conversion input too large.\")\n    # Find starting factor\n    while True:\n        factor += 1\n        if i < 36 ** factor:\n            factor -= 1\n            break\n    base36 = []\n    # Construct base36 representation\n    while factor >= 0:\n        j = 36 ** factor\n        base36.append(digits[i // j])\n        i = i % j\n        factor -= 1\n    return ''.join(base36)\n\ndef parse_etags(etag_str):\n    \"\"\"\n    Parses a string with one or several etags passed in If-None-Match and\n    If-Match headers by the rules in RFC 2616. Returns a list of etags\n    without surrounding double quotes (\") and unescaped from \\<CHAR>.\n    \"\"\"\n    etags = ETAG_MATCH.findall(etag_str)\n    if not etags:\n        # etag_str has wrong format, treat it as an opaque string then\n        return [etag_str]\n    etags = [e.encode('ascii').decode('unicode_escape') for e in etags]\n    return etags\n\ndef quote_etag(etag):\n    \"\"\"\n    Wraps a string in double quotes escaping contents as necessary.\n    \"\"\"\n    return '\"%s\"' % etag.replace('\\\\', '\\\\\\\\').replace('\"', '\\\\\"')\n\ndef same_origin(url1, url2):\n    \"\"\"\n    Checks if two URLs are 'same-origin'\n    \"\"\"\n    p1, p2 = urllib_parse.urlparse(url1), urllib_parse.urlparse(url2)\n    return (p1.scheme, p1.hostname, p1.port) == (p2.scheme, p2.hostname, p2.port)\n\ndef is_safe_url(url, host=None):\n    \"\"\"\n    Return ``True`` if the url is a safe redirection (i.e. it doesn't point to\n    a different host).\n\n    Always returns ``False`` on an empty url.\n    \"\"\"\n    if not url:\n        return False\n    netloc = urllib_parse.urlparse(url)[1]\n    return not netloc or netloc == host\n", "target": 1}
{"idx": 968, "func": "# vim: tabstop=4 shiftwidth=4 softtabstop=4\n\n# Copyright 2011 United States Government as represented by the\n# Administrator of the National Aeronautics and Space Administration.\n# All Rights Reserved.\n# Copyright (c) 2011 Citrix Systems, Inc.\n#\n#    Licensed under the Apache License, Version 2.0 (the \"License\"); you may\n#    not use this file except in compliance with the License. You may obtain\n#    a copy of the License at\n#\n#         http://www.apache.org/licenses/LICENSE-2.0\n#\n#    Unless required by applicable law or agreed to in writing, software\n#    distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n#    License for the specific language governing permissions and limitations\n#    under the License.\n\nfrom nova import context\nfrom nova import db\nfrom nova import flags\nfrom nova import log as logging\nfrom nova.openstack.common import cfg\nfrom nova import utils\nfrom nova.virt import netutils\n\n\nLOG = logging.getLogger(__name__)\n\nallow_same_net_traffic_opt = cfg.BoolOpt('allow_same_net_traffic',\n        default=True,\n        help='Whether to allow network traffic from same network')\n\nFLAGS = flags.FLAGS\nFLAGS.register_opt(allow_same_net_traffic_opt)\n\n\nclass FirewallDriver(object):\n    \"\"\" Firewall Driver base class.\n\n        Defines methods that any driver providing security groups\n        and provider fireall functionality should implement.\n    \"\"\"\n    def prepare_instance_filter(self, instance, network_info):\n        \"\"\"Prepare filters for the instance.\n        At this point, the instance isn't running yet.\"\"\"\n        raise NotImplementedError()\n\n    def unfilter_instance(self, instance, network_info):\n        \"\"\"Stop filtering instance\"\"\"\n        raise NotImplementedError()\n\n    def apply_instance_filter(self, instance, network_info):\n        \"\"\"Apply instance filter.\n\n        Once this method returns, the instance should be firewalled\n        appropriately. This method should as far as possible be a\n        no-op. It's vastly preferred to get everything set up in\n        prepare_instance_filter.\n        \"\"\"\n        raise NotImplementedError()\n\n    def refresh_security_group_rules(self, security_group_id):\n        \"\"\"Refresh security group rules from data store\n\n        Gets called when a rule has been added to or removed from\n        the security group.\"\"\"\n        raise NotImplementedError()\n\n    def refresh_security_group_members(self, security_group_id):\n        \"\"\"Refresh security group members from data store\n\n        Gets called when an instance gets added to or removed from\n        the security group.\"\"\"\n        raise NotImplementedError()\n\n    def refresh_provider_fw_rules(self):\n        \"\"\"Refresh common rules for all hosts/instances from data store.\n\n        Gets called when a rule has been added to or removed from\n        the list of rules (via admin api).\n\n        \"\"\"\n        raise NotImplementedError()\n\n    def setup_basic_filtering(self, instance, network_info):\n        \"\"\"Create rules to block spoofing and allow dhcp.\n\n        This gets called when spawning an instance, before\n        :py:meth:`prepare_instance_filter`.\n\n        \"\"\"\n        raise NotImplementedError()\n\n    def instance_filter_exists(self, instance, network_info):\n        \"\"\"Check nova-instance-instance-xxx exists\"\"\"\n        raise NotImplementedError()\n\n    def _handle_network_info_model(self, network_info):\n        # make sure this is legacy network_info\n        try:\n            return network_info.legacy()\n        except AttributeError:\n            # no \"legacy\" function means network_info is legacy\n            return network_info\n\n\nclass IptablesFirewallDriver(FirewallDriver):\n    \"\"\"Driver which enforces security groups through iptables rules.\"\"\"\n\n    def __init__(self, **kwargs):\n        from nova.network import linux_net\n        self.iptables = linux_net.iptables_manager\n        self.instances = {}\n        self.network_infos = {}\n        self.basicly_filtered = False\n\n        self.iptables.ipv4['filter'].add_chain('sg-fallback')\n        self.iptables.ipv4['filter'].add_rule('sg-fallback', '-j DROP')\n        self.iptables.ipv6['filter'].add_chain('sg-fallback')\n        self.iptables.ipv6['filter'].add_rule('sg-fallback', '-j DROP')\n\n    def setup_basic_filtering(self, instance, network_info):\n        pass\n\n    def apply_instance_filter(self, instance, network_info):\n        \"\"\"No-op. Everything is done in prepare_instance_filter.\"\"\"\n        pass\n\n    def unfilter_instance(self, instance, network_info):\n        # make sure this is legacy nw_info\n        network_info = self._handle_network_info_model(network_info)\n\n        if self.instances.pop(instance['id'], None):\n            # NOTE(vish): use the passed info instead of the stored info\n            self.network_infos.pop(instance['id'])\n            self.remove_filters_for_instance(instance)\n            self.iptables.apply()\n        else:\n            LOG.info(_('Attempted to unfilter instance which is not '\n                     'filtered'), instance=instance)\n\n    def prepare_instance_filter(self, instance, network_info):\n        # make sure this is legacy nw_info\n        network_info = self._handle_network_info_model(network_info)\n\n        self.instances[instance['id']] = instance\n        self.network_infos[instance['id']] = network_info\n        self.add_filters_for_instance(instance)\n        LOG.debug(_('Filters added to instance'), instance=instance)\n        self.refresh_provider_fw_rules()\n        LOG.debug(_('Provider Firewall Rules refreshed'), instance=instance)\n        self.iptables.apply()\n\n    def _create_filter(self, ips, chain_name):\n        return ['-d %s -j $%s' % (ip, chain_name) for ip in ips]\n\n    def _filters_for_instance(self, chain_name, network_info):\n        \"\"\"Creates a rule corresponding to each ip that defines a\n             jump to the corresponding instance - chain for all the traffic\n             destined to that ip.\"\"\"\n        # make sure this is legacy nw_info\n        network_info = self._handle_network_info_model(network_info)\n\n        ips_v4 = [ip['ip'] for (_n, mapping) in network_info\n                 for ip in mapping['ips']]\n        ipv4_rules = self._create_filter(ips_v4, chain_name)\n\n        ipv6_rules = []\n        if FLAGS.use_ipv6:\n            ips_v6 = [ip['ip'] for (_n, mapping) in network_info\n                     for ip in mapping['ip6s']]\n            ipv6_rules = self._create_filter(ips_v6, chain_name)\n\n        return ipv4_rules, ipv6_rules\n\n    def _add_filters(self, chain_name, ipv4_rules, ipv6_rules):\n        for rule in ipv4_rules:\n            self.iptables.ipv4['filter'].add_rule(chain_name, rule)\n\n        if FLAGS.use_ipv6:\n            for rule in ipv6_rules:\n                self.iptables.ipv6['filter'].add_rule(chain_name, rule)\n\n    def add_filters_for_instance(self, instance):\n        network_info = self.network_infos[instance['id']]\n        chain_name = self._instance_chain_name(instance)\n        if FLAGS.use_ipv6:\n            self.iptables.ipv6['filter'].add_chain(chain_name)\n        self.iptables.ipv4['filter'].add_chain(chain_name)\n        ipv4_rules, ipv6_rules = self._filters_for_instance(chain_name,\n                                                            network_info)\n        self._add_filters('local', ipv4_rules, ipv6_rules)\n        ipv4_rules, ipv6_rules = self.instance_rules(instance, network_info)\n        self._add_filters(chain_name, ipv4_rules, ipv6_rules)\n\n    def remove_filters_for_instance(self, instance):\n        chain_name = self._instance_chain_name(instance)\n\n        self.iptables.ipv4['filter'].remove_chain(chain_name)\n        if FLAGS.use_ipv6:\n            self.iptables.ipv6['filter'].remove_chain(chain_name)\n\n    @staticmethod\n    def _security_group_chain_name(security_group_id):\n        return 'nova-sg-%s' % (security_group_id,)\n\n    def _instance_chain_name(self, instance):\n        return 'inst-%s' % (instance['id'],)\n\n    def _do_basic_rules(self, ipv4_rules, ipv6_rules, network_info):\n        # Always drop invalid packets\n        ipv4_rules += ['-m state --state ' 'INVALID -j DROP']\n        ipv6_rules += ['-m state --state ' 'INVALID -j DROP']\n\n        # Allow established connections\n        ipv4_rules += ['-m state --state ESTABLISHED,RELATED -j ACCEPT']\n        ipv6_rules += ['-m state --state ESTABLISHED,RELATED -j ACCEPT']\n\n        # Pass through provider-wide drops\n        ipv4_rules += ['-j $provider']\n        ipv6_rules += ['-j $provider']\n\n    def _do_dhcp_rules(self, ipv4_rules, network_info):\n        # make sure this is legacy nw_info\n        network_info = self._handle_network_info_model(network_info)\n\n        dhcp_servers = [info['dhcp_server'] for (_n, info) in network_info]\n\n        for dhcp_server in dhcp_servers:\n            if dhcp_server:\n                ipv4_rules.append('-s %s -p udp --sport 67 --dport 68 '\n                                  '-j ACCEPT' % (dhcp_server,))\n\n    def _do_project_network_rules(self, ipv4_rules, ipv6_rules, network_info):\n        # make sure this is legacy nw_info\n        network_info = self._handle_network_info_model(network_info)\n\n        cidrs = [network['cidr'] for (network, _i) in network_info]\n        for cidr in cidrs:\n            ipv4_rules.append('-s %s -j ACCEPT' % (cidr,))\n        if FLAGS.use_ipv6:\n            cidrv6s = [network['cidr_v6'] for (network, _i) in\n                       network_info]\n\n            for cidrv6 in cidrv6s:\n                ipv6_rules.append('-s %s -j ACCEPT' % (cidrv6,))\n\n    def _do_ra_rules(self, ipv6_rules, network_info):\n        # make sure this is legacy nw_info\n        network_info = self._handle_network_info_model(network_info)\n\n        gateways_v6 = [mapping['gateway_v6'] for (_n, mapping) in\n                       network_info]\n        for gateway_v6 in gateways_v6:\n            ipv6_rules.append(\n                    '-s %s/128 -p icmpv6 -j ACCEPT' % (gateway_v6,))\n\n    def _build_icmp_rule(self, rule, version):\n        icmp_type = rule.from_port\n        icmp_code = rule.to_port\n\n        if icmp_type == -1:\n            icmp_type_arg = None\n        else:\n            icmp_type_arg = '%s' % icmp_type\n            if not icmp_code == -1:\n                icmp_type_arg += '/%s' % icmp_code\n\n        if icmp_type_arg:\n            if version == 4:\n                return ['-m', 'icmp', '--icmp-type', icmp_type_arg]\n            elif version == 6:\n                return ['-m', 'icmp6', '--icmpv6-type', icmp_type_arg]\n        # return empty list if icmp_type == -1\n        return []\n\n    def _build_tcp_udp_rule(self, rule, version):\n        if rule.from_port == rule.to_port:\n            return ['--dport', '%s' % (rule.from_port,)]\n        else:\n            return ['-m', 'multiport',\n                    '--dports', '%s:%s' % (rule.from_port,\n                                           rule.to_port)]\n\n    def instance_rules(self, instance, network_info):\n        # make sure this is legacy nw_info\n        network_info = self._handle_network_info_model(network_info)\n\n        ctxt = context.get_admin_context()\n\n        ipv4_rules = []\n        ipv6_rules = []\n\n        # Initialize with basic rules\n        self._do_basic_rules(ipv4_rules, ipv6_rules, network_info)\n        # Set up rules to allow traffic to/from DHCP server\n        self._do_dhcp_rules(ipv4_rules, network_info)\n\n        #Allow project network traffic\n        if FLAGS.allow_same_net_traffic:\n            self._do_project_network_rules(ipv4_rules, ipv6_rules,\n                                           network_info)\n        # We wrap these in FLAGS.use_ipv6 because they might cause\n        # a DB lookup. The other ones are just list operations, so\n        # they're not worth the clutter.\n        if FLAGS.use_ipv6:\n            # Allow RA responses\n            self._do_ra_rules(ipv6_rules, network_info)\n\n        security_groups = db.security_group_get_by_instance(ctxt,\n                                                            instance['id'])\n\n        # then, security group chains and rules\n        for security_group in security_groups:\n            rules = db.security_group_rule_get_by_security_group(ctxt,\n                                                          security_group['id'])\n\n            for rule in rules:\n                LOG.debug(_('Adding security group rule: %r'), rule,\n                          instance=instance)\n\n                if not rule.cidr:\n                    version = 4\n                else:\n                    version = netutils.get_ip_version(rule.cidr)\n\n                if version == 4:\n                    fw_rules = ipv4_rules\n                else:\n                    fw_rules = ipv6_rules\n\n                protocol = rule.protocol.lower()\n                if version == 6 and protocol == 'icmp':\n                    protocol = 'icmpv6'\n\n                args = ['-j ACCEPT']\n                if protocol:\n                    args += ['-p', protocol]\n\n                if protocol in ['udp', 'tcp']:\n                    args += self._build_tcp_udp_rule(rule, version)\n                elif protocol == 'icmp':\n                    args += self._build_icmp_rule(rule, version)\n                if rule.cidr:\n                    LOG.debug('Using cidr %r', rule.cidr, instance=instance)\n                    args += ['-s', rule.cidr]\n                    fw_rules += [' '.join(args)]\n                else:\n                    if rule['grantee_group']:\n                        # FIXME(jkoelker) This needs to be ported up into\n                        #                 the compute manager which already\n                        #                 has access to a nw_api handle,\n                        #                 and should be the only one making\n                        #                 making rpc calls.\n                        import nova.network\n                        nw_api = nova.network.API()\n                        for instance in rule['grantee_group']['instances']:\n                            nw_info = nw_api.get_instance_nw_info(ctxt,\n                                                                  instance)\n\n                            ips = [ip['address']\n                                for ip in nw_info.fixed_ips()\n                                    if ip['version'] == version]\n\n                            LOG.debug('ips: %r', ips, instance=instance)\n                            for ip in ips:\n                                subrule = args + ['-s %s' % ip]\n                                fw_rules += [' '.join(subrule)]\n\n                LOG.debug('Using fw_rules: %r', fw_rules, instance=instance)\n\n        ipv4_rules += ['-j $sg-fallback']\n        ipv6_rules += ['-j $sg-fallback']\n\n        return ipv4_rules, ipv6_rules\n\n    def instance_filter_exists(self, instance, network_info):\n        pass\n\n    def refresh_security_group_members(self, security_group):\n        self.do_refresh_security_group_rules(security_group)\n        self.iptables.apply()\n\n    def refresh_security_group_rules(self, security_group):\n        self.do_refresh_security_group_rules(security_group)\n        self.iptables.apply()\n\n    @utils.synchronized('iptables', external=True)\n    def do_refresh_security_group_rules(self, security_group):\n        for instance in self.instances.values():\n            self.remove_filters_for_instance(instance)\n            self.add_filters_for_instance(instance)\n\n    def refresh_provider_fw_rules(self):\n        \"\"\"See :class:`FirewallDriver` docs.\"\"\"\n        self._do_refresh_provider_fw_rules()\n        self.iptables.apply()\n\n    @utils.synchronized('iptables', external=True)\n    def _do_refresh_provider_fw_rules(self):\n        \"\"\"Internal, synchronized version of refresh_provider_fw_rules.\"\"\"\n        self._purge_provider_fw_rules()\n        self._build_provider_fw_rules()\n\n    def _purge_provider_fw_rules(self):\n        \"\"\"Remove all rules from the provider chains.\"\"\"\n        self.iptables.ipv4['filter'].empty_chain('provider')\n        if FLAGS.use_ipv6:\n            self.iptables.ipv6['filter'].empty_chain('provider')\n\n    def _build_provider_fw_rules(self):\n        \"\"\"Create all rules for the provider IP DROPs.\"\"\"\n        self.iptables.ipv4['filter'].add_chain('provider')\n        if FLAGS.use_ipv6:\n            self.iptables.ipv6['filter'].add_chain('provider')\n        ipv4_rules, ipv6_rules = self._provider_rules()\n        for rule in ipv4_rules:\n            self.iptables.ipv4['filter'].add_rule('provider', rule)\n\n        if FLAGS.use_ipv6:\n            for rule in ipv6_rules:\n                self.iptables.ipv6['filter'].add_rule('provider', rule)\n\n    @staticmethod\n    def _provider_rules():\n        \"\"\"Generate a list of rules from provider for IP4 & IP6.\"\"\"\n        ctxt = context.get_admin_context()\n        ipv4_rules = []\n        ipv6_rules = []\n        rules = db.provider_fw_rule_get_all(ctxt)\n        for rule in rules:\n            LOG.debug(_('Adding provider rule: %s'), rule['cidr'])\n            version = netutils.get_ip_version(rule['cidr'])\n            if version == 4:\n                fw_rules = ipv4_rules\n            else:\n                fw_rules = ipv6_rules\n\n            protocol = rule['protocol']\n            if version == 6 and protocol == 'icmp':\n                protocol = 'icmpv6'\n\n            args = ['-p', protocol, '-s', rule['cidr']]\n\n            if protocol in ['udp', 'tcp']:\n                if rule['from_port'] == rule['to_port']:\n                    args += ['--dport', '%s' % (rule['from_port'],)]\n                else:\n                    args += ['-m', 'multiport',\n                             '--dports', '%s:%s' % (rule['from_port'],\n                                                    rule['to_port'])]\n            elif protocol == 'icmp':\n                icmp_type = rule['from_port']\n                icmp_code = rule['to_port']\n\n                if icmp_type == -1:\n                    icmp_type_arg = None\n                else:\n                    icmp_type_arg = '%s' % icmp_type\n                    if not icmp_code == -1:\n                        icmp_type_arg += '/%s' % icmp_code\n\n                if icmp_type_arg:\n                    if version == 4:\n                        args += ['-m', 'icmp', '--icmp-type',\n                                 icmp_type_arg]\n                    elif version == 6:\n                        args += ['-m', 'icmp6', '--icmpv6-type',\n                                 icmp_type_arg]\n            args += ['-j DROP']\n            fw_rules += [' '.join(args)]\n        return ipv4_rules, ipv6_rules\n\n\nclass NoopFirewallDriver(object):\n    \"\"\"Firewall driver which just provides No-op methods.\"\"\"\n    def __init__(*args, **kwargs):\n        pass\n\n    def _noop(*args, **kwargs):\n        pass\n\n    def __getattr__(self, key):\n        return self._noop\n\n    def instance_filter_exists(self, instance, network_info):\n        return True\n", "target": 0}
